{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predicting Stock Yields using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "- update text portions of notebook for intro price EDA\n",
    "- make notebook able to updated dfs.\n",
    "- get rid of hardcoded feature names in modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning NLP techniques to map raw text to dense vector representations have had some surprising success in the world of computer natural language processing compared to classical means of encoding text. In this project we will attempt to leverage some of these techniques to help assist us in time series analysis on stock yields. The company we will choose to investigate is Wells Fargo (stock ticker: WFC), and the text data we will be leveraging are the SEC forms of Wells Fargo along with its competitors: JPMorgan Chase, Bank of America, and Citigroup. Specifically the 8-K form. The 8-K form was chosen because it tends to be the more text rich SEC document when compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Notebook Global Variables\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "# Company Stock Ticker and CIK number\n",
    "ticker = 'WFC'\n",
    "competitors = ['JPM', 'BAC', 'C']\n",
    "tickers = [ticker] + competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we will need two data sources. Firstly we will need access to Wells Fargo's historical stock price data. We will use an API to access this data (since it will be much easier than webscraping it). This gives us two options: Quandl's end of day stock price data API, or Alphavantage's end of day stock price, adjusted time series API. Since Quandl's API costs money we will use Alphavantage's API since its free. The second data source we need is access to Wells Fargo's published 8-K forms. For this data source we will web scrape the SEC's database: EDGAR, to gather the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import io\n",
    "import re\n",
    "import lxml\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "from functools import reduce\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Stock Price Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching end of day stock price data from alphavantage: https://www.alphavantage.co/ using fetch_stock_data. Then checking the returned DataFrame object to confirm that the end of day stock price data was successfully loaded into the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes\n",
    "\n",
    "def get_api_key(source):\n",
    "    '''\n",
    "    STILL NEEDS WORK, want to keep same API, but don't know how to link to area where user api keys are stored.\n",
    "    \n",
    "    Returns api key for the specific source, :param source:.\n",
    "    \n",
    "    :param source: string, name of api source\n",
    "    \n",
    "    ---> String, api key for the the specific source :param source:\n",
    "    '''\n",
    "    \n",
    "    path_to_keys = os.path.join(project_dir, 'api_keys.json')\n",
    "    with open(path_to_keys, 'r') as f:\n",
    "        api_keys = json.load(f)\n",
    "    \n",
    "    return api_keys[source]\n",
    "\n",
    "\n",
    "def fetch_stock_data(ticker, start_date, end_date=None, source='alphavantage'):\n",
    "    '''\n",
    "    Returns end of day stock price DataFrame from various sources.\n",
    "    \n",
    "    :param ticker: string, stock ticker\n",
    "    :param start_date: string, date to start collecting data after, format: YYYY-MM-DD\n",
    "    :param end_date: string, date to end collecting data at, format: YYYY-MM-DD\n",
    "    :param source: string 'alphavantage' or 'quandl', specifies the source of the data\n",
    "    \n",
    "    ---> DataFrame, of end of day stock price data\n",
    "    '''\n",
    "    \n",
    "    # endpoints for each data source\n",
    "    source_urls = {'alphavantage': 'https://www.alphavantage.co/query',\n",
    "                   'quandl': 'https://www.quandl.com/api/v3/datasets/EOD/'}\n",
    "    \n",
    "    # API parameters for each data source\n",
    "    source_params = {'alphavantage': {'function': 'TIME_SERIES_DAILY_ADJUSTED',\n",
    "                                      'symbol': ticker, 'datatype': 'csv', 'apikey': get_api_key(source),\n",
    "                                      'outputsize': 'full'},\n",
    "                     'quandl': {'api_key': get_api_key(source)}}\n",
    "\n",
    "    # Setting endpoints\n",
    "    url = source_urls[source]\n",
    "    if source == 'quandl':\n",
    "        url = url + ticker + '.csv'\n",
    "    \n",
    "    # Settings API parameters\n",
    "    params = source_params[source]\n",
    "    \n",
    "    # Requesting API\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Creating DataFrame\n",
    "    if source == 'alphavantage':\n",
    "        date_col = 'timestamp'\n",
    "    elif source == 'quandl':\n",
    "        date_col = 'date'    \n",
    "    df = pd.read_csv(io.StringIO(response.text), parse_dates=[date_col])\n",
    "    \n",
    "    # Slicing DataFrame\n",
    "    if start_date != None:\n",
    "        df = df.loc[df[date_col] > start_date]\n",
    "    if end_date != None:\n",
    "        df = df.loc[df[date_col] <= end_date]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating end of day stock price DataFrames stored in dictionary price_dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dfs = {}\n",
    "\n",
    "for t in tickers:\n",
    "    # Fetching price DataFrame for ticker t\n",
    "    price_dfs[t] = fetch_stock_data(t, start_date=None)\n",
    "    # Modfiying columns with stock ticker data\n",
    "    price_dfs[t].columns = [name if price_dfs[t][name].dtype == 'datetime64[ns]' \n",
    "                            else '_'.join([name, t]) for name in price_dfs[t].columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the info of the price DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5033 entries, 0 to 5032\n",
      "Data columns (total 9 columns):\n",
      "timestamp                5033 non-null datetime64[ns]\n",
      "open_WFC                 5033 non-null float64\n",
      "high_WFC                 5033 non-null float64\n",
      "low_WFC                  5033 non-null float64\n",
      "close_WFC                5033 non-null float64\n",
      "adjusted_close_WFC       5033 non-null float64\n",
      "volume_WFC               5033 non-null int64\n",
      "dividend_amount_WFC      5033 non-null float64\n",
      "split_coefficient_WFC    5033 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(7), int64(1)\n",
      "memory usage: 354.0 KB\n",
      "\n",
      "JPM\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5033 entries, 0 to 5032\n",
      "Data columns (total 9 columns):\n",
      "timestamp                5033 non-null datetime64[ns]\n",
      "open_JPM                 5033 non-null float64\n",
      "high_JPM                 5033 non-null float64\n",
      "low_JPM                  5033 non-null float64\n",
      "close_JPM                5033 non-null float64\n",
      "adjusted_close_JPM       5033 non-null float64\n",
      "volume_JPM               5033 non-null int64\n",
      "dividend_amount_JPM      5033 non-null float64\n",
      "split_coefficient_JPM    5033 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(7), int64(1)\n",
      "memory usage: 354.0 KB\n",
      "\n",
      "BAC\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5033 entries, 0 to 5032\n",
      "Data columns (total 9 columns):\n",
      "timestamp                5033 non-null datetime64[ns]\n",
      "open_BAC                 5033 non-null float64\n",
      "high_BAC                 5033 non-null float64\n",
      "low_BAC                  5033 non-null float64\n",
      "close_BAC                5033 non-null float64\n",
      "adjusted_close_BAC       5033 non-null float64\n",
      "volume_BAC               5033 non-null int64\n",
      "dividend_amount_BAC      5033 non-null float64\n",
      "split_coefficient_BAC    5033 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(7), int64(1)\n",
      "memory usage: 354.0 KB\n",
      "\n",
      "C\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5033 entries, 0 to 5032\n",
      "Data columns (total 9 columns):\n",
      "timestamp              5033 non-null datetime64[ns]\n",
      "open_C                 5033 non-null float64\n",
      "high_C                 5033 non-null float64\n",
      "low_C                  5033 non-null float64\n",
      "close_C                5033 non-null float64\n",
      "adjusted_close_C       5033 non-null float64\n",
      "volume_C               5033 non-null int64\n",
      "dividend_amount_C      5033 non-null float64\n",
      "split_coefficient_C    5033 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(7), int64(1)\n",
      "memory usage: 354.0 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in price_dfs.keys():\n",
    "    print(t)\n",
    "    price_dfs[t].info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first five rows and the last five rows of each price DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "   timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
      "0 2019-11-25     54.53    54.530   54.040      54.21               54.21   \n",
      "1 2019-11-22     53.90    54.350   53.805      54.28               54.28   \n",
      "2 2019-11-21     53.84    53.930   53.340      53.56               53.56   \n",
      "3 2019-11-20     53.73    53.860   53.250      53.54               53.54   \n",
      "4 2019-11-19     54.10    54.329   53.870      54.03               54.03   \n",
      "\n",
      "   volume_WFC  dividend_amount_WFC  split_coefficient_WFC  \n",
      "0    14868600                  0.0                    1.0  \n",
      "1    13823401                  0.0                    1.0  \n",
      "2    16183535                  0.0                    1.0  \n",
      "3    14994663                  0.0                    1.0  \n",
      "4    14434065                  0.0                    1.0  \n",
      "\n",
      "JPM\n",
      "   timestamp  open_JPM  high_JPM  low_JPM  close_JPM  adjusted_close_JPM  \\\n",
      "0 2019-11-25    131.25    132.07  130.865     131.49              131.49   \n",
      "1 2019-11-22    130.15    131.22  130.100     130.79              130.79   \n",
      "2 2019-11-21    130.00    130.72  129.390     129.93              129.93   \n",
      "3 2019-11-20    130.30    130.62  128.940     129.63              129.63   \n",
      "4 2019-11-19    130.99    131.25  130.180     130.58              130.58   \n",
      "\n",
      "   volume_JPM  dividend_amount_JPM  split_coefficient_JPM  \n",
      "0     9514219                  0.0                    1.0  \n",
      "1     8166883                  0.0                    1.0  \n",
      "2     7568586                  0.0                    1.0  \n",
      "3    11782789                  0.0                    1.0  \n",
      "4     8822987                  0.0                    1.0  \n",
      "\n",
      "BAC\n",
      "   timestamp  open_BAC  high_BAC  low_BAC  close_BAC  adjusted_close_BAC  \\\n",
      "0 2019-11-25     33.33     33.51   33.255      33.47               33.47   \n",
      "1 2019-11-22     32.96     33.32   32.940      33.18               33.18   \n",
      "2 2019-11-21     32.78     33.04   32.630      32.84               32.84   \n",
      "3 2019-11-20     32.79     32.83   32.420      32.69               32.69   \n",
      "4 2019-11-19     33.12     33.15   32.820      32.94               32.94   \n",
      "\n",
      "   volume_BAC  dividend_amount_BAC  split_coefficient_BAC  \n",
      "0    50238685                  0.0                    1.0  \n",
      "1    38774161                  0.0                    1.0  \n",
      "2    42780098                  0.0                    1.0  \n",
      "3    43611602                  0.0                    1.0  \n",
      "4    33176771                  0.0                    1.0  \n",
      "\n",
      "C\n",
      "   timestamp  open_C  high_C  low_C  close_C  adjusted_close_C  volume_C  \\\n",
      "0 2019-11-25   74.93   75.85  74.87    75.68             75.68  11497743   \n",
      "1 2019-11-22   74.10   74.92  73.97    74.87             74.87   7900612   \n",
      "2 2019-11-21   74.08   74.63  73.51    73.90             73.90   8584204   \n",
      "3 2019-11-20   74.63   74.72  73.22    73.91             73.91  12799672   \n",
      "4 2019-11-19   74.97   75.24  74.47    74.82             74.82   9094918   \n",
      "\n",
      "   dividend_amount_C  split_coefficient_C  \n",
      "0                0.0                  1.0  \n",
      "1                0.0                  1.0  \n",
      "2                0.0                  1.0  \n",
      "3                0.0                  1.0  \n",
      "4                0.0                  1.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in price_dfs.keys():\n",
    "    print(t)\n",
    "    print(price_dfs[t].head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "      timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
      "5028 1999-12-01     46.38     47.06    46.25      46.88             13.4641   \n",
      "5029 1999-11-30     45.00     46.94    45.00      46.50             13.3549   \n",
      "5030 1999-11-29     45.63     45.81    45.00      45.00             12.9241   \n",
      "5031 1999-11-26     46.25     46.31    45.94      45.94             13.1941   \n",
      "5032 1999-11-24     46.00     46.63    46.00      46.00             13.2113   \n",
      "\n",
      "      volume_WFC  dividend_amount_WFC  split_coefficient_WFC  \n",
      "5028     3343900                  0.0                    1.0  \n",
      "5029     4779900                  0.0                    1.0  \n",
      "5030     3103800                  0.0                    1.0  \n",
      "5031     1040200                  0.0                    1.0  \n",
      "5032     2324700                  0.0                    1.0  \n",
      "\n",
      "JPM\n",
      "      timestamp  open_JPM  high_JPM  low_JPM  close_JPM  adjusted_close_JPM  \\\n",
      "5028 1999-12-01     77.13     78.00    76.56      77.39             27.8911   \n",
      "5029 1999-11-30     76.62     79.25    76.56      77.25             27.8406   \n",
      "5030 1999-11-29     78.81     78.81    76.31      76.94             27.7289   \n",
      "5031 1999-11-26     80.88     80.88    79.06      79.06             28.4929   \n",
      "5032 1999-11-24     79.75     79.94    78.75      79.56             28.6731   \n",
      "\n",
      "      volume_JPM  dividend_amount_JPM  split_coefficient_JPM  \n",
      "5028     3046200                  0.0                    1.0  \n",
      "5029     4031467                  0.0                    1.0  \n",
      "5030     3480867                  0.0                    1.0  \n",
      "5031      794200                  0.0                    1.0  \n",
      "5032     2521400                  0.0                    1.0  \n",
      "\n",
      "BAC\n",
      "      timestamp  open_BAC  high_BAC  low_BAC  close_BAC  adjusted_close_BAC  \\\n",
      "5028 1999-12-01     57.13     59.00    57.13      57.88             16.4798   \n",
      "5029 1999-11-30     57.50     59.50    57.44      58.61             16.5447   \n",
      "5030 1999-11-29     60.13     60.19    56.31      56.94             16.0733   \n",
      "5031 1999-11-26     59.94     61.38    59.81      60.50             17.0783   \n",
      "5032 1999-11-24     61.25     61.56    59.75      60.00             16.9371   \n",
      "\n",
      "      volume_BAC  dividend_amount_BAC  split_coefficient_BAC  \n",
      "5028     4690100                  0.5                    1.0  \n",
      "5029     7492700                  0.0                    1.0  \n",
      "5030     7984500                  0.0                    1.0  \n",
      "5031     2333300                  0.0                    1.0  \n",
      "5032     6184300                  0.0                    1.0  \n",
      "\n",
      "C\n",
      "      timestamp  open_C  high_C  low_C  close_C  adjusted_close_C  volume_C  \\\n",
      "5028 1999-12-01   53.06   54.63  53.00    54.31          265.7717   7419000   \n",
      "5029 1999-11-30   53.50   55.19  53.44    53.88          263.6674  11431500   \n",
      "5030 1999-11-29   54.19   54.19  53.00    53.00          259.3611   8924250   \n",
      "5031 1999-11-26   54.50   54.94  54.13    54.38          266.1142   3012750   \n",
      "5032 1999-11-24   54.81   54.81  53.75    53.94          263.9610   6423000   \n",
      "\n",
      "      dividend_amount_C  split_coefficient_C  \n",
      "5028                0.0                  1.0  \n",
      "5029                0.0                  1.0  \n",
      "5030                0.0                  1.0  \n",
      "5031                0.0                  1.0  \n",
      "5032                0.0                  1.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in price_dfs.keys():\n",
    "    print(t)\n",
    "    print(price_dfs[t].tail())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the data is successfully loaded. Next we merge all these price DataFrames into one price DataFrame that summarizes all the pricing data for all stock tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = reduce(lambda x, y: pd.merge(x, y, how='outer', on='timestamp'), price_dfs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if the DataFrames were merged properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>dividend_amount_BAC</th>\n",
       "      <th>split_coefficient_BAC</th>\n",
       "      <th>open_C</th>\n",
       "      <th>high_C</th>\n",
       "      <th>low_C</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>54.53</td>\n",
       "      <td>54.530</td>\n",
       "      <td>54.040</td>\n",
       "      <td>54.21</td>\n",
       "      <td>54.21</td>\n",
       "      <td>14868600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.93</td>\n",
       "      <td>75.85</td>\n",
       "      <td>74.87</td>\n",
       "      <td>75.68</td>\n",
       "      <td>75.68</td>\n",
       "      <td>11497743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.350</td>\n",
       "      <td>53.805</td>\n",
       "      <td>54.28</td>\n",
       "      <td>54.28</td>\n",
       "      <td>13823401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.10</td>\n",
       "      <td>74.92</td>\n",
       "      <td>73.97</td>\n",
       "      <td>74.87</td>\n",
       "      <td>74.87</td>\n",
       "      <td>7900612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>53.84</td>\n",
       "      <td>53.930</td>\n",
       "      <td>53.340</td>\n",
       "      <td>53.56</td>\n",
       "      <td>53.56</td>\n",
       "      <td>16183535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.08</td>\n",
       "      <td>74.63</td>\n",
       "      <td>73.51</td>\n",
       "      <td>73.90</td>\n",
       "      <td>73.90</td>\n",
       "      <td>8584204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>53.73</td>\n",
       "      <td>53.860</td>\n",
       "      <td>53.250</td>\n",
       "      <td>53.54</td>\n",
       "      <td>53.54</td>\n",
       "      <td>14994663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.63</td>\n",
       "      <td>74.72</td>\n",
       "      <td>73.22</td>\n",
       "      <td>73.91</td>\n",
       "      <td>73.91</td>\n",
       "      <td>12799672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>54.10</td>\n",
       "      <td>54.329</td>\n",
       "      <td>53.870</td>\n",
       "      <td>54.03</td>\n",
       "      <td>54.03</td>\n",
       "      <td>14434065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.97</td>\n",
       "      <td>75.24</td>\n",
       "      <td>74.47</td>\n",
       "      <td>74.82</td>\n",
       "      <td>74.82</td>\n",
       "      <td>9094918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "0 2019-11-25     54.53    54.530   54.040      54.21               54.21   \n",
       "1 2019-11-22     53.90    54.350   53.805      54.28               54.28   \n",
       "2 2019-11-21     53.84    53.930   53.340      53.56               53.56   \n",
       "3 2019-11-20     53.73    53.860   53.250      53.54               53.54   \n",
       "4 2019-11-19     54.10    54.329   53.870      54.03               54.03   \n",
       "\n",
       "   volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "0    14868600                  0.0                    1.0    131.25  ...   \n",
       "1    13823401                  0.0                    1.0    130.15  ...   \n",
       "2    16183535                  0.0                    1.0    130.00  ...   \n",
       "3    14994663                  0.0                    1.0    130.30  ...   \n",
       "4    14434065                  0.0                    1.0    130.99  ...   \n",
       "\n",
       "   dividend_amount_BAC  split_coefficient_BAC  open_C  high_C  low_C  close_C  \\\n",
       "0                  0.0                    1.0   74.93   75.85  74.87    75.68   \n",
       "1                  0.0                    1.0   74.10   74.92  73.97    74.87   \n",
       "2                  0.0                    1.0   74.08   74.63  73.51    73.90   \n",
       "3                  0.0                    1.0   74.63   74.72  73.22    73.91   \n",
       "4                  0.0                    1.0   74.97   75.24  74.47    74.82   \n",
       "\n",
       "   adjusted_close_C  volume_C  dividend_amount_C  split_coefficient_C  \n",
       "0             75.68  11497743                0.0                  1.0  \n",
       "1             74.87   7900612                0.0                  1.0  \n",
       "2             73.90   8584204                0.0                  1.0  \n",
       "3             73.91  12799672                0.0                  1.0  \n",
       "4             74.82   9094918                0.0                  1.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>dividend_amount_BAC</th>\n",
       "      <th>split_coefficient_BAC</th>\n",
       "      <th>open_C</th>\n",
       "      <th>high_C</th>\n",
       "      <th>low_C</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5028</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>46.38</td>\n",
       "      <td>47.06</td>\n",
       "      <td>46.25</td>\n",
       "      <td>46.88</td>\n",
       "      <td>13.4641</td>\n",
       "      <td>3343900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.06</td>\n",
       "      <td>54.63</td>\n",
       "      <td>53.00</td>\n",
       "      <td>54.31</td>\n",
       "      <td>265.7717</td>\n",
       "      <td>7419000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5029</td>\n",
       "      <td>1999-11-30</td>\n",
       "      <td>45.00</td>\n",
       "      <td>46.94</td>\n",
       "      <td>45.00</td>\n",
       "      <td>46.50</td>\n",
       "      <td>13.3549</td>\n",
       "      <td>4779900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>55.19</td>\n",
       "      <td>53.44</td>\n",
       "      <td>53.88</td>\n",
       "      <td>263.6674</td>\n",
       "      <td>11431500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>1999-11-29</td>\n",
       "      <td>45.63</td>\n",
       "      <td>45.81</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>12.9241</td>\n",
       "      <td>3103800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.19</td>\n",
       "      <td>54.19</td>\n",
       "      <td>53.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>259.3611</td>\n",
       "      <td>8924250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5031</td>\n",
       "      <td>1999-11-26</td>\n",
       "      <td>46.25</td>\n",
       "      <td>46.31</td>\n",
       "      <td>45.94</td>\n",
       "      <td>45.94</td>\n",
       "      <td>13.1941</td>\n",
       "      <td>1040200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.50</td>\n",
       "      <td>54.94</td>\n",
       "      <td>54.13</td>\n",
       "      <td>54.38</td>\n",
       "      <td>266.1142</td>\n",
       "      <td>3012750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5032</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>46.00</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>13.2113</td>\n",
       "      <td>2324700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.81</td>\n",
       "      <td>54.81</td>\n",
       "      <td>53.75</td>\n",
       "      <td>53.94</td>\n",
       "      <td>263.9610</td>\n",
       "      <td>6423000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "5028 1999-12-01     46.38     47.06    46.25      46.88             13.4641   \n",
       "5029 1999-11-30     45.00     46.94    45.00      46.50             13.3549   \n",
       "5030 1999-11-29     45.63     45.81    45.00      45.00             12.9241   \n",
       "5031 1999-11-26     46.25     46.31    45.94      45.94             13.1941   \n",
       "5032 1999-11-24     46.00     46.63    46.00      46.00             13.2113   \n",
       "\n",
       "      volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "5028     3343900                  0.0                    1.0     77.13  ...   \n",
       "5029     4779900                  0.0                    1.0     76.62  ...   \n",
       "5030     3103800                  0.0                    1.0     78.81  ...   \n",
       "5031     1040200                  0.0                    1.0     80.88  ...   \n",
       "5032     2324700                  0.0                    1.0     79.75  ...   \n",
       "\n",
       "      dividend_amount_BAC  split_coefficient_BAC  open_C  high_C  low_C  \\\n",
       "5028                  0.5                    1.0   53.06   54.63  53.00   \n",
       "5029                  0.0                    1.0   53.50   55.19  53.44   \n",
       "5030                  0.0                    1.0   54.19   54.19  53.00   \n",
       "5031                  0.0                    1.0   54.50   54.94  54.13   \n",
       "5032                  0.0                    1.0   54.81   54.81  53.75   \n",
       "\n",
       "      close_C  adjusted_close_C  volume_C  dividend_amount_C  \\\n",
       "5028    54.31          265.7717   7419000                0.0   \n",
       "5029    53.88          263.6674  11431500                0.0   \n",
       "5030    53.00          259.3611   8924250                0.0   \n",
       "5031    54.38          266.1142   3012750                0.0   \n",
       "5032    53.94          263.9610   6423000                0.0   \n",
       "\n",
       "      split_coefficient_C  \n",
       "5028                  1.0  \n",
       "5029                  1.0  \n",
       "5030                  1.0  \n",
       "5031                  1.0  \n",
       "5032                  1.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5031 entries, 0 to 5030\n",
      "Data columns (total 33 columns):\n",
      "timestamp                5031 non-null datetime64[ns]\n",
      "open_WFC                 5031 non-null float64\n",
      "high_WFC                 5031 non-null float64\n",
      "low_WFC                  5031 non-null float64\n",
      "close_WFC                5031 non-null float64\n",
      "adjusted_close_WFC       5031 non-null float64\n",
      "volume_WFC               5031 non-null int64\n",
      "dividend_amount_WFC      5031 non-null float64\n",
      "split_coefficient_WFC    5031 non-null float64\n",
      "open_JPM                 5031 non-null float64\n",
      "high_JPM                 5031 non-null float64\n",
      "low_JPM                  5031 non-null float64\n",
      "close_JPM                5031 non-null float64\n",
      "adjusted_close_JPM       5031 non-null float64\n",
      "volume_JPM               5031 non-null int64\n",
      "dividend_amount_JPM      5031 non-null float64\n",
      "split_coefficient_JPM    5031 non-null float64\n",
      "open_BAC                 5031 non-null float64\n",
      "high_BAC                 5031 non-null float64\n",
      "low_BAC                  5031 non-null float64\n",
      "close_BAC                5031 non-null float64\n",
      "adjusted_close_BAC       5031 non-null float64\n",
      "volume_BAC               5031 non-null int64\n",
      "dividend_amount_BAC      5031 non-null float64\n",
      "split_coefficient_BAC    5031 non-null float64\n",
      "open_C                   5031 non-null float64\n",
      "high_C                   5031 non-null float64\n",
      "low_C                    5031 non-null float64\n",
      "close_C                  5031 non-null float64\n",
      "adjusted_close_C         5031 non-null float64\n",
      "volume_C                 5031 non-null int64\n",
      "dividend_amount_C        5031 non-null float64\n",
      "split_coefficient_C      5031 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(28), int64(4)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "price_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like everything works out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Wells Fargo's, and its competitors' 8-K forms from the SEC database. (Link to SEC database, EDGAR: https://www.sec.gov/edgar/searchedgar/companysearch.html) The scraped 8-K forms are saved to the documents folder which lies in the data folder inside a company specific folder labeled by stock ticker, and are saved in raw text file format. A DataFrame is returned for each company where each row consists of a filing date, and a path to where the 8-K form is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes\n",
    "\n",
    "def generate_url_df(cik, start_date, end_date=None, form_type='8-k'):\n",
    "    '''\n",
    "    Returns a DataFrame  where each row consists of a forms filing date, and an url to the raw text version\n",
    "    of the form.\n",
    "    \n",
    "    :param cik: string, the SEC CIK number for the specific company or stock ticker symbol\n",
    "    :param start_date: string, date to start collecting data after, format: YYYY-MM-DD\n",
    "    :param end_date: string, date to end collecting data at, format: YYYY-MM-DD\n",
    "    :param form_type: string '8-k', '10-k', ..., the type of SEC form to search for\n",
    "    \n",
    "    ---> DataFrame, of filing dates and urls to raw text versions of the specified form\n",
    "    '''\n",
    "    \n",
    "    edgar_url = 'https://www.sec.gov/cgi-bin/browse-edgar'\n",
    "    \n",
    "    edgar_params = {'action': 'getcompany', 'CIK': cik, 'type': form_type,\n",
    "                    'owner': 'exclude', 'count': '100', 'output': 'atom', 'start': ''}\n",
    "    \n",
    "    edgar_response = requests.get(edgar_url, params=edgar_params)\n",
    "    \n",
    "    soup = BeautifulSoup(edgar_response.text, 'lxml')\n",
    "    \n",
    "    all_docs = []\n",
    "    # While the link to the next page existing is true\n",
    "    while True:\n",
    "        # Find all document entries on the page\n",
    "        entries = soup.find_all('entry')\n",
    "        # For each entry\n",
    "        for entry in entries:\n",
    "            # scrape the entry's filing date\n",
    "            filing_date = entry.find('filing-date').text\n",
    "            # Add entry url to list if its filing date meets certain requirements, CAN REFACTOR this section\n",
    "            if (start_date == None) and (end_date == None):\n",
    "                doc_link = re.sub('-index.htm.*', '.txt', entry.find('link')['href'])\n",
    "                doc_entry = (filing_date, doc_link)\n",
    "                all_docs.append(doc_entry)\n",
    "            elif (start_date == None) and (end_date != None):\n",
    "                if date.fromisoformat(filing_date) <= date.fromisoformat(end_date):\n",
    "                    doc_link = re.sub('-index.htm.*', '.txt', entry.find('link')['href'])\n",
    "                    doc_entry = (filing_date, doc_link)\n",
    "                    all_docs.append(doc_entry)\n",
    "            elif (start_date != None) and (end_date == None):\n",
    "                if date.fromisoformat(filing_date) >= date.fromisoformat(start_date):\n",
    "                    doc_link = re.sub('-index.htm.*', '.txt', entry.find('link')['href'])\n",
    "                    doc_entry = (filing_date, doc_link)\n",
    "                    all_docs.append(doc_entry)\n",
    "            else:\n",
    "                if date.fromisoformat(start_date) <= date.fromisoformat(filing_date) <= date.fromisoformat(end_date):\n",
    "                    doc_link = re.sub('-index.htm.*', '.txt', entry.find('link')['href'])\n",
    "                    doc_entry = (filing_date, doc_link)\n",
    "                    all_docs.append(doc_entry)\n",
    "        # Break loop after scraping entries on the current page, but before requesting on the link to the next page which is potentially none existant\n",
    "        if soup.find_all('link', {'rel': 'next'}) == []:\n",
    "            break\n",
    "        # Find link to the next page, request next page, and update soup object to consist of the next page\n",
    "        nxt_pg_link = soup.find_all('link', {'rel': 'next'})[0]['href']\n",
    "        nxt_pg = requests.get(nxt_pg_link)\n",
    "        soup = BeautifulSoup(nxt_pg.text, 'lxml')\n",
    "    # Creating DataFrame\n",
    "    doc_df = pd.DataFrame(all_docs, columns=['filing_date', 'doc_loc'])\n",
    "    doc_df['filing_date'] = pd.to_datetime(doc_df['filing_date'])\n",
    "    \n",
    "    return doc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating url DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dfs = {}\n",
    "for t in [ticker] + competitors:\n",
    "    doc_df_t = generate_url_df(t, start_date=None)\n",
    "    doc_dfs[t] = doc_df_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking info of each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1251 entries, 0 to 1250\n",
      "Data columns (total 2 columns):\n",
      "filing_date    1251 non-null datetime64[ns]\n",
      "doc_loc        1251 non-null object\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 19.7+ KB\n",
      "\n",
      "JPM\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1178 entries, 0 to 1177\n",
      "Data columns (total 2 columns):\n",
      "filing_date    1178 non-null datetime64[ns]\n",
      "doc_loc        1178 non-null object\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 18.5+ KB\n",
      "\n",
      "BAC\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 542 entries, 0 to 541\n",
      "Data columns (total 2 columns):\n",
      "filing_date    542 non-null datetime64[ns]\n",
      "doc_loc        542 non-null object\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 8.6+ KB\n",
      "\n",
      "C\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 830 entries, 0 to 829\n",
      "Data columns (total 2 columns):\n",
      "filing_date    830 non-null datetime64[ns]\n",
      "doc_loc        830 non-null object\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 13.1+ KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc_dfs.keys():\n",
    "    print(t)\n",
    "    doc_dfs[t].info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first five, and last five rows of each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-22  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "1  2019-10-21  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "2  2019-10-18  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "3  2019-10-17  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "4  2019-10-15  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "\n",
      "JPM\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-15  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "1  2019-10-15  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "2  2019-09-26  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "3  2019-09-12  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "4  2019-08-20  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "\n",
      "BAC\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-16  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "1  2019-09-17  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "2  2019-09-16  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "3  2019-09-04  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "4  2019-07-25  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "\n",
      "C\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-15  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "1  2019-09-12  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "2  2019-09-05  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "3  2019-07-15  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "4  2019-06-28  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First 5 Rows\n",
    "for t in doc_dfs.keys():\n",
    "    print(t)\n",
    "    print(doc_dfs[t].head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "     filing_date                                            doc_loc\n",
      "1246  1995-01-09  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "1247  1994-11-15  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "1248  1994-11-01  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "1249  1994-07-21  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "1250  1994-02-15  https://www.sec.gov/Archives/edgar/data/72971/...\n",
      "\n",
      "JPM\n",
      "     filing_date                                            doc_loc\n",
      "1173  1994-07-07  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "1174  1994-06-20  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "1175  1994-06-01  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "1176  1994-04-20  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "1177  1994-01-21  https://www.sec.gov/Archives/edgar/data/19617/...\n",
      "\n",
      "BAC\n",
      "    filing_date                                            doc_loc\n",
      "537  1995-01-26  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "538  1994-12-22  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "539  1994-10-04  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "540  1994-09-21  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "541  1994-08-04  https://www.sec.gov/Archives/edgar/data/70858/...\n",
      "\n",
      "C\n",
      "    filing_date                                            doc_loc\n",
      "825  1994-09-26  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "826  1994-06-10  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "827  1994-03-01  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "828  1994-01-26  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "829  1994-01-13  https://www.sec.gov/Archives/edgar/data/831001...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last 5 Rows\n",
    "for t in doc_dfs.keys():\n",
    "    print(t)\n",
    "    print(doc_dfs[t].tail())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating both the end of day stock price DataFrame, and the 8-K url DataFrames, we first save the 8-K documents to disk locally while updating the links to the 8-K forms in the corresponding DataFrames. Next we merge all the document DataFrames into one document DataFrame with two columns: filing_data, and doc_loc, where doc_loc now contains lists of document paths that were released on the same date. These two DataFrames, the merged document DataFrame, and the stock price DataFrame, are merged into a DataFrame that contains both sources of data and will represent our full dataset. Each row in this DataFrame contains a date, and the corresponding end of day stock price data, along with a list of paths to the 8-K documents that were released on the corresponding date. This DataFrame is then cleaned and saved locally as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes\n",
    "\n",
    "def save_doc(url, endpoint):\n",
    "    '''\n",
    "    Downloads and saves the text file stored at :param url:, and saves it as its downloaded name in directory\n",
    "    :param endpoint:.\n",
    "    \n",
    "    :param url: String, the url that points to the SEC text file\n",
    "    :parame endpoint: String, path to location to save SEC filing\n",
    "    \n",
    "    ---> String, path to saved document\n",
    "    '''\n",
    "    \n",
    "    if not os.path.isdir(endpoint):\n",
    "        os.mkdir(endpoint)\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except Exception as e:\n",
    "        raise Exception('error with url: {}'.format(url)) from e\n",
    "        \n",
    "    fname = url.split('/')[-1]\n",
    "    with open(os.path.join(endpoint, fname), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return os.path.join(endpoint, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the 8-K forms to disk in the documents folder located in the data folder. Updating the doc_loc column of each document DataFrame to reflect the local location of where the 8-K documents were saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: WFC\n",
      "saving: JPM\n",
      "saving: BAC\n",
      "saving: C\n"
     ]
    }
   ],
   "source": [
    "# Run only if you want to download all 8-K documents linked to in all of the DataFrames stored in the doc_dfs Dictionary.\n",
    "\n",
    "for t in doc_dfs.keys():\n",
    "    print('saving: {}'.format(t))\n",
    "    doc_dfs[t]['doc_loc'] = doc_dfs[t]['doc_loc'].map(lambda url: save_doc(url, os.path.join(path_to_docs, t)) if not pd.isnull(url) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only if you have already downloaded all the 8-K documents linked to in a doc_dfs object.\n",
    "# This cell loads the saved document DataFrames with paths to the downloaded documents into a doc_dfs object.\n",
    "\n",
    "for t in doc_dfs.keys():\n",
    "    path_to_doc_dfs = os.path.join(path_to_data, 'doc_dfs')\n",
    "    doc_dfs[t] = pd.read_csv(os.path.join(path_to_doc_dfs, 'doc_' + t + '.csv'), parse_dates=['filing_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the document DataFrames of each ticker were updated properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-22  /media/Data/Programs/FinTech/data/documents/WF...\n",
      "1  2019-10-21  /media/Data/Programs/FinTech/data/documents/WF...\n",
      "2  2019-10-18  /media/Data/Programs/FinTech/data/documents/WF...\n",
      "3  2019-10-17  /media/Data/Programs/FinTech/data/documents/WF...\n",
      "4  2019-10-15  /media/Data/Programs/FinTech/data/documents/WF...\n",
      "\n",
      "JPM\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-15  /media/Data/Programs/FinTech/data/documents/JP...\n",
      "1  2019-10-15  /media/Data/Programs/FinTech/data/documents/JP...\n",
      "2  2019-09-26  /media/Data/Programs/FinTech/data/documents/JP...\n",
      "3  2019-09-12  /media/Data/Programs/FinTech/data/documents/JP...\n",
      "4  2019-08-20  /media/Data/Programs/FinTech/data/documents/JP...\n",
      "\n",
      "BAC\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-16  /media/Data/Programs/FinTech/data/documents/BA...\n",
      "1  2019-09-17  /media/Data/Programs/FinTech/data/documents/BA...\n",
      "2  2019-09-16  /media/Data/Programs/FinTech/data/documents/BA...\n",
      "3  2019-09-04  /media/Data/Programs/FinTech/data/documents/BA...\n",
      "4  2019-07-25  /media/Data/Programs/FinTech/data/documents/BA...\n",
      "\n",
      "C\n",
      "  filing_date                                            doc_loc\n",
      "0  2019-10-15  /media/Data/Programs/FinTech/data/documents/C/...\n",
      "1  2019-09-12  /media/Data/Programs/FinTech/data/documents/C/...\n",
      "2  2019-09-05  /media/Data/Programs/FinTech/data/documents/C/...\n",
      "3  2019-07-15  /media/Data/Programs/FinTech/data/documents/C/...\n",
      "4  2019-06-28  /media/Data/Programs/FinTech/data/documents/C/...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc_dfs.keys():\n",
    "    print(t)\n",
    "    print(doc_dfs[t].head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: WFC\n",
      "saving: JPM\n",
      "saving: BAC\n",
      "saving: C\n"
     ]
    }
   ],
   "source": [
    "# Saving doc_dfs to disk\n",
    "\n",
    "for t in doc_dfs.keys():\n",
    "    print('saving: {}'.format(t))\n",
    "    tdf = doc_dfs[t]\n",
    "    path_to_doc_dfs = os.path.join(path_to_data, 'doc_dfs')\n",
    "    tdf.to_csv(os.path.join(path_to_doc_dfs, 'doc_' + t + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating and saving our document DataFrames, we must reshape them to the proper structure in order to be merged with our pricing DataFrame. This structure assumes that the column: filing_date, must contain only unique date values since it will serve as the time axis (or index) for the rest of the features. This implies that our document column must contain lists of document paths because there is a potential that multiple documents of the same type can be released on the same day. After reshaping our document DataFrames we merge each one with our pricing DataFrame to produce the final DataFrame representing our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping document DataFrames\n",
    "\n",
    "def json_list(el):\n",
    "    return json.dumps(list(el))\n",
    "\n",
    "for t in doc_dfs.keys():\n",
    "    # Reshaping doc_dfs[t]\n",
    "    doc_dfs[t] = (doc_dfs[t].groupby('filing_date')['doc_loc'].apply(json_list)\n",
    "                  .reset_index().sort_values(by='filing_date', ascending=False))\n",
    "    # Renaming doc_dfs[t]'s to unique values to prepare for merging.\n",
    "    doc_dfs[t].columns = ['filing_date', '_'.join(['docs', t])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the document DataFrames were reshaped properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WFC\n",
      "     filing_date                                           docs_WFC\n",
      "1140  2019-10-22  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "1139  2019-10-21  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "1138  2019-10-18  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "1137  2019-10-17  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "1136  2019-10-15  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "\n",
      "JPM\n",
      "    filing_date                                           docs_JPM\n",
      "968  2019-10-15  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "967  2019-09-26  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "966  2019-09-12  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "965  2019-08-20  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "964  2019-08-02  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "\n",
      "BAC\n",
      "    filing_date                                           docs_BAC\n",
      "503  2019-10-16  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "502  2019-09-17  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "501  2019-09-16  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "500  2019-09-04  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "499  2019-07-25  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "\n",
      "C\n",
      "    filing_date                                             docs_C\n",
      "720  2019-10-15  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "719  2019-09-12  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "718  2019-09-05  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "717  2019-07-15  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "716  2019-06-28  [\"/media/Data/Programs/FinTech/data/documents/...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc_dfs.keys():\n",
    "    print(t)\n",
    "    print(doc_dfs[t].head())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging document DataFrames with pricing DataFrame\n",
    "\n",
    "# Merging doc_dfs ---> docs_df: a DataFrame containing all doc_dfs[t]\n",
    "docs_df = reduce(lambda x, y: pd.merge(x, y, how='outer', on='filing_date'), doc_dfs.values())\n",
    "docs_df = docs_df.sort_values(by=['filing_date'], ascending=False)\n",
    "# Merging docs_df with price_df\n",
    "df = price_df.merge(docs_df, how='outer', left_on='timestamp', right_on='filing_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking our DataFrame to see if it was merged properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5254 entries, 0 to 5253\n",
      "Data columns (total 38 columns):\n",
      "timestamp                5031 non-null datetime64[ns]\n",
      "open_WFC                 5031 non-null float64\n",
      "high_WFC                 5031 non-null float64\n",
      "low_WFC                  5031 non-null float64\n",
      "close_WFC                5031 non-null float64\n",
      "adjusted_close_WFC       5031 non-null float64\n",
      "volume_WFC               5031 non-null float64\n",
      "dividend_amount_WFC      5031 non-null float64\n",
      "split_coefficient_WFC    5031 non-null float64\n",
      "open_JPM                 5031 non-null float64\n",
      "high_JPM                 5031 non-null float64\n",
      "low_JPM                  5031 non-null float64\n",
      "close_JPM                5031 non-null float64\n",
      "adjusted_close_JPM       5031 non-null float64\n",
      "volume_JPM               5031 non-null float64\n",
      "dividend_amount_JPM      5031 non-null float64\n",
      "split_coefficient_JPM    5031 non-null float64\n",
      "open_BAC                 5031 non-null float64\n",
      "high_BAC                 5031 non-null float64\n",
      "low_BAC                  5031 non-null float64\n",
      "close_BAC                5031 non-null float64\n",
      "adjusted_close_BAC       5031 non-null float64\n",
      "volume_BAC               5031 non-null float64\n",
      "dividend_amount_BAC      5031 non-null float64\n",
      "split_coefficient_BAC    5031 non-null float64\n",
      "open_C                   5031 non-null float64\n",
      "high_C                   5031 non-null float64\n",
      "low_C                    5031 non-null float64\n",
      "close_C                  5031 non-null float64\n",
      "adjusted_close_C         5031 non-null float64\n",
      "volume_C                 5031 non-null float64\n",
      "dividend_amount_C        5031 non-null float64\n",
      "split_coefficient_C      5031 non-null float64\n",
      "filing_date              2631 non-null datetime64[ns]\n",
      "docs_WFC                 1141 non-null object\n",
      "docs_JPM                 969 non-null object\n",
      "docs_BAC                 504 non-null object\n",
      "docs_C                   721 non-null object\n",
      "dtypes: datetime64[ns](2), float64(32), object(4)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>50.44</td>\n",
       "      <td>51.02</td>\n",
       "      <td>50.23</td>\n",
       "      <td>50.62</td>\n",
       "      <td>50.62</td>\n",
       "      <td>18007709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.45</td>\n",
       "      <td>...</td>\n",
       "      <td>72.06</td>\n",
       "      <td>72.06</td>\n",
       "      <td>10885809.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>50.28</td>\n",
       "      <td>50.50</td>\n",
       "      <td>50.18</td>\n",
       "      <td>50.46</td>\n",
       "      <td>50.46</td>\n",
       "      <td>19409100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.05</td>\n",
       "      <td>...</td>\n",
       "      <td>71.81</td>\n",
       "      <td>71.81</td>\n",
       "      <td>13080600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>49.34</td>\n",
       "      <td>50.22</td>\n",
       "      <td>49.32</td>\n",
       "      <td>49.97</td>\n",
       "      <td>49.97</td>\n",
       "      <td>21199500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>...</td>\n",
       "      <td>69.74</td>\n",
       "      <td>69.74</td>\n",
       "      <td>10413600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>49.98</td>\n",
       "      <td>50.17</td>\n",
       "      <td>49.48</td>\n",
       "      <td>49.61</td>\n",
       "      <td>49.61</td>\n",
       "      <td>20560100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.75</td>\n",
       "      <td>...</td>\n",
       "      <td>69.60</td>\n",
       "      <td>69.60</td>\n",
       "      <td>11382800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>50.04</td>\n",
       "      <td>50.28</td>\n",
       "      <td>49.45</td>\n",
       "      <td>49.59</td>\n",
       "      <td>49.59</td>\n",
       "      <td>23728400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.96</td>\n",
       "      <td>...</td>\n",
       "      <td>69.50</td>\n",
       "      <td>69.50</td>\n",
       "      <td>17295400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>49.28</td>\n",
       "      <td>51.25</td>\n",
       "      <td>48.78</td>\n",
       "      <td>50.11</td>\n",
       "      <td>50.11</td>\n",
       "      <td>38478400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.85</td>\n",
       "      <td>...</td>\n",
       "      <td>71.22</td>\n",
       "      <td>71.22</td>\n",
       "      <td>22030100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>49.09</td>\n",
       "      <td>49.45</td>\n",
       "      <td>48.98</td>\n",
       "      <td>49.27</td>\n",
       "      <td>49.27</td>\n",
       "      <td>16870500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.85</td>\n",
       "      <td>...</td>\n",
       "      <td>70.24</td>\n",
       "      <td>70.24</td>\n",
       "      <td>11398600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>49.46</td>\n",
       "      <td>49.92</td>\n",
       "      <td>49.15</td>\n",
       "      <td>49.21</td>\n",
       "      <td>49.21</td>\n",
       "      <td>23024600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.03</td>\n",
       "      <td>...</td>\n",
       "      <td>70.10</td>\n",
       "      <td>70.10</td>\n",
       "      <td>14921700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>48.33</td>\n",
       "      <td>49.07</td>\n",
       "      <td>48.16</td>\n",
       "      <td>48.65</td>\n",
       "      <td>48.65</td>\n",
       "      <td>18267800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.14</td>\n",
       "      <td>...</td>\n",
       "      <td>68.62</td>\n",
       "      <td>68.62</td>\n",
       "      <td>9817000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>48.17</td>\n",
       "      <td>48.42</td>\n",
       "      <td>48.08</td>\n",
       "      <td>48.15</td>\n",
       "      <td>48.15</td>\n",
       "      <td>13467800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.67</td>\n",
       "      <td>...</td>\n",
       "      <td>67.43</td>\n",
       "      <td>67.43</td>\n",
       "      <td>8357800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "0 2019-10-22     50.44     51.02    50.23      50.62               50.62   \n",
       "1 2019-10-21     50.28     50.50    50.18      50.46               50.46   \n",
       "2 2019-10-18     49.34     50.22    49.32      49.97               49.97   \n",
       "3 2019-10-17     49.98     50.17    49.48      49.61               49.61   \n",
       "4 2019-10-16     50.04     50.28    49.45      49.59               49.59   \n",
       "5 2019-10-15     49.28     51.25    48.78      50.11               50.11   \n",
       "6 2019-10-14     49.09     49.45    48.98      49.27               49.27   \n",
       "7 2019-10-11     49.46     49.92    49.15      49.21               49.21   \n",
       "8 2019-10-10     48.33     49.07    48.16      48.65               48.65   \n",
       "9 2019-10-09     48.17     48.42    48.08      48.15               48.15   \n",
       "\n",
       "   volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "0  18007709.0                  0.0                    1.0    123.45  ...   \n",
       "1  19409100.0                  0.0                    1.0    122.05  ...   \n",
       "2  21199500.0                  0.0                    1.0    120.00  ...   \n",
       "3  20560100.0                  0.0                    1.0    120.75  ...   \n",
       "4  23728400.0                  0.0                    1.0    119.96  ...   \n",
       "5  38478400.0                  0.0                    1.0    118.85  ...   \n",
       "6  16870500.0                  0.0                    1.0    115.85  ...   \n",
       "7  23024600.0                  0.0                    1.0    116.03  ...   \n",
       "8  18267800.0                  0.0                    1.0    113.14  ...   \n",
       "9  13467800.0                  0.0                    1.0    112.67  ...   \n",
       "\n",
       "   close_C  adjusted_close_C    volume_C  dividend_amount_C  \\\n",
       "0    72.06             72.06  10885809.0                0.0   \n",
       "1    71.81             71.81  13080600.0                0.0   \n",
       "2    69.74             69.74  10413600.0                0.0   \n",
       "3    69.60             69.60  11382800.0                0.0   \n",
       "4    69.50             69.50  17295400.0                0.0   \n",
       "5    71.22             71.22  22030100.0                0.0   \n",
       "6    70.24             70.24  11398600.0                0.0   \n",
       "7    70.10             70.10  14921700.0                0.0   \n",
       "8    68.62             68.62   9817000.0                0.0   \n",
       "9    67.43             67.43   8357800.0                0.0   \n",
       "\n",
       "   split_coefficient_C  filing_date  \\\n",
       "0                  1.0   2019-10-22   \n",
       "1                  1.0   2019-10-21   \n",
       "2                  1.0   2019-10-18   \n",
       "3                  1.0   2019-10-17   \n",
       "4                  1.0   2019-10-16   \n",
       "5                  1.0   2019-10-15   \n",
       "6                  1.0          NaT   \n",
       "7                  1.0   2019-10-11   \n",
       "8                  1.0          NaT   \n",
       "9                  1.0          NaT   \n",
       "\n",
       "                                            docs_WFC  \\\n",
       "0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4                                                NaN   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                NaN   \n",
       "7  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                            docs_JPM  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                            docs_BAC  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                              docs_C  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5244</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-07-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5245</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-06-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5246</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-06-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5247</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5248</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-04-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5249</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-02-15</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5251</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5252</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5253</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "5244       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5245       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5246       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5247       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5248       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5249       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5250       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5251       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5252       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "5253       NaT       NaN       NaN      NaN        NaN                 NaN   \n",
       "\n",
       "      volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "5244         NaN                  NaN                    NaN       NaN  ...   \n",
       "5245         NaN                  NaN                    NaN       NaN  ...   \n",
       "5246         NaN                  NaN                    NaN       NaN  ...   \n",
       "5247         NaN                  NaN                    NaN       NaN  ...   \n",
       "5248         NaN                  NaN                    NaN       NaN  ...   \n",
       "5249         NaN                  NaN                    NaN       NaN  ...   \n",
       "5250         NaN                  NaN                    NaN       NaN  ...   \n",
       "5251         NaN                  NaN                    NaN       NaN  ...   \n",
       "5252         NaN                  NaN                    NaN       NaN  ...   \n",
       "5253         NaN                  NaN                    NaN       NaN  ...   \n",
       "\n",
       "      close_C  adjusted_close_C  volume_C  dividend_amount_C  \\\n",
       "5244      NaN               NaN       NaN                NaN   \n",
       "5245      NaN               NaN       NaN                NaN   \n",
       "5246      NaN               NaN       NaN                NaN   \n",
       "5247      NaN               NaN       NaN                NaN   \n",
       "5248      NaN               NaN       NaN                NaN   \n",
       "5249      NaN               NaN       NaN                NaN   \n",
       "5250      NaN               NaN       NaN                NaN   \n",
       "5251      NaN               NaN       NaN                NaN   \n",
       "5252      NaN               NaN       NaN                NaN   \n",
       "5253      NaN               NaN       NaN                NaN   \n",
       "\n",
       "      split_coefficient_C  filing_date  \\\n",
       "5244                  NaN   1994-07-07   \n",
       "5245                  NaN   1994-06-20   \n",
       "5246                  NaN   1994-06-10   \n",
       "5247                  NaN   1994-06-01   \n",
       "5248                  NaN   1994-04-20   \n",
       "5249                  NaN   1994-03-01   \n",
       "5250                  NaN   1994-02-15   \n",
       "5251                  NaN   1994-01-26   \n",
       "5252                  NaN   1994-01-21   \n",
       "5253                  NaN   1994-01-13   \n",
       "\n",
       "                                               docs_WFC  \\\n",
       "5244                                                NaN   \n",
       "5245                                                NaN   \n",
       "5246                                                NaN   \n",
       "5247                                                NaN   \n",
       "5248                                                NaN   \n",
       "5249                                                NaN   \n",
       "5250  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "5251                                                NaN   \n",
       "5252                                                NaN   \n",
       "5253                                                NaN   \n",
       "\n",
       "                                               docs_JPM  docs_BAC  \\\n",
       "5244  [\"/media/Data/Programs/FinTech/data/documents/...       NaN   \n",
       "5245  [\"/media/Data/Programs/FinTech/data/documents/...       NaN   \n",
       "5246                                                NaN       NaN   \n",
       "5247  [\"/media/Data/Programs/FinTech/data/documents/...       NaN   \n",
       "5248  [\"/media/Data/Programs/FinTech/data/documents/...       NaN   \n",
       "5249                                                NaN       NaN   \n",
       "5250                                                NaN       NaN   \n",
       "5251                                                NaN       NaN   \n",
       "5252  [\"/media/Data/Programs/FinTech/data/documents/...       NaN   \n",
       "5253                                                NaN       NaN   \n",
       "\n",
       "                                                 docs_C  \n",
       "5244                                                NaN  \n",
       "5245                                                NaN  \n",
       "5246  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "5247                                                NaN  \n",
       "5248                                                NaN  \n",
       "5249  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "5250                                                NaN  \n",
       "5251  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "5252                                                NaN  \n",
       "5253  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up our DataFrame by filling missing document lists with empty lists, dropping rows ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN values in document list columns with empty lists\n",
    "df = df.fillna(value={'_'.join(['docs', t]): json.dumps([]) for t in tickers})\n",
    "# Droping rows that don't have pricing data\n",
    "df = df.dropna(subset=['timestamp'])\n",
    "# Droping the filing_date column\n",
    "df = df.drop(['filing_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if the DataFrame was cleaned properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5031 entries, 0 to 5030\n",
      "Data columns (total 37 columns):\n",
      "timestamp                5031 non-null datetime64[ns]\n",
      "open_WFC                 5031 non-null float64\n",
      "high_WFC                 5031 non-null float64\n",
      "low_WFC                  5031 non-null float64\n",
      "close_WFC                5031 non-null float64\n",
      "adjusted_close_WFC       5031 non-null float64\n",
      "volume_WFC               5031 non-null float64\n",
      "dividend_amount_WFC      5031 non-null float64\n",
      "split_coefficient_WFC    5031 non-null float64\n",
      "open_JPM                 5031 non-null float64\n",
      "high_JPM                 5031 non-null float64\n",
      "low_JPM                  5031 non-null float64\n",
      "close_JPM                5031 non-null float64\n",
      "adjusted_close_JPM       5031 non-null float64\n",
      "volume_JPM               5031 non-null float64\n",
      "dividend_amount_JPM      5031 non-null float64\n",
      "split_coefficient_JPM    5031 non-null float64\n",
      "open_BAC                 5031 non-null float64\n",
      "high_BAC                 5031 non-null float64\n",
      "low_BAC                  5031 non-null float64\n",
      "close_BAC                5031 non-null float64\n",
      "adjusted_close_BAC       5031 non-null float64\n",
      "volume_BAC               5031 non-null float64\n",
      "dividend_amount_BAC      5031 non-null float64\n",
      "split_coefficient_BAC    5031 non-null float64\n",
      "open_C                   5031 non-null float64\n",
      "high_C                   5031 non-null float64\n",
      "low_C                    5031 non-null float64\n",
      "close_C                  5031 non-null float64\n",
      "adjusted_close_C         5031 non-null float64\n",
      "volume_C                 5031 non-null float64\n",
      "dividend_amount_C        5031 non-null float64\n",
      "split_coefficient_C      5031 non-null float64\n",
      "docs_WFC                 5031 non-null object\n",
      "docs_JPM                 5031 non-null object\n",
      "docs_BAC                 5031 non-null object\n",
      "docs_C                   5031 non-null object\n",
      "dtypes: datetime64[ns](1), float64(32), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>low_C</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>50.44</td>\n",
       "      <td>51.02</td>\n",
       "      <td>50.23</td>\n",
       "      <td>50.62</td>\n",
       "      <td>50.62</td>\n",
       "      <td>18007709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.45</td>\n",
       "      <td>...</td>\n",
       "      <td>71.47</td>\n",
       "      <td>72.06</td>\n",
       "      <td>72.06</td>\n",
       "      <td>10885809.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>50.28</td>\n",
       "      <td>50.50</td>\n",
       "      <td>50.18</td>\n",
       "      <td>50.46</td>\n",
       "      <td>50.46</td>\n",
       "      <td>19409100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.05</td>\n",
       "      <td>...</td>\n",
       "      <td>70.52</td>\n",
       "      <td>71.81</td>\n",
       "      <td>71.81</td>\n",
       "      <td>13080600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>49.34</td>\n",
       "      <td>50.22</td>\n",
       "      <td>49.32</td>\n",
       "      <td>49.97</td>\n",
       "      <td>49.97</td>\n",
       "      <td>21199500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>...</td>\n",
       "      <td>69.14</td>\n",
       "      <td>69.74</td>\n",
       "      <td>69.74</td>\n",
       "      <td>10413600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>49.98</td>\n",
       "      <td>50.17</td>\n",
       "      <td>49.48</td>\n",
       "      <td>49.61</td>\n",
       "      <td>49.61</td>\n",
       "      <td>20560100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.75</td>\n",
       "      <td>...</td>\n",
       "      <td>69.18</td>\n",
       "      <td>69.60</td>\n",
       "      <td>69.60</td>\n",
       "      <td>11382800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>50.04</td>\n",
       "      <td>50.28</td>\n",
       "      <td>49.45</td>\n",
       "      <td>49.59</td>\n",
       "      <td>49.59</td>\n",
       "      <td>23728400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.96</td>\n",
       "      <td>...</td>\n",
       "      <td>69.42</td>\n",
       "      <td>69.50</td>\n",
       "      <td>69.50</td>\n",
       "      <td>17295400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>49.28</td>\n",
       "      <td>51.25</td>\n",
       "      <td>48.78</td>\n",
       "      <td>50.11</td>\n",
       "      <td>50.11</td>\n",
       "      <td>38478400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.85</td>\n",
       "      <td>...</td>\n",
       "      <td>68.70</td>\n",
       "      <td>71.22</td>\n",
       "      <td>71.22</td>\n",
       "      <td>22030100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>49.09</td>\n",
       "      <td>49.45</td>\n",
       "      <td>48.98</td>\n",
       "      <td>49.27</td>\n",
       "      <td>49.27</td>\n",
       "      <td>16870500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.85</td>\n",
       "      <td>...</td>\n",
       "      <td>69.46</td>\n",
       "      <td>70.24</td>\n",
       "      <td>70.24</td>\n",
       "      <td>11398600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>49.46</td>\n",
       "      <td>49.92</td>\n",
       "      <td>49.15</td>\n",
       "      <td>49.21</td>\n",
       "      <td>49.21</td>\n",
       "      <td>23024600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.03</td>\n",
       "      <td>...</td>\n",
       "      <td>69.99</td>\n",
       "      <td>70.10</td>\n",
       "      <td>70.10</td>\n",
       "      <td>14921700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>48.33</td>\n",
       "      <td>49.07</td>\n",
       "      <td>48.16</td>\n",
       "      <td>48.65</td>\n",
       "      <td>48.65</td>\n",
       "      <td>18267800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.14</td>\n",
       "      <td>...</td>\n",
       "      <td>67.55</td>\n",
       "      <td>68.62</td>\n",
       "      <td>68.62</td>\n",
       "      <td>9817000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>48.17</td>\n",
       "      <td>48.42</td>\n",
       "      <td>48.08</td>\n",
       "      <td>48.15</td>\n",
       "      <td>48.15</td>\n",
       "      <td>13467800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.67</td>\n",
       "      <td>...</td>\n",
       "      <td>66.79</td>\n",
       "      <td>67.43</td>\n",
       "      <td>67.43</td>\n",
       "      <td>8357800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "0 2019-10-22     50.44     51.02    50.23      50.62               50.62   \n",
       "1 2019-10-21     50.28     50.50    50.18      50.46               50.46   \n",
       "2 2019-10-18     49.34     50.22    49.32      49.97               49.97   \n",
       "3 2019-10-17     49.98     50.17    49.48      49.61               49.61   \n",
       "4 2019-10-16     50.04     50.28    49.45      49.59               49.59   \n",
       "5 2019-10-15     49.28     51.25    48.78      50.11               50.11   \n",
       "6 2019-10-14     49.09     49.45    48.98      49.27               49.27   \n",
       "7 2019-10-11     49.46     49.92    49.15      49.21               49.21   \n",
       "8 2019-10-10     48.33     49.07    48.16      48.65               48.65   \n",
       "9 2019-10-09     48.17     48.42    48.08      48.15               48.15   \n",
       "\n",
       "   volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "0  18007709.0                  0.0                    1.0    123.45  ...   \n",
       "1  19409100.0                  0.0                    1.0    122.05  ...   \n",
       "2  21199500.0                  0.0                    1.0    120.00  ...   \n",
       "3  20560100.0                  0.0                    1.0    120.75  ...   \n",
       "4  23728400.0                  0.0                    1.0    119.96  ...   \n",
       "5  38478400.0                  0.0                    1.0    118.85  ...   \n",
       "6  16870500.0                  0.0                    1.0    115.85  ...   \n",
       "7  23024600.0                  0.0                    1.0    116.03  ...   \n",
       "8  18267800.0                  0.0                    1.0    113.14  ...   \n",
       "9  13467800.0                  0.0                    1.0    112.67  ...   \n",
       "\n",
       "   low_C  close_C  adjusted_close_C    volume_C  dividend_amount_C  \\\n",
       "0  71.47    72.06             72.06  10885809.0                0.0   \n",
       "1  70.52    71.81             71.81  13080600.0                0.0   \n",
       "2  69.14    69.74             69.74  10413600.0                0.0   \n",
       "3  69.18    69.60             69.60  11382800.0                0.0   \n",
       "4  69.42    69.50             69.50  17295400.0                0.0   \n",
       "5  68.70    71.22             71.22  22030100.0                0.0   \n",
       "6  69.46    70.24             70.24  11398600.0                0.0   \n",
       "7  69.99    70.10             70.10  14921700.0                0.0   \n",
       "8  67.55    68.62             68.62   9817000.0                0.0   \n",
       "9  66.79    67.43             67.43   8357800.0                0.0   \n",
       "\n",
       "   split_coefficient_C                                           docs_WFC  \\\n",
       "0                  1.0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "1                  1.0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2                  1.0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3                  1.0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4                  1.0                                                 []   \n",
       "5                  1.0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                  1.0                                                 []   \n",
       "7                  1.0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "8                  1.0                                                 []   \n",
       "9                  1.0                                                 []   \n",
       "\n",
       "                                            docs_JPM  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "8                                                 []   \n",
       "9                                                 []   \n",
       "\n",
       "                                            docs_BAC  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "5                                                 []   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "8                                                 []   \n",
       "9                                                 []   \n",
       "\n",
       "                                              docs_C  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "6                                                 []  \n",
       "7                                                 []  \n",
       "8                                                 []  \n",
       "9                                                 []  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>low_C</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5021</td>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>24.000</td>\n",
       "      <td>24.188</td>\n",
       "      <td>23.3130</td>\n",
       "      <td>23.406</td>\n",
       "      <td>13.6034</td>\n",
       "      <td>10887600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.125</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0000</td>\n",
       "      <td>54.375</td>\n",
       "      <td>267.0091</td>\n",
       "      <td>1847600.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5022</td>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>23.313</td>\n",
       "      <td>23.656</td>\n",
       "      <td>23.3130</td>\n",
       "      <td>23.500</td>\n",
       "      <td>13.6578</td>\n",
       "      <td>8867000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.875</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0630</td>\n",
       "      <td>54.750</td>\n",
       "      <td>268.8504</td>\n",
       "      <td>7179800.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5023</td>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>23.594</td>\n",
       "      <td>23.656</td>\n",
       "      <td>23.0630</td>\n",
       "      <td>23.063</td>\n",
       "      <td>13.4036</td>\n",
       "      <td>8204400.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.625</td>\n",
       "      <td>...</td>\n",
       "      <td>52.6880</td>\n",
       "      <td>53.000</td>\n",
       "      <td>260.2570</td>\n",
       "      <td>1630100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5024</td>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>23.344</td>\n",
       "      <td>24.031</td>\n",
       "      <td>23.2491</td>\n",
       "      <td>23.688</td>\n",
       "      <td>13.7087</td>\n",
       "      <td>9976400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.500</td>\n",
       "      <td>...</td>\n",
       "      <td>53.3750</td>\n",
       "      <td>53.688</td>\n",
       "      <td>263.6330</td>\n",
       "      <td>1520000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>23.500</td>\n",
       "      <td>23.594</td>\n",
       "      <td>23.1560</td>\n",
       "      <td>23.438</td>\n",
       "      <td>13.5640</td>\n",
       "      <td>10083800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.625</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0627</td>\n",
       "      <td>53.375</td>\n",
       "      <td>262.0986</td>\n",
       "      <td>1475000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5026</td>\n",
       "      <td>1999-10-29</td>\n",
       "      <td>24.250</td>\n",
       "      <td>24.531</td>\n",
       "      <td>23.6250</td>\n",
       "      <td>23.938</td>\n",
       "      <td>13.8534</td>\n",
       "      <td>11853400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.125</td>\n",
       "      <td>...</td>\n",
       "      <td>53.5630</td>\n",
       "      <td>54.250</td>\n",
       "      <td>266.3951</td>\n",
       "      <td>2973100.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5027</td>\n",
       "      <td>1999-10-28</td>\n",
       "      <td>24.063</td>\n",
       "      <td>24.969</td>\n",
       "      <td>23.8750</td>\n",
       "      <td>24.531</td>\n",
       "      <td>14.1970</td>\n",
       "      <td>24287800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.500</td>\n",
       "      <td>...</td>\n",
       "      <td>53.1250</td>\n",
       "      <td>54.125</td>\n",
       "      <td>265.7814</td>\n",
       "      <td>4253600.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5028</td>\n",
       "      <td>1999-10-27</td>\n",
       "      <td>22.563</td>\n",
       "      <td>23.250</td>\n",
       "      <td>22.4380</td>\n",
       "      <td>23.250</td>\n",
       "      <td>13.4555</td>\n",
       "      <td>11327200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.063</td>\n",
       "      <td>...</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>51.313</td>\n",
       "      <td>251.2830</td>\n",
       "      <td>2032200.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5029</td>\n",
       "      <td>1999-10-26</td>\n",
       "      <td>22.375</td>\n",
       "      <td>22.719</td>\n",
       "      <td>22.2190</td>\n",
       "      <td>22.344</td>\n",
       "      <td>12.9310</td>\n",
       "      <td>11607400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.313</td>\n",
       "      <td>...</td>\n",
       "      <td>47.6250</td>\n",
       "      <td>48.500</td>\n",
       "      <td>237.5099</td>\n",
       "      <td>2682700.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>1999-10-25</td>\n",
       "      <td>22.250</td>\n",
       "      <td>22.342</td>\n",
       "      <td>21.9380</td>\n",
       "      <td>22.156</td>\n",
       "      <td>12.8225</td>\n",
       "      <td>7817600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.688</td>\n",
       "      <td>...</td>\n",
       "      <td>47.1250</td>\n",
       "      <td>47.813</td>\n",
       "      <td>234.1432</td>\n",
       "      <td>1027000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "5021 1999-11-05    24.000    24.188  23.3130     23.406             13.6034   \n",
       "5022 1999-11-04    23.313    23.656  23.3130     23.500             13.6578   \n",
       "5023 1999-11-03    23.594    23.656  23.0630     23.063             13.4036   \n",
       "5024 1999-11-02    23.344    24.031  23.2491     23.688             13.7087   \n",
       "5025 1999-11-01    23.500    23.594  23.1560     23.438             13.5640   \n",
       "5026 1999-10-29    24.250    24.531  23.6250     23.938             13.8534   \n",
       "5027 1999-10-28    24.063    24.969  23.8750     24.531             14.1970   \n",
       "5028 1999-10-27    22.563    23.250  22.4380     23.250             13.4555   \n",
       "5029 1999-10-26    22.375    22.719  22.2190     22.344             12.9310   \n",
       "5030 1999-10-25    22.250    22.342  21.9380     22.156             12.8225   \n",
       "\n",
       "      volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "5021  10887600.0                  0.0                    1.0    86.125  ...   \n",
       "5022   8867000.0                  0.0                    1.0    83.875  ...   \n",
       "5023   8204400.0                  0.1                    1.0    83.625  ...   \n",
       "5024   9976400.0                  0.0                    1.0    84.500  ...   \n",
       "5025  10083800.0                  0.0                    1.0    86.625  ...   \n",
       "5026  11853400.0                  0.0                    1.0    88.125  ...   \n",
       "5027  24287800.0                  0.0                    1.0    85.500  ...   \n",
       "5028  11327200.0                  0.0                    1.0    78.063  ...   \n",
       "5029  11607400.0                  0.0                    1.0    78.313  ...   \n",
       "5030   7817600.0                  0.0                    1.0    79.688  ...   \n",
       "\n",
       "        low_C  close_C  adjusted_close_C   volume_C  dividend_amount_C  \\\n",
       "5021  54.0000   54.375          267.0091  1847600.0               0.00   \n",
       "5022  53.0630   54.750          268.8504  7179800.0               0.00   \n",
       "5023  52.6880   53.000          260.2570  1630100.0               0.00   \n",
       "5024  53.3750   53.688          263.6330  1520000.0               0.00   \n",
       "5025  53.0627   53.375          262.0986  1475000.0               0.00   \n",
       "5026  53.5630   54.250          266.3951  2973100.0               0.00   \n",
       "5027  53.1250   54.125          265.7814  4253600.0               1.05   \n",
       "5028  48.7500   51.313          251.2830  2032200.0               0.00   \n",
       "5029  47.6250   48.500          237.5099  2682700.0               0.00   \n",
       "5030  47.1250   47.813          234.1432  1027000.0               0.00   \n",
       "\n",
       "      split_coefficient_C  docs_WFC  \\\n",
       "5021                  1.0        []   \n",
       "5022                  1.0        []   \n",
       "5023                  1.0        []   \n",
       "5024                  1.0        []   \n",
       "5025                  1.0        []   \n",
       "5026                  1.0        []   \n",
       "5027                  1.0        []   \n",
       "5028                  1.0        []   \n",
       "5029                  1.0        []   \n",
       "5030                  1.0        []   \n",
       "\n",
       "                                               docs_JPM  docs_BAC  \\\n",
       "5021                                                 []        []   \n",
       "5022                                                 []        []   \n",
       "5023                                                 []        []   \n",
       "5024  [\"/media/Data/Programs/FinTech/data/documents/...        []   \n",
       "5025                                                 []        []   \n",
       "5026                                                 []        []   \n",
       "5027                                                 []        []   \n",
       "5028                                                 []        []   \n",
       "5029                                                 []        []   \n",
       "5030                                                 []        []   \n",
       "\n",
       "                                                 docs_C  \n",
       "5021                                                 []  \n",
       "5022                                                 []  \n",
       "5023                                                 []  \n",
       "5024                                                 []  \n",
       "5025                                                 []  \n",
       "5026                                                 []  \n",
       "5027                                                 []  \n",
       "5028                                                 []  \n",
       "5029  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "5030                                                 []  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the final DataFrame to disk as raw.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving DataFrame to disk\n",
    "df.to_csv(os.path.join(path_to_data, 'raw.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving onto the modeling phase we will explore our data both in its raw state and preprocessed state to ensure that nothing is deeply flawed with our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries and Setting Variables\n",
    "\n",
    "import re\n",
    "import lxml\n",
    "import json\n",
    "import pickle\n",
    "import unicodedata\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Instantiating Spacy NLP object with the parser and named entity recognition components\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading DataFrame from disk\n",
    "df = pd.read_csv(os.path.join(path_to_data, 'raw.csv'), parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the DataFrame was loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5031 entries, 0 to 5030\n",
      "Data columns (total 37 columns):\n",
      "timestamp                5031 non-null datetime64[ns]\n",
      "open_WFC                 5031 non-null float64\n",
      "high_WFC                 5031 non-null float64\n",
      "low_WFC                  5031 non-null float64\n",
      "close_WFC                5031 non-null float64\n",
      "adjusted_close_WFC       5031 non-null float64\n",
      "volume_WFC               5031 non-null float64\n",
      "dividend_amount_WFC      5031 non-null float64\n",
      "split_coefficient_WFC    5031 non-null float64\n",
      "open_JPM                 5031 non-null float64\n",
      "high_JPM                 5031 non-null float64\n",
      "low_JPM                  5031 non-null float64\n",
      "close_JPM                5031 non-null float64\n",
      "adjusted_close_JPM       5031 non-null float64\n",
      "volume_JPM               5031 non-null float64\n",
      "dividend_amount_JPM      5031 non-null float64\n",
      "split_coefficient_JPM    5031 non-null float64\n",
      "open_BAC                 5031 non-null float64\n",
      "high_BAC                 5031 non-null float64\n",
      "low_BAC                  5031 non-null float64\n",
      "close_BAC                5031 non-null float64\n",
      "adjusted_close_BAC       5031 non-null float64\n",
      "volume_BAC               5031 non-null float64\n",
      "dividend_amount_BAC      5031 non-null float64\n",
      "split_coefficient_BAC    5031 non-null float64\n",
      "open_C                   5031 non-null float64\n",
      "high_C                   5031 non-null float64\n",
      "low_C                    5031 non-null float64\n",
      "close_C                  5031 non-null float64\n",
      "adjusted_close_C         5031 non-null float64\n",
      "volume_C                 5031 non-null float64\n",
      "dividend_amount_C        5031 non-null float64\n",
      "split_coefficient_C      5031 non-null float64\n",
      "docs_WFC                 5031 non-null object\n",
      "docs_JPM                 5031 non-null object\n",
      "docs_BAC                 5031 non-null object\n",
      "docs_C                   5031 non-null object\n",
      "dtypes: datetime64[ns](1), float64(32), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our raw dataset has two different types of data (numerical and textual), we will inspect each type seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pricing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first things we will check for our pricing data are a plot of the time series of our adjusted closing prices along with its distribution to check and see if there is anything unusual, and if the distribution conforms to our expectations of this type of data. We will then check these types of plots for other types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking some basic statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>high_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>dividend_amount_BAC</th>\n",
       "      <th>split_coefficient_BAC</th>\n",
       "      <th>open_C</th>\n",
       "      <th>high_C</th>\n",
       "      <th>low_C</th>\n",
       "      <th>close_C</th>\n",
       "      <th>adjusted_close_C</th>\n",
       "      <th>volume_C</th>\n",
       "      <th>dividend_amount_C</th>\n",
       "      <th>split_coefficient_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5.031000e+03</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5.031000e+03</td>\n",
       "      <td>5031.000000</td>\n",
       "      <td>5031.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>35.583694</td>\n",
       "      <td>35.954724</td>\n",
       "      <td>35.209422</td>\n",
       "      <td>35.585835</td>\n",
       "      <td>28.466109</td>\n",
       "      <td>2.316536e+07</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>1.000199</td>\n",
       "      <td>53.546744</td>\n",
       "      <td>54.156783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>1.000199</td>\n",
       "      <td>42.903531</td>\n",
       "      <td>43.380461</td>\n",
       "      <td>42.388165</td>\n",
       "      <td>42.882042</td>\n",
       "      <td>174.771051</td>\n",
       "      <td>1.807609e+07</td>\n",
       "      <td>0.028848</td>\n",
       "      <td>0.999887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>11.847026</td>\n",
       "      <td>11.863345</td>\n",
       "      <td>11.843391</td>\n",
       "      <td>11.848686</td>\n",
       "      <td>13.482288</td>\n",
       "      <td>2.780215e+07</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>23.920267</td>\n",
       "      <td>24.043933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037961</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>18.696407</td>\n",
       "      <td>18.826358</td>\n",
       "      <td>18.578379</td>\n",
       "      <td>18.708705</td>\n",
       "      <td>149.176072</td>\n",
       "      <td>2.345764e+07</td>\n",
       "      <td>0.452462</td>\n",
       "      <td>0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.276300</td>\n",
       "      <td>1.774000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.370000</td>\n",
       "      <td>16.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>9.480500</td>\n",
       "      <td>2.420000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.370000</td>\n",
       "      <td>25.607500</td>\n",
       "      <td>25.980000</td>\n",
       "      <td>18.580600</td>\n",
       "      <td>9.267500e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.590000</td>\n",
       "      <td>38.030750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.965000</td>\n",
       "      <td>35.620000</td>\n",
       "      <td>34.440000</td>\n",
       "      <td>34.990000</td>\n",
       "      <td>44.343800</td>\n",
       "      <td>1.531900e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>31.550000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>31.160000</td>\n",
       "      <td>31.510000</td>\n",
       "      <td>23.314900</td>\n",
       "      <td>1.551570e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.980000</td>\n",
       "      <td>45.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.480000</td>\n",
       "      <td>47.880000</td>\n",
       "      <td>47.050000</td>\n",
       "      <td>47.460000</td>\n",
       "      <td>68.622900</td>\n",
       "      <td>1.261520e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>47.393600</td>\n",
       "      <td>47.895000</td>\n",
       "      <td>46.930000</td>\n",
       "      <td>47.495000</td>\n",
       "      <td>43.126300</td>\n",
       "      <td>2.654285e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.090000</td>\n",
       "      <td>61.597500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.040000</td>\n",
       "      <td>53.600000</td>\n",
       "      <td>52.408650</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>333.506650</td>\n",
       "      <td>2.467630e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>65.891900</td>\n",
       "      <td>66.315500</td>\n",
       "      <td>65.660000</td>\n",
       "      <td>65.930000</td>\n",
       "      <td>62.175200</td>\n",
       "      <td>4.787366e+08</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>123.450000</td>\n",
       "      <td>125.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.120000</td>\n",
       "      <td>80.700000</td>\n",
       "      <td>79.830000</td>\n",
       "      <td>80.080000</td>\n",
       "      <td>474.080800</td>\n",
       "      <td>3.772638e+08</td>\n",
       "      <td>24.150000</td>\n",
       "      <td>1.333300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open_WFC     high_WFC      low_WFC    close_WFC  adjusted_close_WFC  \\\n",
       "count  5031.000000  5031.000000  5031.000000  5031.000000         5031.000000   \n",
       "mean     35.583694    35.954724    35.209422    35.585835           28.466109   \n",
       "std      11.847026    11.863345    11.843391    11.848686           13.482288   \n",
       "min       8.650000     8.940000     7.800000     8.120000            6.276300   \n",
       "25%      26.000000    26.370000    25.607500    25.980000           18.580600   \n",
       "50%      31.550000    31.900000    31.160000    31.510000           23.314900   \n",
       "75%      47.393600    47.895000    46.930000    47.495000           43.126300   \n",
       "max      65.891900    66.315500    65.660000    65.930000           62.175200   \n",
       "\n",
       "         volume_WFC  dividend_amount_WFC  split_coefficient_WFC     open_JPM  \\\n",
       "count  5.031000e+03          5031.000000            5031.000000  5031.000000   \n",
       "mean   2.316536e+07             0.003969               1.000199    53.546744   \n",
       "std    2.780215e+07             0.034511               0.014098    23.920267   \n",
       "min    1.774000e+06             0.000000               1.000000    15.370000   \n",
       "25%    9.267500e+06             0.000000               1.000000    37.590000   \n",
       "50%    1.551570e+07             0.000000               1.000000    44.980000   \n",
       "75%    2.654285e+07             0.000000               1.000000    61.090000   \n",
       "max    4.787366e+08             0.510000               2.000000   123.450000   \n",
       "\n",
       "          high_JPM  ...  dividend_amount_BAC  split_coefficient_BAC  \\\n",
       "count  5031.000000  ...          5031.000000            5031.000000   \n",
       "mean     54.156783  ...             0.003502               1.000199   \n",
       "std      24.043933  ...             0.037961               0.014098   \n",
       "min      16.350000  ...             0.000000               1.000000   \n",
       "25%      38.030750  ...             0.000000               1.000000   \n",
       "50%      45.540000  ...             0.000000               1.000000   \n",
       "75%      61.597500  ...             0.000000               1.000000   \n",
       "max     125.100000  ...             0.640000               2.000000   \n",
       "\n",
       "            open_C       high_C        low_C      close_C  adjusted_close_C  \\\n",
       "count  5031.000000  5031.000000  5031.000000  5031.000000       5031.000000   \n",
       "mean     42.903531    43.380461    42.388165    42.882042        174.771051   \n",
       "std      18.696407    18.826358    18.578379    18.708705        149.176072   \n",
       "min       1.020000     1.070000     0.970000     1.020000          9.480500   \n",
       "25%      34.965000    35.620000    34.440000    34.990000         44.343800   \n",
       "50%      47.480000    47.880000    47.050000    47.460000         68.622900   \n",
       "75%      53.040000    53.600000    52.408650    53.000000        333.506650   \n",
       "max      80.120000    80.700000    79.830000    80.080000        474.080800   \n",
       "\n",
       "           volume_C  dividend_amount_C  split_coefficient_C  \n",
       "count  5.031000e+03        5031.000000          5031.000000  \n",
       "mean   1.807609e+07           0.028848             0.999887  \n",
       "std    2.345764e+07           0.452462             0.013532  \n",
       "min    2.420000e+05           0.000000             0.100000  \n",
       "25%    1.531900e+06           0.000000             1.000000  \n",
       "50%    1.261520e+07           0.000000             1.000000  \n",
       "75%    2.467630e+07           0.000000             1.000000  \n",
       "max    3.772638e+08          24.150000             1.333300  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAWYCAYAAAAm73dbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5xcVfnH8c+zPW3Tew9pgJBAQq+BAEIoAopSVBBExQIiKKiIBfhFRVBBQIqAgEiVFggkgVBDSSAJSUhCekL6pm22l/P7496Znbo7OzO7s+X7fr32tfeeuXPn7Exgn33OOc8x5xwiIiIi0n5kZboDIiIiItK8FACKiIiItDMKAEVERETaGQWAIiIiIu2MAkARERGRdkYBoIiIiEg7owBQpI0ws4vN7J2Q871mNiLDfTrezDY04f2PMbNlIedrzGxyE7zOMDNzZpaTwj2G+J9Jdjr7lmRffmlm9zfBfW8ys+1mtjnd9xaR9FIAKNLCmdlsM9tpZvmNeZ5zrrNzblWKr/2Qmd2Uyj0auL8zsxI/MCoys1lm9vVEn++ce9s5NyZNfRltZk/5AcxuM1toZlenK2Bzzq3zP5OadNwvlP85Vfrv4w4zm2FmY+vpyy3OucvS3IchwM+A/Zxz/dJwv3+a2d0h57n+v5VYbYeHBOl7Q74WhFzb38weMLNNZlZsZkvN7Hdm1inVvoq0RgoARVowMxsGHAM44MyMdqbpjHPOdQbGAA8Bd5rZjc3ZATPbB/gAWA8c4JzrCnwNmAh0ac6+pOBP/vs4CNiK915GSSWL2YAhQJFzbmtjnxinT28Bx4acTwTW4f33ENoGMC+krZsfaHd2zo3z798DmAN0AI5wznUBTgK6Afs0tr8ibYECQJGW7VvA+3i/zL8d+oCZ9TSzF8xsj5l9SMQvMj8bMtI/nm1ml4U8FhwuNs/tZrbVv9enZvYlM7scuBD4uZ9NedG/foCZPWNm28xstZn9JOS+Hfxs1E4zWwIckugP6pzb7px7BPgBcL2Z9fTveYmZfeZnbVaZ2fdCXi/mELOZ9TOz0sA9/LaD/T7nxnj53wHvOeeuds5t8vuzzDl3gXNuV4z7D/Df+x1mtsLMvhvy2KFmNtd/L7eY2W1+e9gwsv+Z/MHM3vV/ttfMrFfIfb5lZmv9zOgNluDwtnOuFPgP8CX/Pr81s6fN7FEz2wNc7Lc9GvJaR5vZe2a2y8zWm9nFfnu+md1qZuv8n+UeM+sQ4/2YDMwABvj/Vh7y2880s8X+fWeb2b4hz1ljZr8ws4VASYwg8C1g35D35Bjgv0CniLY5zrmqBt6Wq4Fi4CLn3Br/fVrvnLvSObewgeeKtEkKAEVatm8Bj/lfp5hZ35DH/gGUA/2B7/hfyTgZL9MyGugKnIeXybnXf90/+dmUM8wsC3gRWAAMBE4ErjKzU/x73YgXiO4DnEJE0Jqg54Ec4FD/fCtwOlAIXALcbmYH13cD59xmYLb/swR8E/hvnGBhMvB0I/r4X2ADMAD4KnCLmZ3gP/Y34G/OuUK89+HJeu5zAd7P1AfIA64BMLP9gLvwAvD+eJ/LwEQ6Zmad/ed9EtJ8Ft7P1w3vMw29fijwCnAH0BsYD8z3H56K9+9iPDDS78NvIl/TOTcTOBXY6P9budjMRgOPA1f5930ZeNHM8kKeej4wBS9rVx1xz/XAWuoyfscCbwPvRbS91eCb4n2+zzrnahO4VqRdUAAo0kKZ2dHAUOBJ59w8YCVewIB589LOBX7jnCtxzi0CHk7yparwhjnHAuac+yyQBYvhEKC3c+73zrlKf47hfcA3/MfPA252zu3wf4H/vbGd8QO07UAP/3yac26l87wJvEb4MGA8DwMXQfD9Oh94JM61PYF4P3MYMxsMHAX8wjlX7pybD9yPF6yD936ONLNezrm9zrn367ndg8655c65MrxAcbzf/lXgRefcO865Srygq6GN268xs13ACqAzcHHIY3Occ88552r91wp1ATDTOfe4c67KOVfknJtvZgZcDvzU/zyLgVuo+6wb8nVgmnNuhv+Z3oo3BHtkyDV/9zNxkX0KeBM41v/D41C8bPjbIW1H+deE2u5nHHeZ2TV+W8Kfr0h7oQBQpOX6NvCac267f/4f6jJqvfGyZOtDrl+bzIs4514H7sTLKG41s3vNrDDO5UPxhvkCv2B3Ab8EApnJAan2yR+i7Q3s8M9PNbP3/eHWXcBpQK/67uF7HtjPzIbjzffa7Zz7MM61RXiZtkQMAAIBUcBa6jJ0l+JlzZaa2Udmdno99wpdLVuKF7gFXiP4PvrDukUN9OtW51w351w/59yZzrmVIY+tj/ssGIz3x0Wk3kBHYF7IZz3db0/EAEI+fz/7tp7wTGZ9/YK6eYAHAKv89+GdkLYOeHM3Q/Xy34duzrlb/bbGfL4i7YICQJEWyJ9ndR5wnJltNq+sxk+BcWY2DtgGVOP98g4YUs8tS/B+mQeErdJ0zv3dOTcB2A8veLk28FDEfdYDq0N+wXZzznVxzp3mP76pEX2K5yy8n+1D81Y+P4OXPerrnOuGN5RoDd3EOVeOl1W7CG/4N172D2AmXkY1ERuBHmYWujhkCPCF/7qfO+fOxxvW/SPwtDV+pekmvMUcQPDfQ8/4lzeovuzhemIvhNgOlAH7h3zWXf2FJonYiPcHA+DNNcX7t/FFgv0CLwAchzdM/Lbftti/zxTgI/9zbshM4Gw/aygiKAAUaam+AtTgBWTj/a998X4JfssvJfIs8Fsz6+jPGatvvt184Bz/2pF4WSoAzOwQMzvMz7yV4M0rDMyV2gKE1hL8ECj2J+93MLNs8xaMBBZ7PIm3gKO7mQ0CfpzoD2xmPczsQrxM5B+dc0V48+Ly8QNeMzsVb85iov6NNxR6JvUHgDcCR5rZn82sn9+fkf7CiW6hF/pD2+8B/2dmBWZ2IN77+aj/vIvMrLef8QosIGns3LOngTPM7Eh/ztxvSSDoTdJjwGQzO8/McsxbXDTe7/99eHMu+wCY2cCQ+Z4NeRKYYmYn+v+2fgZU4L13CXHOrcD7N3glfgDonHN4Wb8rSWz+H8BteHNIH/bnPAZ+ltv8z0+k3VEAKNIyfRtvftg659zmwBfeUO2F/orJH+ENGW7GWyX8YD33ux2oxPtl+jDhCwEK8X7R78QbsisC/uw/9gDeMOouM3vODzxPxwtIV+Nlie7HW6QA3mratf5jr1F/0BWwwMz24s1duwxvztlvAPxh1p/gBRM78earvZDAPfGf/y5e8PWxcy7ucLQ/XHoEMAxYbGa78TKPc/FWj0Y63792I/A/4EZ/IQTAl/177MVbEPKNeua4xevPYrzg+b942cC9eIthKhpznwRfax3esPrP8Ibd5+Nl3QB+gfe5vO+vIJ6JV64nkfsuw8u+3oH37+QM4Ax/TmNjvIU37PxuSNvbeBnWhAJA59wOvLmHVcAHZlYMzAJ24/18Iu2OeX9MiUhb4g911QBD/V/w7ZaZvQ78xzmX9p0vmou/sncXMMo5tzrT/RGR1k8ZQJG26Ut4Q7nteksuf2j6YOCJTPelsczsDH/IvhPeHMhPgTWZ7ZWItBUKAEXaGDM7F3gDr0xJY4fb2gwzexhvyPKqiBW7rcVZeEPMG4FReEPJGrIRkbTQELCIiIhIO6MMoIiIiEg701SbgjeLXr16uWHDhmW6GyIiIiIt0rx587Y756IKuLfqAHDYsGHMnTs3090QERERaZHMLGYJLA0Bi4iIiLQzCgBFRERE2hkFgCIiIiLtjAJAERERkXZGAaCIiIhIO6MAUERERKSdUQAoIiIi0s4oABQRERFpZxQAioiIiLQzCgBFRERE2hkFgCIiIiLtjAJAERERaVWqamqZfNubPPju6kx3pdVSACgiIiKtyrLNxazYupffvbgk011ptRQAioiISKtSVlWT6S60egoARUREpFUpq1QAmCoFgCIiItKqlCoATJkCQBEREWlV9pRVZboLrZ4CQBEREWlVfv7Mwkx3odVTACgiIiKtUm62ZboLrVZGAkAz62ZmT5vZUjP7zMyOMLMeZjbDzD73v3fPRN9ERESkZTthbB8ACgtyM9yT1itTGcC/AdOdc2OBccBnwHXALOfcKGCWfy4iIiISpqqmFoBa5zLck9ar2QNAM+sKHAs8AOCcq3TO7QLOAh72L3sY+Epz901ERERavsAqYIV/yctEBnA4sA140Mw+MbP7zawT0Nc5t8m/ZjPQNwN9ExERkRauotoLAGtrFQImKxMBYA5wMHC3c+4goISI4V7nnCNOYG9ml5vZXDObu23btibvrIiIiLQsFVXeELBGgJOXiQBwA7DBOfeBf/40XkC4xcz6A/jft8Z6snPuXufcROfcxN69ezdLh0VERKRl2LKnnM+37gU0BzAVzR4AOuc2A+vNbIzfdCKwBHgB+Lbf9m3g+ebum4iIiLRsT3y0Pnis8C95ORl63R8Dj5lZHrAKuAQvGH3SzC4F1gLnZahvIiIi0kLdNmN58FgZwORlJAB0zs0HJsZ46MTm7ouIiIi0TloDkjztBCIiIiKtzsSh3XHKACZNAaCIiIi0Ol8a2FWrgFOgAFBERERaja4dvO3fuhTkaA5gChQAioiISKswbeEmdpdVcfJ+fTEzzQFMgQJAERERaRWufnI+ALvKqjC/TfMAk6MAUERERFqFimpvB5APV+8gy7wQUPFfchQAioiISKuT5acANQ8wOQoARUREpFXJMsjyI0DNA0yOAkARERFpVf76jYOCx9v3VjT6+Z9vKWbT7rJ0dqnVUQAoIiIiLd7cNTuCx2eOGxCcA3jk1Ne58/XPE75PTa3jpNvf4oj/e53Nu8vT3s/WQgGgiIiItHjPz98Ydh6YAwhw62vLSdQzH28IHh/+f7NS7ldrpQBQREREWrzc7PCQJZABbKyfP70wHd1p9RQAioiISIsXiPc65+eEnTdGURLzBdsqBYAiIiLS4i3ZuCfs3JKIAH/93KKw82NG9UqpT62ZAkARERFp8easKgKgeydvL+CsJDKAryzaHDwuLMhJehi5LVAAKCIiIq3GrV8dB4TPARw3uFuDz9u6J3zF75h+Xaiorklv51qRnEx3QERERCRR+/TpDITPAexfWNDg86ojKkbvrahhbVFJWvvWmigDKCIiImlVXF7F8/O/SOs9jx3dm6E9O9Krcz4QPgdw+uLNPD1vQ7ynAlDp7yMM8PB3DuWzTXsorayhtp1uJaIAUERERNLqumc/5cr/zuezTXsavjhBVdW19O1Sl+mLnAN4/bP1l3epqqkLAI8Y0ZNvHDIYgMqQ9vZEAaCIiIikVWCHjRueW0RJRXVa7llRXUNeTl3YErmAo6qm/kxeaKCXl5PFPr29oeTIoeH2QgGgiIiIpFW2H5zNXbuTu2avSMs9K2tqyQ8JAHeUVDbq+btLq8LOc7K9PlYrAygiIiKSuoqQoKq6gcxcwvesqg3LAP5tZuL7/wJccP8HADx66WEA5Pg7izSUOWyrFACKiIhI2jjnWLB+V11DmkrtRWYAr5i0T8LPnbOyKHic62f+cv1JhNW1ygCKiIiIpOSJj9aHnQfm2qUqMgN4+IieCT93+Zbi4HG2H/gFvqcrQ9naKAAUERGRtPlw9Y6w83QFWF4GMDt43tAuHtuKK4J9ufGFxcH2zgVeCeTc4BCwMoAiIiIiKelSEL7HRLp229hRUhmWAazxV+92ysuOef1Zd77Def+cE9U+tl8hULcI5POte9PSv9ZGAaCIiIikzeAeHcPOQwswJ2Phhl3M+mwLALOXbQ22BwLAcYO78Z2jhtM5Pzzw3OiXoimvih2A5mR5IdD3HpmXUv9aK20FJyIiImlT4Qd8P5o0kjvfWJFSALhk4x7OvPPdYJZv5ba6rdsCizeys4zO+dmUVFbjnAvbIQRg7A3TY947sBikvVIGUERERNLCOceLCzYCcPVJowGoSqHQ8q4yr9ZfSaWXxSsMGV4OZABzsoxO+Tk4B2Vxsn2xBMrAtFft+6cXERGRtJm9bBtLN3srbrOyjJwsS6nQcklFeEB314UTgseBHTxysrPo6A//7m1g15EfTRoZPO4YZ+7gna9/zrjfvYZzbXt1sAJAERERScqe8iq+/8g8tuzx5tstCym3At5K21RW2e4qDd/to1eXvOBxjl/GpbAgl875XjAXCBh3l4Xv+hG4/ppTxgTPu3bIDR4X7a1gW3EFALe+tpzdZVWsaOOLQxQAioiISFJeW7yF6Ys388fpSwGY+srSsMdzsi2lnTamL9ocfr+sunl7k8b04dpTxnDjmfvRKc/LAAb2HV65LTp4O3pUr7Dz0EUjE26aySE3zwx7vK3vEKJFICIiIpKUQDwWb7Q0NzsrqZ02dpVWMv73M6Las7Pq8lZZWcYP/SHdQDAXCAB/8Gj0yt7IuoG9u+TX24daDQGLiIiIRAus74hXk7mqppZH31/H2qKSqMe27inn5NvfZPveiqjHYgV/EJ4BDBWYA1hS6QWAhQW5UdeUVobPD8zNzuL3Z+0fu+PUzTFsqxQAioiISFJq/SAp3q4cxeVe0HXTtM+iHjv0llks37KXiTfNjHosnpw4pVsCgWFg2DZyuBeiF5QAdMwLHwi97OGPgsc1CgBFREREogWGSV/+dBMbdpbGve6DVUX13ifRFbfZcTKAgcAwEJCWV0UPOxeXRy8MiVwJPPOz6ELTbZUCQBERkVZg8+5yfvifj4Pz3FqCGj9wK62s4eg/vhH3ur6FBUxftJk/v1q3SOScgwYGjzf5u3YERG4nF5CTFTtsyfYzkIH+VITUAxzVpzMQu0RMvFIwQFJzF1sTBYAiIiKtwG+eX8S0hZvY/8ZXefDd1ZnuDlA3BzDUhKHdefe6E8LaPt+6l+8/Oo9/vLGS3aVeJq5n57qSLkdOfT3s+tF9u8R8vXhDwFl+ZjCQtasI2X2kb2EB4AWpkSKHgEO18fhPAaCIiEhLVl1Ty46SSl5bsiXY9rsXl2SwR3VqYtT4mzi0OwO7dQBiZ9iWb/VqBUaWWQkMAzvnmLd2Z8zXy44z1zDQHhiSDt3/NxAA9utaEPW89pwBVBkYERGRFuz3Ly3h33PWRrUv3LCLAwd1y0CP6sSqlReapZv/m5MZ/etXwh5fva2EFVv38tB7a8LaK6prKcjN5pWI2n+h4gVs2cEMoHdeXl0XAHYpyOGvXx/PhKHdo57XKT9+GBRvDuCj769lvwGFHDwk+n71efi9Nby5fBunHdCfLgU5nLJ/v0Y9P90yEgCa2RqgGKgBqp1zE82sB/AEMAxYA5znnIv9J4CIiEg7ESv4A/hiZ1nGA8DKGBnAwI4aAHk5WZw1fgDPz98YbCvIy+Ynj38CeLX4AtcHyq6siSgZ852jhvOvd1fz0a8mY3EygIEh4GueWkB2FqzZXkq3jrnsKq1i8r59Y64KhvBi0JHiBYC/fm6R18+pU+I+N5YbX1gMwMZdZQzp0THjAWAmh4AnOefGO+cm+ufXAbOcc6OAWf65iIhIu1XfStT6slfNpbI6OgB8YcHGsPORvTvHfU5osLjc30Yucpj3mNG9WDN1Sr2Fm0Of89MnFvDFrjIOHtKdNVOnxA3+AHp0ygs7nzSmd/C4qVYB7yytDNuGLlNa0hzAs4CH/eOHga9ksC8iIiIZ99Tc9WHngRWtEL7QIVNi7fPbKWJhRYeIYdvIoPHQ4T0AuPK/XlYwsgBzIsFSrMXBHXLjz+8LiCwrk51l/MjfXaSmiXYC2bKnokV8dpkKAB3wmpnNM7PL/ba+zrlN/vFmoG+sJ5rZ5WY218zmbtu2rTn6KiIikhHXPftp2PmJ+/bl4iOHAeELHULFCsqayutLvbp5T3//iGBbt47hAVt0ABje7z5+Zm+vXzS6vKoGM9indycgOqCMJdbikIrq2O9PpHu/OSF4PPOzrZxzsFeepinrAH6+NXqv4uaWqQDwaOfcwcCpwA/N7NjQB523FCjmO++cu9c5N9E5N7F3796xLhEREWmTOuVlc+nRw4HoALCssoZh101j1K9e4a3l23jgndUJF1hO1tLN3rDtAH/VL8Dk/cLzN5ELN34bsYK5zC/PElrCJT8ni6smj8YMhvTo2GA/YhWIDi3qXJ/I0jKBe1XHWOCSrqCwa4fMD99npAfOuS/871vN7H/AocAWM+vvnNtkZv2BxD45ERGRNugvry2LauuYn0N+rpe7KY8YRvzbrM+Dx9/614cAHDKse7MsFAkNAH9+ytiwxzrk1h9qHDaiB7OWbmVPeTXTF22mvKqGgtxszhg3gDPGDUjo9bPi7BCSiF6dw+cW5mR772+sMjDxsq6NdcFhQ9Nyn1Q0ewbQzDqZWZfAMXAysAh4Afi2f9m3geebu28iIiItwZ7yKu54fUVUe35OVnA3jMgafLEWZGzcVR7V1lQG9/CCwMhsXOQQcKTLjh4RPP7DS0uoqPIygI0Rrz5gIg4c1I2vjK8LNPP8ADDW+7m7LHo7uWScfkD/tNwnFZkYAu4LvGNmC4APgWnOuenAVOAkM/scmOyfi4iItHk1tS5sztqBv30t5nW52Ray7Vn4Y8P9OXOhvv/ovPR1sgHPXXEUL//kmKj2+ootQ3j2bk95FeXVXgawMWIOAV99XMLPnzjMW4hyzsEDgxnWyIUazjmOv3V2o/oV8MWusrDzVDKW6dLsAaBzbpVzbpz/tb9z7ma/vcg5d6JzbpRzbrJzbkdz901ERCQTfvrEfMb8enrMOXvzf3MSx/ilTHKysoIrXmtD5qM557jBr08XqbaJFjM88r5Xn3CiX2C5Z+d89htQGHVdIKNWn3MPHgRAcXk1u0qrKMhpXACYFZEB/PWUfRnZp3Ocq+PLz8kO9jcyAHzgndUxs4KxeLuZ1IUxR0VsddcStKQyMCIiIu1SoHZeYFVtqG4d8ygs8FbW5mRb3a4XIcFirB05Akoqq9PZVcCbCxcIOEPn/8USKzsX8NPJowHokFcXjry/qiiYhUtUTsRrNHbtS1386ILDz4Fgb9h10xh23TRumvZZwvd7cu56zr17Dq98uqnhizNEAaCIiEgGfbSmLlO0bkcpG0OGC5f+4cth13btkBvMdoWuSK1v39qSivQsXAgVGmBFBl/1+eqEQcHjOy84iCsnjwLg2pPrFo4EVgE3RuSQqotdSCQuw3u+c2Bm5GVnUVFdS2mc4LmhGoOrtnm7mazdUdpkGdhUKQAUERFpJmWVNfz51aXB1aR3zPqcr90zJ/h4dpaFDeUG5sL95oz9+P5x+3DMqN7BjFpoYPHER3UFo/sVFoS95t6K9CxcCBWafVyyaU/Cz7v1a+OCx9071u3C0bVjblhw+NGa5t0Jdkw/b7g4MBcwPyeLiuqaYImaUN89ZjhlVTXMWVnU4H2dg817mm8hTmOkFACaWUczu8HM7vPPR5nZ6enpmoiISNty7dML+McbK3nw3TUA/GXG8qhrZsUYBu5bWMB1p44lOyt0EUhdEPZeSDDyu7P2D3tueVX6C0PXhAw5B2oBNlZoAAgw9ZwDUurTmqlTgrt4NDbrOWFoD+ZcfwLn+kWg83OzqKyujbnXcVFJJQDn3/d+3DqLgfmDSzfvCeYif3vGfo3qU1NLNQP4IFABBEqAfwHclOI9RURE2qSXFnpzwnaUVMR8fG1RafD4oUsOiXlNYLgzdEFC6DDsKfv3C7s+0R0xGqMx26QFLv3SwPAFIpELRnKys8j1izJ/45DBSfUrsF9wMuVa+nftgPnBdWAIONaij2c//iJ4vHp7Scx7PfTeGgCen78xGCx3Kcj8/r+hUg0A93HO/QmoAnDOlQKZX9ssIiLSwtzz5srg8bBe0SVbwFtpGnD8mD713u+u2XX3G+GXgOnVOS/quibJAIYMPze0yrcx8/H6dPGGr4/Yp2dS/fraxEGcfdBArjh+n6SeH5Cfm01ldW3USuARvTvRt7CucPQj769ln1++TElF/IU2q7Z7277trahm6jkH8J/vHpZS39Il1QCw0sw64G/bZmb74GUERUREJMTUV5YGj6uqa7n/7VVxr40VyMVy+b/nsml3WbA49Ae/nBx1TVNkAGtDMoANFXoOLFoJlHY5YWwfDhzUNea1gcUfuQmUjomlY14Ot399PH0i5kE2lpcBrInKAJ45bgD9u9aten7w3TXU1LqwTOCe8iq65Hu7n5w1fgD/eMMr6D190Wa+cegQjtynV0p9S5dUt4K7EZgODDazx4CjgItT7ZSIiEhbErmYoLy6NiwgjJTocOFrS7bQpSCXnp3zKMjNCi4Q6Zyfw14/K1XRxBnAQA2/ePbrX8gPJ+3Dhf72Z/+6OPbQNtTty5tsAJgu+bneEHBkBvCCw4bw5vJtUddX++9HTa0LK+LdKT8nGADXNvG+zI2V0jvsnJsBnIMX9D0OTHTOzU69WyIiIm3HNU8tCDuvqKrlyxFz9UJdd+rYuI9FKsjNoqSimk55dTmd2dcez73fnABAeVPMAfQDnutOHcuvpuxb77VZWca1p4xtsF4gEMxkBuYCZkpetrcI5L0V28Pac7OyOG5076jrA5nCmZ9tCWtfuXUvx43xrr/o8Mzv/xsq1VXAZwPVzrlpzrmXgGoz+0p6uiYiItL63fPmSqZFFAQur64JzgM8+yBv5WlgLt3dFx4ctZCjPgW52RTtrQxmzwB6dc5n/4HeMGuiu1c0RiCb1adLfr2FnhsrEPglsntIUwpkACNXaWdnGz85YRT/vfzwsPbAMHugvE/AB6t30LuzN2dw/OBuTdjjxkv1Hb7RObc7cOKc24U3LCwiItLuOediDvWuLSrhozU7yMkyzhw/AIDDRvRgzdQpnHpA/0a9Rn5OFtMXb2bLnvAp+IFgqrKeXUKSFRjyTGfwB3XzCaszXDw5Pyc7bO5k1w7ekHxedhZZWcYEf/u7gF/9z6vdGKtA9Oxl3pBxToazmpFSnQMYK4BM9Z4iIiJtQuQcsoCXP90MeEFaICzo3zW5hQuhpWNCBbJo1TFq2aUqUIQ6cg/eVE0c2oP3V+3I+Hy5vOwslm6qq2/4x3MPZGjPjsHC3JFzFNft8D6DJ+duiLpXIPub6axmpFR7M9fMbjOzffyv24B56eiYiIhIa1caYyeJUFU1jq3m6q0AACAASURBVGNH9ebXU/blN2fsX++18QQDjIjt03L8gKMqgQCwttbx1Nz1MYeLH/9wHZNvezOsLVAHMN0ZwKsmj+LuCw+OOc+uOeXnZoUFoWP6dWHf/oX1PMMTOQcwVKf8lpUfSzUA/DFQCTzhf1UAP0y1UyIiIq1VaWU1W/ztv0L3kj1qZOzadllZxmXHjKBzigFCZIASGAKuSmAI+F/vrubapxfysF/AONT1z37Kiq172V1aV1y5pomGgHOyszj1gP7BgsyZkpedRWAUelSfzgyPU7exMRq7v3FTS3UVcIlz7jrn3ET/63rnXOyy2CIiIu3Ahfd/wGG3zALqdv44b+Igrpo8OuradK52rYhYgJDrr6gtLo9fpDjgpmmfefeoZ8Xwh2t2BI9r/URhdoYDtaaSn1sXHl05eVRCzzn7rnfjPjZxaPeMB7WRkvpzw8z+6py7ysxehOgS3865M1PumYiISCv0ybpdgLcApGcnr6DzBYcNDW5TFiqR7FyiIvetDWwZd8+bK+OWlZl062yOGtmTHp3y2FFSyWY/cxlqeK9OrN5eEjbE3FRDwC1FXnbdYo5Ed1IJfO6xLN+S3H7JTSnZDOAj/vdbgb/E+BIREWnTKqpr2BojYKp7vJYyPys3qHsHBnbrwLvXndBk/Tl2VGLz5h55fy0/efwTqmpqWb29hEffXxfceeTR99dFXR8Yunzs/bXBtsAQcFYbDQBzc+p+rtcWb455zcVHDuP2r49L6H57EsjCNrekMoDOuXlmlg1c7py7MM19EhERadE27Czl6D++AcAzPziCCUN7RF1TXF7NnjJv3lyXAu/X7cAEiiEnq6GCzAE3POeVLPnaxLodPAJlTmIJ9P2dkKLIwTmALWxYM13eW1EUPI63Ovu3Z3qLdm566TOKSiqbpV/plPQcQOdcDTDUzBLbsFBERKQNcM7x51eXBc8Xb9wT87r1O0vZU15NQW4W+Tn175ebqu8dN6Le7dOK9no1AhdvDJbuDRu+DezAcfTI6H1qA6tXvxmyk0VdBjCFTrdgFx42JHh82TEj6r3264cMDjs/wC/AndPCs6OpfnSrgHfN7AYzuzrwlY6OiYiItESfrN/F8/M3Bs/jZc/Oues9/vXOagoj9vV94UdHBY/vvOCgtPRpQNf6M4uvL90KwJS/vxNs21lSt6p3Z6mXwYpVBiawl3DoHMNAiZScNhoB7tOnc/A4UJw6nismjQw7P2y4lw1u6cnRVD+5lcBL/n26hHyJiIi0SSUV4fO51mwvZfoib7Vv5FZg1bUuKkAMLfdy+oED0tKnhoKUa59eyLy1O8PaQhd8LN3sLVIIXQW8u6yKm15awtZi77rQ4LCuDExq/W6pthXX7aoSusdyLJ3zczh0WN0UgKtPHs1xo3tz77cmBtu6dYw/xJ4pSRcdMrPewDRghb8FnIiISJsXuSr09pnefrH3f2sil/17btT1hREBYMcGAorG+NNXD+TnTy+M2poslqWbw4eqQ4OcgNCdS+59ayX3v7M6eB5aUDqwCjjdO4G0FKE/a0PBNYRn+zrm5fDwdw4Ne/yK4/dJW9/SJdkyMJcBt+BlAIeb2eXOuRfS2jMREZEWKDQDOKJ3J1Zt88rfxgr+AAoLwn/VJhJQJOq8iYM59+BBCZVjCfQzIFYAWFldy86SSg76wwxGRBQ/Di1ZU9tEhaBbipP269uo6wOB8NRzDoj5+HcbmEeYCcn+GXIVsL9zbpuZjQAeAxQAiohIm7c3JABMZH/X6Axg6gHgQ5ccElz0kWgQ9kBINg/gmY+j962tqK5l/gZvUG/V9vCAMXQOYHUT7QXcUnTIbdxnFBgSH9KjY8zHW1oRaEh+DmClc24bgHNuFRBd3VJERKQNWrejNHgcmDsX6rjRvZl9zfHB88hFILnZWRwyrDt/Pz/5BSDHj+nDUTFW7EZ66JJDGnXfiuoaymPsXzy0Z8ewOYBtPQPY2IDtF6eOYWy/Lowb3K2JepR+yWYAB5nZ3+OdO+d+klq3REREWqZ731oVPC7IzQqbE3j5sSP45Wn74pzDDJyLvUr4qe8f2Sx9LWhkJquiqpYXFmwMa+tSkEPXDrkx5wC29FInzWXC0B5Mv+rYTHejUZLNAF4LzAv5ijwXERFpk4b06EiWwYLfnMwxEbtvDPCLBpsZfowUtfiiOSWy13AgiDtseA+KK6rDAj2AmVcfR152VngA2MZ3AmkPkt0J5OF0d0RERKSl21pczrodpXTKy6Zrx1yuOH4fZizZEnx8QIydPhZ9kbkAMFadvm8dMZR/z6nb1m384G7MXbszOKdw5mdbw67vW1hAbnYWVdUhi0Bc294JJF0++OWJLXaYvI1W8BEREUm/wEraEn+e3EFDuvO/K+qGcwd2jw4Abz77S83TuRhyYmQAl2+pm7d4wWFDONgvIdMvxpZnZ47z6hTm5mSFLQIJHLbU4Kal6FtYQK/OLXOZRPqKEYmIiLRxpZXeCuA/fKUuqDtoSF0NvkHdoleBZjIAiDUHsHvHuh1cuxTkcO3JYzjjwAF8tGZH2HVrpk4JHudlW8xFIBoCbr0UAIqIiCSguLyK7zzk1fo7cWyfsMce/+7hbC0up2uMHR9iZeGaS2iwF9CjU11blhk52VkcMKgrC7+Iv6dDQW42O0oqg+eBMjAaAm69UgoAI1YCB+wG5jrnnk/l3iIiIpnmnOPxD9dz2Ige4duD5Yf/+jxin55x75Gbwf3SQoO9ADO45KhhPPjuGkLDt8DCjli2FVeweU85T85dz9kHDQzWENQQcOuVagawABgLPOWfnwusBsaZ2STn3FUp3l9ERCRjPlqzk1/+71OG9ezImqK6+n+dGlHMuSAnfTt/JOO9607gyKmvB8+dg51+Nm/LnrqgNl4RY4BNu739gF/+dBM7SiqD+wq35QDwmR8cETOD2lakGgAeCBzlnKsBMLO7gbeBo4FPU7y3iIhIRm3aXQYQFvwB5DQiq9cpP7MB4IBuHejTJZ+tfgbzaxMHY8Bz8zfyg5A9aiNL2oQq7OCFCzW1jp2ldUPBbXkIeMLQHpnuQpNKNS/dHegcct4J6OEHhNGbDIqIiLQi9729quGLGtC5IPPT7QPD0E9//wjGD+7GuMHdWDN1CiP71P0Kz84yjhoZeyi7sz/k/cGqHeSHBL/ZGZzfKKlJ9V/ln4D5ZjYbMOBY4BYz6wTMTPHeIiIiGRWrhl/o6thE5Gd4CNjrQ2L7BlfXePMAf3/W/mHtgT1/K2tq+fvrK4LtHRu504i0HCkFgM65B8zsZeBQv+mXzrnAHjLXptQzERGRFmbZTV/OdBeS0sXPQsZf5uEJLAQZ268wrP2AgV15b2VR1PUqA9N6pWNpUhawDdgJjDSz1rUZnoiISAzF5VVh5/dcdHCjsnmd8zM/9BsQmLNYW89KXwgp7xIR2F1zypim6ZhkTKplYP4IfB1YDAQqRDrgrRT7JSIiklEH/Pa1sPMuBdE1/urz9s8nUV5dk84uJS0Qz9VX6gXqtnjLiQgAM1nKRppGqn+efAUY45zTgg8REWnTujRyMUf3GDX4MiUwh6+B+C84BzDWXMH9BxSyeGPdnMiZV2vArzVLNaRfBTTuTyKfmWWb2Sdm9pJ/PtzMPjCzFWb2hJm1nP9yRESkXakK2fc2oLEZwJYkMBzdUNWWW782jpP368uYfl2iHrv06OHB44uPHMbIPtHXSOuRagawFG8V8CxCyr44536SwHOvBD4DAjNN/wjc7pz7r5ndA1wK3J1i/0RERBptb3l18PiJyw/nnRXbGdYzfqHklm7quQfyyJw1HDqs/tp2+w0o5N5vTYz5WOi+wr/48th0dk8yINUA8AX/q1HMbBAwBbgZuNrMDDgBuMC/5GHgtygAFBGRDCgOCQAPGtKdw0bE3+qtNejdJZ+rT05tIUcHf/eTY0b1Ch5L65VqGZiHk3zqX4GfA4H8cU9gl3Mu8F/cBmBgrCea2eXA5QBDhgxJ8uVFRETiK67wVgDfc9EE8nK0AAKg0J8DubeiuoErpTVI6l+1mT3pf//UzBaGfH1qZgsbeO7pwFbn3LxkXts5d69zbqJzbmLv3vG3rREREUlWIANY2AJ28WgpDhjYjTPGDWDqOQdmuiuSBsn+y77S/356Es89CjjTzE4DCvDmAP4N6GZmOX4WcBDwRZJ9ExERScrGXWUM6NaBldv2Ai1jG7eWIi8nizvOPyjT3ZA0SSoD6Jzb5B9uB9Y759YC+cA4YGPcJ3rPvd45N8g5Nwz4BvC6c+5C4A3gq/5l3waeT6ZvIiIiyXhxwUaOnPo6c1YW8av/LQKgg7Y6kzYq1YkNbwEFZjYQeA34JvBQkvf6Bd6CkBV4cwIfSLFvIiIiCbvuGW8G0/n3vR9s69k5P1PdEWlSqea2zTlXamaXAnc55/5kZvMTfbJzbjYw2z9eRd2ewiIiIs1my55ySiqjd+3o0YKKOYukU6oZQDOzI4ALgWl+m/LlIiLSqmzYWRbVNn5wtwz0RKR5pBoAXgVcD/zPObfYzEbgzeUTERFpFZxz3PXGiqj2Oy/Qggdpu1KtA/gm8KaZdTazzv4wbiK7gIiIiLQIG3aWMWvp1rC2H07ah0HdW+/OHyINSSkDaGYHmNknwGJgiZnNM7P909M1ERGRpvfxup3B43MPHgS07n1/RRKR6hDwP4GrnXNDnXNDgJ8B96XeLRERkebx0HtrgsfZ/m/FTtrqTNq4VAPATs654Jw/f1VvpxTvKSIi0uScc6wtKmHCkO4ArJk6hSfnbgDgnRXbM9k1kSaXahmYVWZ2A/CIf34RsCrFe4qIiDS5Zz7+gmueWgBAF3/Hj5F9OrNi615O2q9fJrsm0uRSDQC/A/wOeNY/f9tvExERyZhNu8uoqXX1LuRYuGFX8Diw9++zVxzJ3DU7OGFs3ybvo0gmpboKeCda9SsiIi3MaX97m52lVfzx3AP4+iFDYl7TJcY+v4UFuQr+pF1IKgA0sxcBF+9x59yZSfdIREQkRTtLqwD4xTOfxg0A31tZ1JxdEmlRks0A3prWXoiIiDSzT9btavgikTYq2QBwCdDbObcktNHM9gO2pdwrERGRNCmtrKZDbjY7Sirp2TkfgJra8EGsZTd9ORNdE8mYZMvA3AH0itHeE/hb8t0RERFJTW1EcHf1Ewu4961VTLhpJht2lgLw5nJv54+fnTSat38+ifwc1f2T9iXZDOBI59xbkY3OubfN7O4U+yQiIpK015ZsDjvfVVbJfW+vBrxt3376xHw+WuPt/lFZU8vgHtryTdqfZAPALvU8pv1zREQkY97+PLyI8/urdgSPK6trg8EfwNY9Fc3WL5GWJNkh4BVmdlpko5mdigpBi4hIBj32wTrv+2WHRT02f334wo9Dh/dolj6JtDTJZgCvAqaZ2XnAPL9tInAEcHo6OiYiIpKKgd06cOzo3ry1vG5t4qbdZWHXnH3QwObulkiLkFQG0Dn3OXAA8CYwzP96EzjQObc8XZ0TERFJVoe8bO44/6Cwto27ysPOs7KsObsk0mIkvROIc64CeDCNfREREUmbgpxs8rLD8xxv+tnAP3/1QLJMwZ+0X6nuBSwiItIi5edmkRMnw7dv/0K+NLBrM/dIpOVQACgiIm3G7GVefb/J+/alIDcb52LvWrr/gMLm7JZIi5PsKmAAzOwMM0vpHiIiIqla9MVuDrl5Jhc/+BFAcOGHhQzzfvuIocFj0/CvtHOpZgC/DvzVzJ4B/uWcW5qGPomIiDTK6Xe8E3Z+89lfCh4/e8WR5OdkMbBbBx6es7a5uybSIqUUADrnLjKzQuB84CEzc3gLQx53zhWno4MiIiKN9bWJg4PHBw/pDhB3OFikPUp5+NY5twd4Gvgv0B84G/jYzH6c6r1FREQa8sGqooSu07CvSJ2UMoBmdiZwCTAS+DdwqHNuq5l1BJYAd6TeRRERkfi27U18O7cfTtqHA7T6VyTlOYDnArc7594KbXTOlZrZpSneW0REpEHxSr3Ecu0pY5uwJyKtR6pzAL9dz2OzUrm3iIhIIsqrajPdBZFWJ6kA0MyKgdDZtOafG+CccyqwJCIizaK4ohqAS48ezojenejWIS/DPRJp+ZIKAJ1zXdLdERERkWT87+MNAFxz8hg65GVnuDcirUOyGcBC59weM+sR63Hn3I7UuiUiIpKYmlpvQKogV/sSiCQq2TmA/wFOB+ZRN/Qb4IARKfZLREQkIf26FlBeVasyLyKNkOwQ8On+9+Hp7Y6IiEjjvLeyiOG9OmW6GyKtSqplYDCz7sAooCDQFlkWRkREpCks2biH4vJqFm7YnemuiLQqqRaCvgy4EhgEzAcOB+YAJ6TeNRERkWgV1TXkZWdhZnyxqyzT3RFplVKdMXslcAiw1jk3CTgI2JVyr0RERGIoraxmzK+nc/uM5QBsLS4HILsRxaBFJPUAsNw5Vw5gZvnOuaXAmNS7JSIiEq2ssgaAB99bA8Cv/rcIgBd/dHSmuiTSKqU6B3CDmXUDngNmmNlOYG3q3RIREYkWKPlSXF7NX2cuD7YP7dkxU10SaZVS3QrubP/wt2b2BtAVmJ5yr0RERGKoqq3bhOqvMz8PHndUAWiRRkl1EcgBQGBn7c+cc2+m3iUREZHYZi/bGtX2zcOHqgagSCMluxNIV+B5YAiwAK8Q9AFmtg44yzm3p57nFgBvAfn+6z/tnLvRzIYD/wV64hWY/qZzrjKZ/omISNsUmPMX6pKjhjV/R0RauWQXgfwBmAuMdM6d7Zz7Cl4twI+Amxt4bgVwgnNuHDAe+LKZHQ78EbjdOTcS2AlcmmTfRESkHenVJT/TXRBpdZINACcD1znnagMN/vEv/cficp69/mmu/+Xwagc+7bc/DHwlyb6JSDu3fEsxM5ZsyXQ3pAmcMLYPAM/84MhgW5f8lPc0EGl3kg0AK51z1ZGNfltFQ082s2wzmw9sBWYAK4FdIffcAAyM89zLzWyumc3dtm1bkt0Xkbbs5Nvf4rv/npvpbkgT2F1WxREjejJhaHdO2q8vgOb/iSQh2T+bCszsILy5f6EMb25fvZxzNcB4v4TM/6hbSNIg59y9wL0AEydOdA1cLiIibcTCDbuYt3YnZ40fAMC935xArX4LiCQl2QBwE3BbnMc2J3oT59wuv3zMEUA3M8vxs4CDgC+S7JuIiLQC5VU1fOUf7/KLU8ey/4BC+nQpiHttVU0tZ975LgB9C73rzIxsJf9EkpJUAOhv+5YUM+sNVPnBXwfgJLwFIG8AX8VbCfxtvFXGIiLSRq3aVsLSzcVc8uBHAKy85bS4W7rd8vJnweM+WvQhkrJMzJztDzxsZtl4cxCfdM69ZGZLgP+a2U3AJ8ADGeibiIg0k8ipe5v3lDOwW4ewtj+/upSVW0uYvrhucKmwILc5uifSpjV7AOicWwgcFKN9FXBoc/dHRERahtKK8LWF97y5kn+8sTLquj6FygCKpCrZVcAiIiIpWb+jNOz8jtdXBI/veXMlU19ZGvN54wd3a9J+ibQHye4EcnB9jzvnPk6uOyIi6bO3oprOqhHXYl3+yLyw82E9OwaP31wWXubr+lPHMrpfFw4c2JVuHfOapX8ibVmy/2f8i/+9AJhI3XZwB+LtEHJE6l0TEUnN4bfMYtHvTsl0NyRBf399BVefPAaAM8YNYM6qIgBe+NFRHDhIWT+RdEpqCNg5N8lfCbwJONg5N9E5NwFvbp/Kt4hIi7C3IqpevbQQX737vZjtU/7+NjW1LmyByD69OzdTr0Taj1TnAI5xzn0aOHHOLQL2TfGeIiLSCr22eDNjb3iFor3xN4RauW0vw66bxty1O4NtN5y+X/B48cY9LN64m4qqmmBbx7zspumwSDuWagC40MzuN7Pj/a/7gIXp6JiIiLQeldW1XP7IPMqranl4ztqY1xx+yyxO/MubUe2XHj087Dw/J5v1O8sAuO28cdrqTaQJpBoAXgIsBq70v5b4bSIi0o7c+MKi4PHfZ33OsOumMX3RprBrNu8pj3peYD/fUHsrqnjgndWANxdQRNIvpQDQOVcO3ANc55w72zl3u98mIgJ4231tLfb+t1Bb67j3rZXsLq3KcK8k3R7/cH1U2/cfrSsIERkM3nD6fqyZOoX7vjURgBU3n8pvz/CGgs+9e07wupw4O4OISGpSCgDN7ExgPjDdPx9vZi+ko2Mi0jaMvWE6h948ixcXbGTEL1/mlpeXcs3TCzLdrTatuqaW2lrXrK+5/4DCmO27SiuB8GAQoEtEeZ6c7CzG9o++h4Z/RZpGqkPAN+Lt3rELwDk3Hxhe7zNEpF26bcby4PGMJVsy2JO2b+SvXuErd73brK85rGenmO2vL93Khp2lUe3nThgU1ZafE/4r6c1rj09L30QkWqoBYJVzbndEW/P+2SkircLq7SXB48jsT1NyzvHO59ubPSOWqK3F5SxYvyvt9124YTcV1TUNX5gmNbUuKoADyMvJ4tg/vRHWtvQPXyY7xtBuXsjzrz1lDEPjBJUikrpUA8DFZnYBkG1mo8zsDiB2cScREd++MYb6msqri7dw0QMf8NB7a5rtNRP16YbdHHrzLM76x7u8uGBjWu4ZWvtw+97KtNwzEZU1tYzu2yWqPcuM0Nj77Z9PoiA3dlmX0Hp/lx87Iu19FJE6qQaAPwb2ByqA/wC78VYDi0grVVVT2+jnfLZpD2fe+Q6/e3Ext81YTnF53SKP3OzoTM/O0uYLTALDj+tjDENm2hl3vhM8/vHjn6Tlnj/6T91cu60xVt02lYrqGvJzslh205c5eEg3Ju/rre69/tlPw64b3KNjrKcDhAWGudnaql6kKaU6DjPFOfcr4FeBBjP7GvBUivcVkWZWXlXD+h2lnHT7Wxw1siePXXZ48LFNu8voUpAbta/u7tIqnpy7nptf/gzwhh0BamprufaUsQAUFuRSVBIe8K0tKsU51ywT/G+a5vUtu50sJpgXUmB50+5y9q+uDRtabSqV/uvk52Tz7BVHsbOkkoP+MIPdZXV/DDz+3cPruYOINKdUA8DriQ72YrWJSAtSXVNLTkiG5Y1lW7nkwY+C5++uKAoeV1TXcMT/vc7gHh1Yv6OM40b35uHvHArAuN+/FvP+u0qrggFerLlelTW1VNbUkp+T/h0eFn0ROS3ZE6sfbc2sz7ZQXF43BHzFYx/Tv2sBc64/sclfu6K6NuwPhMIOuWGPn3/oYI7Yp2eT90NEEpNUAGhmpwKnAQPN7O8hDxUC2nxTpAWbuWQLl/17LjOvPo6RfTpzw3OLeOT96J0bdpZUsqaohD+/ugyA9Tu8nRneXL6twdd47IN1PPbBOm792riwOm5j+3Vh3KBuPDF3PeVVTRMAbo+zDdmqkEUobVFNrePSh+dGtW/aXc6dr3/Osi17ueP8g5rs9TftLqd35/zgeWTA3b1jXkL3mfWz43Atc72OSJuSbAZwIzAXOBOYF9JeDPw01U6JSNO5/51VACzfUsyIXp1iBn/gle/42VOx6/XNXbMjoYzaNRHP/80Z+7F6e4kfANbQNSJLlA4frt4Rs3384G5pf61UrNq2N633u/etVXEfu/U1rwRPUwWAbyzbyrbiCmYt3Rr3mo/X7Yz7WKjQhSAi0nSSCgCdcwuABWb2H+dcFYCZdQcGO+cS+69cRDLi/VVegFRVU8vqorqs2AEDu3LV5FEs3riH22Ysjxv8AXz1njlh5z+aNJJ9+xfyw/98HPP6M8cN4C/njSM3O4tNu7yFCUs27aFvYUGqP06Uu2avjNneo1NiGajmckKMPXFTsWzzngavqa11ZDXBUHhg+sCg7h3iXtMhzspfEcmMVGcGzzCzQjPrAXwM3Gdmt6ehXyLSxHaUVAbny71y5TG8+OOjOXHfvvxw0sioa3OyjA9+eSInju1DXsTqzAMGduWaU8Yw5cD+3P+tiVx90uiYrxVY1RlY6XnJgx9RXhVdp+6puev5y2vLUv75Ihnw9ufbmLOyqMFrM8U18dhn6PzAdHkhpHzN+YcOCXvs1C/1Cx7fcs4BaX9tEUleqgFgV+fcHuAc4N/OucOApp9tLCJJeeCd1cHj3724hCv/O5+cLGNkn7pht9Ch3VevOpY1U6ew4pbT6FtYQG52FpURZWLOHDcgeDx5v7785MRRUa/7zortweMOeXX/2xl7w3TmRxRBvvbphdzx+ookfrr6mcE3H/iQ8+97P+33TsbkffvSMS88K1aTZLFq5xzLt9QNKS/+3Skxr1u2pTip+8fy/qoivvfIXH4SUr6mIiKgv/uiCcHj/l3jZwdFpPmlGgDmmFl/4DzgpTT0R0Sa0FNz10e1Vde6qJpri353Ckv/8GXG9Asv7Dt98eao5+fnRv9v5JFLDw07Dx1+7ZAbPvPkkwTnhqXKaNpVwDOWbGHT7rKEr/9gdRGj+nbh2lPGBNsig+tEPfrBOpZs8oaAe3XOp1N+DhOGdmes//kFAvzQkiyp+ta/PuTVxeFb+jXF8LKINI1UA8DfA68CK5xzH5nZCODz1LslIk0h0YUQnfNzYu7WcO83J0S1FRZEL+Q4ZlTvsPOwADAi65XVTPX5XBPuUllb6/juv+fy1bvnNHwxcPO0JRSXV7Ng/a6wPXSrqpPrY2gQ/dT3jwDgmR8cyStXHsOzVxwZ/Nz2VqQvAKysjg5WcxQAirQaKQWAzrmnnHMHOueu8M9XOefOTU/XRCQVe8qrqK6p5blPvmDYddMoq6wJZoAuOWoY5x86mPGDu/Hk945I+J7Hj+kTdm4WPgQcanivusDmHxccHDyODBIaiv8e/3BdWna0aMqtgMv9PXe/2JVYBvC+t+uG4rt3rAugK2qS27v3kGE9AC/7F/q+mxkHD+lOFz9I39sEcwBD7Tcgeou/mVcfy8s/OaZJX1dEGi+lQtBm9iBE/1ntnPtOKvcVkdQ45zjwt69x1vgBPD/fm6T/3PwveGWRN4R74xn7J3XfPKV2fwAAIABJREFUvJwsjhjRkzmrinjwkkOYFBEQhnrye0dwyM0zAcKGkiMzfu+vKuKh99Yw46fHhc0/dM6xbW8F1z/7KV8aWMhLP64/iPh8SzFLN8ef45bs/LpElFZ6gVusbe/q88Y1xzOsZ0cOHdaDD9fsoKomuT6+v8pb2DLrZ8fFfLxLgfe/+uKKpgkAV91yGos27ubAQdEZ5pF9ovcHFpHMS3UI+CVgmv81C68QdHqLW4lIo/3TrwkXCP4A3vl8e7zLG+WqyaMY3KNDMOsUT+8u+THbB3QLL/3y8qebWbWthLlrwuv31dS64Ly9L3Y2nFk76fa36t1PtylX2Jb4gVUiAVzo0OnwXp0wM84/bDAAZZWND9DW7ygNfs6Ri0oC8v2t4P40PT2rq3eXhg8lZ2VZzOBPRFquVIeAnwn5egxvMcjE9HRNRJI19ZWlUW3TPt0EwICuqdXeO2xET97++QlR+wInqlvHPF696tio9sjQ6ZqnFvDQe95QaVmMcjGN1ZQZwNDV1VUNLOQoKvF2KjlhbF32tGivt1fyjS8sbvRr7woJxiIX8wSke8/leetiF9sWkdYj3TuEjwLijwmJSLM4sp49V2dfO6nZ+vH+9Scy79eTo9pjBUmRCbrn5m/kH294RZ3Lq2opq4wfBH6wquHafk05B7BfSFC9s6Sy3msDw7XnHDww2FZS4f1soXswJ6q0kVnDf7wRXWLn5mlLmLFkS4yrY3sviX6KSMuSUgBoZsVmtifwHXgR+EV6uiYiyYpXcy0328jLSfffffH161pAz87RQ8GR5WXAWwxS3zDty59u4ug/vs65d78X9dg1T0fvWrJ/xIKE2iYcAu4XsqNJVQOR5tPzNgDQKa8ug5rMZ7J9bwUbd5UF5x8+98Oj6r0+sBNHYG/nUPe9vZrv/jt6H+F47g/JeP7rYg36iLRGqQ4Bd3HOFYZ8H+2ceyZdnROR5JRX1dC3MDrwOnn/fjGubn6xhiovfvDDelfRvr+qiA07y5i3NrpuYEVVdEbxhtP3A+oCn9AA8LKHP+KjNakPYy7fUsyw66Zx9ZN1AWhkpnJXaWXYvL/Az37s6LpSOaEBYKzdUWI59k9vcOTU15nuL+zpFGf+X8ABg7oGj8f8+pXgcTJzIycM7U5utrFm6hROGNu30c8XkcxLKgA0s7H+94NjfB1kZkPT200RaUhNreO1xZuprXWUVlbTu0s+lx87gpd+fDQXHuZt0VUVo3ZbS1FeVcvfZsYvI/qUnzmLZWtxRVRbYOVrILgKHXWe+dlWvnZPYjX76hNr6Lm0sjpskcT4389g9K9fYdrCTdTWOmYv2waE77iSF7J6eOZniQ3FBjJ/T/jFvTs2MCdzV2nd0HSF/+/greXbGH79y8H2xgSDDS0CEpGWLdkyMD8Dvgv8Jc7jPc1sgXPum0neX0QaYeOuMo790xtUhww/jh/cjV+eti8Avz/rS/TpUsDFRw7LUA8Tk855eoFyM4GM212z07O9nHOO+99ezenj+pOdFf039Jl3vgt4u6mEZuV++J+P+fWUfWPes3NB3f+KS0MyiJ+s20nfwgIGdGt4G7WOMQp3hzpx375h28Vd89QCIus2l1bW0CmBxT17y6vp1atjg9eJSMuVVAbQOfdd//ukOF8HAhoXEGkGa4tKOHLq62HBH8BXxtcVaM7OMq6cPIquHaN37ciUmVdHrwSuqU0sQ1nfghCALAsNAL3vxWkqgrxtbwU3v/wZ33zgQ3Lqqfu3p6yK8oih6Q07y+iYl81lRw8Paz/jwLrPKpCF27qnnLPveo8jp76eUL9Cg8hYrjh+n7Dzp+dtYM320rC2HQ0sYAHvj41lW4rZU9a0RaVFpGklOwR8Tn1fAM65k9PbVZH27cmP1vOn6UtZsnEPa4tKgu3H/Xl2zOsvPmp4zPaWIlaB4OdC6hbWZ9/fTA8e18ZIGz7xvSOCO4zEL41S/2vsrahmb4zCyYH5hkV7o4edQ+0uq6IkYoVubrZRWllDYYfwQDwnpI+/eOZT1hWVhi3WWFZPgWuAE8f2iftzBnQpyOWdX4SvAB/dr3PY+aIvdtd7D4CfPjEfgDkJrLwWkZYr2SHgM/zvfYAjgcCfqJOA94BnU+yXiET4+TMLAbhr9spg24yfhmfRHrz4EJZvKeZ7x4Vne1q6wT06sH5HYtuoRaqKkTXMyQqUkCZuli43xvBtqC/d+CoAa6ZOCWtf4wffO0ur+HxL/MDs1L+9zVsRJXcCW8AVNpCtO/bPb4Sdby0uj1o5nZttwcLTsfZtjmVQ945MOaB/sCbkYx+sC3t8T3nDewUHthOMV+hbRFqHZIeAL3HOXQLkAvs558719wDe328TkWZw0u1vMbhHB44e2Ys1U6cwaWyfVhX8BVbo/vOiiYzs05nRfTs38Ixo1TF23+jaITc4nzA7TqqvvuHb+oQOk4bu6RtLZAYwIDIDCPDRr6LrJQZEbp8H4bUH83MT/195YHU0RNde/MUzn0Zdv6Okkg9XeyumH/tgbXC7va9OGJTwa4pIy5NqQbDBzrlNIedbgCEp3lNEIqzZXhL3sfU7yhjas3VOyL/1a+PIzjKG9+pEQW4We/15evdcNIHvHTsioXvECgCH9+oU3PkjO3Klgy9ee0PyGhhqDRXYezlSrJi0viAuVuHs0DqCXWMElPH0a8ROMD95/BMO/sMMzvvnHJxz/Op/i4KP/XTy6ITvIyItT6oB4Cwze9XMLjazi4GXgZmpd0uk/Vi/o5Qn/VIe8Uz6y+yw8znXnxB2vqus4aG7lmjKgf1ZectpdMjLJj8nO7hQIy/HWFtUGvM5x43uzbjBdfvOxhoCNrNg3b9Y2TOIPzewIZUNbPUW6u+zYpe1iVVCJTSgi1QRo3xPaG3B9Ttiv1eJCH0vLzlqWNhjLyyom5MZut0dJFe8WkRajlQLQf8IuAcY53/90zn343R0TKS1qKqp5Z9vrqQ4gflTsVx4/wf8/OmFbNgZ/5d4YKjuR5NGMvfXk6N2+vhOxC/u1qggN4tif9FFbnYWPzphZPCxwNDwvy6eSOeCHL7YWRrMisXKAAINZgA7JDhvLnIhSFXE6/Vp5Fy4O84/iP9n777j26ru/4+/Pt5xnL23s0MCIYQQQhhlbwgFShllU/qjpS1Q2jIKoZRSSvnSFkoHpZS9yiwNe88QAknIJiF77+3YlnV+f9wrWbIlW3YsS7Lez8dDj1ydu458HfvjMz6nd4faLba5OcZJ+/SIeU6sADAyYXRoKblE/WbCiPD2iz8cz6s/PZQOxflxv5YAt02a26B7iEh62+M/4ZxzLzjnrnbOXQ1sMLP7mqBeImmvPFDFrS/PYfCNr/K7V+exzy1vRCXbrcvc1dv4waNTKb1uEsv81ptDfv9unZMKAA7o35HO/tJqb11zGHeeMZJXfnIo+/fL/KS8hXnVAVl+bk5UC1PbovzwMbNXbmXDjorw0mVLImZEjxvQkd9+e28AqkItgHECwPYJpsT5pT/5JqRmd2yfjtXB3LXHet2iNW/5/s8PD28fV8dqLPedN5rvjas9iqa8sopr/zOD0usmsdgfDrA7EGSkv7rHL08YVv8HiRA5BtHM2KtHW/JycwgEg7w4bWV4zJ+ItFx7HAD6K3/caWZLgFuBefUc38fM3jWzOWY228x+6pd3NLM3zWyB/2+HPa2bSDK9NG0VD34c3S026tY3mbNqG49NXho3dccdr87jhD9/yOuza6/4cMwfP+Dml2ZFde+9MK16BYxvRSwfNqhrG846oA/Da6x5m6mKIsbA5efmRLVwhbpxc3OMJX7XcGhFjdCs6MK8HJ66/CDOO9BbiCiUHiYvx7jzjJG17leSQMJjgJWbo2cn1wwAIxMnX3nkYH95tK7hsvMO7Eu/Tq3D7+vrOo3VPVweCIbXED7irve45+0FbNpZwYH9O7LkjpMYFdGNm4jQKin79a0+Ly/HCFQ5rnp6Omf949OY6XVEpOVobB7AIWY20czmAfcCywHzk0DfW8/pAeBnzrnhwDjgR2Y2HLgOeNs5Nxh4238vkrZ+/1rsv3VOvOdDfvXiLI770wd8vHADW8sqCQYd5YEqLnxwCn9//5ta55w+uld4+5FPlzLkV6/y3vx1VAUdVz/trTN7wt7psY5vskSOySvIzWFINy/tye3f3ic8acI5eOuab0Wdd/DATgDcd+7oqPLhPdsyuGsJN5y4FwcOqB1U1UycHU+wxlTZihrdsYV+QDc6IpiaeEp1F+t3D+gDwOTrj6qVhy+WWCldaq4PfPebXwMwM4G8fbGUFNZu/czLtaivSaJfHxHJTI3NAzgP+BA42Tm3EMDMrk7kRH/W8Gp/e7uZzQV6AROAw/3DHgbeA37ZyPqJJF1obNiVRwzigvH96Ny6kAE3vBJ1zHkPfMaoPu05aGAn/vZedOD3y+OHUVKUxycLN3DTScO5eHx/TvnLR+H9F/37c07Zt3qFiOtPiL2MWEvxUkQS6IK8HIryc8M5+F72JyM45xjUtTpVzJZdFeEZsCN6RbeEFhfk8aYfLMaaJBFrZm0sNQPA0BjAF344nm//9RMuObg/v5mwd9RM3Mgcee1bFQCJz76NHJs4bkBHvlqxNe74uxPjjBmsT05EQB2Sn5PDzojxjmu37W7UtUUkMzQ2ADwdOBt418xeA54CGpxTwcxKgf2Az4BuESll1hBnKTkzuxy4HKBvX2WckeZVWRXkx09M40dHDMI5+MFhA7j2uKF1njN9+RamL99Sq/wKf2mu88d5XZYdWhfQqXUBGyPyzIUCnx8dMZC+GZrqpTHya+ToO2P/3ny6aCP9u7SOKq+oCobz/cWb7QuxJ4LUnMwRz6yV2/jLOwu48sjBVFYFw+M89+nVrlaS6JDIVrye7RNPuwJQ7K8fXFKYx8OXjA0npI4l9L3TUKFxixMilgvMyzXemFM9LOHQO9+tdR7AjSfuxTHDtdKnSKZrbCLoF51zZwPDgHeBq4CuZvY3M0toCTgzKwGeA65yzm2rcX0HxPzp7Jy73zk3xjk3pkuXLrEOEWlyzjl2V1bx2qw1vDZ7Daf85SMqqoK11tZ97NIDATi2jl+QbQrzeO6Kg2Lue/FHB8cs//lxDRvkn4nOGF2dWLhmipYz9+/NottPrDX7ee7q7eEWurqWdosVAAbqaAF0NVr97nrja6Yu2cTpf/2Ef3ywKO41Y8lrYLqZ0OQU5xyFeblxA9VzxvbF6lvPLo5ubYuYe+vxXDS+NFz29dodCZ07omdbSju3rv9AEUlre5oGZqdz7gnn3ClAb2AaCXTbmlk+XvD3uHMutGzcWjPr4e/vAazbk7qJNKWrn57OsJte48dPTosqD3XvhRwyuDMf/fIIfnPa3nGv9eY134o7a7dPx2KW3HES0246Jlw2pl92zIcqq6zufow1USJyNu//fWdfAC58cEq9+f5i7Tt9dC821zFju+YKGQDPT1sZNeauvuDrllOG888LxtR5TCwdir3vqV3+uL/vxFlxo+ZYxIZqVZDbqACysQm0RSS9NFkmT+fcZr917qi6jjPvJ86/gLnOubsjdv0XuNDfvhB4qanqJpKIxRt28uWyzazcUhaV0885x4sR49MihQb4R+rdoZhubYt465rDWPjbE2rtT2QsWIfWBUy54Sh+cfxQ/n3xAQ34FJmrVX71iJT6kjRHdrGGZqvGW/INooOWG0/ci57tWrFpZ0Wtlr7wNWOU5zUw8Lno4P6N6ipt7weAPzlyMFCdzgbg8csOpIf//fPclytqn5wkc249Lrzd2FZHEUkvjR0DuCcOBs4HZprZdL/sBuAO4BkzuxRYCpyVgrpJFjvirvfC2yN6tuX3Z4xkSLc2vDY7ejmvYd3bhNdDras1ZFBXbxZraJzYvDXbGrRkV9e2Rfzw8EH1H9hC3HzK8HBQU3MMYE1zV1ePGgnNVq1zDGDEPjMoLswl6GB3ZZBWBbVn3caaADtjReNm3DZUbo5FjS18/suV4e2DB3XmwP4deXH6qoTzGO6pf104huKIVUriBc0iklmaPQB0zn1E/AkjdbYeijTU50s2MXf1Ni44qJSKQJCd5QGenrqcl2es4p8XjKFne29M2eIaa+3OXrWNk+/9KKrskUvG8vvX5nHrhBGc8bdPG1yXYd1bRr6+ZIkMjutrAYwM2v7op0SxOk7JjQgoc8wo8pNOlweq4gSAtYOcGTEm8jSHG04cxu2vVKccCrUQ/thvIUy2fWvkGBzRq12z3FdEkisVLYAizSIYdHzn716gNqpPe079y8dR+797/6d8+AtvTd1QEBFP7w6tOGxIFw7zEzF/+IsjNBYqieoLAMf7uf8AdlZ4Y+Ua0gIYmpgRb4JFZAtjqo0f2Dml96+5ZF6iS+iJSHrTat7SIt337kLOfWBy+H3N4A9g+aYySq+bxEvTV4YXvV/8uxPpGWOM3v9+fEjU+z4di8Oth9J0QnkP6wuu9+vbgT+fPSqqrK5TcnIijzOW+i2+8Vr1FqyrnhHbvW3t74cD+zff0nvdaty/Oil283TF1kxMrT98RFoGBYDS4vz0qWn84fX5TF6U2HqmP31qenjbzLjLn2EacvHBpeFuN0muu8/alxk3J5RJqlaLX6ItgDkG78zzkgy8NCP25J7ICR+Tb6g9MqWuezW1Tq2jv/cuObg/g7uWcGpEDr+m9vAlY8PboYDv1Z8eyt+/NzreKSKSYdQFLC3Kf6Yuj1pRoqbfTBhBu+ICivNzueyRqVH7OviD6scP6szXt51Q75qt0vTyc3NoV5zY171m+1fCeQDNwuP+4k02qa+V67xxzZeEPifHyM81urbxWgL7dCwOr3CSLN8a0oUZE48NJ6UG2KtHW/bqoXGsIi2FAkBpUX7+7Fe1yq49dghvzFnLCz88OOoX+9xbj2evm18Lv49s1VHwl/5qJtuuq1XOarQATjxlBGf941MOH9o15vGhbt8T96m9/vJBAzpx8sjktb7FMu83tdMJNbWvbzuBRRt20LnEW8auITPWRSTzKACUFuO9+dW5w/9x/v4cUNqR8kAVPdq14soYMyYjZ392b1vELacOb5Z6StOoOTYt0W7ZMf06hlv+4o2jC137zBhJmMc24/i/kOYYd1eQl6OZ6iJZRAGgtAhfr93ORf/+HPCWyDpuRO2Wm1j+9+ND6FRSUGuJMck8icZIQ7u3YfmmXQCUx1lNI7y8XI2MVU9+fxzjBjR/ACgi0tTUzyUtwovTqpPl7ts78Txle/dqp+Avg31z+4nh7YasUBFaVi5eC2CoNHTJF344nltOGc5BAztpJQwRaRHUAigtwscLNwDe+quxuu2kZWps12hoVnCsFT+gOjAMdSvv17cD+/XNjjWZRSQ7KACUjFcVdCzbtIvv7N+biw7un+rqSAYIxY1VcSLAULEa+0SkpVIXcJorD1TxzNTlVMQZq5RNNuwop/S6Sfzvq+g0L6u2lLF5VyWj+6mFRhJTXxfwTH/d3+bM9yci0pwUAKa5xyYv4xfPfsWkmfFz2zW3neUBpixOLMlyU/lk4Qbe9ZP3XvnENLbsqqAq6Pjkmw189x/ecm8dlKxZ6lHaqRioDuzitQDe+r85QPxFy0VEMp26gNPcnFXemqTllenTAjhi4usAvPKTQxneszptRFlFVTiv3oybj6VdcdPkEVu8YSfnPvBZVNn5/5rChFE9uW3S3HDZoK6tm+R+0jLNufW4cOAXGgO4bns5zrm4Ezs04UNEWiq1AKa58kCV/296BIArt5SFt5+Zujxq3wMfLgpv73vrG012z6Pvfr9W2cyVW6OCP4BBXds02T2l5SkuyAvn9zP/J99f3/uGJ6csj3uO4j8RaakUAKa5HeUBALaVVaa4JrB+ezkH3/FO+P1Dnyyh9LpJ4ff/9+bXUccHgw7nHP+Zujycd60x4nXTRXr32sMbfX3JPpFrA3+0cH3c4zQGUERaKgWAaW7G8i0ATJq5OqX12LqrkgN++1bMfaXXTeLJKctqla/etpv/e+Nrfv7sVxx657vh1syGqKyqbvm879zRzLj52FrHnHtgX/p3VvevJC4ysKs5D+SpiO9lxX8i0lIpAExjgaogm3d5LX/z1myn9LpJXP/8TD5euIHS6yaxKqI7NllenrGKE/78IYs27Igqr7lW7vXPzwxv//G7+wKwcUc5f3l3Ybh81ZbdCd83UBXk3fnrWLvNO+ei8aWcNLIH7Yrz+eqWY7n//P05Z2wfnrtiPLd/e58Gfy7JbjkR377BGhHg67PXhLdXb038e1ZEJJNoEkga2747UKvsySnLeMVvDZy2bAs92yd3FYsfPzkNgG//9ZNw2XUnDOOxyUtZsbl2ADp+YCf6dfJa437jz6QMWbm5LNxS96sXZ9KhuIBrjhkSc6D9na/P5/4PqscUHjGsa3i7bVE+x47ozrEJLvcmLVuPdkUNDtTqagF8d351l/DmnRV7VDcRkXSlADCNbfXH/RXk5lAR0RUaKk/2+vCPfLqkVtm/Lz6AI4Z25fTRvRj727dr7c/NMfr7AeDnSzYDMG5ARyYv2sTjny3lkMGdWbmljMcme91s+/Vtz5HDukVdY2d5ICr4A+japrAJPpG0RK/+9FA27GhYoBY5BrCuIaZnaFUZEWmh1AWcxi769xQA8nJjR3pXPP4lpddNikpmG5p40RRufml21PvcHOOIoV5LXNc2RSy6/UTm33Z81DE5ZrSvkf6la5siAF6dtYa/v/8NOyJaNi95aCo3vuB1H78+ew2l100Kp5mJNLBLyZ5/IGmR2hcXMKhrw74/Ihud35q7NvxHVaRBXUsoKdTfyCLSMikATGNLNnozZ3dVVE+eiLX26c6I/QNueIXLHp7aJPc/Z2wfAD6/8WgOHdyZj395ZNT+nByjMC83quy20/au1aXbJaL17o5X53Hcnz6I2v/4Z8s45u73+cGjX0SV79unPT87ZgjPXTG+1phDkT1R83s0lG9TRCRb6M/bNNahOJ8jh3Xjy2WbWbxhJwB792oXnhkcsvfE1zlnbB96d/BWOXjbXzFjy64KcnKMorxchvzqVcYP7MQT3x9X5z13V1Zxx6vzOHRwZ75Zt5N+nYrp0qaQRy89sN76HjyoE306Ftcq71RS/wodC9btqFX20o8Orvc8kWRZGON7UkSkpVAAmICJL83i4U+XsuSOkxp1/q6KAIGgo21R/JUx3pm3ljdmr+WOM0Zy/J8+oGvbIjbvqqRTSQFvXn0Y97y9gFNH9WTVlt3c+fo8Zq2MbrGomcz2ySnLwjNzDxrQCYBPvtlYb13fmbeOhz5ZwkOfLAHgyIjJF/FMPGU4v355DhZn4aw2MbrRSjsV8+61h9P/+ldinvPlTcfUe18RERFpHPWrJeDhT5cCXr67yNUuEnXEXe8x8pb4K2PsqghwyUNTeerz5WzZVcG8Ndv54GtvJuL789eTl5vDNccOZVDXNhw2pAv/+/Gh9d4zMi3Lp4uqA79X68kn+PXa7VHv9+pR/+oaHVt7LXyRCZtfv+qw8HYg6Dh0cGeOGNoFM3j5ykN47+dHYGb8/ozaKVxycyx8TREREWl6agFsoNsmzWVUn/aMKe2Y8Dlrt5XH3TdvzTaO/9OH4fd/fz86wLz44NIG17Eur89ewwn79Ii7/09vLYh6/71x/eq9Zpsi79soEKyeqTy0e3XguGpLWdwu5O8e0JfvHtCXf7z/Db97dR7nHtiXm04aXu89RZLtkoP7p7oKIiJJoxbARrjmmRlNcp0Fa7fzl3cWRpV9tji6m/bMOGkorjh8YIPu9dwVBwFQVlnFfe8uJBgn90Urf63U5384nsW/O5Ee7erPM9i6IBQARl8zNF/l+4cOqPcalx7Sn58cOYgbT9yLVgW59R4v0pRCic53V1ZPqIo3+15EpCVQC2ACivJz2F1Z3bq1cUf8Fr2aIgOtjTvK6VTizYh9a85aLnuk9mzdmmvm5uXGjtFDqxf87JghnD22L0Hn+PGT0/jREYO48EEvfcyNJ+5Fp5ICjh7ejbZF+eTnGq/PXsvrs9dy9F7dwq10q7aU8eL0lSzZsJOyyipOG9WT0X07JPwZC/2gMVAVHQCee2BfHpu8jLat4o99jPyc1xw7NOF7ijSlG1+YxZZdlfzh9fnhMoV/ItKSKQBMwKg+7Zm8aFP4fWTalbrsqggw/ObqnHYPfLSYXx4/DCBm8AcknNA231/LqrgwL5xm5ZkfHBQ1c/H7h0W3vFVGBGgbd5YDbXhp+kp++tT0qONCCZwTlec39UWu2wtwyykjuPbYoRTlq0VP0l9k8AfQWjkARaQFUxdwAiJb/0JCaVnqsrFGMPe3975h7bbdTFtWO8C688yR4e29erSt99o/+NYALhpfyrlj+0aVd23rBYOFMfLmjY0Yt7hjd4AfPDq1VvAHcMFB9Y/7izSwSwk92hVx/Yl7RZXn5ebQvliTOSQzXX5Y/UMXREQylf7ErYdzjsUbdnLO2L787vR9KL1uEgAbdpSH17WNtGFHOWNue4s/nDmSrm2Lau0/8Pbq5dPGD+wUTs1yxuje/OLZrwCYu3obo/u2r7PrtE1RPrecOqJWeduifCaeMpzDh9ZO33LFEQOZ8m+vJfPZL1bwxpy14X3jBnTkd6ePpLRTccy1eevSqiCXT68/qkHniKSzc8b2Vcu1iLRoCgDrYWa8efVhVPpj+X5x/FDufG1+3HGAa7d5i9L/3A/mIrVrlR+15NTpo3uzcksZ1xwzpNYKH8/+v/GNrvPFcWYvHjG0K89dcRBn/O3TqODvjasPY0i3+tO9iLRU+/Vtz7Rl1QnW35m3FqidokhEpKVQF3ACurYtold7bzbsCXt7KVTKKmOPA4y1DO+LPzqYsf07sqsiEFXepiiP939+BBNG9Yoqf+L7B5KTY+TEWPZtT+3fr2PU+qbXHDNEwZ9kvX17t496n+hYXBGRTKUWwAYKpUmZ+NJsXp+1ln16t+NHRwzDej55AAAgAElEQVQK749MwBzSt2MxBbk5UZMwAApqzPB9/ofj+WbdDsYP7JyEmlc7a0wfHvx4MQDti+ufoSvS0pUHov+gy23gMAgRkUyjFsAGKsr3vmTbdgd4bfYa/vD6/KjZrzNXbq11TsfWBWzaWd2iEJqgMX5Qp6jjRvftwHfG9ElGtaN0blM9MUPjnESo9cdZjn4yikgLpx9zDRQrYNp7opfqxcXq//XNWV29du+0m49hyR0nUZiXmuCrMlBdzwmjeqakDiLppGYKI7UAikhLpy7gBoqVXqU8ECQYdDHHBf4hIr1LSKsUt7pdckgp89Zs467v7JuyIFQkXQzs0rpWEnOlLxKRlk4tgA1kZjHXCP3T2wv4akV19+/po3vx+Y1Hx+zSbWialabWpiifv31vfyW6FQHyc3NqjQF88KIDUlQbEZHmoQCwEW4+ZXitsnveXsD9H3wDwDlj+3D3WaPCK3QA3DrBy9n3+Y1HN08lRSQhgaDjrbnrospCyySKiLRUCgCb0LgB3qSOK48cXGvfBQeVsuSOk6KCQhFJvR27A/UfJCLSwigAbEKhUUQdNX5IJO0N6VbC0Xt1JQnpNkVE0l5KAkAze9DM1pnZrIiyjmb2ppkt8P/tkIq6Jeq9aw8Pb4dW8agMeDMJ83L1G0Uk3b1x9bd44MIDUj4mV0QkFVLVAvgQcHyNsuuAt51zg4G3/fdpq7Rza9679nDGD+zEZYd4k0Ke/XIFAHlqUhAREZE0lpIA0Dn3AbCpRvEE4GF/+2HgtGatVCOUdm7NE98fx5Ql3kdZunEXkPpZviLSOD8+chBf/EoTtUSk5UunMYDdnHOr/e01QLdYB5nZ5WY21cymrl+/vvlqV4cOGvMn0iJ0LimkU4kmaolIy5dOAWCY85bUiLmshnPufufcGOfcmC5dujRzzWK75pghqa6CiDQBjd8VkWyRTgHgWjPrAeD/u66e49PG3r3apboKItJIkSM28nPT6UeiiEjypNNPu/8CF/rbFwIvpbAuDfbZDUelugoi0gjRAaBaAEUkO6QqDcyTwKfAUDNbYWaXAncAx5jZAuBo/33GKPLX1C3tVJzimohIQxjVQV9eTjr9TSwikjwpWQzWOXdOnF0Z24zWrjif+8/fnzGlHVNdFRFpAHUBi0g2SkkA2FIdO6J7qqsgIntAXcAiki30566IZLV+nVqHt9UCKCLZQj/tRCSr3XnGyPC20sCISLZQACgiWa17u6Lwet5qARSRbKGfdiIiPgWAIpIt9NNORMSXl6MuYBHJDgoARUR8BXn6kSgi2UE/7UREfGoBFJFsoQBQRLJeKOzTGEARyRb6aSci4lMAKCLZQj/tRCTrBZ0DtBKIiGQPBYAikvWCXvxHSZFWxxSR7KAAUESy3lVHDwagMC83xTUREWke5vyuj0w0ZswYN3Xq1FRXQ0RERCQtmdkXzrkxNcvVAigiIiKSZRQAioiIiGQZBYAiIiIiWUYBoIiIiEiWUQAoIiIikmUUAIqIiIhkGQWAIiIiIllGAaCIiIhIllEAKCIiIpJlFACKiIiIZBkFgCIiIiJZRgGgiIiISJYx51yq69BoZrYeWNpMt+sMbGime0nj6TllBj2nzKDnlBn0nDJDqp5TP+dcl5qFGR0ANiczm+qcG5Pqekjd9Jwyg55TZtBzygx6Tpkh3Z6TuoBFREREsowCQBEREZEsowAwcfenugKSED2nzKDnlBn0nDKDnlNmSKvnpDGAIiIiIllGLYAiIiIiWUYBoIiIiEiWUQBYDzM73szmm9lCM7su1fXJNmb2oJmtM7NZEWUdzexNM1vg/9vBLzczu8d/Vl+Z2eiIcy70j19gZhem4rO0ZGbWx8zeNbM5ZjbbzH7ql+tZpREzKzKzKWY2w39Ov/bL+5vZZ/7zeNrMCvzyQv/9Qn9/acS1rvfL55vZcan5RC2bmeWa2TQz+5//Xs8pzZjZEjObaWbTzWyqX5YZP/ecc3rFeQG5wDfAAKAAmAEMT3W9sukFHAaMBmZFlN0JXOdvXwf83t8+EXgVMGAc8Jlf3hFY5P/bwd/ukOrP1pJeQA9gtL/dBvgaGK5nlV4v/+td4m/nA5/5X/9ngLP98r8DV/jbPwT+7m+fDTztbw/3fx4WAv39n5O5qf58Le0FXAM8AfzPf6/nlGYvYAnQuUZZRvzcUwtg3cYCC51zi5xzFcBTwIQU1ymrOOc+ADbVKJ4APOxvPwycFlH+iPNMBtqbWQ/gOOBN59wm59xm4E3g+OTXPns451Y75770t7cDc4Fe6FmlFf/rvcN/m++/HHAk8KxfXvM5hZ7fs8BRZmZ++VPOuXLn3GJgId7PS2kiZtYbOAl4wH9v6Dllioz4uacAsG69gOUR71f4ZZJa3Zxzq/3tNUA3fzve89JzbEZ+99N+eK1LelZpxu9WnA6sw/tF8w2wxTkX8A+J/JqHn4e/fyvQCT2n5vAn4BdA0H/fCT2ndOSAN8zsCzO73C/LiJ97ecm+gUgyOeecmSmXUZowsxLgOeAq59w2rxHCo2eVHpxzVcAoM2sPvAAMS3GVpAYzOxlY55z7wswOT3V9pE6HOOdWmllX4E0zmxe5M51/7qkFsG4rgT4R73v7ZZJaa/1mc/x/1/nl8Z6XnmMzMLN8vODvcefc836xnlWacs5tAd4FDsLrigo1CER+zcPPw9/fDtiInlOyHQycamZL8IYeHQn8GT2ntOOcW+n/uw7vD6qxZMjPPQWAdfscGOzPvCrAG1z73xTXSbxnEJoldSHwUkT5Bf5Mq3HAVr8Z/nXgWDPr4M/GOtYvkybijzf6FzDXOXd3xC49qzRiZl38lj/MrBVwDN54zXeBM/3Daj6n0PM7E3jHeaPW/wuc7c8+7Q8MBqY0z6do+Zxz1zvnejvnSvF+77zjnDsPPae0YmatzaxNaBvv59UsMuXnXipmzWTSC2/Wztd442RuTHV9su0FPAmsBirxxkVcije25W1gAfAW0NE/1oD7/Gc1ExgTcZ1L8AZALwQuTvXnamkv4BC8sTBfAdP914l6Vun1AkYC0/znNAu42S8fgBcYLAT+AxT65UX++4X+/gER17rRf37zgRNS/dla6gs4nOpZwHpOafTyn8cM/zU7FCNkys89LQUnIiIikmXUBSwiIiKSZRQAioiIiGQZBYAiIiIiWUYBoIiIiEiWUQAoIiIikmW0EoiISB3MrAovZUM+EAAeAf7onAvWeaKISBpTACgiUrcy59woAH+5pyeAtsDElNZKRGQPqAtYRCRBzlvu6XLgSj+bf6mZfWhmX/qv8QBm9oiZnRY6z8weN7MJZjbCzKaY2XQz+8rMBqfqs4hIdlMiaBGROpjZDudcSY2yLcBQYDsQdM7t9oO5J51zY8zsW8DVzrnTzKwd3soog4E/ApOdc4/7y0vmOufKmvcTiYioC1hEZE/kA38xs1FAFTAEwDn3vpn91cy6AGcAzznnAmb2KXCjmfUGnnfOLUhZzUUkq6kLWESkAcxsAF6wtw64GlgL7AuMAQoiDn0E+B5wMfAggHPuCeBUoAx4xcyObL6ai4hUUwugiEiC/Ba9vwN/cc45v3t3hXMuaGYXArkRhz8ETAHWOOfm+OcPABY55+4xs77ASOCdZv0QIiIoABQRqU8rM5tOdRqYR4G7/X1/BZ4zswuA14CdoZOcc2vNbC7wYsS1zgLON7NKYA1wezPUX0SkFk0CERFJAjMrxssfONo5tzXV9RERiaQxgCIiTczMjgbmAvcq+BORdKQWQBEREZEsoxZAERERkSyjAFBEREQkyygAFBEREckyCgBFREREsowCQBEREZEsowBQREREJMsoABQRERHJMgoARURERLKMAkARERGRLKMAUERERCTLKAAUaYHM7CIz+yji/Q4zG5DiOh1uZiuSeP1DzWx+xPsl/pq8TX2fUjNzZpa3B9fo6z+T3KasWyPrcoOZPZCE695mZhvMbE1TX1tE9pwCQJEMYmbvmdlmMytsyHnOuRLn3KI9vPdDZnbbnlyjnus7M9vpB0YbzextM/tuouc75z50zg1toroMMbP/+AHMVjP7ysyuaaqAzTm3zH8mVU1xvUj+c6rwv46bzOxNMxtWR11ud85d1sR16Av8DBjunOveRNcMB/T+HzhV/mfcZmbTzexkf9/h/vfSCzXO39cvf68p6iOS6RQAimQIMysFDgUccGpKK5M8+zrnSoChwEPAX8xsYnNWwMwGAp8By4F9nHPtgO8AY4A2zVmXPXCn/3XsDazD+1rWsietmPXoC2x0zq1r6IkNqNOn/mdsD/wLeMbMOvj71gMHmVmniOMvBL5uaH1EWioFgCKZ4wJgMt4v8wsjd5hZJzP7r98aMgUYWGO/M7NB/vZ7ZnZZxL5wd7F5/mhm6/xrzTSzvc3scuA84Bd+q8vL/vE9zew5M1tvZovN7CcR123lt0ZtNrM5wAGJflDn3Abn3KPAFcD1oV/kZnaxmc01s+1mtsjMfhBxv5hdzGbW3cx2RQYDZjbar3N+jNv/GvjEOXeNc261X5/5zrlznXNbYly/p/+132RmC83s+xH7xprZVP9rudbM7vbLo7qR/WfyGzP72P9sb5hZ54jrXGBmS/2W0Zsswe5t59wu4Algb/86t5jZs2b2mJltAy7yyx6LuNchZvaJmW0xs+VmdpFfXmhmd5nZMv+z/N3MWsX4ehwNvAn09L9XHvLLTzWz2f513zOzvSLOWWJmvzSzr4CdDQlMnXNB4EGgFdXf9xXAi8DZ/vVzge8Cjyd6XZGWTgGgSOa4AO8X2OPAcWbWLWLffcBuoAdwif9qjGOBw4AhQDvgLLyWnPv9+97pd12eYmY5wMvADKAXcBRwlZkd519rIt4v5IHAcdQIWhP0EpAHjPXfrwNOBtoCFwN/NLPRdV3AObcGeM//LCHnA0855ypjnHI08GwD6vgUsALoCZwJ3G5mR/r7/gz82TnXFu/r8Ewd1zkX7zN1BQqAawHMbDjwV7wAvAfec+mVSMXMrMQ/b1pE8QS8z9eeGgGRmfUDXgXuBboAo4Dp/u478L4vRgGD/DrcXPOezrm3gBOAVf73ykVmNgR4ErjKv+4rwMtmVhBx6jnASUB751wgkc/n1zkPuAzYASyI2PUI3v8Z8L7/ZgGrEr2uSEunAFAkA5jZIUA/4Bnn3BfAN3gBQ6h14wzgZufcTufcLODhRt6qEq+bcxhgzrm5oVawGA4AujjnbnXOVfhjDP+J3+qCF3D91jm3yTm3HLinoZXxA7QNQEf//STn3DfO8z7wBl63eH0eBr4H4a/XOcCjcY7tBMT7zFHMrA9wMPBL59xu59x04AGqA49KYJCZdXbO7XDOTa7jcv92zn3tnCvDCxRH+eVnAi875z5yzlXgBV2unqpda2ZbgIVACXBRxL5PnXMvOueC/r0inQu85Zx70jlX6Zzb6JybbmYGXA5c7T/P7cDtVD/r+nwXmOSce9N/pnfhtdiNjzjmHufc8hh1imec/xnX4D3PbzvntoZ2Ouc+ATqa2VC85/FIgtcVyQoKAEUyw4XAG865Df77J6huUeuC10q2POL4pY25iXPuHeAveC2K68zsfjNrG+fwfnjdfFtCL+AGINQy2XNP6+R30XYBNvnvTzCzyX536xbgRKBzXdfwvQQMN7P+wDHAVufclDjHbsRraUtETyAUEIUspbqF7lK8VrN5Zva5+RMV4oicLbsLL3AL3SP8dfS7dTfWU6+7nHPtnXPdnXOnOue+idi3PO5Z0Afvj4uaugDFwBcRz/o1vzwRPYl4/n637XKiWzLrqlcsk/3P2Nk5N85veazpUeBK4AjghRj7RbJWsgYAi0gT8cdZnQXkWnVKjUKgvZnti9e1FcD75T3P39+3jkvuxPtlHhI1S9M5dw9wj5l1xWuJ+jlwE7VbnZYDi51zg+PcZ7Vfp9kJ1CmeCXifbYp5M5+fw2vNeck5V2lmLwJW30Wcc7vN7Bm8VsBhxG/9A3gLr0X13wnUbxVeK1ObiCCwL7DSv+8C4By/u/x04FmLnpiQiNV4k2KA8PdDQ68Rqa7Ww+VUd7dH2gCUASOccysbcc9VwD6hN36LYh/8r1MC9WqsR/FaQR9xzu3ybisioBZAkUxwGlAFDMfrFhwF7AV8CFzgpxJ5HrjFzIr9MWN1jbebDpzuHzsIr5UKADM7wMwO9FveduKNKwz6u9cCkbkEpwDb/cH7rcws17wJI6HJHs/gTeDoYGa9gR8n+oHNrKOZnYfXEvl759xGvHFxhXgzPANmdgLemMVEPYLXFXoqdQeAE4HxZvYHM+vu12eQP3GifeSBftf2J8DvzKzIzEbifT0f88/7npl18Vu8QhNIgjTMs8ApZjbeHzN3CwkEvY30OHC0mZ1lZnnmTS4a5df/n3hjLrsCmFmviPGe9XkGOMnMjvK/t34GlON97ZLGObcY+BZwYzLvI5KJFACKpL8L8caHLXPOrQm98Lpqz/MHwV+J12W4Bm+WcF2tV3/EmyW5Fm9sXOREgLZ4v+g343XZbQT+4O/7F1436hYze9EPPE/GC0gX47USPYA3SQG82bRL/X1vUHfQFTLDzHbgtdpchjfm7GYAv4XtJ3jBxGa88Wr/TeCa+Od/jBd8femci9sd7XeXHgSUArPNbCtey+NUYHuMU87xj12F1804MaI78nj/GjvwJoSc3YAxbqH6zMYLnp/Caw3cgTcZprwh10nwXsvwutV/htftPh3Y19/9S7znMtmfQfwWES2T9Vx3Pl7r67143yenAKf4YxobVMUGHo8/dlKTP0RqMOeS0eouIunC736sAvr5v+Czlpm9AzzhnGvylS+aiz+zdwsw2G/hygpmtgk40p9oIyJ7SC2AIi3f3nhduVm9JJffNT0aeDrVdWkoMzvF77JvjTeDdiawJLW1aj5mdiyQS3SaFxHZAwoARVowMzsDeBcvTUlDu9taDDN7GK/L8qoaM3YzxQS8LuZVwGC8ruSs6L4xs6eAfwDfd87tTHV9RFoKdQGLiIiIZBm1AIqIiIhkmYzOA9i5c2dXWlqa6mqIiIiIpKUvvvhig3OuVtL2jA4AS0tLmTp1aqqrISIiIpKWzCxm2it1AYuIiIhkGQWAIiIiIllGAaCIiIhIllEAKCIiIpJlFACKiIiIZBkFgCIiIiJZRgGgiIiISJZRACgiIiKSZRQAioiIiGQZBYAiIiIiWUYBoIiIiEgzeXHaSt6cszbV1VAAKCIiItJc/vHBIp7+fHmqq6EAUERERKS5BKqCFORZqquhAFBERESkuVRWBcnLSX34lfoaiIiIiGSJyipHXq5aAEVERESyRmVVkILc1Idfqa+BiIiISJYIBNUCKCIiIpJVNAZQREREJMtUVgUpyEt9+JW0GpjZg2a2zsxmRZT9wczmmdlXZvaCmbWP2He9mS00s/lmdlyy6iUiIiKSKoEqR15Oy+4Cfgg4vkbZm8DezrmRwNfA9QBmNhw4Gxjhn/NXM8tNYt1EREREmpVzjkDQkd+SJ4E45z4ANtUoe8M5F/DfTgZ6+9sTgKecc+XOucXAQmBssuomIiIi0tx2VVQBUJSf+jauVIaglwCv+tu9gMh1UVb4ZSIiIiItwkvTVwGwu7IqxTWBvFTc1MxuBALA440493LgcoC+ffs2cc1EREREmtaKzbvYWV7F3NXbAOjWtijFNUpBAGhmFwEnA0c555xfvBLoE3FYb7+sFufc/cD9AGPGjHGxjhERERFJF4f8/l0A7jxzJACHDemcyuoAzdwFbGbHA78ATnXO7YrY9V/gbDMrNLP+wGBgSnPWTURERCSZpiz2pkakw0ogSWsBNLMngcOBzma2ApiIN+u3EHjTzAAmO+f+n3Nutpk9A8zB6xr+kXMu9R3kIiIiIk3k8yVeAJgOs4CTFgA6586JUfyvOo7/LfDbZNVHREREJJWWbfI6P/NbciJoEREREakWmvmQr7WARURERFq20X3bR73P11rAIiIiIi1bKAE0QI5BTgtfCk5EREQk62zeWcEn32wIv9+0syK8nS756xQAioiIiDShSx7+nHP/+Rm7K6twzrF+R3l4n0uTCFABoIiIiEgTmrZsCwCvz15DVdDhHHRtU5jiWkVTACgiIiKSBD99ajqBoNfkV1KYktV341IAKCIiIlnpqxVbmL58S6PPn3Dfx5ReN4mKQDBctnDd9vB255ICKqq8feURx6QDBYAiIiKSlU79y8ecdt/HjT5/hh88hhI8A1z+6Bfh7WNHdCdQ5bUAFqZB8udI6VUbERERkSR6cdpK5qza1qTXdBEzO7buqgxvVwaCBPwWwML83Ca9555SACgiIiIZyTlH6XWT+Pv73yR0fDDouOrp6Zx074dNWo8d5YHqOkWUB4Iu3AWsFkARERGRJlDpd6/e8eo8dlUE6jm6uqvWOdhdWVXP0XWbtXJreHtnefW1tuyqzvlXWRVUF7CIiIhIU6qsqp5Y8f8e+7Le4w+/673w9rCbXgtvVwUbnpzv5Hs/Cm+HWgCdc0ReqrIqGK6juoBFREREmkBkAPjB1+sbfZ2BN7xCsBFBYEgoAFy8YWe4bO9ebQlUuXAr5ckjezT6+smQXklpRERERBLwyszVLFy3o8mut213Je2LCxI+vlf7VqzcUgbATj8ADK35e+URg/ho4QYqqoLhMYCdWhfw22/vTb+OrZuszntCAaCIiIhkFOccP3y8/i7fhti+O9CgAPDA/h35cOEG1m8vZ8lGr+Uv1CK5f78OfLZ4I4EqR7k/1rAoP5fzDuzXpHXeE+oCFhERkYyydOOu+g+qwdWzCG9FVcMSNQeCjtYF3ri+bWWBcBlAXq6Rn5tDZVWQ3X4C6KL89Aq50qs2IiIiIvXYFDHTNlH1rcQRmq2bqCrnyM0xerYr4rkvV7BxR3m4BTAvJ4e83Bwqg9UtgIV5mgQiIiIi0mjbyipjlocmclQEgqzbvjtqX3ll3QFgZQNbAL9cupl128tZtdW7z22T5oaDyPxcY2tZJTOWb1ELoIiIiEhT2LY7ds6/Wau83Hw3vDCTsb99m/JAdX6+3YG68/41NBXM6q272R5RjyUbd4aXhsvLzQlv71YLoIiIiMiee/CjxTHLZ6zYyu7KKp79YoX3fnl1suZQIHbXd/Zl6q+O5sR9ukedW1ZZRel1k7j++Zlc88z0BieKnrZsC//35tcA5OVYuPwXz34FQKFaAEVEREQaLzLAinTTi7MYdtNrDO5aAsCNL8wM79vtdwG3ys+lc0khv5mwN5cc3D+8P9St/OSUZTz/5Urem7+u0fXLz60dXhUpEbSIiIhI463YXFbn/p7tWwGwICJP4O5wOhYv9OlUUsjNpwzn3xcdAFTn8AvZky7bvNzaAWqRuoBFREREGm/NtuoJHiWFeZy6b8+o/T3aFdU6Z8OOcqB2S1zbVvlA9WoeIQX1rN3bpjCPiw8uJTdGa2SsFsr8GEFhKikAFBERkYyxpUYKmB3lAa4+ZkhU2daIWcIBf3bvpQ9PBWrPxg0FZjsbGAAGnSPXjDm3HldrX16MLmAzBYAiIiIijbKzovbkjNwawdWrs9bEPT43J6fGe+/cVVuiu5XjDDMMq3KOnByL2VXctiiPBy8aU/cFUkwBoIiIiGSMmrNzcwxy6ohm9v31G1E5AWvGdaEJGw9/ujSqvL60gEEHOX7g2b9z9Pq+JYV5HDmsW90XSDEFgCIiIpIxymq06LXKz405Di/SrJXV6WByarQWxptRHAjWHQEGgy7cShi6RvtibzxhunX3xpKX6gqIiIiIJKpmC2Crgrx6A8BNOyvJzzUqqxyDu5VE7cuL03xYT/xH0LlwMBlqRfzbefszbkDHuk9MEwoARUREJGPUTNfSqiCn1hjAmjbsKGe/vh0was8CjpWyBbwxfrFs311JYV6u1wXsB56hCSP5uZYRrX+gAFBEREQySFnNFsAEuoB3VVQRDLqYM3vjBoBxmgD3ueWNcCtf6LahmC/eanLnHdi3zvqlgsYAioiISMbYVRGdrqVVfm64JS7uOeUBqpyLGSjmx+kCrmsSyORFmwAoLvBaE8f29wLCnu1r5x8E+O2396mzfqmgAFBEREQyxtVPz4h6X5ifG9UF/OtTR9Q6Z+bKrf6kjdoBYG7cFsDo5rx5a7Zx37sLo8q+WuFNLvn5sUN599rD6d2huNZ1SjvVLksH6gIWERGRjHPksK68M28drQuiu4CHdW9T69jPFnstdqGWukitIsYEjunXgalLNwO1A8Dj//RhrXM7FBcAXuLnmqlgAD6/8ehwK2G6UQugiIiIZJyzxvQGvBm4kS177f2gLJYpfiAYKT9i1Y5A0PEzf1WRyEkgNWceh1x55KA669ilTSGtC9OzrU0BoIiIiGSEYNDRo10Rp43qyag+HQA4/6B+Ubn8enVo1eDr/vy4oQA44GR/XeGg3wK4tayS8sraAwIPKO1At7axx/xlgvQMS0VERERquOThz1m9dTcff7OR7u2KWHLHSbWOKSnMY+qvjual6av4zf/mRO1rUxQ77OkdChr99X3Baw3cVRFg31+/EfOcmulkMo1aAEVERCTt7a6s4r356wFYv7281v52rfKZeMpwADqXFBKa29GlTWH4mCcuGxfz2qHcfTNWbA2nhQlUBWvlHIxUkJvZIZRaAEVERCTtDbvptfB29xhdrzMmHhv1fp/e7QA4cmhXnp66HCBuvsCVm8vC26FcgRVVQQJVcRL7ET12MBMlrfZm9qCZrTOzWRFlHc3sTTNb4P/bwS83M7vHzBaa2VdmNjpZ9RIREZHM9vbPvlXvMfv368j0m49hwqie4bJ4AWBhRILo0HZFIEhFIH4ywPwYSaUzSTJr/xBwfI2y64C3nXODgbf99wAnAIP91+XA35JYLxEREclgic6sbV9cEBX0xQ0A86vDoVALYHkgyK7KQMzjwVv2LZMlLQB0zn0A1JxvPcjZF6sAACAASURBVAF42N9+GDgtovwR55kMtDezHsmqm4iIiGQOF5GSpaSBaVV6tKueFRxv3F4od+CoPu3Dx5QHgmzYXhF13NF7dQsv65bpYwCbu/bdnHOr/e01QDd/uxewPOK4FX5ZLWZ2uZlNNbOp69evT15NRUREJC1URozF69W+YWleOrTOD293KomdI3D/fh356JdH8MIPx2NmFOTlUBEIsn13ZdRxvzx+aHj2r8YANpLzwvn4oyvjn3e/c26Mc25Mly5dklAzERERSSflgerZuP0auLRaYV51upa6uo57dygOzwYuzM2hPFDFjvLoLuCSorxwF7ECwIZZG+ra9f9d55evBPpEHNfbLxMREZEst3GH1xWbm2Pcdda+DTo3NFavY+v4K4TUVJjvtQB+4S8LF1KQmxMO/Ao0CaRB/gtc6G9fCLwUUX6BPxt4HLA1oqtYREREstjGnV7evwcvOoC2Rfn1HB3NzPj4uiP55LojEz6nIhBk8YadPPW5NzrtH+fvzz692tGuVX54PGKrDE8EnbQ8gGb2JHA40NnMVgATgTuAZ8zsUmApcJZ/+CvAicBCYBdwcbLqJSIiIpmlrMJLx1Jc0Ligq6HjBrftDvDJNxvD748b0Z3jRnT36+J1R2d6C2DSAkDn3Dlxdh0V41gH/ChZdREREZHMFQh6AWC8NC7N6dHJSwF4bfYarjh8YIpr03iZHb6KiIhIi1cV9Lpd81IQAP7qpL2i3pd2ag3A6fvFTFaSMRQAioiISFpasHY7z32xgkA4AGyesCUy6Ks5c/jAAR0BOGhgp2apS7JoLWARERFJS8f88QMADhnUGYC8Zlp9IzLoW7JhZ9S+G0/ai5P26cGQbm2apS7JUm8obWbFZnaTmf3Tfz/YzE5OftVERERE4KOFG4DmGwMYGQB+vXZ71L7CvFwOHJDZrX+QWBfwv4Fy4CD//UrgtqTVSERERCSG5hoD2DpitnFehid8jieRTzXQOXcnUAngnNsFpH4ajoiIiLRoobQvhX7KlVS0AHYsTjyBdCZJJACsMLNW+Mu2mdlAvBZBERERkaTZ5efcKw94aWCaaxJISUQAePUxQ5rlns0tkUkgE4HXgD5m9jhwMHBRMislIiIi2W35pl21ylIxCaRTSctsAaw3AHTOvWlmXwLj8Lp+f+qc25D0momIiEjWKg9U1SpLxRjA/GwdA2hm3wYCzrlJzrn/AQEzOy35VRMREZFstbsyWKusucYAtmrkknOZJJGwdqJzbmvojXNuC163sIiIiEhSvDFnba2y5hoD2FJb/SIl8gljHaME0iIiIpI097y9IOr9AaUdmq1lTgGgZ6qZ3W1mA/3X3cAXya6YiIiIZKePF1ZPNbjzzJEA/N93RjXb/ZurqzmVEmnJ+zFwE/C0//5N4EdJq5GIiIhktfMe+Cy8fdaYPpw1pk8Ka9MyJTILeCdwXTPURURERESaQdwA0Mz+5Jy7ysxexk8CHck5d2pSayYiIiIiSVFXC+Cj/r93NUdFRERERACOH9Gd12avYc6tx6W6Ki1W3ADQOfeFmeUClzvnzmvGOomIiEiWcs4xe/VWRvdtT3GBko4kS51fWedclZn1M7MC51xFc1VKREREstNzX65k+aYycq3lz8RNpURC60XAx2b2X2BnqNA5d3fSaiUiIiJZaeqSTQAs2Vh7LeDmdO2xQ+jXqXVK65BMiQSA3/ivHKBNcqsjIiIi2eK+dxdy7PBu/PPDRWzcUcG/LjqAvFyv5a8oP7XJmK88cnBK759sdQaAZtYFmAQs9JeAExEREdlj89ds5w+vz+cPr8+PKg91/Z66b89UVCtrxA2vzewyYDZwLzDPzJT2RURERJrEll21pxZUBR1llVWYwW2n7ZOCWmWPuloArwJGOOfWm9kA4HHgv81TLREREWnJLMYkj/s/WMS2sgCDu5ZQkNfy1+NNpbq+uhXOufUAzrlFQGHzVElEREQy2daySp6ZurzOY3ZXVtUq+/1r89hZEaB1odK/JFtdX+HeZnZPvPfOuZ8kr1oiIiKSqa5//itembmG4T3asnevdjGPiRUAAny4YAOHDOqczOoJdQeAP6/x/otkVkRERERahmWbvBQu36zfET8ADATjnr9m2+6k1Euq1bUSyMPNWRERERFpGWat3AbA7a/MZcKoXjGPKasIxD1/4bodSamXVNMISxEREWlSw3u0BWDttnKCQRfzmDVbywF44IIxvHft4VH7rjh8YFLrJwoARUREpIkdPbxbePudeetiHrM7UEVBbg5HD+9GaefWLLr9xPC+nu1bJb2O2U4BoIiIiDSpe95eEN4uizPZo7wyGJXqJSenOi1MjpYBTrp651nXmAkcshWY6px7qemrJCIiIpnqy2Wbo95v3x17rF95oIrCGrn+9uvbnmnLtuBi9xpLE0qkBbAIGAUs8F8jgd7ApWb2pyTWTURERDLM23PXRr3fvrsy5nHlgWCtAHBYd2/soFMEmHSJBIAjgSOcc/c65+4FjgaGAd8Gjk1m5URERCSzdG9bBMCHvzgC8LqAq4KO/321KmpCSHkgSGF+btS5Z43pDcBhQ7o0U22zVyKptjsAJXjdvgCtgY7OuSozK09azURERCTj7Krwxvx1bF2AGTw2eSlB540L/Nt5xgn79GDzzgpenrGKgV1aR527X98OLLnjpFRUO+skEgDeCUw3s/cAAw4Dbjez1sBbSaybiIiIZJjQpI+i/Fycgw07KsKTQn77ylyKC/N4Y/YaAL5ZvzNl9cx29QaAzrl/mdkrwFi/6Abn3Cp/u+ZqISIiIpLFyiqrKMjLITfGVN4Vm8u48MEpKaiV1JRoGpgcYD2wGRhkZoclr0oiIiKSqcoqqiguyK3/QKAgV9noUiWRNDC/B74LzAZCC/c54IPG3tTMrgYu868zE7gY6AE8BXTCW3f4fOdcRWPvISIiIs1n3bbdFBfm8cinS+s8rkubQtZv96YQPHbZgc1RNYkhkTGApwFDnXNNMuHDzHoBPwGGO+fKzOwZ4GzgROCPzrmnzOzvwKXA35riniIiIpI8j05eyk0vzqpVftLIHkz6anX4/fAebZmzelv4/cje7ZqlflJbIm2vi4D8Jr5vHtDKzPKAYmA1cCTwrL//YbzAU0RERNLY1l2VMYM/gPvOHc19544Ov1+6sXrSx9VHD6EoP7GuYml6ibQA7sKbBfw2EG4FdM79pDE3dM6tNLO7gGVAGfAGXpfvFudcKF34CqBXrPPN7HLgcoC+ffs2pgoiIiLSRL5cvrnO/V3aFIa3d1ZULwvXulDBXyolEgD+1381CTPrAEwA+gNbgP8Axyd6vnPufuB+gDFjxihVuIiISArd8cq8WmU/OWpweDvWbGCAVglOFJHkSCQNzMNNfM+jgcXOufUAZvY8cDDQ3szy/FbA3sDKJr6viIiINKFAVZD5a7fXKj9scOfw9uBuJTHPLSlMpA1KkiXuGEB/cgZmNtPMvop4zTSzr/bgnsuAcWZWbGYGHAXMAd4FzvSPuRB4aQ/uISIiIkk2Y8WW8PbJI3uEt1dsLgtvty3KZ8kdJ7HkjpP41Ul7hctbFygATKW6vvo/9f89uSlv6Jz7zMyeBb4EAsA0vC7dScBTZnabX/avpryviIiINK2qYPX2yi3VQd8J+3SPefxlhw7gtklzASjWGMCUihsAOudC87Y3AGXOuaCZDQGGAa/uyU2dcxOBiTWKF1G92oiIiIikuZ3l3tzNP313FFc9PR2Av543msK8+oO7DsUFSa2b1C2RNDAfAEV+/r43gPOBh5JZKREREUl/oYTOo/t2CJclGtgN7dYmKXWSxCTSAW/OuV1mdinwV+fcnWY2PdkVExERkfS2cksZZtC9XRGzf30cr8xczbgBHes856wxvdm4o4KcOLODpXkkFACa2UHAeXircwCo415ERCTLbS2rpE1hHgV5ORTk5fCdMX3qPefOM/dthppJfRLpAr4KuB54wTk328wG4M3YFRERkSy2qyJAsWbzZqRE8gC+D7xvZiVmVuKcW4S3lq+IiIhksZ0VVZrNm6HqbQE0s33MbBowG5hjZl+Y2YjkV01ERETSWVlFFcVa0SMjJdIF/A/gGudcP+dcX+BnwD+TWy0RERFJdzvL1QWcqRIJAFs758Jj/pxz7wGtk1YjERERyQhllWoBzFSJBICLzOwmMyv1X7/CS9osIiIiWWxXRZWWdMtQiQSAlwBdgOf9Vxe/TERERLKQc47b/jeHhet20EotgBkpkVnAm9GsXxEREfGVB4I88NFiAHUBZ6i4AaCZvQy4ePudc6cmpUYiIiKS1iqqguHtt+as5dYJe6ewNtIYdbUA3tVstRAREZGMURGoDgAHdi1JYU2kseoKAOcAXZxzcyILzWw4sD6ptRIREZG0VRnRAnj/+WNSWBNprLomgdwLdI5R3gn4c3KqIyIiIumuMlA9QkyTQDJTXQHgIOfcBzULnXMfAiOTVyURERFJZxVVVQD86qS9UlwTaay6AsA2dezLb+qKiIiISGao8FsAe3coTnFNpLHqCgAXmtmJNQvN7ASUCFpERCRrhcYAFuRZimsijVXXJJCrgElmdhbwhV82BjgIODnZFRMREZH0FEoDk5+byHoSko7iPjnn3AJgH+B9oNR/vQ+MdM593RyVExERkfRT6aeBKVAAmLHqXAnEOVcO/Pv/s3fX4XGV2QPHvyfeNEndLXUvNQrUqECp4a5t0R/LsguLFYpLKSyL2+KyuEuh0JYCLZS6u6XeppZK0vj7++PembkjmUySiZ/P8+TpXJm5b3LTyZlXzimjtiillFKqEshy9QBGaQBYWemdU0oppVSRaA9g5ad3TimllFJFkpNnrQKO0R7ASqvQOyciZ4qI3mGllFJKAZ48gLoIpPIK5c5dDGwQkSdFpFNpN0gppZRSFZurEkh0pKaBqawKDQCNMVcAvYBNwDsiMldErheRYImilVJKKVVFZbvzAGoPYGUV0p0zxhwBPgc+BpoA5wKLReTmUmybUkoppSqgbF0EUumFMgfwLBH5CvgVqwRcP2PMKOAE4LbSbZ5SSimlKpoc7QGs9ILmAbSdDzxjjPndudMYkyEi15ROs5RSSilVUbl6AHURSOVVaABojBkX5NjM8DZHKaWUUhWdqwcwKkIXgVRWBQaAInIUMM5d9rYAxhiTVMptU0oppVQFlJ1niImKQEQDwMqqwADQGKOrfJVSSinlJT/f8Opvm8q7GaqEgvUAJhljjohI3UDHjTEHS69ZSimllKqI3vkzpbyboMIg2BzAD4GxwCI8Q78uBmhTiu1SSimlVAVz/XsL+Xn13vJuhgqDYEPAY+1/W5ddc5RSSilVUWnwV3WEtH5bROqISD8RGez6Ku2GKaWUUspj75FM/vHREtKzcsu7KaoKCCUR9LXA78BPwEP2vw+WbrOUUkopBWCMISs3jzOe/Z1vl+3i22W7yvT6C1IOcv4rf7Ix9ah737BODfntjiFl2g4VXqH0AP4TOBHYaowZilUXOK1UW6WUUkopAF75bRMd751GWkYOAK/9vpmMbP9ewPx8w6x1qRhj/I6VxIWvzmXR1kOc9rRVDyImMoJ/X9CDVvVqhvU6qmyFEgBmGmMyAUQk1hizFuhYkouKSG0R+VxE1orIGhE5RUTqish0Edlg/1unJNdQSimlqoLPFu7w2t6yP51BT8zyO+/ThduZ8PYCPl+0g31Hs8J2/ZZ147227xvbmXoJsWF7fVU+QgkAd4hIbeBrYLqIfANsLeF1nwOmGWM6YdUUXgNMBGYaY9oDM+1tpZRSqtrKzMljy/50v/0H0rM5bPcIuuw6nAnAHZ8v58THZnDf1ytLdO3ZG/YxYMovfnMOE+JCqSKrKrpCA0BjzLnGmDRjzIPAfcCbwDnFvaCI1AIG26+DMSbbGJMGnA28a5/2bkmuoZRSSlUF//ur4P6WPzbt99qO9KnK8f5fW3l/bkqxr/3cjA3sTDvOgfRsr/0dG2khsKoglEUg3UXkQhG5EDhgjPnWGJNd2POCaA3sA94WkSUi8oaI1AQaGWN22+fsARoV0J7rRWShiCzct29fCZqhlFJKVWxHM7173548v4f7cYRPwNemgf+cvPu+WRXSnMADx7K44f2FpB7NdO9rkOgZ5v3xn4Pcj1vW8x4SVpVTgQGgiNQSkV+Bb4DLgMuBb0RkloiUJPyPAnoDrxhjegHp+Az3Guu3NeBvrDHmNWNMX2NM3wYNGpSgGUoppVTFtWjrQZ6bucFrX634aO44w5qGn5OX73UsK9d72yXNZ6g4kD6PzuCnVXsZ8/wc976oSCtEePy87nRukkTKlDGkTBlDQqwOAVcFwXoAHwEWAu3sYeBzgPbAAuCxElxzB7DDGDPP3v4cKyDcKyJNAOx/U0twDaWUUqrSyss3nP/KXL/9ibFRjO3RBIBsn4Bv6wH/uYIAB9JDXxDiWjyyIOUg39npZi7t1zLk56vKI1gAeBow0Rjj/g2zH99jHysWY8weYLuIuFYSDwdWA98C4+x947B6HpVSSqlq58Ax76CtV8vaAERHRRBt98w5ewCNMbzwy8aAr5WZE7hnMDMnj1lrU8nL9x5wO56dx4Wv+gefqmoJ1o+bbYzxSzRkjMkVkZKuL78Z+EBEYoDNwASsYPRTEbkGa5XxRSW8hlJKKVUpvT57s/tx3ZoxtK5fkyXb0oiLiiQmygoAsx0BoPPx8gdH0OPBn93bvkPFLnd9sZxvlvonle58/zT348gI8TuuqoZgAWCciPQCfO++ACVKAGSMWQr0DXBoeEleVymllKoKvnYEZr/dMYTICOHUDg3o3rwWh49bc/qcQ8DOx0lx0V6vdTw7L+A1pi7fHXC/y6TRnTm3d7Mit11VDsECwN3A0wUc21MKbVFKKaWqvbx8456LlzJljHv/2T2tYCzW7gF8dOoaBrSrT6fGiew5nOn/QrZpq/bQv119v/3/d2pbXpwVeNgY4MTWdamvCZ+rrAIDQLvsm1JKKaXKSMr+dF4KEpQB7jmAAKOem80DZ3Yhw+7lcy3YmHPXUPYdzeLcl//0q+Th4hv8TRiQzNt/pLi369WMKc63oCoJXcutlFJKVRCXvzGPnWnHg57jOy9vze4jnNDCWiRy09C2ADSvE0+jpDig4CFgX87AEqBeggaAVVkopeCUUkopVQb2HvEM5X503ckhPSc6MoJJX1ll3+rEe4K2qAhBpOBFIL6GdPTOrRsfo31EVZkGgEoppVQFketIyXJicp2QnvPBvG3ux/Exke7HIkJMZARZBQSAdeK9F4v0blmHkV0bF6W5qhILVgmkd7CvsmykUkopVRXk5OXz2NTV7kUewURFFr2PRnzKw8VERvgljHa6/KSWiMCNQ9oSFx3pFYCqqi1Y/+5/7H/jsFK2LMNKAdMDq0LIKaXbNKWUUqrqeG9uCnM27Ofn1Xt5ffYW9wrf1KOZpB7JoluzWjSpFcfuw5mc0qZekV8/0IrdmKgIvyHgbQcyOJ6TR1ZuPjWiI9nyuGelcW5+aMPFqvIrdBWwiHwJ9DbGrLC3uwEPlknrlFJKqUrO1QN3/zerAh4f/p/fOJpp1V2IihBuGNyGu0d3LvJ1AnUYRvv0AC7edohLXvuL7Nx8IgRio72f5FsVRFVdoczw7OgK/gCMMStFpOi/mUoppVQ11H/KTGKjIr32XdinOQBZuXnu4A+sOYDN6tQo1nUixL9qR0xUBFm5+azZfYTOTZI47+U/3cfyDcREerfL1Vv43tX9itUGVXmEMsFguYi8ISJD7K/XgeWl3TCllFKqMkrPyuWR71eTkW0FdvuPZfuldnGVbks94j8XsLGdvqWobj29g9++CIFvlu5i1HOzmbvpgN9x3x7A3DyrBzAuOtLvXFW1hBIATgBWAf+0v1bb+5RSSinlo+sDP/HmnC3876+tLN52KOA5rhq8qQEWg7RvlFjoNZrVrkGnxok8f2kvAF65vDcX9W3hd17KgQz340tf/8vveFaO95y/HHsIWGsAV32FDgEbYzJF5FXgB2PMujJok1JKKVXpTf5hLbV9Uq04Zefmc/4rf/rtb1VA5Q6nPyYOcz8+MbkOTWoFHjauHR9NWkZOga8T5zcH0AoIoyM1AKzqCu0BFJGzgKXANHu7p4h8W9oNU0oppcrbY1NXkzxxKrPWpYZ0vm/KlWDB15FMz7GuTZMAK49fRBF73woK/gq6/qPndOPcXlZd4To+5d76tqoLQD2tAVzlhTIE/ADQD0gDMMYsBVqXZqOUUkqpiuD12VsAuOadBYWeu2HvUTrc+2PAY2sfGcndozp57dud5qj6cf3JvHd1Pz65vvQzrKXsT2d8/2Rqx0cztGNDr2OTxnRm+q2DaVa7eAtRVOURyirgHGPMYZ/kkrpOXCmlVLXRtkFCgcfu/HwZWw9kkBBb8J/UuOhI+rTyruyxYudhAK48uRVJcdEM7tAg0FNL5PYRHXjq5/Ve+zbvT+eEFrVZev8Iv/OjIyNCmoOoKr9QegBXichlQKSItBeRFwD/SQtKKaVUJTZj9V4+W7jdvf3jit3uxxtSjwV8zsbUY3y6cAfzthz0Wjjx9EUnuB9fflJLwFNbt3X9mgD8tt4aVvYtyRZOgYLKpDit8atCCwBvBroCWcCHwGGs1cBKKaVUlbBh71GufW8hd3xuZTnLyzfc+MHiQp839oXZ7sc7047Tom4NNk8ezXm9m7vr8qZnWelgOjdJ5LFzu/HMxT0B+GnVXgBGlGL93UC9klee0qrUrqcqj1ACwDHGmEnGmBPtr3uBs0q7YUoppVRZOf2Z392P9x7JZOIXnnS3ro49Z0m1LfvTuejVuWQ60qhsP5hB/YRY9yKOjOw8ABZutVLBiAiXn9SKhoneCyxcPYKlITHOu3dx4qhO9LEXeqjqLZQA8O4Q9ymllFKVjjHe09pv+mAxny3a4d7u2rQWAMdzrIBu75FMhj71K/NTDno970hmbsAULv+58ASv7Zgo7z+9NUox6XJdn1W+PZrXKrVrqcqlwIkAIjIKGA00E5HnHYeSgNzAz1JKKaUqj51px9nvk4zZ1WPn0r5RAit2HiYzJ4+kuGi/qh5O+475J3Zu7hMU+gaARU37UhSREcL8ScO54f1FLNmWpks4lVuwmaC7gIVYw72LHPuPAreWZqOUUkqp0vbpgu3c6RjqrZ8Qw/5j2X7nNbdToriqZgQq3+Zy1SnJfvsSYrz/1MZEhjL4Fj4NE+OItYNOjf+US4G/hcaYZcaYd4F2xph37cffAhuNMYFr2yillFKVhO8Q7kuX9Q54XlM7ABz05CwOpWdzMN0KEp84v7vfuSO6NPLbVzPWe4i3rANAAEEreyhvoawFn25XA4nC6glMFZE/jTHaC6iUUqpC2pl2nHV7jjCwXQO/IVeXBj6LMRolxfmd8/n/ncIhRzWNK9+ax8qdRwA484Sm3PXFCgDeuKoviXFROHPm1k+IZf+xLKIiy27ItyCi8Z/yEUoAWMsYc0RErgXeM8Y8ICLLC32WUkopVU4GTPkFsFbYzrp9SMBzdvvM5XOWRXv8vO60qBNP3+S6/L5+n3v/jkOe58THRLH4vtOJi45w5/hz+v7mgaQcSA947ZQpY0ieOJX+beuF/D2VxJ0jO3HrJ0s5oUXtMrmeqvhCCQCjRKQJcBEwqZTbo5RSSoXNlv2BAzCAXY5SbOCdILlFnXgGtq8PQJSjx85VW/fvQ9sB/qtsnRrXiqNxLf9eRZdVD51RYO9kuPVsUbvAQFhVT6H85j0M/IQ192+BiLQBNpRus5RSSqnQbT2Q7q7c4Zqj55KfH3jpw67Dxzm7Z1M2PjaKDY+N8hq+re2oznFSm3rcO6az13PP6tm0xG2uGRtFdDnMB1QKQggAjTGfGWN6GGP+Zm9vNsacX/pNU0oppUJz5gtzuPGDxeTnG/o8Ot3rWKojzYsxhs8WbmfHoQx2HDpOk1o1iIqMcAdiNwxuA0DDJM/8wMgI4dpBbbxes1U9/3x/SlUmhQ4Bi8jbBFg5boy5ulRapJRSShXRkUwrPe2hjGwSY6M4kpnLK5f35sYPFvPjyt1MGNAasIaEXeXewL8O7x1ndOTKU1rRMLHgoVuA2KjSS96sVFkIZQ7g947HccC5WDkClVJKqQqlz6MzaJwUx6D2DejWzKp68dKsjSTXr0mPZrW8VvQCDO/c0Gs7KjKC5nUC9+79dMtgPl24ndMDpHpRqrIpNAA0xnzh3BaRj4A5pdYipZRSqgh8S7ntOZJJg8RYWtSNJzE2ip4t6jDh7QUA/Ov0Dl7nNkgI3tPn1LFxIveN7VLyBitVARRn9ml7oGGhZymllFJlYPfhTL99rhx/bRsmsO2gZyXw09PXe51XI0aHclX1FMocwKNYcwDF/ncPcFcpt0sppZQKyaEM//Jt++2avJk5eazfe6zA55ZVGhalKppQVgEnGmOSHP928B0WVkoppcrL0u1pAHx43UnufUM6WgNVa/ccLZc2KVXRFdgDKCKdjDFrRSRQcUQDHDTGbC29pimllFKFy82z5gC2a5jg3ndqhwYAjOrWmB9X7vF7ziPndKOXVsVQ1ViwIeDbgOuA/xRwvJ6ILDPGXBn+ZimllFKhmb/lIACJsdF+x16+vDet7/7Ba1/XpklceXKrMmmbUhVVgQGgMeY6+9+hBZ0jIj+XRqOUUkqpQDJz8rj9s2XcNbITLepa6Vqm2hVAYgPM53NW93D5/uaBpdtIpSqBYEPA5wV7ojHmS2PMiPA3SSmllAqs033TACsQfGPciYA13LvjUAYREcKyB0b4lS6Yc9dQ8vINP6zYw8lt6gYMCpWqboINAZ9p/9sQ6A/8Ym8PBf4EvizFdimllFIFyrbn/R3OyOG39fuIsGO6WjX8h4FdiZ1vHNK2zNqnVEUXbAh4AriHebsYY3bb202Ad0p6YRGJBBYCO40xY0WkNfAxUA9Y2EgvsAAAIABJREFUBFxpjPFf26+UUqraMcZw6et/ubfrxEeTPHGqezvfr2CpUiqYUBIgtXAFf7a9QMswXPufwBrH9hPAM8aYdsAh4JowXEMppVQVMPCJWfy1+aB7+5ul3hVJm9WuUdZNUqpSCyUAnCkiP4nIeBEZD/wAzCjJRUWkOTAGeMPeFmAY8Ll9yrvAOSW5hlJKqapjZ9rxoMffHN+3jFqiVNUQSi3gv4vIucBge9d/jTFflfC6zwJ3Aon2dj0gzRiTa2/vAJqV8BpKKaWqgHyf8d2GibGkHs3y2le7RkxZNkmpSi+kGjjGmK+MMbcaY24F9ovIS8W9oIiMBVKNMYuK+fzrRWShiCzct29fcZuhlFKqklhiV/pwefbinl7bvVrWpn6CBoBKFUWhPYAAItILuBS4CNhCyVYADwDOEpHRQByQBDwH1BaRKLsXsDmwM9CTjTGvAa8B9O3bV6f9KlUBrNl9hI6NEomI0PQaKrwysnM5/5U/AXjygh60qV+T3i3reJ3z1d8GlEfTlKrUguUB7IAV9F0K7Ac+ASRYYuhQGGPuBu62rzEEuN0Yc7mIfAZcgLUSeBzwTUmuo5Qqfceycun2wE/u7ZQpY8qxNaoqmvLjWvfjM3s0pUZMJAALJp3G/C0H2Xc0s7yaplSlFmwIeC3WwoyxxpiBxpgXgLxSbMtdwL9EZCPWnMA3S/FaSqkwOOuFOV7bP6/yr7laXq58c55XcKoqp/fmWiXnE+Oi3MEfQIPEWMb0aML4Aa3Lq2lKVWrBAsDzgN3ALBF5XUSGA2Ed3zHG/GqMGWs/3myM6WeMaWeMudAYk1XY85VS5SvteI7X9vXvLyI7N7+cWuNt9ob9HMvKLfzEKuhoZg7JE6eyZNshAFbtOsycDfvLuVVF5/xdWna/Fp5SKpwKDACNMV8bYy4BOgGzgFuAhiLyiojo/0SlqplZa1NJnjiVu79c4d7XvmECvVvW5t4xnd37/ti0H2NKZ3ruxtRjpFehoK7/4zO5+aMlYX/daSutntg7P18OwJjn53DFm/PCfh1fL83aSPLEqWTmhGewaEPqUQAePLOLzi9VKswKXQVsjEk3xnxojDkTa3HGEqzhWhVAyv50DqZrARNVtcxYvZcJ7ywA4KP529z7D6Zn0yAxlmsHteHz/zsFgAlvL+CN2Vu447Nl5OaFrzfQGMNpT//mbkdF8/7cFDbaAUuodh3O5Ltluwo/sYhio62h0kifoGn34eC59Erq3z+tA+CHFbsLOTM07/6ZAkC3ZrXC8npKKY+Q0sC4GGMOGWNeM8YML60GVXZDnvqVQU/8UviJSlUizl6qxDjP2rGD6dnUrRkLQBNHJYbHfljDZ4t28ME8T7BYUln2cOD8LQcLORN2FZI0OJzSMrI5cCyL+75Zxdkv/lFm1w1mxuq9AKzdc5SxL8x27/9kwXb2HC6dRRNzNx1wP35y2roSv97OtON8unAHAPUTYkv8ekopb0UKAFVo0rNLc62MUmXLGMNxe0gvKS6KY1m55OTlcyg9mwPp2STEWr1NDcL0R/r75bu45WP/YdE1u4+E/Bql3dPl1PPh6fR51CqOVJT/+8t3pBV+UjH8tfkA3zp6FVfu9Pzcnp2xgZMfn1kq150yzbNad8+RogeZefnGa87fpwu2ux/X0xx/SoWdBoBKqaCcUxruHt0ZY6yhufFvzwdw9wDGREXw0FldvZ5bnEUYf/9wCV8v9R8Wve3TZe7H2w9mBH2N81+ZW+Trhkuoi2DOcvQW5uWHZ85kVm4el7z2V6HnFfbzKw7fGXrJE6cWqbdx/Nvz6XDvj6zceRiw8v+5JMSGlLJWKVUEGgAqpQr0xLS1nPHs7wA8fl53GifFAfDo1DUs22H9ob5moCcNx7j+yV7PdwaPK3ce5vEf1pA8cSoTv1juXpWaejSTp6ev9yv35do+nJHDf35eR5emSe5jg56cFabvMPx8ex9X7TrMjkPeAdemfce8tjcUce5gIIczcuh477SAxy7q29xr+9d1qSW+nq829WvSom4Nr303fhB6wafZ9u/D2BfmsO1ABq/P3gLAq1f0wSoXr5QKJw0AlVJk5uTx4LerSHUM3S3ZdohXft3E/mNWEJdcryaN7ADQKSbK+23kw2tPcj/efyyLg+nZHEzP5v/+t4j//r4ZgI8XbOeKN+exed8x7vhsOc/P3MBSnyHRzFxrOPWEh3/mhV828v3y8CwsCKdAcw1veH+R189xzPNzGPjELK9g+OP53nMjf11X8rKWL/+20Wt78rnduWFwGwBa1avpdey+b1aFfaV2RnYeNaIjvfaF2ht63GfofNN+T4A8slvjkjdOKeVHA8Awcr6hflsKK/uUKi0fzd/GO3+m0G/yTJInTiV54lSue2+h1zknt6lLwyTveX6/3j7E77X6t6vPnxOH0bRWHOv2HKX3I9Pp/ch0dhzyD5a+XbaLA+lWys/8fOPVC+gbFBRXaaWkASvA9bV2z1FOsufZOQOgfUc95061g9n/XWMFy85qF8XlTI/z5ri+XHZSS/fcucS4KG4e1o4HzuziPmfz/vQSX9MpM9cKAGffOZShHRsA0D2E1bvZufmMfn6217799s/qsXO7hbWNSikPDQDDaN1ezzCOK32BUhXdjkMZPPTdar/9rp6/b/8+gI2PjUJEvFZjNqkVR3L9mn7PA2hauwbdmtVi7R7P/4kx3Zv4ndepcZJ7kcJnC3fwtuP/TXpWnt+wcHGEa36d72smT5zqNY/PyRhrDtt2x9Dv/C3WKtmjmTnssufGtW+UELY2xUZ5et9O7WAFYOP7t+b+sV24tF9LbhvRkQmOqhnD//Obo70l/xkdz84jNjqSFnXjeXtCP7o1Syp0MUhaRjYd7v2RLT7B6B12/sLW9QL/fimlSk4DwDB6wvEp/lhm1UlWq6quA8eyGPhEwfPpatWIpkfz2kRFet4q3p5wIgDf/H1A0NeuVSPaa3tqgNxwk77yJJU+kJ7ttThhyrQ1ZPvkETypdV3O7tmUVvXig17bKbcUAsC3/9hS6DnXv7eIw45KKa4e0PNf+ROA07s0Ij4mMuBziyov3/DmHKtNax8Z6b5fMVERXD2wNdGO+9e5SZLf80c/P4d7v17ht78oMnPzvYaAGyfFFboIJPWodw+qq+fQpaYu/lCq1GgAGIK8fBNSZvvjjnOcvYFKlYeXZm0MmmokPSuXp35e795+8vwezLtnOAsmnebe99F1J/s9b2jHhqRMGUPDRP/5gE5JPgGgy+Rzu7sfH3DMi5uxZi9fLt7h3v5hxR5OmuydsuT83s2Ji4pk9+HMkOeXlUYP4KNT1xR6zpyN+70+CDZIjMUYw/q91vy2/17Rh/gYT4CzvgTvGc7ciHHRwYPKj6/33NNFWw9y80dLWLP7CP/7q/g5G/PzDcu2p/Hbes9cxuM5eazdc5ScIMnA0zK8Swk+fl4P9+MOjRICBqtKqfDQADAEN32wmE73BV5d55STV/Q/NL+v38d5L/8R9E1SqaLKzcvn3z+tCzhE+cG8rfR9dDpdH/jJXdVj/aOjuOjEFjRKiqNBYizPXdKTS/u18Fp5W1S/r/df2NCvdV0uO6mlV5DpdMSn5/ywT63huJhIIiOF7Nx8bvkktBJquXkmbPMJwRq2DNVVb813P87KzWfmGs/q24gIITJCOKdnUwBGPPO73/Nf+31ToSt2jTFM/sEKSMed0qrQNtWqEc3fhrQFrHQ54ahE8vD3/lMIatrB7aEglZG8FsZcfzKNa3k+VHx/8yC/BUZKqfDR/10hmLbKqqtZWI+D7zyalBAmWV/11nwWb0sLqXLB0z+v80sfoVQgszfuL/DYpK9Wuuf3ufj+oT27ZzOv3pjiaNfQf35boj2kFxtdvLee2KgIPrSri/ywYo97vys5dSAPfb+KzvdPY+aavcW6pq/HfHr/eresDUDTWnHccUZHrx5Op5y8fPf/30v7tXDvP6NrwatcJ/+wlvFvW6Xvrn5nAckTp7LXnle3cudh5m46wKZ9x1hh5867dlCbkL6HhomBk3YfycwJuL8w79hzN53zPE/r3AjAbxjf6dtlOwGYe/cwTm5TD4BOjRMB/99JpVR46f+wIuhw74+s2+M9TGOM4bOF2zmenef3Rp4V4hAVUGgP4KZ9x3j+l41eE7eVKsiEtwPXyz3q8wf+kbO7eqVtCadnLu7pt+/iE63AJy7Ke5jyFPuPf3F1e+An2k/6keSJU/2SHH+52AoyXHnmSmqbz+u3b5jIXSM78fH1p3DT0HZcdlJLppznCQLP692MqAjhvblbedyeJ3zbiI7u47XiPUPlm+0Acc/hTJInTnXvN8bwy1qrJ/Dpn9cza20qY1+Yw6Wv/8WmfZ4Pms4yfcEUVLHkmwAJuIuiZ4va7sfRUVbuvmAjI64gvk68p9LHJzecwrL7R5SoHUqpwmkAWEQvzvLOtfX10p3c8flyJv+wBtdUo1ev6AMUrQpCdm7w4eMjx4v3yVxVT60dq3PX7vGUAtuY6t2DfOUpyfRvV79U2hAXHcmWx0cDMLJrY6bdMogR9ock396dSWM6ewUPL1/eO+BrRoiw5L7T3duBhmNLO0m0q6eqTf2a3DWyE/eO7cyNQ9rS0rEw5ZJ+LenXui4Awzo1JDffeA131nUEPKe0qYcrz/Ew+wPev3/yrqXrDNg+WbidCe94Avwb3vckWw510cTfhrTlypP9h4uXbDsU0vN9ue7nub2bufe5Fp7kFvDhdqdj1MM5b7FWjWivoFgpVTo0ACyiX9d6z8e59ROrPNX7f23lCbsWZm37zauwhSPOeUnBegB/XZfKuS//Waz2quqpT6s67scjn53tHjZ1rUQd06MJN9rzwEqTiLDsgRG8cFkvOjX2nk94YrKnjbFREV7/X3q2qM14R1WRe0Z3Aqzh1jo1YxjTwxpqzMkzfLrQUzM2mIgwVZPIys0nOlKYedup3DikLYlxgYOVt8afyD2jOzGqm3/6m4gIT1tEhEHtPatf1+45ws+r93idv+1AaKXbnKt9gxERHjnHk2Pv7J5NiY+J9Fu5XZjF2w6RPHEq2bn51ImP9koTFBVhtaWgIeABU34BoF9y3SJdUykVHrrGvoiOZuWy72gWDQqYQwOeyc8ZQSaepx7JZOwLc9zbwQLAj+d7/sAlaloEFYL0rFziYyLdv4P3fLWCzxdtZ/E2a1XwA2d2KXQVb7gUFFR89n/93cOcsVGRXjkDIyPEq1fo1A4NuX6wJ2Ad3L4+U5fvJjsvn08XhBoAFq3drh67ujVjvPYfPp5N7fiYQsuTJcRGebXZ5c1xff32ORfMjHx2tt/x//y8zm9fy7rxXsPR028dHLQ9gax++AwiI4TYqEj6PDI95JXVYL2Hnef4YHph3xZex2OCDAF/5KiEovOalSof2gMYggHtvOcnjXrO/w3aqYad28uV0uJvHyxi6FO/uo/n5OVzxrO/e+XACjZRuoM9KRqsANRVLF0pX4czchj85Cx+XLnH7wOIK/gDyiz4C5UI9G/r+X8WFxXplVMuKtI72HINOb49Z0vIPXtF7QB0VTDxlZaRQ+0i9pQ5dW/uXx3jakeC5kBmrvVfCewM/ga1r0/7Rol+5xQmPibKnUA6NiqC7Nx8Vu48HNKq6TfmeOdCvGd0Z69t3yHg1COZZGTnMu6t+dz9pXf+R6VU2dMAsBhc5Z+ycgO/Scbaf5x+XGkN4/ywYo870/1nC7fTftKPHPLJfxVsovTzMzd4bTt7DpVyyc3L5+p3F/gtUqjIXClQ6iXEePWq14iJpEaM5+0pOsL7rcoVXLwxZ0vIgV1hPXah2Jl2nB9X7mFDatF6re4d4wmOAgXfbRsGrnjhHAYHChx5CMcCl5ioCPYezWLsC3PofL8n7dWstam85DP3+WhmDq/ZdZ0BPrzOfyGRawg4MyefHYcy6Dd5Jl3u/8mdK7BPqzo8fl53Vj50RonbrpQqOg0AQ3AsK48OjRK8Jqln5+aTmR24166g7P65efnuEke+coow9BLodf/1yVK/FcqqejiUnk3yxKm0m/Qji7Z6JvGveugMltx3On8f2q4cWxfcs5f0ImXKGOJjorjdsTI2JiqC2jU8Q69+PYCOuW4t64ZeFaQ4nOmdFjgSLhfFtYPaePVo+nKlTHGKi47gXyM6uLdjIiP49fYhdAhj+TinY1m5AXM3Tnhngd+ilBU7PKMQqx8+g/5t/RcS7bM/KD8/cwMX//cvv+NDOzbg0n4tSdBpLUqVCw0AC3E8O49l29NIy8ihWzPPJPYO9/7I/+Zt9Tv/8fO6U88xEdr5xyPYUEdRE0H//cPF7mGal2Zt4sslOznj2d+58NU/ycjWMnRVXU5evnsV5cWvzfU7vuyBEdSMjaJOzRivoVWAExwfZCqSFnXjeerCE3j36n4A1E8sOAB09pcnhJj65HBG8VbSD33qV3c1kfkpVgBYnNQ58yYNLzC9SaOkOJbef7rXvtw8Q5JjgUl2Xj41Y6P4z4We9DrDOjVkfP9k5tw1tMjt8eWbG9KXczWva3QD8Kpm4tSsdg3AavfOAHlOw9Ejq5QqPg0ACxEbFcE/hrXjjjM6Uq+m9/CL76digEv7tfTafvnXTe7HewMURne9SQZbMOKy8N7TuKhvcwC+X76b5TvS2H4wg2dmeMp5LUg5xKAgtV2VFZT7Ju2ubN6as4UBU35hx6EMd2kxsFZUpkwZ47Xwwpl0ef6k4XxQSnn/wuGCPs05tYO1Ita5otR3CHiJYz7j23+khPTanyzcXuC0jWBSDmTw8QJr0YJrNXVxSpQlxQVPb+LqCbt2oDUf0FXD2BUQu3RvXouNj43iq7/15/lLe/HgWV1pXqd0e0HBe57y+3/5f/j15UqQ7TuH2uWKAGlolFJlRwPAQkRECP8a0ZEL+7bg2kGtuWmoZ1VfdGThn2CdQaJvWa5xp7Tiq5v6A57hkmDqJ8S6J2yD9Yb8ym+b/M7TSdXBXfHmPG79ZGl5N6PYfl61x51QeKAd7CfFRZEyZQyf/t8pfue3a5DoPqdhYlylGXLzSini839taMcGvqdzniMHXUEmT13jN58tEN/6wb7lzOr4rAwOh6jICFKmjHEP+7ZpYM0L7NTYf3FHVGQEvVrWKbV7GWi4+qYPFrsfd7QXnASq9uIiIkQITF/tX4HlukGti5xyRikVXhoAFkFiXDT/HO6Zk+NauHH9YKv80ox/neo+dnKbwnNbPXBmVxomxhEfE8n+o4UHgOD9yTs3zxAf4I36zBOahvRa1VFOXj5/bDzA10t3kTxxKskTp5KfX3l6A1OPZHK9I/Gvy9+CzPOrFR9NypQxLH+wck22r5fgCbJ889v1a13Xr2fpvjFd/F7jx38O8tp+d+7WgD33vnzr7z7183p3r/GobgWXbguH+JgoXri0Fx9eezJglW2LihB3/d6ycDwnz28l8Kx1nvmBUZFC92a1+PqmAUFfJ9/g7qGu4+j97N2yTkFPUUqVEQ0AiyhQfcozujYmZcoYr0/DQzs2LPA1ouyEZK5ksDWiI0nPzvPrdQDPHMJ/Dm/vd+y7Zbv8VgXGx0Ty3bJddL5vmt/5CrYe8K/P/O7clDJvR3H8vn4f/SbPBLxz053Sph7XhVgDtjJx9nZH+STxExE+sAMkl0BVMIozVAtwNNN/Hm3ru38ArLmKpe3ME5rSuJa1WlhE2Dh5NHeO7FTq13XacyTT7z3ppg8Wc/LkmWxMPUbbBjWL1APZp1UdZt85lD8mDmNUd//k2EqpsqUBYBj0DDCp/tQAQ1Qu39080GvC94H0bD6av42TJs/wO9eV0sM1/+b+sZ5eji+X7CTKp2eklz3v5nhOHgtSirdisaoyxnDa078H2F/4c49nWz/P057+jeSJU1mz+wiLth4i9aj/vM7SMHX5bq56a757e7GjHNorV/QmsqhZjiuJD689ifeu7uf3ex5IZIQwvn8yb47ry3d/H8jM204t9DkF+cLO4RlIehFKPFYmrrmHLqOe+51ZPvkHp67YzZ4jmWTl5vN1EesG7z+WTYu68e55z0qp8lU5JgNVMG+N78vV7yx0bwf649upcRInt6nLX5v9g7DmdWoELB+1/1g2xhgyc/LdyaTv/XolAH9utPJ8XT2wNQ9/v9r9nG+XWW/Cc+4aSlpGjtf8pgtfnUvKlDHF+RarFGMM/af8wu7DgYO1whYjZuXmeeVFA+9k4AsmncaH87bxzIz1tK5fk19uOzWsKxyNMdz0oWf+1QuX9gKsXuFpK/dQOz7889EqiqLUKY4QePCsriW+5i9r9wbNq9e9mX8i56rg3rFd2LTvmHuoNzMnn2vfW1jIs0L31IU9wvZaSqmS0x7AYhjWqZG7kPrIrgXPB8q3F821qe+d5DXYsMkrv22i8/3TmL1hH8YY9x+iJMeE6RtO9Qz3LdturYZsWqsG3ZrV8itbNXPNXrZXosTApWHVriNewd9Vp7QiZcoYNjw2CoCHvltd0FMBWLw1Lejxe75a4V6JvWV/Oq3v/oE1u4+EbW7h3E0H3I8/uu5k9xzPW0/vwE/FKP9VVYUr6HZ+uLt7VCd+usX7Z/xzgEUNVcUb407ktSv7hHRuKKvJf719iPtxu4ZFr1SilCo9GgAW08Nnd+Xt8SfywmW9Cjzn6oHJAF4rM28f0SHoH6onp1kT1K96a767egjgVaPz7lHeJZdO69zQPZ/QtzfymncXMujJ6p0WxrdyysNndwO8FxZMXb7b/XhhykFOfGwGe+yg8dLXrSS2g9rX57bTO3BBn+ZerxdoleOo52bTb/IMXv99c0hltYL50w4A35lwIqe0DZxSo7p67pKehZ6z5uGR/DfEoMZXQlwUHX1W4Vb2FELBREYI+QG+vyfP9++9GxBC72xy/cAVTpRS5U8DwGISEYZ2aui3OtFpZLcmpEwZQ/2EWKbdMoi3xvfl78P8F3Oc0dVTBaBFXWt+jDF4pSoJtPgk0LGC8gkGykFYHfhOYn/PJ6eay00fLubw8RySJ07lglfnsu9oFr+sTWW+o/LD+9ecxM3D23PNwMB1W6f+YyCNkjyLcvYfy+axH9bw/C8b/M51BRHHsnILzUv4oj2sPyTIwqLq6uyehad+qRETSaJPr3ugBVeB9GphrVa9y7EA4/QupbsKuLwN7eT/e9a1WfEW0yilKi6dA1hGOjVOolPjwG+iL1zamzfnbOGJaWupWzOW7QetrPlrHKXd/n3BCV7P6do0iVW7jgBWcXqXyed2p2OjRKIjhQcdQ5snTZ7JlsdHV7vs+wfSrfQ6D5/dlatOSfY7fvWA1rz1h1XU3pXk1+WerzwF6501WVs7ejX+fUEP7vh8OXeP6kTXprV4/aq+nPXiH9RPiHXXjH7l103cPqIjkRHCDe8v5KdVVo/h8E4NmemYZB8fE8lPtwz2WmXqquriSqqrisd3nuSdny/n8fO6B/1gBdClqfV/9sYhbRnZrTHr9x5lRBf/sm1VSWxUJNcObM0bc7a49zlzMhbVvHuGu5NaK6UqDg0AK4CYqAha17f+6O91zFXr1jSJxdvSePny3u6UEC5ndG3sDgD/dMwRi4mK4LrBbVi16zC+lm5Po1clz791+HgOSXFRIQey++z8ig0TA/8Bu2d0J1rXj+e+b1bxxLS1Bb5O32TPzy0uOpKl959ORISQFBfNhX1buI/1aF6btY+MZMeh45z29G/u/dNX7+FIZq47+AO8gj+wem8nvLOA167sw4R3FjD53O7uxUD/d2rZ5YCrinzrc3+xeAex0RFMPrd7gc/xXRXbun5Nr+C/KnMGxu9f089vbvGrV/QO+bUaJcUVfpJSqszpEHAF4ar5uccxVOvK8Tc6QM6swj5Rd21qrVQc1qkhj59n/ZE79+U//c5btesw7/+1lWemr/c7VtEcSs/mhId+5oVf/Cs57Eo77k7s/F9HdZRv7VQVBf0RioqM4NQO3kNeP/xjEA+e6Um3ExkhjO7mfQ9qx8d41Wl1iouOpF3DBF69og9z7x4GwP/9bzF3fr7c71zfOHZj6jGG/ec3th7I4PI35nGefc/aN9IJ9CXhW0kEPL8bBYkModJPVeUMAK0RBc/2u1f3Y2Q3zeOnVGWnPYAVRFKAskjO3iJfoawwXf/oKCIjhM37PLVis3Lz3Al2Dx/PYczzngUSl/RrweM/rOXx87oHTKpb3lxDqp8s2M4/fBJjj3PkyHv8x7Uk1YimZmwU//19MwAnNC94CNVZceK/V/ahS9Mk2jasSW6+4ZxezcjLN+5FNkUxMkjFiCtObsmj53QnKzePh75bzf8Nbsu2gxlc8ea8gOc3ra29KAUZ3z+ZL4Pk7QP/SiJgzb8MRqi+AWCE45NJDZ/e00CLRJRSlY/2AFYQTWoV7Q98nuNN2LfclUtMVASREUL7Ronu5Kuv/rrZffyOz5Z5nX/K47/w7bJdAXvYwJqPlpdvGPfWfJInTi2zhLjGGO77eiUfL9gOwM604+5rZ+Xmcc5Lf7Ah9ZjXc+7+cgX/+GgJAI+c0y1oAOccHnTN74qNiuTaQW2onxBb4iGsx87t5n783yv7MPvOoTxwZlf3dSaf252W9eIZ2L4+N9hlBRPjPAH4mSc09aqKobw9eFbXQsvchZoo27na/oTmVTPfXyjO7eVZXBMf4/1hcJPP/zWlVOVU8bp5qqk6jknqNWOs0nDBuD6F3zWyU0jlru4d05kbP1hMbUc9zsXbDgU8d+7mA377jDF0uf8nRnRpxG/rrUSxm/el070M/kgu2Z7mVQMZ4NyX/+DW0zrw+4Z9LN0ePE+fK2djQUSELY+Pdj8Ot8tPakW7Bgl0bVar0NJZd4/uzE3D2pEYa81zzMs31bgfKnyiIwr/rJuZk0cnRwnF6lyurEXdeK4b1JrXZ29xB8/n927OF4t3cEm/luXcOqVUOGgPYAXh7KHyzTMXyKntrVJzoeaFO7mNdZ4rcPx6yU72H8tmMq5sAAAgAElEQVQOeO6yAAGVa6WxMwnujkNlk2D6vABzF9fvPcaNHyzmo/nb3fvG90/mor7N+ei6k+nZojbxMZG8M+HEkK4hIqW6QvqkNvVCrpuaFBftbktkhBRr+Fl5CzQHsFU975q+7/6Z4jlff+ZMGtPFq5LQUxf2YN2jI4tU/1cpVXHp/+QKqJ1jwr+z9q9T/3b12fDYqKB5CJ1cc/oe+m41Ewa05hY7x+CQjg341S79FMiXi3dw+HiOO4B0SjlQ+gGgc0iuMP8Y3t69WvHrmwaUVpNUJeQbAJ6YXIcdh47z/fJdNEiI5aQ29chy/K5VxDmw5U1EdCqCUlWI9gBWQBc6egCDdUqFGvxBwYmkV+48EnD/OjsH4b8+XcZD3632qn3r8sS0tdz26TK//eG0+/Bxr+2C0k+kTBnjl6pCKZcoxxDwPaM70aVJErsPZ/L3D5dw8Wt/kbI/nZ2HPL9r2sullKrqyjwAFJEWIjJLRFaLyCoR+ae9v66ITBeRDfa/lTthXTGMsleNxkZFcFFfKwgMZ96+Md2b0KaBdx6zi09sTsqUMcTaAeJtp3cAYOn2Q+TmFdz7VseeS/hFIasvS2rJNms4+tUrerN58mhGdmvCxXbevesHt+HNcX1ZeO9ppdoGVfk5F4FERURQw2dhw94jmXyy0DOdINSpA0opVVmVx8fcXOA2Y8xiEUkEFonIdGA8MNMYM0VEJgITgbvKoX3l5tlLevJQRg4iwhPn9+Afw9vTvE584U8MUVKNaDbvS2fks7+79904pB0Aax8ZSXp2Hnl5hv9MX8+ClEOMCFLyqlFSHIfseYHfLN0ZUkmu4rjzCyt3Xtemtdxz4R47txs3DW1Hy3rh+9mo6iMqUtjj07O8Yqd34nTNu6iUqurKvAfQGLPbGLPYfnwUWAM0A84G3rVPexc4p6zbVt5ioyJpaKccEZGwBn/g6bVbaw/vnphcxz3UJSIkxEa50498vmgHe49aSalfvKwXNaKtuT8LJp3GxsdGMbyzJ3nyPz/21CwOp5y8fPccQGd5tKjICA3+VLHVT4hluU/A9+jUNeXUGqWUKh/lOgdQRJKBXsA8oJExZrd9aA8QsOCmiFwvIgtFZOG+fQUvXlD+fOt5Pn5eD79znCtO9x6xEi83Sopjxm2n8tXf+tMgMZaoyAgu7NPC63kLUg6Gta05efm0n/RjWF9TKbCmWtQKkHhdKaWqk3ILAEUkAfgCuMUY47USwRhjgIDp5o0xrxlj+hpj+jZo0KAMWlp1+Ga2aNcwIej5Ww+kA9AgIZZmtWt4zUdMrl+TW0/r4N52VhsJh42OZLPdmhWe51CpUImIex6pUkpVV+USAIpINFbw94Ex5kt7914RaWIfbwKklkfbqjJn/eDvbx5Y6Pn3f7MK8K5K4fSP4e3cj3ccOh7wnOLIyzfuVcdt6tfkyxs1pYsKL99cm0M7ej5MvnZln7JujlJKlbnyWAUswJvAGmPM045D3wLj7MfjgG/Kum1VXZ4dAF4/uA3dmhVcwWN8/2Sv7YQCAkBrsUp3gALLxxXHrjRPMPnDPwcVmMJGqeKK8kmhJEFq3yqlVFVUHn9ZBwBXAsNEZKn9NRqYApwuIhuA0+xtFUaumrbOBRWBZOZ4ytBFRwZP/nqRPZQWziDtQLqnQklctP4xVqWrd8va/LLWM+DgLMuolFJVVZmngTHGzIECy5sOL8u2VDdn92xKQmwUwzo1DHqeMwDLyQs4FdNNRLiob3N3feBQnf/Kn2zed4xF957uV+os9Yi1+riwdioVDs7f8RZ1awTtHVdKqapCx9aqERHhtC6NCq0te3rngAuwC1QnPoZDGTkYEzxYdFq09RCHMnKYtmqP37Gnfl4HWPn+lAqXFy/rxcfXn+y33zjWm13Wr1VZNkkppcqNBoDKz4V9mzPjX4MBuPykloWeXys+muzcfLJy83l2xnq2FVIj2BkoHsrI9jqWl29Yv9daAeybtkapkhjbo2nAmtbOzy3RkcE/HCmlVFWhAaDyIyK0a5jI9FsH89BZXQs9PzHOyqn2zdKdPDtjA4P/PcudQiaQzBxPibndaZlex+ZtPuB+XJRax0qFQ6wuOFJKVRP6bqcK1L5Rot9qyUCS7FXCd32xwr3vf39t9Ttv39EsZq1NJe24p9fvxVneq4cf+NZKPfPGVX2L1Walisq7B1DfEpVS1UN51AJWVUxSgKoKb/+RwqQxXbz2nfjYjKCv8/H8bWywE0Cf1qVo8xCVKi5HBhgNAJVS1Ya+26kSSwqQJ9CZdBo8OQidEu06xKt3WYVgtB6rKg83DfUkNI/WIWClVDWh73aqxHxz9cVERdC2QU2vfenZuX7P69XKKi03+vnZ3PHZMo5lWef4JqJWqjSN7t6Ejo0SAYjRRSBKqWpCA0BVYs5hswHt6nH5SS3ZmXac7FxrsYcxhh+W7/Z6zr8v6MFzF/d0b3+2aAcAPZrX4sEQFp4oFU5RduCnQ8BKqepC5wCqEosQ716Tbk1rkZmTz45DGbRpkMC3y3Yx8UtrgciTF/RwVw8BuOLklvzvr23u7RU7D5dNo1W19+oVvd0r2KMiNABUSlUv+m6nwsAzv+++sV3cJedmb9hv7ft6pft4t6beVRZuGNzW+5VCzyWtVImM7NaEAe3qA57awBoAKqWqC+0BVCXmWt/RrmECnRonkd/Q2rF53zHy8w1HMj3z/7o0TfJ6bou68Xz5t/4cz87j8jfmcccZHcus3Uq5RNo9gM6qIEopVZVpAKhKzNVr5xoIdpWa+3ThDhravYFQcJLd3i2txSDz7xlOg0St/qHKXv2EGACkwDLlSilVtWgAqEqssR3k+ZaNO56Tx79/sur6ThiQzI1D2vo918kZLCpVlh48qyst6sTTN7lOeTdFKaXKhAaAqsRqxUeTMmWM177E2CiOZnmGfu8f2wUR7V1RFVPDxDjuHt25vJuhlFJlRmc8q1Ixsltjr20N/pRSSqmKQwNAVSqeOL+H+3Gnxonl2BKllFJK+dIAUJUK10IQgLV7jpZjS5RSSinlSwNAVWoGtKsHWMmelVJKKVVxaACoSs1l/VoB0LdV3XJuiVJKKaWcdBWwKjWjuzfmy7/1p1eL2uXdFKWUUko5aACoSo2IuJM8K6WUUqri0CFgpZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRgNApZRSSqlqRowx5d2GYhORfcDWMrpcfWB/GV1LFZ/ep8pB71PloPepctD7VDmU131qZYxp4LuzUgeAZUlEFhpj+pZ3O1Rwep8qB71PlYPep8pB71PlUNHukw4BK6WUUkpVMxoAKqWUUkpVMxoAhu618m6AConep8pB71PloPepctD7VDlUqPukcwCVUkoppaoZ7QFUSimllKpmNABUSimllKpmNAAshIiMFJF1IrJRRCaWd3uqGxF5S0RSRWSlY19dEZkuIhvsf+vY+0VEnrfv1XIR6e14zjj7/A0iMq48vpeqTERaiMgsEVktIqtE5J/2fr1XFYiIxInIfBFZZt+nh+z9rUVknn0/PhGRGHt/rL290T6e7Hitu+3960TkjPL5jqo2EYkUkSUi8r29rfepghGRFBFZISJLRWShva9yvO8ZY/SrgC8gEtgEtAFigGVAl/JuV3X6AgYDvYGVjn1PAhPtxxOBJ+zHo4EfAQFOBubZ++sCm+1/69iP65T391aVvoAmQG/7cSKwHuii96pifdk/7wT7cTQwz/75fwpcYu9/FbjRfvw34FX78SXAJ/bjLvb7YSzQ2n6fjCzv76+qfQH/Aj4Evre39T5VsC8gBajvs69SvO9pD2Bw/YCNxpjNxphs4GPg7HJuU7VijPkdOOiz+2zgXfvxu8A5jv3vGctfQG0RaQKcAUw3xhw0xhwCpgMjS7/11YcxZrcxZrH9+CiwBmiG3qsKxf55H7M3o+0vAwwDPrf3+94n1/37HBguImLv/9gYk2WM2QJsxHq/VGEiIs2BMcAb9rag96myqBTvexoABtcM2O7Y3mHvU+WrkTFmt/14D9DIflzQ/dL7WIbs4adeWL1Leq8qGHtYcSmQivWHZhOQZozJtU9x/szd98M+fhioh96nsvAscCeQb2/XQ+9TRWSAn0VkkYhcb++rFO97UaV9AaVKkzHGiIjmMqogRCQB+AK4xRhzxOqEsOi9qhiMMXlATxGpDXwFdCrnJikfIjIWSDXGLBKRIeXdHhXUQGPMThFpCEwXkbXOgxX5fU97AIPbCbRwbDe396nytdfuNsf+N9XeX9D90vtYBkQkGiv4+8AY86W9W+9VBWWMSQNmAadgDUW5OgScP3P3/bCP1wIOoPeptA0AzhKRFKypR8OA59D7VOEYY3ba/6ZifaDqRyV539MAMLgFQHt75VUM1uTab8u5Tcq6B65VUuOAbxz7r7JXWp0MHLa74X8CRohIHXs11gh7nwoTe77Rm8AaY8zTjkN6ryoQEWlg9/whIjWA07Hma84CLrBP871Prvt3AfCLsWatfwtcYq8+bQ20B+aXzXdR9Rlj7jbGNDfGJGP93fnFGHM5ep8qFBGpKSKJrsdY71crqSzve+WxaqYyfWGt2lmPNU9mUnm3p7p9AR8Bu4EcrHkR12DNbZkJbABmAHXtcwV4yb5XK4C+jte5GmsC9EZgQnl/X1XtCxiINRdmObDU/hqt96pifQE9gCX2fVoJ3G/vb4MVGGwEPgNi7f1x9vZG+3gbx2tNsu/fOmBUeX9vVfULGIJnFbDepwr0Zd+PZfbXKleMUFne97QUnFJKKaVUNaNDwEoppZRS1YwGgEoppZRS1YwGgEoppZRS1YwGgEoppZRS1YwGgEoppZRS1YxWAlFKqSBEJA8rZUM0kAu8BzxjjMkP+kSllKrANABUSqngjhtjegLY5Z4+BJKAB8q1VUopVQI6BKyUUiEyVrmn64G/29n8k0Vktogstr/6A4jIeyJyjut5IvKBiJwtIl1FZL6ILBWR5SLSvry+F6VU9aaJoJVSKggROWaMSfDZlwZ0BI4C+caYTDuY+8gY01dETgVuNcacIyK1sCqjtAeeAf4yxnxgl5eMNMYcL9vvSCmldAhYKaVKIhp4UUR6AnlABwBjzG8i8rKINADOB74wxuSKyFxgkog0B740xmwot5Yrpao1HQJWSqkiEJE2WMFeKnArsBc4AegLxDhOfQ+4ApgAvAVgjPkQOAs4DvwgIsPKruVKKeWhPYBKKRUiu0fvVeBFY4yxh3d3GGPyRWQcEOk4/R1gPrDHGLPafn4bYLMx5nkRaQn0AH4p029CKaXQAFAppQpTQ0SW4kkD8z7wtH3sZeALEbkKmAaku55kjNkrImuArx2vdRFwpYjkAHuAyWXQfqWU8qOLQJRSqhSISDxW/sDexpjD5d0epZRy0jmASikVZiJyGrAGeEGDP6VURaQ9gEoppZRS1Yz2ACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACqllFJKVTMaACpVxYjIeBGZ49g+JiJtyrlNQ0RkRym+/iARWefYTrHr8Yb7OskiYkQkqgSv0dK+J5HhbFsx23KPiLxRCq/7qIjsF5E94X5tpVR4aACoVCUhIr+KyCERiS3K84wxCcaYzSW89jsi8mhJXqOQ1zcikm4HRgdEZKaIXBzq840xs40xHcPUlg4i8pkdwBwWkeUi8q9wBWzGmG32PckLx+s52fcp2/45HhSR6SLSKUhbJhtjrg1zG1oCtwFdjDGNw/Sazt+P/SLykYjUDnDeOyKSKyJNAhwr1fuqVGWjAaBSlYCIJAODAAOcVa6NKT0nGGMSgI7AO8CLIvJAWTZARNoC84DtQHdjTC3gQqAvkFiWbSmBJ+2fY3MgFetn6ackvZiFaAkcMMakFvWJhbTJ9fvRBqgDPOjz3JrA+cBh4AqfY1XhvioVVhoAKlU5XAX8hfXHfJzzgIjUE5FvReSIiMwH2vocNyLSzn78q4hc6zjmHi4WyzMikmq/1goR6SYi1wOXA3faPTDf2ec3FZEvRGSfiGwRkX84XreG3RtzSERWAyeG+o0aY/YbY94HbgTuFpF69mtOEJE1InJURDaLyA2O6wUcYhaRxiKS4XoNe19vu83RAS7/EPCnMeZfxpjddnvWGWMuM8akBXj9pvbP/qCIbBSR6xzH+onIQvtnuVdEnrb3ew0j2/fkERH5w/7efhaR+o7XuUpEtto9o/dJiMPbxpgM4EOgm/06D4rI5yLyPxE5Aoy39/3Pca2BIvKniKSJyHYRGW/vjxWRp0Rkm/29vCoiNQL8PE4DpgNN7d+Vd+z9Z4nIKvt1fxWRzo7npIjIXSKyHEgvLDA1xhwBvgW6+Bw6H0gDHsbn/whFvK9KVQcaACpVOVwFfGB/nSEijRzHXgIygSbA1fZXcYwABgMdgFrARVg9Oa/Z133SHro8U0QigO+AZUAzYDhwi4icYb/WA1iBaFvgDPz/IIfiGyAK6GdvpwJjgSRgAvCMiPQO9gLGmD3Ar/b34nIl8LExJifAU04DPi9CGz8GdgBNgQuAySIyzD72HPCcMSYJ6+fwaZDXuQzre2oIxAC3A4hIF+BlrAC8CdZ9aRZKw0QkwX7eEsfus7G+v9pY99R5fivgR+AFoAHQE1hqH56C9XvRE2hnt+F+32saY2YAo4Bd9u/KeBHpAHwE3GK/7g/AdyIS43jqpcAYoLYxJreQ76sOcA7WByKncfZ1PgY6iUgfx7Gi3lelqjwNAJWq4ERkINAK+NQYswjYhBUwYM9fOh+43xiTboxZCbxbzEvlYA2HdQLEGLPG1VsSwIlAA2PMw8aYbHuO4evAJfbxi4DHjDEHjTHbgeeL2hg7QNsP1LW3pxpjNhnLb8DPWMPihXkXe0jQ/nldCrxfwLn1gIK+Zy8i0gIYANxljMk0xiwF3sAK1sH6ebYTkfrGmGPGGN+AxeltY8x6Y8xxrECxp73/AuA7Y8wcY0w2VtBlCmna7SKSBmwEEoDxjmNzjTFfG2Py7Ws5XQbMMMZ8ZIzJMcYcMMYsFREBrgdute/nUWAynntdmIuBqcaY6fY9fQqoAfR3nPO8MWZ7gDY5Lba/r/1Yw8z/dR0Qa97hUOBDY8xeYCae+wBFuK9KVRcaACpV8Y0DfjbG7Le3P8TTo9YAq5dsu+P8rcW5iDHmF+BFrB7FVBF5TUSSCji9FdYwX5rrC7gHcPVMNi1pm+wh2gbAQXt7lIj8ZQ+3pgGjgfrBXsP2DdBFRFoDpwOHjTHzCzj3AFZPWyiaAq6AyGUrnh66a7B6zdaKyAIRGRvktZyrZTOwAjfXNdw/R3tY90Ah7XrKGPP/7N13nJTV9fjxz52yHZald+kC0sXeRY2KNYkao/lpYklXo7EmtkSj0a+xpGiIJZpoNFFjw46AJQjSkSLSOyxt2b47M/f3x1P2mbY7dafseb9e82LmmXlmLrA7c+bce8/porXurbU+R2u91nHf5qhnwQCMLxehegAlwALH//W75vFY9MXx/6+1DpjjcGYyWxuXZZLWugtQBDwOfKKUKjLv+x6w0gzCwchuftcxzR/P/6sQHYIEgEJkMXOd1YXACUqpHcooq/ELYLxSajxQCfgwPrwtA1t5ylqMD3NL0C5NrfVjWutDMdZXjQButO4KeZ7NwHoz0LAunbTWZ5r3b49jTNGci/F3m6eMnc+vYGSPepmBwNuAautJtNYNGFm1SzEChWjZP4APMTKqsdgGdFVKOTcRDAS2mq/7tdb6Yoxp3d8DLytjo0I8tmNs5gDsn4du0R/eptayh5sJWT9q2g3UA4c4/q/LzQ0ZsdiG8YUBMNaaYvxsbI1xXEHMLOKTwGDM9Y0Y2b4hjt+RP2B8ObB+HuP5fxWiQ5AAUIjsdh7gxwjIJpiXUcAnwP8zS4m8CtyllCox14y1tt5uMfBN87HDMLJUACilDlNKHWFmTWox1hUGzLt3Yuy+tMwDqs3F+8VKKbcyNoxYmz3+jbGBo0Ip1R/4eax/YaVUV6XUJRiZyN9rrfdgrIsrxAx4lVJnYKxZjNVzGFOh59B6AHgncLRS6kGlVG9zPMPMjRNBZUfMqe3/AfcppYqUUuMw/j3/aZ53qVKqh5nxsjYaBIjPy8DZSqmjzTVzdxFD0Jug54FTlFIXKqU8ythcNMEc/98w1lz2BFBK9XOs92zLv4GpSqkp5s/WDUAjxr9d3Mxp/O9jBKXrlFJHYQSuh9PyOzIGI1NuTQPH/P8qREchAaAQ2e0yjPVhm7TWO6wLxlTtJeaOyZ9hTBnuwNgl/Ewrz/cw0IQR0D1L8EaAzhgf9Pswpuz2AA+a9z2FMY26Xyn1mhl4noXxYbseI0v0JMYmBTB2XW4073uf1oMuyxKlVA3G2rUrMdac3QFgTrNegxFM7MNYr/ZGDM+Jef5nGMHXQq111Oloc7r0KGAQsFwpVYWReZwPVEc45WLzsduA/wJ3mhshAE43n6MGY0PId9pY4xZpPMsxgucXMbKBNRibYRrjeZ4YX2sTRsbsBoxp98XAePPumzH+Xz43dxB/iFGuJ5bn/Qoj+/pHjJ+Ts4GzzTWN8bB+PvZh/F6cr7Xea15/XWu9LOR35FHgLKVU1wT+X4XIe0rrmDPvQogcY+7W9QMHmR/wHZZS6iOMTQIp73zRXsydvfuB4Vrr9ZkejxAid0kGUIj8NgZjKrdDt+Qyp6YnAS9leizxUkqdbU7Zl2KsgVwGbMjsqIQQuU4CQCHylFLqW8BMjDIl8U635Q2l1LMYU5bXhezYzRXnYkwxbwOGY0wly9SNECIpGZsCNhfyzge2aq3PMivGn4DRxgfgcseWfiGEEEIIkSLp6gUZi2uBlRgLzy03aq2lWrsQQgghRBplJAA0y0JMBe4Frk/0ebp3764HDRqUqmEJIYQQQuSVBQsW7NZahxVuz1QG8BHgJoy2U073KqXuwGjjc4vWOqzUgTIa018NMHDgQObPn5/usQohhBBC5CSlVMTSV+2+CcRsh7TL7GnqdCtGD9LDMHp/3hzpfK31NK31ZK315B49Yu1EJIQQQgghLJnYBXwMcI5SagNGcdOTlVL/1FpvN5u8N2IUsj08A2MTQgghhMh77R4Aaq1v1Vr311oPAr4DfKS1vlQp1QfsPpHnAV+299iEEEIIITqCTO4CDvW8UqoHRp/LxcCPMjweIYQQQoi8lNEAUGs9C5hlXj85k2MRQgghhOgopBOIEEIIIUQHIwGgEEIIIUQHIwGgEEIIIUQHIwGgEEIIIUQHIwGgEEIIIUQHIwGgEKJdNTT7Mz0EIYTo8CQAFEK0m8176xh5+7tM+3htpocihBAdmgSAQgiWbN7Ppj11AFzy5OcMumU61Q3NKX+dtZU1APzu7VUpf24hhBCxkwBQCMG5f/6M4x+cSSCg+WzNHgA+X7c36DH+gOa5ORuSCgwLPe5khimEECJFJAAUQthe/GKzff2q5+YH3ffE7LXc8fpyJv7mg4SfX9b/CSFEdpAAUAhh+8usNUG3b355KRdP+5ydBxrYdaABAF9AJ/z8NY2+pMYnhBAiNTLaC1gIkV227KsPuv3SfCMjeMTvZnBQtxIARvQqS/j5JQMohBDZQTKAQnRwWseW0dtobhLxuBJ/22j0BRI+VwghROpIAChEB9fkjy8o87hV4q8lAaAQQmQFCQCF6OBCp30Bbjh1BABFXhc3nz4y6D6l4gsA563fyxG/+5C731zOb95aYR8PJLGWUAghRHIkABSigzvz0U/CjlmxWXmxlx+fODToPl+cGcML/zqHnQcaeeazDUHHmwOSDRRCiEyRAFCIDi50Xd5/f3I0ry3eCsDOA41hj/f5U5O5S9XzCCGEiJ8EgEJ0cBcfPgCARbefytzbpjBxYAUPXTg+4mNH9u5Esz/AX2ev5djff8T8DXtZuGlfQq8rAaAQQmSOlIERooPTGnp1LqSitMA+NrRH5FIvnYu9bK+q5753jFZu335iDgAb7p8a9+vKFLAQQmSOZACF6OAONDRT4Al+KyhwR35r6FzkjZi5u/TJuVz41zm8++X2sPvKi70Rn6s5zrWEQgghUkcygEJ0cG8v2xF2zBul1EvnYg/NEQLAT9fsBowdv7N+eSKDupfa97mibBqWKWAhhMgcyQAKIcK4o0RtZYUedteEbwxxuvalxVTVNdu3Q8vGPHyRsb5QMoBCCJE5EgAK0UF9tmY3O83+vhMGdAm6TynF2H7lPPjtcUHHvVGmhp2WbN7Pg++vsm+HxpLWcyTTU1gIIURyZApYiA5Ga82bS7dzzb8W2ceOGNw17HFv/vxY+/o1U4bz2qKt/Gveppheo77Jmd0LjgCtVnKSARRCiMyRDKAQHcyrC7cGBX8AtU2+Vs+5/tQRfHzTSdQ1+WN6jV3VDfb18AygcUDWAAohROZkLABUSrmVUouUUm+ZtwcrpeYqpdYopV5SShW09RxCiPit210TdqzI407qOX94whBe+fHR9u0Ct4s/z1xDTaMPl2MNYM9OhXjsKWDJAAohRKZkcgr4WmAl0Nm8/XvgYa31i0qpJ4ArgMczNTgh8lVJQfiv/eXHDIr7eZQyagj+euoorjxuCE2OjiIzVu1ixqpdPPjeV0HnTBpYgddMCUbaTSyEEKJ9ZCQDqJTqD0wFnjRvK+Bk4GXzIc8C52VibELkO2dQ1qXEqNHXv6IkpnNfuOoI+3q30gI+vP54rjh2MAAFHhdPXTa51fPPmdC3JQMoAaAQQmRMpjKAjwA3AZ3M292A/VprayHSFqBfpBOVUlcDVwMMHDgwzcMUIr/N/uVJNPhiW9cH0K9LsX19d00TwwGSPrwAACAASURBVHp2Crp/yqheEc87d0JfHv3ORAAWma3jZBOIEEJkTrtnAJVSZwG7tNYLEjlfaz1Naz1Zaz25R48eKR6dEPnP2fWjvMRLr85FMZ9b5E1sraCz4otVBkYCQCGEyJxMTAEfA5yjlNoAvIgx9fso0EUpZWUk+wNbMzA2IfJep8LEE/89OxXa1+8+55CEnsNj7gK+751V1Me4q1gIIURqtXsAqLW+VWvdX2s9CPgO8JHW+hJgJvBt82GXAa+399iEyHdNvgAHGpqZOq4Pbznq/MVKKcUnN53E1ccP4XtHHhTzeVq3pACtOoDrd9fy9/9tiHsMQgghkpdNdQBvBq5XSq3BWBP4VIbHI0Te2byvjma/5pRRPRnTrzyh5xjQtYTbzhyFK0q7uLm3TQk7tnpntX3d2We40JNNb0FCCNFxZLQTiNZ6FjDLvL4OODyT4xEi31U3GPusyou9aXuNSGsKV+9sqT3ocbSTG9Q9tt3HQgghUku+fgvRgdSYAWBZYfoCQICHLxofdNu57tCZN5R9IEIIkRkSAArRgdQ0GgFgaWFynT/acv7E/lSUtASZJY7Xc2YI/YEAPn+A5duq0joeIYQQwSQAFCJPffMvn/Hqwi1Bx57+dD0AndKcAQTYV9dsXx/Ws8y+7nasHfQH4IH3vmLqY5+yZld4izohhBDpIQGgEHkoENAs3LSf6/+9JOj4vA17gfRnAEP9+buTIh73a20Xht5T09ieQxJCiA5NAkAh8lCjr/XFdaVJ1AJMRJeSgqDb3zjE6BgSCEg7OCGEyAQJAIXIQ/e9s9K+vmVfnV1w+duH9qe0wJ1wR49Uue3MUQD4A5oNe+oAo8agEEKI9iEBoBB56Lk5G+3rx/5+Jpc/M4+qumZeXrAFVxYEWtYY/FpTWW1M/WbBsIQQosOQAFCIDmDu+r2M/837AFSbO4HTbZ5ZELpX58Kw+6yNIM/N2dAuYxFCCBEso4WghRD5q2fnIlb+5vSImT0rAPxy6wH7mCQAhRCi/UgAKIRIm+KCyGsNs2EaWgghOjKZAhYiD11waP9MD6FV7gh9hK1NIDWNPjbvrWvvIQkhRIciAaAQot25I2QAA9ooCfOdaXM47oGZ7T0kIYToUCQAFCIP+QKaIm/2/nq7IgzNb9YEdK4LFEIIkR7Z+wkhhEhYsz9AaUHkJb4PXzS+nUcTzhMhApSi0EII0X4kABQiD/n8OuIGjF+dOYrzJ2Z+fWDEDKAODgAlIBRCiPSRAFCIPOQLaDoVeblo8gB+dMJQ+/juLOm3W+AOf+vxhwR8zYHW29kJIYRInASAQuQhXyCA1634/bfHceyw7vbxZn92ZNUitX0LhGQAfVkyViGEyEcSAAqRh5r9Abxmls1ZceWm0w/O0Ija5g9J+EkAKIQQ6SMBoBB5qLE5YO8CdmbbiryRCzNng9Ap4KbQiFAIIUTKSAAoRB6qa/JT5DGCPSv+O3xQ1wyOqG1hU8CyBlAIIdJGAkAh8sTcdXsYdMt0Vu+sZltVPZ2LvQAc0rcz3csK+MWpIzI8wtY1h2T8Ln/6iwyNRAgh8p8EgELkiYumfQ7AaQ9/zIH6Zvp1KQagU5GX+b8+laOGdsvk8NpU1+QPuv3VzmoArn9pMe8t35GJIQkhRN6SAFCIHNPQ7OePM77my61VUR8T0FBWFLkQdLaqbfSFHft83R5eXbSVH/5jQQZGJIQQ+UsCQCFySG2jj5G3v8tDH6zmrD9+GnRf97KCoNulhbkVADb6wtf8fcfMagohhEgtCQCFyCHvfhl9KjQ04OuUYwFgU4QAUAghRHq0ewColCpSSs1TSi1RSi1XSt1tHv+7Umq9UmqxeZnQ3mMTIpvNWbuHu95cHvX+jXvqgm53LS2I8sjsMO9XU4JuS9kXIYRoP5lIETQCJ2uta5RSXuBTpdQ75n03aq1fzsCYhMh6F/8tfDrUKvi8dX992H3ZHgD27FQUdPvxWWs5b0K/DI1GCCE6lnbPAGpDjXnTa16k5L/ocAIBzf/W7A4rgByPfXVNABz/wMyw+7qUeBN+3kyZvXoX4/qXZ3oYQgiR9zKyBlAp5VZKLQZ2AR9oreead92rlFqqlHpYKVUY5dyrlVLzlVLzKysr223MQqTam0u38d0n53LLK0vjPndoj1IA9tU2U9fks4PI/hXF9mPKi3MvAAxoqKpvZkj3UiYO7MKwnmWZHpIQQuSljASAWmu/1noC0B84XCk1BrgVGAkcBnQFbo5y7jSt9WSt9eQePXq025iFSLWlW4wyLv9ZsCWmxxe4W35dbzp9JACLNu2jsrrRPj7zlyey6PZT+ddVR9KpKPcCQLdSNPkCTB5UQZ/yItkYIoQQaZLRXcBa6/3ATOB0rfV2c3q4EXgGODyTYxMi3Z76dH1cj+9U5KF35yKmju3D5IMqAKhv9lNV32w/xut2UVFakPVFn6NxuRS+gMbtcuF2uYK6gzQ0+1s5UwghRDwysQu4h1Kqi3m9GDgVWKWU6mMeU8B5wJftPTYhUqnJF+CJ2Wtp9IUHLrO+2hXXc2mtOdDQzPmT+vHnSybRpaQApWBfbRM1DUYB5ed+kPvfmXz+AP6AxuNSeFwqKAB8a+n2DI5MCCHySyYygH2AmUqppcAXGGsA3wKeV0otA5YB3YF7MjA2IWIWCGgWbtpn335r6TY27K4FYP6GvYz49Tvc/84qnvlsQ9B5h937IZc/E1+f2y827KPZr+lkdvdwuxTdSgvYeaCRGrODRrbv+o3k+8cMAuC1nx4DwH3vrMLnD+B2KdwuFVQcWqaDhRAiddq9DIzWeikwMcLxk9t7LEIk45WFW7jx5aU8cekk+leU8LMXFgHw0Q0n8O0n5tiP27inNug855o9y1XPzWfa9w7FSICHu/CvxvN5XC33lxd7eWn+ZiYPMqaDy3Ks8DPAr84cxY9PGEqPTi17vqJlAD/5upLvHjEwE8MUQoi8k3ufGEJkiS37jNp7T36ynr1mORaAkx+aHfS4LiXBmTmXMna7On2wYieNvgBFXnfMr7+20ggsb3zZ2EWca63fADxuFz07G/UAu5YWML5/Of9buwe328gAOrN+u2vCA2chhBCJyb1PDCGyhNdtZOPmb2yZBu7VuZCdB4IDlS6OciyffF1JQBt9e88c24eyQg9/mbUWgMbm+ALAUNb0cK46qFsJvoCm0RewM4DOQHl0n86ZG5wQQuQZ6QUsRIK87vBfn5ICT1gP3vveWWVf/95T8wA4eWRPfnPumKDnaIiwWcRiPeexw6KXPir05Pavc0mBm0++3g3AF+v34XYF/338WvOf+ZtZsHFvJoYnhBB5Jbc/MYTIIFeE9Xq1jT6OGNI14vFVOw7Yt1fvNJrh+AItU5z1TdEDwJF9OnHUkG6M7hs5CzZ1XJ+o6wdzRbEj+7m2sgaPO/jv4w9obnx5Kd96fE7oqRHd9cZy7nojeu9kIYToyHJ7zkiIDPrvoq1hx/bWNvHhyvASLz/8xwI+XbPbvr14836AoB3C1WY5l1CBgOaLDfsoaCXDl9uhn8E5/e3XGrcr+G/1r3mb43q+v/9vAwB3nXNI0mMTQoh8IxlAIRK0YvuBsGO+KH19ncEfQDezZMutZ4y0j539p08jnrvfLPRcEdLb9+nLJ9vX86FGnjMA9vt10I5nIYQQqSUBoBAJ0DpyoBerq44fAsBJI3u2+dgXv9hknHPckKDjJ4/sZV8//ZDeSY0nG3z8dUtv70gZwMPMcjdCCCGSl3AAqJQqUUrdrpT6m3l7uFLqrNQNTYjs5SxQ/MMThoTdf/7EflHP/dlJw/jRCUMB6F9RwvK7vwHAyN6dIj7+gXe/Mu+Pvgv2gQvGtT3oLHfdlBH2dV8gPAPY7I896L7llaUpG5cQQuSjZDKAzwCNwFHm7a1I9w7RAQy6ZTpj73oPgDvPHs2tZ4ziymMHBz3mxIN7cHCvTlw7ZXjY+cUFwaVeSgs9nDGmd9D08U9fWMgD764KetywnmVRxxS68zgXlRa2/LtMHNAFlyt8E0isXvwivvWCQgjR0SQTAA7VWj8ANANorevIj7XoQkRldfGwslHWztVfnzWaKxxB4Dnj+/LeL47nosMGhD3HT04cGnasS4mXNbtqqG5oprqhmelLt9v1AS3dysJbvQ3pUQqQ8zuAATbvrbOv33n2IWEZwGVbq9p7SEIIkbeSSRs0KaWKAQ2glBqKkREUIm/VNQXv1HVm844c0o2nPl0PtARkkWrzRQrWrE0iY+96P+j4Hkf3i0h1B6f//Li86ZFrdTYBKPS68LhkibIQQqRLMu+wdwLvAgOUUs8DM4CbUjIqIbLUgfrgALBbaUsP21NHG5syirwtv1bO0iYVJV7e+vmxEZ93woDIGxyi7Sq2FBe4KQ/ZHZyrAo6NNS6lwqbKhRBCpE7CGUCt9QdKqYXAkRhTv9dqrXe3cZoQOamm0ceJD85kd01T0PHQadlPbjopqCevMwM4+6aT6FwUOVi7feoo3lyyLey4FQDec96YhMeeK5zBriK4MLQQQojUSmYX8PmAT2s9XWv9FuBTSp2XuqEJkT3G3PleWPAHLfX8LAO6ltDVcczjmLaNFvwB9OxcFPG4z29M73aEYMg5le1SKiiTKoQQIrWSmgLWWtursrXW+zGmhYXoMCpKwzdmhHrr58ey5I7TEnr+rfvqAcLaouWjY4d1t68rFTx9HiqeHcFCiPy3ePN+e5OeiE0yAWCkc3O/FoUQIVor+hxpY0aoMf3K416nZxU9/u6TcwFYsjn/d8Bed0pLyRylgrOe4/qXBz222Z8fG1+EEKlx3p8/49wo3ZREZMkEgPOVUn9QSg01L38AFqRqYEJki3umr2yX1zlllNEV5IlLJ3HoQV2D7jt2eLd2GUMmOafLlVJ4HesnQ7uCvL0s91vfCSFSI2DOCGyrasjwSHJLMhm7nwO3Ay+Ztz8Afpr0iITIMlZpl3R78rLDaPYH8LpdDOpeyhOzW+oAHj44/wNAJ5cCr6MMjDukdM7izfv55qT+7T0sIUQW2by3jkZfgN7lkddQi9Ylswu4FrglhWMRIiudPb4vby7ZRkmBm7omP2BMVw7uXpry17KmlHt1Cn5DK4hhqjmfuJQKyvqFZgDjaQsnhMhPxz0wE4Cx/crbeGR2Wb6tiiKvm6E9ond3ag9xB4BKqUe01tcppd7ELALtpLU+JyUjEyJL7K5uZMKALrz202O48tkv+HDlLq47ZUTbJyahS8iaQW8H2ATipAj+O4dugllXWdPOIxJCZBOfYx2ws0tQIKDD2khmmxv/s5S+XYp48rLDMjqORDKA/zD//L9UDkSIbLWvron+FSUA/PV7k9tlB6pSiq/vPQN/QLO7pjEvWr3FQymF37H5xh3SFWTu+r3tPSQhRBbZ5Ggd6bR1fz0Dupa0eu7cdXvo37WEfl2K0zG0NjX4/BRmQWmvuANArfUCpZQbuFprfUkaxiREVqlt8tGpyPhVcbtU2HRkunjdLrxu7OCzI3G7FM7N11Zf4G8f2p+XF2yhZ6fCKGcKITqCf36+KeLx9btr2wwAL5r2OcVeNyt/e3o6htamhiZ/VtR2TWhhkdbaDxyklGq7CJoQOWxfbRN7a5ooK5QKR+3J7VKM6tPZvu0yM6Aje3diQNdijnHUDBRCdDw7DtRHPF7f7G/1PGsGp63HJSsQ0Pzqv8tYuf1A2H0NvkBWFLpP5lNtHfCZUuoNwO7irrX+Q9KjEiKDtu2vx+NWeF0uJv72AwDpS9vOQrOs1h6YgNYUedw0tPLmvWCjTA8Lke+i1WANtLFEZ/6GlveHHVUNHGhoJqA1I3t3buWs+H24cifPz93E83M3seH+qUH31Tf5KfJk/jMlmQBwrXlxAZ1iPUkpVQR8DBSar/+y1vpOpdRg4EWgG0Y9we9prcN7bwmRZkff/1HYselLt3PbmaMyMJqOKbTsixUQBrTRIaS1APBbj89J69iEEJl3oL456HbnIg8HGnxBa4cjuWja5/b1I++bYV8PDdJidf2/F1NZ3cg/rjgi6PjV/4hcFllrTYPPnxVJhYQCQKVUD2A6sMZsARePRuBkrXWNUsoLfKqUege4HnhYa/2iUuoJ4Arg8UTGJ0Si3l++I+Lxkb1j/o4jUiA0A1hSYLxVBbSm2OtO+/SNECK7OTeBnDKqF7eeOZIpD822p3hrGn1c869F3H3OIW2uCUzGqwu3AkZNwtZep6qumQafH6/bhdZQXhxfd6h0iHsSWil1JbAc+COwSikVV9kXbbBqOHjNiwZOBl42jz8LnBfv2IRIxt7apqjf2u49f2w7j6ZjCw0AK8yyOFpDoddFQ7O0ghOiI1tbaa8844sNe+1Zg4CZAXzvyx18tGoX//f+V/bjWpsebq3lZyysGrGhrLaelzz1OUf8bgbrdxvjHtIj9XVk45XIKsTrgEO01kcBRwO3xvsESim3UmoxsAujg8haYL/W2mc+ZAvQL4GxCZGwmgZf1PsqSjP/ba0jCd1o/YNjB3NI385ccGj/NqeAhRD5rckX/AWwqr7Z/tJolQesbTLez99Yss1+XGszB9WN0d//Y1HXFHz+xYcPALCLPX+51dgM8vXOagDKCjP/mZJIANikta4E0Fqvw1jLFxettV9rPQHoDxwOjIz1XKXU1Uqp+Uqp+ZWVlfG+tBBR1UR4A/C4FKeO7kVhFizY7Qhu/MbBAEF1DytKvPQpL2b6NcfRs3MRRV43jT7JAArRUUV6r7aKP1tZvt3VjQBB5aRqQ4I0ZxZu3rr4N49d869FLc/dGDm49IVkHdfsMiZAc3UXcH+l1GPRbmutr4n1ibTW+5VSM4GjgC5KKY+ZBewPbI1yzjRgGsDkyZOlH5RImaVbWpazfu/Ig5gyqicnHtwzgyPqeH560jB+etIw+/bb1xxHj5Caf0Uel2QAhejAQmdrSgvc9hTwTa8s5aZXlvLD44eEnVcfMk3bp7yIdeZU8pXPzY97I4gzuxgaXFpfUq2OJaUFbmqb/Gzdb5SvKcqCOoCJBIA3htyOvGgqCnMDSbMZ/BUDpwK/B2YC38bYCXwZ8HoCYxMiYet2t6wp+e15YzI4EmEZ3Te8NEORbAIRokOrCtkBXFbkIaRZUMQviaFZutCe4g3N/pgCs5mrdjEopBd86BSwNU3dbGYAOxV5qW3ys3GPsXklJ8vAaK2fTfI1+wDPmt1EXMC/tdZvKaVWAC8qpe4BFgFPJfk6QsTlhbmRK8uL7LJhTy3765pp9gei1gITQuSvjXtrg26XFXrCSkc9O2ejfd3aobtutzH9+vglkwhoGNqzlNMf+cR+3IH65pgCwO///YuwY/tqg4PSFduMNX9+M8i01iiuMAtDZ8MUcLuPQGu9VGs9UWs9Tms9Rmv9G/P4Oq314VrrYVrrC7TWje09NpH/tNYMumU6N7+8NOw+a13J1/ee0d7DEnH45OvdAPz0+YUxPb6twrBCiNzysxcWBd0uKfC02qLzuAdmsmxLlX1e906FTB3Xh5G9O/OfHx1lP642yk7ehmY/O6oawo6XFLi58tjBlBV67LI0e2oaGXTLdHtGyRcwM4H+4HXL2bCuPPMhqBDtqLLG+F7x0vzN+AM6bE0IRK8wL7LD78ySPO+v2GkfCwQ01Q3NER8fSLK8gxAiO1mbxsqLvfYmkGicLdk8jsc6e/L6/JE3l/3shYUced8M6pp83PpqS/LAF9B43C46F3nsBMIXG4I3k1jTzKFT0oVZkAGUBqeiw5h8zwf0q2gp1Dn0trcBOHpoN+465xDKCj1cMLl/poYnYuRxh7/R3//uKqZ9vC7iwm9JAAqRP5xf2kf1MQr0e9wqbAo41N66lsZizmxhgaclEAtdE2j5cOUuAEbf8V7Q8SZfAI9L4XIpe6ahU1FweRcrAxhau7TQk8MBYMhOYEsVMF9rLRs4RFb588w17K5pYndNeHfB/63dw2kPfwxAl+KC9h6aiNP0pdvDjk37eB0AfzX/dJIMoBD54xZHBs4K2LxuV6tTwABb99Xb1w/q1rKBwznjYwVrTm1VHFi3uwa3S9kt6FwhgajPr/H5AzSFZBdVGwFre0gmBC0CJgBfm5dxGOVbrlBKPZKCsQkRxB/QXPb0PAbdMt2upWTRWjPrq10R13vVN/l58L2vwo5HcnDvspSMVaTP2H7lcT1eAkAh8sf8Dfvs66P7GFUCvjWpf1jgFWrr/npOGdWL0X06B7VhG9y9lEuPHAhEzgCG9hwO1dAcwK2U3YLOWut37oS+TBzYBV9A02DuCO7Xpbitv167SiYAHAecpLX+o9b6j8ApGAWdzwdOS8XghHDatLeO2auN4t8X/+3zoPveW76Dy5/5gmfnbIh4XqyKC2RVRLa74bQRABwSoURMJDIFLET+sOroje1XzoCuJWy4fyqnj+kdlAEc3z/8S+JHq3ZR3dCMN8ISkjPG9AEirwGM1uLNcsGh/Y0pYK3RWvPUp+sBuPLYIXQu8uLzB+wsYmcz8MyC5B+QXABYATjTJaVAV621H5AdvCLlah3V3yurg3/Eqs3CoHe/uSKsHpM/jgjgmKHdkhihaA9KKQ4f1JXORbG1Uorn/18Ikb32O9bxPX35YUH3OWeAn7ws+D7L3PV78UTY5GdtCtm4p476Jn/QTFLo7t1QZ4ztw5pdNby9bAd/mbXWTlJ4PQqN8VllrVu0XidbJiWSCQAfABYrpZ5RSv0do3bfg0qpUuDDVAxOCKfaVno1On+fNu9tWesx66tdPORoBr7ud2e2+hqR3hxE9in0umIvBp0lb7ZCiORYS3m6lHjDOgRZa+ouOWIg3csKOH5ED44b3j3sORZs3Bd2zHrfv+mVpYy6413ue2elfV9oKzenKSODO0X94YPV9vUCt4uPV1eyraqB1Wb/32yT8Ked1vop4GjgNeC/wLFa6ye11rVa69BuIUIk7bXF24Ju3zt9hZ1ar6prWafh3NZ/5bPzmbHK2MF16EEVuFyKg7q17AR+97rjePUnR6dz2CINir3umNvBaYkAhcgLz5vF+jsVRV6qs+H+qdx7/liUUjz3g8O56LABABw/okerzxs6LfzivM329UgzCAO7lpjnBYdQzsc6dxe/utDobJsNxZ+dkh2NC6gE9gHDlFLHJz8kISL7fN2eoNt/+2Q9/5pnvCH8aeYa+7jfkV93fnu77cxRAHx4/Qn2sdICj92Sp095UeoHLdKiKJ4AUOI/IfJKWWFsyz+mju3DE5dO4sbTDm71caGBXHWjj0G3TGdXdUPYJrLzzM0dAN5WSrmUFbYEqdXm7FU29P91SjgAVEr9HvgM+BVGf+AbgV+maFxChDk+QjrfWvjr7A1p/cKGrt2wvn05f9lLCz0UFxi/lK2l+kV2KXb0A9ZtRHjyvypEfiktiC2QUkpx+pg+dClpPWC01pCHWralKuxz4f5vjbM/d6zM4Vs/PzbsXGc9wBqzSP0xw8I/wzIpmQzgecDBWuupWuuzzcs5qRqYEKGej9Cr1+1SXPKksSO4k/mNy1rAu2xrVdBjna13rjh2sHFOkcdemNtGGSmRRYq8LnYeaCQQ0G1m+NoKEIUQueWxiyfG9fjOjrIvz3w/fIPI+AGRS0uVFnrsz5O7zzmEV39yNEVeN16XETpZxZzHRChN5XYpHv3OBADqzSLQxw83pqIj7UTOhGRqXqwDvMiOX9EO3lu+w/4mNqhbCRv2GKVd5qzdw2drjKnhPl2KqN5ZY5f9CO3d6Jzi/dWZo/jlaQfjdbuoKDWKP//4hKHp/muIFGky63VVN/razAZI+CdE7rO+yF1+9CD6xllPzzkdG6kWX7S+vIUeF01mDb/hPcuYNLACaOlGFK1t6O1njQZg8qCuQEsbuuICNx/dcEJYt5BMSSYArMPYBTwDRxCotb4m6VEJ4bB5bx0//McC+/YJI3qwYc5GABZt2m8fLzV/ya2FuHtqg7t+lDreBFwuZU/9lhV62HD/1PQMXqTFwb2MClT+gG6zzp8kAIXIfdb7etfS+Ls1OWsEttUxxCmgW17X2WvY42o9ALRmmEKDzWKvm95ZtNY8mSngN4DfAv8DFjguQqRUbUhdv1+fNdpec2EVBQXoVmqUBbDWAO4zA8DV95whAV6ecZtvvL5AoM1OH7ILWIjcZy3p+eTryqSeJ1r90FF9wgvL+wPa3lToCQoijfcf567ewd2N9nJPXDop6msXZ9kmkIQzgFrrZ1M5ECGiaXQ00b7quMF43S6G9wpv2WaVBrACgqr6ZkoK3EHb8UV+sN6MA4EYMnwS/wmR86yNfmeP75vQ+dbSoe5lkTOIFx8+gDteXx50zBcIRMwAWhsMnVO51nrA1qZ3C7OsDEzcAaBS6t9a6wuVUssIfmtVgNZaj0vZ6IQAdhxoWct31XFDAKPIptP1p45gTL/O/HfRVvsX9kB9c1DPR5E/rGmc2DKAQohcpbXm9cXb7ABrXP8uCT3Pv390FNv2N9gFo0NFms71B7T9eeLMAH64cidAUE/6QjO711pP4sIsS0YkkgG81vzzrFQORIho9jnW8lnr9kJ/ia88bjBfmE3C95ntgvZLAJi3rDdjYw2ghHhC5KspD81m3e5ae/rUk2C5hp6diujZKfr6u0jP63MEgM7Abru5wdDZZ77A3BjSWp/faMFnpsQdjmqtt5tXdwObtdYbgUJgPLAt6olCJKjG0QIu2hqKYq/bLuPyg7/P588z1/DBip2s2pGdLXhEcloygG2v8JP4UIjctW53LYBd9zPaxotkRVoqFHAEgM7NI9Z6wetOGW4fc9vLUnLnDSeZf8mPgSKlVD/gfeB7wN9TMSghnN5fbqTbn758clCv3kcummBfV0rhdny7snpGivzkMRdh+wMa3XqvdtkEIkQe8aSphl6kwNIXZRPI/10wjuNH9LDLwhj3u+xzckUyAaDSWtcB3wT+orW+ADgkNcMSosW8DXsBOHlkr6Djpx0SfDtSILQ5LAAAIABJREFUev3WM0amb2AiY+wMoL/tKWDJAAqRm0K7OQF2EeZUswLAkgI33cuMihLONYDOTSCH9C3nuR8cHtTabUgPYxdwImVqMiWpAFApdRRwCTDdPJZde5xFXispCF7CGlrfqdDj4urjh7TnkEQ7sb6Nn/nYJ7IJRIg8VdsY3qItfRlA43ndSvHi1UcCwWsA3W2s37vp9JE88/3DInYFAVh4+6kpHG1qJFMI+jrgVuC/WuvlSqkhwMzUDEuI+IWu4b3ulBFZt+hWpIbb8SHQdiFoCQGFyEWRevSmKwCsazLWGFY3+hybzAL22sPiNjoOlRV6OOngnmHHf3HKCEoL3VmZGUymDuBsYLZSqkwpVaa1XgdIFxCRUtaC2pMO7hHx/gsO7U+JvTM4+L5+FfG1CxK5w7kep60AT+I/IXJTTYQMYLqmgA+YdQahZTap2a/tINSqMxuvax0bRbJNwgGgUmos8BzQ1bipKoH/p7Ve3vqZQsSuwWd8+zpiSLeI9z94wXj7epMv+JO+i5SAyVvO6f4cWnMthIhDpAAwXRlAq8zLwb062TuCm/0BqhuacbtU1nXxSIVkpoD/ClyvtZ4JoJQ6EfgbcHQKxiU6uGZ/gA9W7AxamNuWRjNYtIxPsGCoyC2yCUSI/FTd0Bx2LF2dnY4Y0hWAu889xG400OQLcKDeR6ciT14uJ0omACy1gj8ArfUspVRpWycppQZgZA57YazPnqa1flQpdRdwFWA1+rtNa/12EuMTOUprzSF3vEeTYwdYLN++mnzG408Z1ZMnLzssbeMTmTegosS+Lr2AhchPoWsAfz11FIWe9GTiDupWaveMtzafNPkCvLZ4a8S1iPkgmVB6nVLqdqXUIPPya2BdDOf5gBu01qOBI4GfKqVGm/c9rLWeYF4k+MtS9729kj999HXann/HgYag4A/iS/uXF2ffYluRWs4F2ZLhEyL/NPr8XPviYqBlDfjg7m3mmFLCatnW5AvkbfAHyWUAfwDcDbxq3v7EPNYqs5PIdvN6tVJqJdAviXGIdvbXj404/9wJ/RjQtaSNR8fPyuQ5xfKtb8qoXlx3ynC+f8zglI9JZBdn0VaZAhYi/7z75Q77+iPfmcgLczdxYoRdtungcbtwKdhWVd8ur5cpCWcAtdb7tNbXaK0nmZdrtdb74nkOpdQgYCIw1zz0M6XUUqXU00qpiijnXK2Umq+Uml9ZWRnpISKNnIU5L3t6Xlpeo7bRH3bsyCibQJzcLsV1p4yQ/r8dgDeeMjBpHosQIvWsfrsA5cVefnzi0LBar+lU4HFRZe4MvuLY/EwqxJ0BVEq9SSvvqVrrc2J8njLgFeA6rfUBpdTjwG/N5/4t8BARMopa62nANIDJkyfLe3s7W72zpbeusxF2Ks1avSvodv+K4qysoSQyx5kRbjsDKG8TQuSa+99ZldHXL3C77NqAY/p1zuhY0iWRKeD/S/ZFlVJejODvea31qwBa652O+/8GvJXs64jUc2bnpoxKTzr+gXeD+/j2l3p+IoTbpbhmynAem/F123UA22lMQojU6V5WyO6axoy9fqHXTZ35eedOU+3BTEvkb7UCqNRaz3ZeMHbvrmjrZGXspX4KWKm1/oPjeB/Hw84HvkxgbCLNKqtbfiHfW76TaR+vTeh5tNYs3bK/1ce8d93x/OiEofyfo9afEBavOR3U0By+ZtRJEoBC5J5MBn9gZACtPvRfbq3K6FjSJZEA8I9A9wjHuwGPxnD+McD3gJOVUovNy5nAA0qpZUqppcBJwC8SGJtIs5++sBCAvuVFAPzu7cTS9P+cu4lz/vQZH67YGXZfRYmxhm9ErzJuOWMk/StSv9FE5D6PuREktP5jOIkAhWhvm/fWcdYfPwlaN56Ixy6emKIRxafQUW9wh2M9Yj5JZAp4mNb649CDWutPzHV8rdJafwpEWskpZV9ySN8uxWwzfykCAY0rzsW5t79mJHjnb9zHKaN7Bd1XUVrAxIEVeVl4U6SOtRGkvkkygEJkmykPzabJH2D4r95h/X1nxvV+vmyLkXEb0r2Uc8b3TdcQW+UsOJ2u4tOZlsjfqlMr98n2yw7ikL4ti2KbA4l/w3tidssUcrM/wIcrdrKuspaPVu1q5SwhWkrBWM3aLz58IC9cdQQzbjgh6HES/wnR/pw79edvjKtACPe/uxLI7O/uqh0tGx5/cuLQDI4kfRIJANeYU7ZBlFJnEFshaJGjnKl8Z8Yv1kKZc9ftYW9tU9T773lrBVc+Nz/xAYoOxSoO3mAGgGeN68PRQ7vTtzx405BkAIVof1ccN8S+vjlKxQitNb9/dxVb9tXxh/e/4i+z1gTdX5TB/rtnOzKPQ3qUZWwc6ZTIFPB1wHSl1IXAAvPYZOAo4KxUDUxkn0WbWjZteBwB4OR7PuRfVx3JUUMj1+rz+QP8e/4WbvvvMgBuOv3goPt3VDWwbGtV0LfEAV1l569ondfcmWcFgFaNMGn9JkTm+R0zQ9Hq933y9W4en7WWx2e1zAT95MRhduvPs8b1iXhee7j6uCG8uWRbxl6/PcSdAdRafw2MBWYDg8zLbGCc1np1KgcnssuFf50DwNRxfcLW/M1bb+yWevfL7Uz67QdBC/Mfn7XWDv4gvMzLkffN4Krn5rPPkR08ZmikfUZCtPB6zAyg2TnGDgBD4j8JCIVof0/MbpkQrG+KvFErUtcnrTUFHhcVJd6MTr06203mq4RawWmtG4FnUjwWkSO+ObEfP35+YdAxa33v3W+uYG9tE7trmujXpZg3lmzjoQ9i+16wzbHT6obTDm7lkUKAx9XSrxPA+k4SGu7JFLAQ7avR58fvaNFTFyUAjNTjfev+et5etoM+5UUZ3QhY0gECwPzc2iJSzvlNbWiPsrBvbtaHr9W+p7bRWBd4zb8WJfR6PToVJnSe6DisRebWz6L1YWEdt34mz3j0k/YfnBAd2EtfbA66bW3UChWp7eeP/mmsLNue4dIrpQUJ5cdyigSAIiYLHOvzBnUvpXtZcGs2pZQd9AGc9rBRKUhauIl0Cc0AWrmCQo+bj288iUe+k5n6YUJ0dIUhZVMaI0z1AtQ2hW8g/HLrAQDOHNs79QOLQ0eYAk44AFRKna2UkgCyg3jny+1AS1HOkw4ObgOnVPg3tveW72DCgC4Rn29QtxKeumxyGkYqOgqv+SFj9aR2OaaLBnYrCfsQEkK0j2Z/y/Svx6XwmRUkNu2pY9At0/nHnA0AQUmDUJMGVqRziG3K19p/Tsn8DS8CvlZKPaCUGpmqAYns9NycjQAM7Gp05bj3/LH8/ORhLff/byN/nR3cFu6H/1gQtQr8W9ccx5RRvaLuDhOiLXXmh8crC7cAwQEgRK42L4RIPysr//KPjsLrdrGuspb5G/Zy/IMzAbj99eV8sGInd78ZvXusfIFLv4T/hbXWlwITgbXA35VSc5RSVyulWisULXLMwk37OP2RlsYvbvNDtsDj4urjW+o87TjQwH8WbAk7f3D30rBjJ4/sSVmhsb7igW+NS/WQRQfhCwTv7ghdLy6dZITIjCbzi//ovp2pb/bz7vIdfPuJOfb9XUsLuCqk5mvvzkVBtwszWAOwo0gqxNZaHwBeBl4E+gDnAwuVUj9PwdhEFvjmX/4XVBF9tKMDiNWJoTW+gA5aL3j18UN4/NJJ9u3Jg4w0vzVVPKR7Ka/8+Kikxy3yX+jm3rAAsN1GIoRwsjKABVE+I4b3DC6svOTO05h904lBxzJZBLqjSGYN4DlKqf8CszBawB2utT4DGA/ckJrhiUzzhmzTd07ZetqYvh3YtYRmXyAoUDx3Ql8KPS2/2Ad1K2XJnafx3cMHAjDpoAoOPahrKoYuOhgVEvJJAlCIzGj0+XEp8EQJAKvqm4Nulxd7gz4XoO3PF5G8ZDKA3wIe1lqP1Vo/qLXeBaC1rgOuSMnoREYFAjpoMe/c26YE3e8MBsf2Kw87/+ih3fAFdFCtp0P6hj+uvNhL3y5G54/xUTaNCBFqULeSoNuukHczCQCFaH/n/ulT/jxzbaubKJyzSk7OdeXR1o+3pyHdS/n2of0zPYy0SbjQjdb6slbum5Ho84rssa+upTPHS1cfSa+QNRpKKd76+bHc985Kdlc3UVboocaxq+utpdvp26UIr9vFU5dNpkuJN+prHTOsG2/+7FjG9Osc9TFCOI3rb3xZKPS4aPQFwjKAQoj2UdPow+/XlJd4WbKlCoCG5vgDuBtOO5ht+xt4ZeEWGhM4P9U++uWJmR5CWsWdAVRKVSulDjgu1c4/0zFIkRnOYO6IIZH7/I7pV07X0kK+2llNTaOP00b3YsP9U1HKOH/1zhoK3C6mjOrV6tSuUoqx/ctl4b6Iy+DupfZmkNAZIwkIhUi/Zn+AMXe+x/jfvM+Tn6xr+4Q2TBhofLHrVyH94NMt7gyg1lp2+XYQX5lp+rZS4M7t+lbLH2f7rUjtfoRIBY9L2S2nwr47yI+dEGm3dMt++/o901cm/XyXHjGQiQO6MCbCsiKRWolkADubf3aNdEn9EEWmXP0PoyXPqaN7tfo451qPSHX9YtktLEQinIvMQ7PHzlvb9te304iE6Fja6rW95I7T+MslkyLe982J/ZhxwwlBx5RSEvy1k0Q+mV8w/1wAzDf/XOC4LfJMWxXRnRnASBu3vKGr84VIEedOwbBC0I7bR9//Ea8v3tpu4xKio6htitzn11Je4o26/vvMsX0Y2qMs4n0i/eL+ZNZan2X+OVhrPcT807oMaet8kXvcbazLcwaIkb4Mej0yFyfSw7m8oK0Z4EWb9iOESK3qhuaIx+fcerJ93aoHOGlgF17+UUud1/rm1oNHkV5JpWaUUhVKqcOVUsdbl1QNTGTe+P5GGn7iwNZLsxQ6puEiTQd4JAMo0sSZXQ7PAAY/trW+o0KIxETa7bv+vjPpU96yicPqCHXh5AFMHtSVX505CjA6gojMSbgMjFLqSuBaoD+wGDgSmAOc3Np5IncM7FbK/vpmOhVFL98CwS17ImYAZQ2gSBNndjm8E0jwgcqaxvYYkhAdSqQsXuh63G5lhWy4f6p9+8rjBnP44K5S9zXDkvlkvhY4DNiotT4Joy+wzLHkmI9XV/LbtyI35N5b2xjTN7SCoAxgeAhYIFPAIk0KgjaBBN8XejvQxmJ1IUT8GhOYxlVKSfCXBRLOAAINWusGpRRKqUKt9Sql1MEpG5lIqdmrKxnSvZQBXYO7J9zyylK2VTVww2kjWL7tADNW7uKJ2Wt5+5rj2FvbTL8uRVGesUWhN/x7xJDupazbXQvIFLBIH2f7qNZ2AUPkLydCiOTUm5tAHrloArtrGjl6aPcMj0jEKpkAcItSqgvwGvCBUmofsDE1wxKpdtnT8ygtcLP8N6cHHd9W1QDAT59fyMyvKu3jZz72Cb07FzGmb9udOSI1/D5ueHc7AJQpYJEuzi8fbbUOnTq2T5pHI0TH0+Dz43YpzpvYL9NDEXFKphXc+ebVu5RSM4Fy4N2UjEqkxPJtVdQ0+Jh0UAUQvl3f5+i16Az+LLVNPkoL2/4Rce4CHtHLqBP+67NG8/m6vXy1sxqvFIIWaRI0BRya8wu5GSlTLYRIzkerKu1i7CK3JLMJZCww0ry5Ums9O8bzBgDPAb0w9gxM01o/ahaRfgkYBGwALtRa70t0fAKmPvYpAL87f2zE+29//ctWz69v8lNS4G71MRA8DXfz6caPhNftYnD3UjMAlA9ekR4FrdSgDA0IpTWcEKm3crt0gM1ViXQCKVdKzQJeB74LXAK8rpSaaXUJaYMPuEFrPRpj5/BPlVKjgVuAGVrr4cAM87ZIgdv+uyzi8QUbW4+vfQEdUwBofQj36lwY3BXEzPxJKziRLqvMdoUQYQ1gyI+djrhHXQghOqZEUjO/xej4MUxrfb7W+jxgOPAFcG9bJ2utt2utF5rXq4GVQD/gXOBZ82HPAuclMLa0afT5+e1bK6iqi1z0MheVFLSdAC7yxpIBNH6MQuuwec2UTKQ1gkKkgrNIeXgZmGD+8HJlQgjRYSUyBXwKME5rbb+daq0DSqnbgMippiiUUoMwysfMBXpprbebd+3AmCKOdM7VwNUAAwcOjHfsCXtzyXae+nQ9jT4/95wXeUo12/XrUhx0e09t23XRCttoAwctGcDQANBt7v6VKWCRLsGbQKK3ggMIyC5gIVJuWM8yRvSSdm65KJFP5iatdVhJffNYzJVWlVJlwCvAdVrroEUE2qjXEPHdWms9TWs9WWs9uUePHvGNPAlb9tUBUNOQ/d0E3liyjZMfmmXfvuWMkXQtLWDr/nqWb6uyjx+o93HMsG727VW/Dd4hDNA3JGiMxA4AQ36arDVZMgUs0sWZoQ5rBRc6BSwBoBAptb2qnjW7aqTNYo5KJANYpJSaSOTWm4WxPIFSyosR/D2vtX7VPLxTKdVHa71dKdUH2JXA2NLmkQ+/BmDx5uz/Qb/p5SU0NAco8roo9Lj54fFDeGL2WgAeen81T19+GLNXV1JV38ykgRWcMqoXJx7ckyKvmz7lRWw3S8OA8e2uLdGmgK2PW8kAinRxBoBhGcCQx8pGRSFSa976vQBBnxkidyQSAG4H/hDlvh1tnayMeZmnMHYOO5/nDeAy4H7zz9cTGFvadS5uvS1aNij0uGloDtDQHOCCQweglLJ79FrB2mVPzwOgc5GX7x8z2D53zq1TGHTL9Lhez1rj5w4NAM3XlDIwIl2Clii02QlEIkAhhLDEHQCabd+ScQzwPWCZUmqxeew2jMDv30qpKzAKSl+Y5OukTIOj1c3YfuUZHElsirwuquqN69YuXms6dtGm/Zzw4Ez7sZ2KWv8RiKUOoCXarkvJAIp0KWylDExoRCgZQCFSa21lbaaHIJKQTCeQhGitPyV8dsYypT3HEqu731xuX4/U+DqbvLpwCzsPtCzFLDYDwF6di9hX18yOA8Gp+oJWNnlcdtRBdC9re1bfCvzKioKzo1bg7JEAUKRJa63gQgNCWQMoRGo9NsNYGnXKqIh7NkWWk0/mGKzY3lJrrCGLA8C1lTVc/+8lQcesNVKPXTwx4jmRgrOPbjiBKSN78uMTh8X0ukN7lHH9qSN4/JJJQcffXmasCPhqhxQKFelR1EoruNA1gQFJAQqRFn/93qGZHoJIQLtnAHOR82Okril7A8ApD4U3YykyM3wjenWic5GHAyG7mE8YHr6TekiPMp66/LCYX1cpxTVThke9v7FZCrCJ9AjeBRyaAZQpYCHag7utRtwiK8UdACqlJrV2v1XkOZ84s351jfEHgLWNPnx+TXlJ+28gcfb/LfC4MRqxGH5y4tB2GVNr08xCJMNZYih0DWoo2QQihBAtEskAPmT+WQRMBpZgJMnGYXQIOSo1Q8seEwdW2C2nqhvjrwN47O8/Yl9dMxvun5rqobXJ4/hmFlrUub2+tckmEJEuXYoL7OvhZYiCAz4JAIVIHZ/ZWue44d0zPBKRqLg/mbXWJ5k7gbcDk8yizIdidPTYmuoBZgO3C7qWFjB1XB8affFnAPdlsH2cu5UAcMu++rS+9tnj+wJQngOlc0RuuuiwAfb18MLPwbdlCliI1GkyA8BjhkkAmKuSWQN4sNbabv2mtf5SKTUqBWPKOk2+AAVuFwVuFz5/9n6KDOpWwph+5fTuXMSmvXW8v2Jn0M7I0KnY08f0Tut4BncrAcIzM0KkivMLTrRC5BbJAAqROk0+IwCUXu+5K5n/uaVKqSeVUieal78BS1M1sGzS5AtQ4HHhcSk77Z2NquqbKfC4+PVZozlltLEtf8KAlrqFoQFgurfuWxkXif9Eewj9MQst+1KdA20chcgVVgDo7Mctcksy/3PfB5YD15qXFeaxvNPs13jdio1769hW1ZB19cR++9YKjnvAWGf46kJjFv6CQ/vz6c0ncehBXe3HhX5TS/cawG9O6keBx8U55lSwEOkUXog82OOz1rbbWITId42SAcx5CU8Ba60blFJPAG9rrb9K4ZiyTqMvQIHHbfc9rG700bkoO9a1bdtfz1Ofrg87rpSif0VJ0LH2DluH9Chj9T1ntPOrio4qtBC09T1tfP9ylmypysCIhMhfVnUMZykmkVsSDt2VUucAi4F3zdsTlFJvpGpg2aTJb0wBW7udEk0A+qOsQq9KYpPIv+dvDrp9x1mjoz52wcZ9Cb+OELnH+H1zZXGNspmrdrFMglORg6wMYOjmQpE7kvmfuxM4HNgPoLVeDAxOxaCyTbMvQIFb2WvmogVybZmzdk/Ysc/X7WH8b97n49WVCT1naUFwEvfg3p0Seh4h8o31Rc0K/44e2i1jY4nm+3//grP/9GmmhyFE3CQDmPuSCQCbtdahX12za3FcilgZwN01Ro/d1Tur2zgjskht5Kys3Cdftx4Aaq158pN17HL08q2sbgzr7dtayZUBXYvjGa4QOc16M3IpxcjenSgtlMZHQqSKZABzXzL/c8uVUt8F3Eqp4UqpPwL/S9G4skZdk4+vdlRTUVLAByt2AnDrq8vaOCuyj77aFXbMWkDb1rTy2spa7pm+kp/9axEAG/fUcti9H4at/6soLYh0OgAXTR4Q9T4h8k0383dhwoAueN2urN7BL0QsGpr9vPTFpqzYiCgZwNyXTAD4c+AQoBF4AajC2A2cV0oKPEz73qHcfPpI+wd9/e7ahJ7rhbmbwo41B4wPpbbWKVk1zPbWNuHzBzjhwVkRH9dFii4LARibkN6+5jhuPmMkHrfCl2WVoLPhQ1zklsdmfM3Nryzj3S93ZHooNJg93iUAzF3JBIBTtda/0lofZl5+DZyTqoFlk6OHdWdA15Kgtmqxck7ZnjWuT9j99Wav3mkfr2PTnrqoz2OtOwxozUshGz+cSgqi/zKG7pIUIt+N7tsZr9uF1+WiOcsygLtrmjI9BJFjrJakz3y2IbMDAbsrlkwB565k/udujfFY3rj+tBFtPqam0cfJD81i8eb9ADwy42v7PufmkQUb93HKH2ZTWd1oH3tl4Zaoz2ul29dV1vKhORXt9Oh3JnDNycNiDvK8bgkGRcfhcau0dvGpafQx6JbpvLlkW8znPPLhavt6MpUARG6pafRx9XPzE5pJ+miVsYxo3oa9/O3jdWH3V9U384uXFnOgoTntSx4kA5j74g4AlVJnmOv9+imlHnNc/g7kdan9o4d2Z1C3klYLGy/dvJ91lbX8/p1VAJQ5Fp47A8Dfvb2SNbtqePGLlmzeozO+jjotVB9hA4nTCSN6cP1pB8f09+jZqZB3rj0+pscKkQ88bhfNaZwC3mr21f7TR2tiPse5YetRxxdFkd/+PHMN76/YybSP4y9MPqhbS23Xe99eGXb/X2ev5b+LtjLurvcZ9qt3mHzPB2nLfFsZwCLpBJKzEvmf2wbMBxqABY7LG8A3Uje07OR1tz6V9N0n5wIwZ90eDjQ0B5VpcQaA0fJvB+ojx9CRdhA7eeKoxv6tQ/szrGdZzI8XItd509zG0eqqE8+H7c4DLdn/pz8LL+YuMk9rzZ2vf5myWo1aa/bXGVP/oYX6Wztn/e5apn28lkJPcLZt6/76Vs/dXdPEim0HEhtsG6wMYOiYRO6Iuy6C1noJsEQp9YLWuhlAKVUBDNBa532l4bYCQKe1u2roU14EQKdCT9Ai9Ggztf5oGcCm1l+zKIZ1GMcM686D733FiSN6tPlYIfJJOqaAff4A++qa6dGp0F7La5XGaEuTL9Dqkg+RHarqm3l2zkZeXbSVZXcln9+4+h8L7GoSNY2xTZi9uXQ715jVH0L7uW/ZW0e/Li3lvcb0KydUW8mDRFnPK2sAc1cy/3MfKKU6K6W6AguBvymlHk7RuLKW1+OiKcYPkqc/22Dv8u1c7LV38gL0Lo9ck68pwgfI7ppG9ta1LBg/pG/4L3ksGcAJA7qw4f6pHDEk+wriCpFOxhRwajOAN/xnCYfd+yE+f4A/fGB0w2wrI2OZuz68KLzIPtUNRpCWqmnUDxzrt6vqY1v3OX/DXvt6ky/A+RP78Z3DBkR8jjcWh69BvWja54kMtU2NvgAFbldWd9oRrUsmACzXWh8Avgk8p7U+ApiSmmFlry+3VvHx6kr7G39r3lyyzc46FHpd9nWtddBi8W8c0su+HikAnHzPh9z+2pf27T/NjH2dkRDCqLfp82sue3oeP/7ngpQ85+vmh21lTSO9zUx/rGojZH+kLEz2Oe6BmUDLdGc8/AFtV3a4560VPDdnQ9D9kcqCRbJye/AUbnGBmyuONZpuOTPOgYDm3eWRy8MEUrz+ddeBBp6YvRZfir9UifaVTADoUUr1AS4E3krReLKetY5vxfbY1oQ0+VrWSVjTu6HTRJMP6spjF080Hu9PT7peiHx1waH923yMx1wDOHt1Je+kuIbaUfd9xL/mGZu5Jh9UEdM5NY3G7/nLPzrKPtacxl3KIn6h2bVXFsQ+Zd/Q7GfobW9z/IMz+cfnG3ny0/Xc8frysMfF0lb0iw3BK6tKvG573Z3zs8SZ4X7hqiOCzqmOcbo5Vof/bgYAWVZaU8QpmQDwN8B7wBqt9RdKqSFAh9nKFus3wtom4xevyOuyf9lDC9Lurmm0O4JUN/i47Ol5cS3cHS4bOkQH9uAF49lw/9RWH5PqXcChWZl4VTcYwcWQHmVhx0Tm/OKlxQy6ZTpb9tXZmzUsry3eGvPznPunz+zrv3kzPPCzWJ8P8agoLaDQ3Hlr7cQFgta4HhWyzEfKDIlIEg4Atdb/0VqP01r/xLy9Tmv9rdQNLbtFmgKOtMuwxlxDUuhx2YGf9bjB3UsBONDQbC+kXba1itmrK/nlf5bEPJaLDx8Y3+CF6GC87tTuAj7j0U8iHg9dpB+J1pq731wBQKciD9edMhyAn72wKGXjE4n57yIjyLvquQV2aR9LPDP0Xzn6xTf7ddS6q9bnQzS/eGlx2LGKkgL786LRkYhwBoBKKfo6liXsr09t0fHWGg6I3JFwd3SG4Fn2AAAgAElEQVSl1DO09Fu3aa1/kNSIckSDLzwAjFSrz9rpVehxU2tO+1hTPUcN7cb63bVMHdvX3hVsvU00Rnj+UBvun0qjz29nD4UQkXlcrrQWgrbEsuPyL7Na6r953S67HuCcdbIxJJPqHNm4ldsP2CW9LM7dtq2JtLmj2a954NvjuOnlpUHHaxp9XPnsFxw/ogf/76hBIecE7ID0qCHd6FZWwFtLt1Na2DIF3OT4UrP9gBGwXjvF+ELx8U0nMW/9Xr775Fz2pzADeOury6hr8lNa4Oa5K45o+wSRtZKJHN4CppuXGUBnoCaWE5VSTyuldimlvnQcu0sptVUptdi8nJnE2NIu0hRwpKygVejZ63ZkAM21GmP7lbP+vjM5dnh3O3NgBZFrK40q8dEWhj/5/yYDRmApLd6EaJ3XrVK+CziSugjvAYNumc6gW6bbt0M3A3jlC1xWiLYp4+SRPQFabcHptKPKaP8Zuh70gkP788qPj+aJSyfx5+9OAoy+8h+u3MUdry9nb21Lli4Q0Az/1Tv27cMGVQR13rA+L+5/ZxXPzdlAfZOft5cZa1s/N79IeNwuenYuBGB/jDuOo/lwxU5+bpai+dc849/pxm8czKExrnkV2SmZKeBXHJfnMTaDTI7x9L8Dp0c4/rDWeoJ5eTvRsbWHX/5nCT99fiFfbm3ZDGIVdg1dfwHGIvSAPQWs7WNW8GZl8V5bFLyN37le8PKjB9nXh8q6PyFilu5WcJbWOvZUVjfS0OwPKgANSAY/S9wzPbyzBsDNp4+0r8eylm5tpZEHCW0dqpTi0IMqOH1MH3qXG4HZD//RsiP9yme/sK8v3Rq8yfAnJw2zZ4WKvW678DjAHa8v55EZq3nM7CZzz3lj7PvKiwuMcScZAF753HzeXLItqCB2z87x7XwX2SeV7zzDgZ6xPFBr/TGwt80HZqE3fnaMfX36su2c9cdP7dtPfmr0ZoxUM8rtUnbmz7rf+c3//7N33+FRlWkbwO8nk0mFBEKHAKH3KlgRuyiIfe2KrLvu+i32dUVdsa/oWnbtZVXUta4NEEVAQBQUBOm9hd4SCJCEJFPe749zzuTMzJmSZCYzmbl/15WLOWVO3skJM0/e8jzGX3RrfCaXmz+0xp/f01N2p2mWHUQUntSUFL/FV7U1f1NRwGPb9LQfBvO8w9JKp1f91vWPa38Dp7Iud1wYc1JHy/3KNNNpwKMzgqZUmbt+P/7vg98AaHP1DK9ff5zXeY3Stfdv8zy937aX4LGvtbmh5nRgGx4/Hxl2Gx67qC8uHtgWJ3TO8/u+5rRCbU1D1cb0gsPlkZkDOPql6s87zgNs+GodAIrIURE5YvwLYCqAe+vYnnEiskIfIrbsWxaRm0VksYgsPnDgQB2/Xc31s8i0bjCGCu4f1cvv2JEKBzYfKENppRNnPvsDAO83fiMA7NGqsdfzzHM80lNTcOUQLQFoTgYDQKJwBZqEXxt79CE+Q7PsNK/t6/6zEM/N3AAAqDB9kD8zYz2KTcN8xjwuDgHHh5QUQeP0VPz+lE5e+zs3b4ShBdUfR769vOb52je+U92Ll2Oq9Tysa3Ov5zTK0Kbf7/b5XXrrJ60k4CI9Ufhnfz7J89lQ0Dwb/7pqkGXptf/+Uj18bQ7M0lJTkJoiIWvJh+I7y6h9XiZO7caKUg1dXYaAGyulckz/dldKfV6HtrwKoAuAgQD2AHg2wPd9Qyk1RCk1pEWL+v8FtJpvt8CnRyA3045FD1TnxJ54aT/8uFE758cN1UFraoqpB1D/EDDSAhhFv81vLiKCh0b3wdpHz2P2daIaqEmt7FBa+wx9DerQxGv7p01FeOH7jSgYP80rndPKnYexdLuW0+2Vawd79puDU9/5gVR/yitdyEq3YcLo3tjyj5F4+ZrB2PKPkUhLTfHqVTPeoxcXHsT3a/ehx9+nY9mOEr/rmReNZKd7r7cMVrrzrZ+24pkZ2h8Q4dYLNjTLTvP7jMq020KWEg1GKYVMu3fQ+cDI3l7D0NQw1fhdUUR66v8OtvgaJCLW/eghKKX2KaVcSik3gDcBHF+b68SCsVrMWN2bZktBy8bVHxJNstI8Hxq36MMDgHdwZyzrN+aYGNf65/T1Xt8rJUWQya53ohpJjeCHlXkxye1ndcNTl/WHiPXc38mm3HFXDm2P5focqpH92nj298uvDiCtkgVT9Ow9XIHuD3yLOev3Y8P+o8hO0wK1lBTBqP5tPH9om6cPVDrc2FZchstf+xk3vbsYAHDpK1rev5O7aL8DKx4+N+j3DfYHiTEMDKDGFWYuHtTOb1+63VanHsAjFU6UV7m80o31aN04yDOooajNn8V36/8+a/H1HICpIvJ+TS+qVxUxXAJgVaBz45Uxt893Tk9qiuCvI3r4nb/YlOHd6OY3MrYbKQm+0NMAGLUfiajmIjnMWmn6ML3znO5o1igdW58chRss5pAdMeV5C7RY3ze9yJPfrGVS6Hrya+FBVLncGPvOr1i6vQRbisosz7t8cHW1GZdboajUeyGPWwGv/7AZVU43TurczDNF5/Xrj8OEC3r7Xc93SsK6x87D/53epa4vB2f19J+Gf7TCgV8Laz/l/p352rD0SV2q/8Bh2cLEUON3RaXUH/V/zwjw1R9Aq2DXEJGPAPwMoIeI7BSRmwA8LSIrRWQFgDMA3Fnzl1M/zu5l/fKcFos7AC0gHOwzTARoHx4G3wSyxl9sRrLo8/u1ARHVju8fZXX5APMt5WiwCjKPmFZfOpyBv+fdpveC1+dtwSNT1+DHjQf4QRtlxT6BXCBn9GzpKdfpdLtxsMw/QH/y23VYt/eo13v5iD6t8fthnfzONU//AbTULn8zrTYGgH9fNTCstk3+i7Yw8dRuzXGyz1xDQPt93bTfOkObUgoPT1mN/UcqLI9/vmQn/jVLW13crkl1b2TbMHMiUnyrcSJoEbk02HGl1BdKqaD930qpqy12v1XTtsTKf8YM8crrBQC7S455hm3t+n/ukzo3w89bimG3pXiVfDLkmSaP+6aCqHC44XYrdG6ejRQBTuvOCbdEtWX3+cB1uBTSUms3LGwke55x53Cv/VareX8wzfl9fpY2r+sei9GAJj4LST5bshOfLdmJV68dzD/+oujwMe9KHOYsD77s+nDwkQpnwFKApZVOr8UfAa8VYFFS15aNUF7pxIL7zrI8bnZi5zxkpaViQPsm2PD4+WFVofE1d8MBTFpQiEkLCjHvnjPw0JRVeOZ3A9CskZamZv7m6vntx3XMw/zxZ8LtVsiwcxpSIqhNJZDR+r8tAZwMYLa+fQaABQC+iEC7GpzxX6zEKXoXuV3/YLnl9C74ZWsx+rTN8Tt/9SMjvLat5oQ43G5Uudx+E3CJqGZ8gzOHy12rD0ygugcwzydos0oCbcXqw9MeYI7ivgA9MxQZr8zd5LXdP99/pMawq0SrtHHpKwuCXtMRoIfYLFDy/ll3nRbyuYaPbz7J8zic3+UdB8vRPs97UYnLlGZs+D/nAADe+3mbZ3TKKG5gJLUOtxoKNQw1DgCVUmMBQERmAOitlNqjb7eBluA5Kc3bcADr92p/FRrd+8O7t8DWJ/2L1E+7bZjfqjArVU435q6v/1Q3RInG9w8sq1yd4ao0VWQwa2VaHXzbWd08iXl9Gbk8zVo0Trc8NyutZm/RT367Fl8v34P548+s0fMSkcutcOSYA1mm0mm+jGC+VU46erb2/0PdrKjUP5de4cRRKK9yYvznKzFluZbE/19hDt0WThyFvYcrkJNZ64qsYRl3Rle8NGeTZZlCq8UhxsKTA0cr8e0qrbrIGzeEW+OBGpK6zIxubwR/un0AOgQ6ORkYGf5D5RxrkpUW9LjBqB1MRHXj28NWl1WRxgdpuk+vS8dm1b0r/YPkC82wCEbO7NkST17az2+/vYbD1K//sMXTU5XsLn9tAQY9NhOXvRq4xy43045rT+iAhfefjXd/HzzxxKndvOfXvTN2KAAtSH/8Eq36xt9H9arR8Gjr3IwaB/k1NbC91qtp1UNtVSLuvi9WAtA6NQy+vd2UGOoSAH4vIt+JyI0iciOAbwDMikyz4t9ffcr8mIWqzZsV5hvEbR8vrVGbiMiabw/gEwHKfoWj0ulGivinljEn4M1rlOaVNsPMKo2TiOD8vq399jtqWb5uweYidH/gW6+KEslm6XYtN9+qXdrIzJTlu3HD24tQ6XRh8rJdKCqtxOFjDrRrGt6w5ik+CyzMfwDkZNhROHEU/nBq5wi1PnKM30urP3qCVQi5+3/Lo9Ymig91SQQ9DsBrAAboX68rpW6NVMPi3bgzu+HSwf45l8KRlR5eALhoa4OslkcUd3yHv5ZsOxTgzNAqnS5k2G1+f+iZe3J6t8nBKV21OcHf3Haq13lWQ8Dafu19wTyfq7b1i695cyGqXG6MfOFH/La99q81URSMn4bbPlqKeRsO4JNfd+D2j5d5Srb5VnIJ5rs7qhf+dG/VMHLhGX9wHLPoATxkUdu4cRjTkygx1Ck5llLqS6XUnUqpOwEUicjLEWpXg/Cn4V3QIa9mmdqB0MXfrxiS77XNibdEdeMb8IW7YMNKhcPtN/zrKz01BRf0b4sVD5+L3m1z8B/THCp3gE65DLsNi+4/Cy+Y5pA5A51swZxY3rBpf2nIRQuJyBlkjqdRy9n4AzslxIiNWY/WjXFcx6ZolJ6K5o2s523GGyMAHDvpV+w46F2rusQnAOzbLgdHK5047rGZaJWjvT7f0niUOOoUAOqVP54WkUIAjwJYF5FWNRA9WjfGvL+dgRM6+RfntjIgX5sXFGqIeLhPyhffOpJEVDPXnOA9HGvVGxIuowfQytXHd8Clg9p5/o8bCYHP7l2dO7S00mn5XABomZOBxqY63xMmr8a7CwrDateb87aEdV4yMIY77/XJrQcA363e57Vd0zl4n99yMlb5ZHGIZ1n26tc3V5/Xt2n/USzZdhCHj1WhranaSHu99FxxWRWKS6twy+ldMGG0fyJrSgy1KQXXXUQeEpF1AF4EsAOA6EmgX4x4CxuAd39/PB67uG/I8z7844n46d4zAh6/SU8Y6pv25d7z/d/EiCh8vv+nqlxuTF+1J8DZwQXrAXzy0n547krrVaCf33ISerRqjPP7+c/1M8vymSP40JTwysOt3m2dmw5IvsoNRgDYOCMVXVv652A1G949sf/Azkir/l11ON1YXHgQZz83D5e9+jMOlTvQsVk23rxhCP54aifkm+ZDOt2qRsPj1PDUpgdwHYAzAVyglBqmB31JvVw1w27D9Sd2xM3DO+NMi1I8huz01KDFvf8+qhe2PjnSL2UBV2AR1U2KRZ69P//3N4szq4378Dfc+pH/QqxgPYDBHNcxD9/dOTxgShJDOImErfRuEziNydwNiZ9Oqsrp9tRSN3p4M+02TP7LKfi/07vg+SsHWD4vO8qrcGPN3MPpVgqvzt3s2V6y7RCaZNlxTu9WeGBUb6/eZ0CrI0yJqzYB4KUA9gCYIyJvishZACJXab0Bu39kL7x949BaP19EICKWqwSJqPYC5FkO6usVezBVz+1mVukMPQewLnItAsAKhwvXvPkLJkwOXCK9Ksi8t1s/TPyMArd/vBQDHp0BQMthBwDNGqUhOz0VfzuvJy4ZlI8B7f0TPVv9cZBIfHu/v1+332u7SVb175vL7d1TXFmHdEkU/2pTC/grpdRVAHoCmAPgDgAtReRVEQlaAo7Cw8ofRJFVk4n+VjbtP+oZRq1wuEL24tWFVQC481A5Fmwuxns/bws4f/FYlcvrvWPCBdVzt0ornfho0fbINzaOGEmLyyqd+HlzMQD4jbi8p+f6u/aEDlg24RyvVb2JymYKcA+W+ad9Mff6HfbJC3jZ4Hzf0ymB1CUNTJlS6kOl1GgA+QCWArg3Yi1LYuwBJIqsugSACzYV4ezn5uGTX3cA0HsAA6RyiQS7LQU//s17rrB5tWavCdOx1CK1yzGHy2v+4O+HdcLXtw7zbBsJfhPRuA+rh/MXbzuEZ2dqdZfzfXL85WZq+fqeuKQfmmSloUfrhpHKJVJeMQ3/WhnvM9+8ttMRqGGIyLuYUuqQUuoNpVToCtYUEnsAiSKrLqN8W4vLAADLd5ZgybZD2LSvNKo9gAD8arY++vUar+1LfFK7VDhc+GDhdriUQoe8LPTXMw70bZeLAlOFkmU7SqLU4tj6ekX1gp4xby/yPK7NXM1k8ZczugDwTmidYbfhvD7Vi5RsCT48nuyi92cs1ZrVEBAR1V5degCNih/7jlTislcX4GilE3nZ0f8/ak4IvWLnYb/j5pW9/5ql1R0uKXdg3t/OwJRx1T1/J3WpXuW661BilomzqqU8qn+bGLQkPl01tD2A6s+Wpy7r51kd3c+nbGGwuaSUWBgAxiEOARNFVl0m+ttStLfJ2abJ8zkZ0Q8Al004B7PvPi3gcfMH9fq9gVPA/OOSvvj8lpMAAAfLKiPXwDixrbjMs+jDbDdrIntMvKw/TurczDPH78gxJy7o3xZTxw3DuX280xIZCcVvPLmgvptJ9YwBYJx64epBuGhgW3z6p5Ni3RSiBq8uI1l2m/+TfXP1RUNWWiramqoAiQBvXH+cZ9tc53dwh6YAgPdvOt7vOiKC/vna6teDZf6lvxqiyct24bMlOwEAOw5qgV7Xlo1QOHGU55w9JRUxaVu8Mg/nLtx6EHZbCvrl5/qdZ/xeWdWmpsTCADBOXTigLf591SAcH2aVESIKrC5DwFbzoDLrKXdcht3mqWahFHBun9Z45MI+AKo/qA8crfQsehikB4K+7LYU5GSkJkwP4O0fL8Nf/7ccQHXS5+ev8E7A/e3tp/o9L5mZe4zvPa9H4PP036u0KKY6ovjAO0xECc8qAAw3l59YpDndtL+0zm0K10Cf3HXGB/M3q/bizGfmYuO+o55jwRaQNc1Ow7s/b8PLczZFp6H1xFxKr8rpxtPTtQqk2ener70pE+gH5LvIyGxwR+2PiJY5GQHPocTAAJCIEl6K6Z3uwQt64+xeLeEIc7K70+1/3uJtByPVtJD6tvOu8JFm017Mg1+twpaiMqzcVb1AJNiqzW3F5QCAf363PgqtjL4KhwuLCw9iybbqFDjd//4tNurBeKP0xK7oUVfmP3iC/fFz/8hemHXXcLRrkhnwHEoM/B9DRAnP3AM49uQClFU6MWvtfrjcKmSqC4fLv47uExf3i3gbA/Etz7X9YLnXdm0WO6zZfQS92wYuHRcvlFL4+NcdGNGnNSbN34oXZgfuvTRy1r1y7WC/ihYET+qipy/rDwkyJcJuS0HXlsmVHzFZMQAkooRnDgBTUgR2vRetyum2XHVvTrFSYVEOq3Wuf9qRaPr45hM9bd58wHv4+ZCeJPqh0b39nmf2xCV98cCXWim5f3+/Aa9fPyQKLY2sTftLcd8XK/H92v04cizwApZR/dp4cv6N7Mf0L1aM32nWlicDA0AiSni+nXzGyt4qlxuZ8A8AzR1If//Ku/7uyV2aoUuLRhFvYzAndm7medwm13tu1urd2hDw8O4tgl7j2hM64prjO6DTfd9gpUVewXi0X0/vMmvtvqDn+VawIH8uPQBM4cQv0vFXgYgSnu+QlzEHKtA8QKt5f4bOLbKDDqFF213neK/g3HxAq1QSTmoao927D1dg1prgQVU8sMrvBwCjB7T1rIYGgGaN2KsVijEsHsvfXYovDACJKOkYw6mBAkDf+K9DXhbmjz8T/fNzMeGCPpbPqS+ZaTbLSfzhlpAce0oBAOAP7y2OZLMirtLpwh2fLLM81ijdhjGmRMVZ9ZSWpyEzZjXYGACSLiYBoIi8LSL7RWSVaV+eiMwUkY36v9YJrYiI6sgTADqtFwu4lPf+EzvnoV2TTEwZNywu8qNVOv0D1+wwV8EWNMuOdHOi4of1BwIe65CnvYZLB7VjvdowGeldfKcQUPKK1TvZJADn+ewbD+B7pVQ3AN/r20REEWfXg7gql/8CDwBw+az8/XTxzqi3qS7ym2Z6gtpQTuhcnVzeGcd1XyctKAx4rFcbbZXqc1cOxOZ/jKynFjVst5/VDbPuGo5urbjClzQxCQCVUvMA+CbSugjAu/rjdwFcXK+NIqKkYdd7jZwB0oX49gDGu52Hwk8F07N1Dk7t1hwAMGHKahSMn2a50jnWztdX804aOxRpqSl46ZpBaJWjrb72TY5NodlShOldyEs8TZxopZTaoz/eC6BVLBtDRInLGDZ0WuT4e2f+Vk9qFcPHN59YL+0K19Rxw7DvSAV2HirHw1PX1Pj5vxvSHj9uLMKHC7cDACZ+uw4PXxjbuY2+XHrvZP/8Jtjw+PkAgE7Ns/HLloNoksVFH0R1FU8BoIdSSomI5Z/gInIzgJsBoEOHDvXaLiJquLLSbLj2BO09wxguteoBfMQioBocoMZurPTLz0U/5AIAfthwANec0LFGz2/sM19w0oLCuAsAP9GH3c2rm/u0zUWftrmxahJRQomnAHCfiLRRSu0RkTYA9ludpJR6A8AbADBkyJCGNU5DRDGz5tHqacdGD6ArSLoXw3Edm8bFwo9A3hl7fI2fk+GzYjjDHl+v73C5A2v3HAEQfs1mIqqZePqfNQXAGP3xGACTY9gWIkpgqXoAaFXmzdcLVw+KdnPqXfs87zqvg9rHVw/ngdIKz2PmrSOKjpj0AIrIRwBOB9BcRHYCeAjARACfishNALYBuCIWbSOixJeqDwGHqhn7/JUD0K5JZtBzGqL8plmYOm4YNh04io8W7cDPW4pRVFqJ5o3qt8RdIIePOQFoC0CIKDpiEgAqpa4OcOisem0IESUlW4hVwNXnxdMgSWT1y89Fv/xcLNtegkVbD+Kc537A0gnnxrpZAIAjFdoinJxMe4xbQpS44mkOIBFRvUj1rAIOPgcwGaomtNITA/uufK6Nh6esRpeWjXD9iTVblGL416wN+NesjZ7tnAx+RBFFC/93EVHSSbWF2wOY+AFgrqmXbVtxGTrWslLIU9PXeZI31z4A3Oi13To38YbfieJF4o5vEBEFkKoP7VrlATRLhgCwcUZ1APjS7E21vs6rczd7Hv+0sSis5yil8O9ZG7G75BgOHK30O94ozPJ2RFRz/N9FREmneg5giCHgJPgTuX+76rx6C7f6FmgKX+fm2dhSVAYAKCr1D+asbC0qw/OzNuD5WRv8js396+m1bgsRhZYEb29ERN7sNiMPYPIuAjEUNM/GWj1HYr92tU+yfGbPlp7Hh4+FN5+wKsgczOaN42NFMlGiSvx3NyIiH8FKwXmdlwSLQAAgM82G3Ew7WtQh6DrmcHmSNj80ZXVYz9lTUhHwWHaaLeAxIqo7BoBElHQ8cwBD9AAmQQegh92Wgkpn6MoogRxzuLzyCO4/Eji4M7w9f6vX9lOX9fM8ZgJooujiHEAiSjqptvBKwR0qq3tqlIYizSZwhEiLE0yFw4VMU6/dg5NX4fXrhwR9zo8+i0WuHNoBZ/RsCbDIJ1HUMQAkoqQTbim4rUWl9dGcuJCWmoKqOvQAVjjcyDTVGE6twQqapy7rh4sGtgMAtGycUes2EFH4kmiAg4hIY8wBDLUI5Ioh7eujOXHBbkuBw+VGhcMFpWreBXesyoUMe/VHSl5WWsjnGIH4lUM7IMPOOX9E9YkBIBElHbstvDmAdVkU0dCkpabgYFkVej44vUb5AJftKMHOQ+U45nAhw27DqkdGAADe/2Ub1u094jnP6XJ79TBu3HcUrXMzMKRj08i9CCIKGwNAIko6tjBLwSXTQgS7LcWTv+/Zmf55+awcrXDg4pfnY9hTc7BsRwmU8k7e/Of3lwAA5qzbj64PfIvuf//Wc+yc5+dh56FjXvMGiaj+MAAkoqRjpHdx1WKoM1HZbVLjVcDzNngv4vhpk7b92nXHAYCnusfYSb96zvlq6S6vRNG+C0GIqH4wACSipJOi9wD6jgCby5F99ZdT6rNJMSci2HnoWI2ec/+XK722Rw9oCwA4r29rAEBZlcvvOXd8sgyTl+32bF80sG1Nm0pEEcBVwESUlFIEcJsiwC9+24m7Pl0OABh7SgEGtm8Sq6bFxNo9R0Kf5OOSQe0waUGhZ/uywe38zvlu9V6/fY99vQYAsOHx85GWyn4Ioljg/zwiSkq2FPEaAjaCPwDYcbA8Fk2KqaMVTq/tcFYCl1U60TonA1ufHImvbx2G03tUl4N78epBAIA/6fMAfZ3ZsyWDP6IY4v8+IkpKAsFrP2xGaaXT79istftj0KL48sa8LQCAHzYcwO0fL/U7vuNgOf63ZCcOllVBRNDXp45wQbNsr23f1b4j+rSKcIuJqCYYABJRUqpyuaEU8MS0NbFuSlx68tt1AIAxby/C5GW7/XImfr92HwDt52ilXdNMr+3HLu6Ld24c6tlm3j+i2OIcQCJKaiXlyVPurS4qHC5km1K8FBZrw+RdWmRbnt80y+613atNDsxZdUb1axP5RhJR2NgDSERJ7dtVe70WgwDAR388MUatiV8vz6lODr3n8DHP4o/J44ZZnm+VQ7Fn6xy8fM1gLH/o3BqViiOiyOP/QCJKejP14UzDSV2axagl8eFSfTXv0Yrq3tF3Tat9F2096HlsTvzs67XrjsM9I3pg+YRzPftG9W+D3Ex7wOcQUf3gEDARJb0Kh3++umSWpVfn6PfwDM8+c06/9DBX7xr5AIko/rAHkIiIcO95PT2PU1OCfzQs3V4CALjuxA5RbRMRRQ8DQCJKeslU8zeQW07vgquPbw8AAfPzGbWTX9dTxNwzoqfleUQU/xgAElHSKymvinUT4sLjF/fD6kdGBJyj9/4v27y2OZePqOGKuwBQRApFZKWILBORxbFuDxElvgmTV6Nn68YAgA55WTFuTezYUgTZ6am4aVgnr/33jOgBAHh+5gb86f3F6NayEc7rw/l9RA1ZvC4COUMpVRTrRhBR8qhwuHDhgLZ4QS9hlswy7DaIAEoBM9D1FWwAACAASURBVO8cjg7NsvDczA04UuHEd6u1FdPHd8qLcSuJqC7irgeQiCgWKp1uZNj5lmgwSgEXNM9GeqoNbXIzvI5XOq0rgBBRwxCP73YKwAwRWSIiN/seFJGbRWSxiCw+cOBADJpHRImmfV4mKhwupKeyPJnhnbFDMXpAW9j1hM2+ybJLK/xrKBNRwxGPQ8DDlFK7RKQlgJkisk4pNc84qJR6A8AbADBkyBAV6CJEROHacfAYALAH0OSMHi1xRo+Wnu3dhyu8jg/r1ry+m0REERR373ZKqV36v/sBfAng+Ni2iIiSRYadPYDhuvYE5gAkasjiKgAUkWwRaWw8BnAugFWxbRURJaK/ntvdbx8DwMCWPngObhrWCS0ap2NwhybMnUjUwMXbEHArAF/qbyypAD5USk2PbZOIKBGNO7MbnpmxwWtfuCXOklHT7DQ8eEFvPHhB71g3hYgiIK4CQKXUFgADYt0OIkoOvdrkYO2eI57tdPYAElGS4J+7RJS0vrjlZK/tDPYAElGS4LsdESWtzDQbMk29fpwDSETJggEgESU181oGBoBElCwYABIR6ZgHkIiSBd/tiCipZadXr4VjJRAiShYMAIkoqb09ZqjnMXsAiShZ8N2OiJJav/xcz2POASSiZMEAkIiSXqucdABMBE1EyYPvdkSU9FrnZAAA3CrGDSEiqidxVQmEiCgWXrv+OHzx2y4UNMuKdVOIiOoFA0AiSnptcjPxlzO6xroZRET1hkPAREREREmGASARERFRkmEASERERJRkGAASERERJRkGgERERERJhgEgERERUZJhAEhERESUZBgAEhERESUZBoBERERESYYBIBEREVGSYQBIRERElGQYABIRERElGVFKxboNtSYiBwBsq6dv1xxAUT19L6o93qeGgfepYeB9ahh4nxqGWN2njkqpFr47G3QAWJ9EZLFSakis20HB8T41DLxPDQPvU8PA+9QwxNt94hAwERERUZJhAEhERESUZBgAhu+NWDeAwsL71DDwPjUMvE8NA+9TwxBX94lzAImIiIiSDHsAiYiIiJIMA8AQROQ8EVkvIptEZHys25NsRORtEdkvIqtM+/JEZKaIbNT/barvFxF5Qb9XK0RksOk5Y/TzN4rImFi8lkQmIu1FZI6IrBGR1SJyu76f9yqOiEiGiCwSkeX6fXpE399JRBbq9+MTEUnT96fr25v04wWma92n718vIiNi84oSm4jYRGSpiHytb/M+xRkRKRSRlSKyTEQW6/saxvueUopfAb4A2ABsBtAZQBqA5QB6x7pdyfQFYDiAwQBWmfY9DWC8/ng8gKf0xyMBfAtAAJwIYKG+Pw/AFv3fpvrjprF+bYn0BaANgMH648YANgDozXsVX1/6z7uR/tgOYKH+8/8UwFX6/tcA3KI//j8Ar+mPrwLwif64t/5+mA6gk/4+aYv160u0LwB3AfgQwNf6Nu9TnH0BKATQ3Gdfg3jfYw9gcMcD2KSU2qKUqgLwMYCLYtympKKUmgfgoM/uiwC8qz9+F8DFpv3vKc0vAJqISBsAIwDMVEodVEodAjATwHnRb33yUErtUUr9pj8+CmAtgHbgvYor+s+7VN+0618KwJkAPtP3+94n4/59BuAsERF9/8dKqUql1FYAm6C9X1KEiEg+gFEA/qNvC3ifGooG8b7HADC4dgB2mLZ36vsotloppfboj/cCaKU/DnS/eB/rkT78NAha7xLvVZzRhxWXAdgP7YNmM4ASpZRTP8X8M/fcD/34YQDNwPtUH/4F4G8A3Pp2M/A+xSMFYIaILBGRm/V9DeJ9LzXa34AompRSSkS4lD1OiEgjAJ8DuEMpdUTrhNDwXsUHpZQLwEARaQLgSwA9Y9wk8iEiFwDYr5RaIiKnx7o9FNQwpdQuEWkJYKaIrDMfjOf3PfYABrcLQHvTdr6+j2Jrn95tDv3f/fr+QPeL97EeiIgdWvD3gVLqC30371WcUkqVAJgD4CRoQ1FGh4D5Z+65H/rxXADF4H2KtlMAXCgihdCmHp0J4N/gfYo7Sqld+r/7of1BdTwayPseA8DgfgXQTV95lQZtcu2UGLeJtHtgrJIaA2Cyaf8N+kqrEwEc1rvhvwNwrog01VdjnavvowjR5xu9BWCtUuo50yHeqzgiIi30nj+ISCaAc6DN15wD4HL9NN/7ZNy/ywHMVtqs9SkArtJXn3YC0A3Aovp5FYlPKXWfUipfKVUA7XNntlLqWvA+xRURyRaRxsZjaO9Xq9BQ3vdisWqmIX1BW7WzAdo8mQdi3Z5k+wLwEYA9ABzQ5kXcBG1uy/cANgKYBSBPP1cAvKzfq5UAhpiu83toE6A3ARgb69eVaF8AhkGbC7MCwDL9ayTvVXx9AegPYKl+n1YBmKDv7wwtMNgE4H8A0vX9Gfr2Jv14Z9O1HtDv33oA58f6tSXqF4DTUb0KmPcpjr70+7Fc/1ptxAgN5X2PlUCIiIiIkgyHgImIiIiSDANAIiIioiTDAJCIiIgoyTAAJCIiIkoyDACJiIiIkgwrgRARBSEiLmgpG+wAnADeA/C8Usod9IlERHGMASARUXDHlFIDAUAv9/QhgBwAD8W0VUREdcAhYCKiMCmt3NPNAMbp2fwLRORHEflN/zoZAETkPRG52HieiHwgIheJSB8RWSQiy0RkhYh0i9VrIaLkxkTQRERBiEipUqqRz74SAD0AHAXgVkpV6MHcR0qpISJyGoA7lVIXi0gutMoo3QA8D+AXpdQHenlJm1LqWP2+IiIiDgETEdWFHcBLIjIQgAtAdwBQSv0gIq+ISAsAlwH4XCnlFJGfATwgIvkAvlBKbYxZy4koqXEImIioBkSkM7Rgbz+AOwHsAzAAwBAAaaZT3wNwHYCxAN4GAKXUhwAuBHAMwDcicmb9tZyIqBp7AImIwqT36L0G4CWllNKHd3cqpdwiMgaAzXT6JACLAOxVSq3Rn98ZwBal1Asi0gFAfwCz6/VFEBGBASARUSiZIrIM1Wlg3gfwnH7sFQCfi8gNAKYDKDOepJTaJyJrAXxlutYVAK4XEQeAvQD+UQ/tJyLyw0UgRERRICJZ0PIHDlZKHY51e4iIzDgHkIgowkTkbABrAbzI4I+I4hF7AImIiIiSDHsAiYiIiJIMA0AiIiKiJMMAkIiIiCjJMAAkIiIiSjIMAImIiIiSDANAIiIioiTDAJCIiIgoyTAAJCIiIkoyDACJiIiIkgwDQCIiIqIkwwCQKMmIyI0i8pNpu1REOse4TaeLyM4oXv9UEVlv2i7U6/VG+vsUiIgSkdQ6XKODfk9skWxbLdtyv4j8JwrXfVxEikRkb6SvTUThYQBIlCBEZK6IHBKR9Jo8TynVSCm1pY7fe5KIPF6Xa4S4vhKRMj0wKhaR70XkynCfr5T6USnVI0Jt6S4i/9MDmMMiskJE7opUwKaU2q7fE1ckrmem36cq/ed4UERmikjPIG35h1LqDxFuQwcAdwPorZRqHaFriojcJiKr9N+Tnfo96heJ6xMlIgaARAlARAoAnApAAbgwpo2JngFKqUYAegCYBOAlEXmoPhsgIl0ALASwA0A/pVQugN8BGAKgcX22pQ6e1n+O+QD2Q/tZ+qlLL2YIHQAUK6X21/SJQdr0bwC3A7gNQB6A7gC+AjCqto0kSnQMAIkSww0AfoH2YT7GfEBEmonIFBE5IiKLAHTxOa5EpKv+eK6I/MF0zDNcrPeyPC8i+/VrrRSRviJyM4BrAfxN71maqp/fVkQ+F5EDIrJVRG4zXTdT7406JCJrAAwN94UqpYqUUu8DuAXAfSLSTL/mWBFZKyJHRWSLiPzJ9P0sh5hFpLWIlBvX0PcN1ttst/j2jwBYoJS6Sym1R2/PeqXUNUqpEovrt9V/9gdFZJOI/NF07HgRWaz/LPeJyHP6fq9hZP2ePCYi8/XXNkNEmpuuc4OIbNN7Rh8Md3hbKVUO4EMAffXrPCwin4nIf0XkCIAb9X3/NX2vYSKyQERKRGSHiNyo708XkWdEZLv+Wl4TkUyLn8fZAGYCaKv/rkzS918oIqv1684VkV6m5xSKyL0isgJAmW8QKCLdAPwFwNVKqdlKqUqlVLlS6gOl1MRQPweiZMUAkCgx3ADgA/1rhIi0Mh17GUAFgDYAfq9/1ca5AIZD613JBXAFtJ6cN/Tv+7Q+dDlaRFIATAWwHEA7AGcBuENERujXeghaINoFwAj4BK1hmgwgFcDx+vZ+ABcAyAEwFsDzIjI42AWUUnsBzNVfi+F6AB8rpRwWTzkbwGc1aOPHAHYCaAvgcgD/EJEz9WP/BvBvpVQOtJ/Dp0Gucw2019QSQBqAvwKAiPQG8Aq0ALwNtPvSLpyGiUgj/XlLTbsvgvb6mkC7p+bzOwL4FsCLAFoAGAhgmX54IrTfi4EAuuptmOD7PZVSswCcD2C3/rtyo4h0B/ARgDv0634DYKqIpJmeejW03rwmSimnz2XPArBTKbUonNdNRBoGgEQNnIgMA9ARwKdKqSUANkMLGCDavLTLAExQSpUppVYBeLeW38oBbZizJwBRSq01esEsDAXQQin1qFKqSp9j+CaAq/TjVwB4Qil1UCm1A8ALNW2MHqAVQRvyg1JqmlJqs9L8AGAGtGHxUN4FcB3g+XldDeD9AOc2AxDoNXsRkfYATgFwr1KqQim1DMB/oAXrgPbz7CoizZVSpUqpX4Jc7h2l1Aal1DFogeJAff/lAKYqpX5SSlVBC7pUiKb9VURKAGwC0AjAjaZjPyulvlJKufXvZXYNgFlKqY+UUg6lVLFSapmICICbAdyp38+jAP6B6nsdypUApimlZur39BkAmQBONp3zglJqh0WbgBrcEyKqxgCQqOEbA2CGUqpI3/4Q1T1qLaD1ku0wnb+tNt9EKTUbwEvQehT3i8gbIpIT4PSO0Ib5SowvAPcDMHom29a1TfoQbQsAB/Xt80XkF324tQTASADNg11DNxlAbxHpBOAcAIeD9CYVQ+tpC0dbAEZAZNiG6h66m6D1mq0TkV9F5IIg1zKvli2HFrgZ38Pzc9SHdYtDtOsZpVQTpVRrpdSFSqnNpmM7Aj4LaA/tjwtfLQBkAVhiutfT9f3haAvT/VdKufV2mHsyg7WrJveEiHQMAIkaMH2e1RUAThORvaKl1bgTwAARGQDgAAAntA9vQ4cglyyD9mFu8FqlqZR6QSl1HIDe0IKXe4xDPtfZAWCrHmgYX42VUiP143tq0KZALoL22haJtvL5c2i9R62UUk2gDSVKqIsopSqg9apdB234N1DvHwDMgtajGo7dAPJExLw4pAOAXfr33aiUuhrasO5TAD4Tkewwr23YA20xBwDP70OzwKeHFKz3cAd85o/qigAcA9DHdK9z9YUm4dgN7Q8GANpcU2i/G7vCbNf3APJFZEiY34+IwACQqKG7GIALWkA2UP/qBeBHADfoqUS+APCwiGTpc8aCzbdbBuBS/dyu0HqpAAAiMlRETtB73sqgzSt064f3ATDnElwE4Kg+eT9TRGyiLRgxFnt8Cm0BR1MRyQdwa7gvWETyRORaaD2RTymliqHNi0uHHvCKyPnQ5iyG6z1oQ6EXIngA+BCAk0XknyLSWm9PV33hRBPzifrQ9gIAT4pIhoj0h/bz/K/+vOtEpIXe42UsIHGjZj4DMFpETtbnzD2MMILeWvoAwNkicoWIpIq2uGig3v43oc25bAkAItLONN8zlE8BjBKRs/TfrbsBVEL72YWklNoIbR7kR6It9knTf95Xicj4mr5IomTBAJCoYRsDbX7YdqXUXuML2lDttfqKyXHQhgz3Qlsl/E6Q6z0PoApaQPcuvBcC5ED7oD8EbciuGMA/9WNvQRtGLRGRr/TA8wJoAelWaL1E/4G2SAHQVtNu04/NQPCgy7BcREqhzV37A7Q5ZxMAQB9mvQ1aMHEI2ny1KWFcE/rz50MLvn5TSgUcjtaHS08CUABgtYgchtbzuBjAUYunXK2fuxvAlwAe0hdCAMB5+jVKoS0IuSrAHLdg7V4NLXj+GFpvYCm0xTCVNblOmN9rO7Rh9buhDbsvAzBAP3wvtPvyi76CeBa0dD3hXHc9tN7XF6H9nowGMFqf0xiu21A9PaEE2lD1JdAWIhGRBVEq1HxhIkpU+mpdF4CO+gd80hKR2QA+VEpFvPJFfdFX9pYA6KaU2hrr9hBR/GIPIFFy6wttKDepS3LpQ9ODAXwS67bUlIiM1ofss6HNgVwJoDC2rSKieMcAkChJichlAOZAS1NSk+G2hCIi70IbsrzDZ8VuQ3ERtCHm3QC6QRtK5tAOEQXFIWAiIiKiJMMeQCIiIqIkE61i3/WiefPmqqCgINbNICIiIopLS5YsKVJK+SVmb9ABYEFBARYvXhzrZhARERHFJRGxTG3FIWAiIiKiJMMAkIiIiCjJMAAkIiIiSjIMAImIiIiSDANAIiIioiTDAJCIiIgoyTAAJCIiIkoyDACJiIiIkgwDQCIiIqIkwwCQiIiIKMkwACQiIiJKMgwAiSigt37aiqemrwvr3KLSSuwqORblFhERUSQwACSigB77eg1enbs55Hkl5VUY8vgsnDJxdj20ioiI6ooBIBHV2cBHZ8a6CUREVAMMAImIiIiSDANAIgrJ7VbYcbAcxaWVlsfP79va61wiIopvDACJyNLsdfs8j8sdLpz69ByMfvEny3NTRDyPn5q+DuVVzqi3j4iIao8BIBFZ+mblXs/jL37bCQDYfbjC77wfNhzAtJV7PNuvz9uCl2Zvin4DiYio1hgAEpGlDnlZnscTJq8GANhSxO+8MW8v8ttX6XRHr2FERFRnDACJyFKj9FS/fS63wprdR0I+N9XmHygSEVH8YABIRJasevsAYOQLP3ptd26e7XfO6z9siUqbiIgoMhgAEpElhyv0MG6V040tRWV++5s3SotGk4iIKEIYABKRJYcrdDqXyct2We4f1a9NpJtDREQRxACQiCw59R7Aq4a2D3jOql2HLffvPlyBeRsORKVdRERUdwwAiciSQ0/o/OSl/XD5cflI1ecEts/L9Jzz7s/bLJ87c80+3PD2Ik8QSURE8YUBIBFZcrjcSE0RiAie+d0AbPrHSFx+XD5cFkPDL149CLPuGu63f99R68ohREQUWwwAiciS0+WG3eb9FmG3iadn0Cw9NQVdWzbGbWd29dr/2NQ1UW0jERHVDgNAIrLkcCm/fH6pKSmWw7rDujUHANx1bg/0aZvj2Z+VZotuI4mIqFYYABKRpcXbDuJohXdN31SbwKkPAe87Ul0WLiutOmm0MnUQHlfQNLqNJCKiWmEASESWVu3yr/hht6XAqQ8B3/3pcgDAyV2aeZ2zZk/18yocXARCRBSPGAASUdhsKQKn241J87fip01Fnn2BVDhc9dU0IiKqAQaARBQ2e4rA4VJ42LS4w2WxKMTAAJCIKD4xACSisKXa/N8y0lIDv40wACQiik8MAInIkt0mGHNSR699vquCAeCOs7t7bX97+6mexwu3HoxO44iIqE4YABJRQFnpqV7bqRbz/Qa2b+K13atNDpZNOAcAsGKndak4IiKKLQaARORHKQWHS8HuE/BZrQy20iQrLRrNIiKiCEkNfQoRJRtjYYfvnL95Gw94bT9/5YCA1zitewuUHHNEvnFERFRn7AEkIj9OTwDo3QNok+rtSwe1wyWD8gNew24T7DpUjq9X7I5OI4mIqNYYABKRF6fL7anyYU/xfotIMQ0Jp9uDv33YbSkoKq3CuA+XWpaPIyKi2GEASERQSnlStnR94Fuc9s+5AIBFhd6reMed0dXzOD01eJ1f8/Bx4EyBREQUCwwAiQid7vsGPR+cjo37jnrt9y3zdlr3Fp7HHyzcFvSa5gUkbsUQkIgonjAAJCKPc56f57XdPz/Xa9tuSvrscAUP6szzB099ak4EWkdERJHCAJCIAspKC50HMBC7aQh4/9FKVDk5D5CIKF4wDQwRBZTtEwCmmFYBn9g5L+hz7T4pZK558xc0b5SOZo3SMLx7C4zo0zpyDSUiohphAEiU5D75dXvAY1np3gs90kxB3Z9O6xL0ur69hYu3HfI8/mDhdhROHFWTZhIRUQRxCJgoQR0ud3hW9gZz7+crAx7z7QHMzbJ7HptzAloxzxckIqL4wndoogQ14NEZ6Png9Bo/b9Zdp6Fdk0wAQIZFrr/BHbTav1lpwdPA+JaRIyKi+MEAkCgBmRMvF4yfhr99ttzvnMPHHF6pXPKbZmLh/Weha8tG+P7u0zDvnjMgFr18Y0/pBADo1qpx0Db4lpEjIqL4wXdoogR0+yfLvLY/XbwTyicX392fLscDX67ybF93Yke0yskAAGTYbejQLMvy2qMHtEXhxFHIzbRbHjf4lpEjIqL4wQCQKAFNW7HHb9+RY05MXrYLDr13MNM0hHv/yJ740/DOEW1DGnsAiYjiFt+hiZLEfxduw+0fL8M787cCAJqaFnRcf2KB5XBvXfimgSEiovjBd2iiBHR8J/8cfc/OWA8AOFrhBAB8vGiH51hmiAUdtZEWZBWwjQtEiIhiKuoBoIjYRGSpiHytb3cSkYUisklEPhGRNH1/ur69ST9eEO22ESWqXq39F2i49SmAIoJbP1qKKld0K3Os2X0k4DGXW/nNSSQiovpTHz2AtwNYa9p+CsDzSqmuAA4BuEnffxOAQ/r+5/XziKgWnO7AwdW7Cwoxdfluz/aksUOj0ob1+44GPR6qljAREUVPVANAEckHMArAf/RtAXAmgM/0U94FcLH++CJ9G/rxsyTSk5KIGjCXW+FQWRUmTF6F8ipnyHObZadZHjt8zOF5vPqRETi9R8uIttNw1zndgx53ulkbmIgoVqLdA/gvAH8DYLzTNwNQopQyPr12AminP24HYAcA6McP6+d7EZGbRWSxiCw+cOBANNtOFFdueHshBj02E+/9vA0vz9kU9FynWyHDbkN6iGoc2enRqwbZKMC1/z6qFwD2ABIRxVLUAkARuQDAfqXUkkheVyn1hlJqiFJqSIsWLSJ5aaK4Nn9Tsefxy3M247mZGwKe63S5kWoTLH/oXLw1Zkh9NM9Pn7Y5lvuN1cHOKM9BJCKiwKLZA3gKgAtFpBDAx9CGfv8NoImIGF0D+QB26Y93AWgPAPrxXADFIIqSv3+1EjdN+jXWzai1F77fiP1HK/z2Hzhaia+WaXP8Muy2gL185jQw0SAi8F3s2zgj1ZMgOtg8RSIiiq6oBYBKqfuUUvlKqQIAVwGYrZS6FsAcAJfrp40BMFl/PEXfhn58tuIyQYqi//6yHd+v2499R/yDqIbi1bmbvbYdLjeGPjELALCtuByAdcqVCwe0xS/3nxX19m18YiQeGNkLVw5pDwC4oH8bTw+ggz2AREQxE4s8gPcCuEtENkGb4/eWvv8tAM30/XcBGB+DtlGSqHC4PI8fnrI6hi2pm1Sf4G7Kst1+5wzu0NRvX6XThfTUyOf+82VLEfxxeGdce2IHAECvNjmwGz2AnANIRBQz0ZsBbqKUmgtgrv54C4DjLc6pAPC7+mgPkTkANBIjR0p5lROvzd2MPw7vjMYZkRlmdQUYLk01VdtQSuHrFf4BoC1FUDhxFACgYPw0AMB3q/dFpF3h6p/fBD/cczo65GXha71MHVcBExHFDiuBxFBxaSUe/GoVKp2u0CdTRG0pKvM87mmRNLkuZq7Zhxdmb8KLs4Ov1K2Jh6asAgDcM6IHVj0yAnl6ipdjVdW/O4XF5ZizPryV8b3aWC/QiKaOzbIhIp4eQK4CJiKKHQaAMfTMjPV4/5dtmLp8T6ybknQufWWB53H7vKyIXtsY2nxj3paIXfO/v2wHAORm2tEoPRW/PXgO2udloqS8ynPO/E1FYV/viUv6RqxtNZWaYqwCZgBIRBQrDABjyPgg/GYlA8BYMg8HR8KbP1YHfuYeukjIsFfP28tOS0W56fp//2qV5/GJnfPwnxsCp3/p1rJRRNtVE9WrgDkETEQUK/UyB5CslegVGWav2x/jliS3SmdkA5HWuRlYt1crg1ZcVon8tLr3MNptAodLobdp6DZFxFPf17xg/tLB7fDcFQODXi9ScxNrw9MDyDQwREQxwx7AGDLXY6XouuW/S/DEtDU4WuHAY1+v8ToW6R7A5o3SPY8PllUFOTN8w7u1QPu8TPQ2JVdOSQHcSuHblXvQ6b5vPPtDBX+xluqZA8geQCKiWGEPYBxIC1Gui+rG7Vb4dtVe7bEC3vppq9fxCkdkApGdh8rxxrwtOFpRXWv3/i9X4qWrB6OgeXadrl3hdKFl4wyvfSki2HKgFD+a5v5dPLBt0OtMGXdKzH/fjNQ1nANIRBQ7jDziQFWEhyDJW1lVdZqXNbuP+B1/e/5Wv301tWrXYQx7ag7e+3kb5qw74KnBu2rXEVz+2gKvc6cu340/vb8YU5fvRri5zo9VuZBp987bt2LnYRQWl+PDhds9+zq3CD63r39+E/RsXf8rgM2M1DWBUtsQEVH0sQcwDhQ0i+wqVPK2bEeJ5/HPW6JTXfB104rfKp+hzaJS72HgWz9aCkDLxbdwazEev7hfyOuXV7nQzDS0HMjNwzuH09yYMnoAOQRMRBQ77AGMA4XF5bj70+W46KWfYt2UhON0uXH9W4tCnldoygtYG65armj97y/bsWrX4ZDnHa1wIieMhRsZ9uhX96gr1gImIoo9BoBx4vPfdmL5zuCBwMRv1+H/PlhSTy1KDMVBFmFcOKB6vtw3q+qWiqerz9DrC1cP8to2D/V29Onxna7PTwzm8DEHcjODB4CN0htGhz5XARMRxR4DwBgJd+6X4ViVC6/9sBnfrAwdLFC1knJH6JMAPD19fZ3mYvqmVemYl4VfHzgb15yg1cCtcLjhcit0e+AbbCsuBwAM7tAEAPDSnOAVQ5wuN0ornUEDwHZNMrHqkRG1bn99ql4EwiFgIqJYYQAYI77zxAyBysKtDGOYkPyZvR/7aAAAIABJREFUK2X4uuGkjnj399VlqeuSssX3fhY0z0aLxunopZeZK6tyYtWuw57yZ6MHtPX63sEc0WsV52QG7uF78ZpBAY/FG2MI+K5Pl7MMIhFRjDAAjJFAvU3llf4fiGc+OxdXvP6zZztYUEPejGTbVppmp+HUrs0923VZlLDSZ/je6K3LStOCtrJKJ37YUF2nd+ry3V69hq/MDdwLeER/DcF6AFuEsUAkXoiI5/GBo5UxbAkRUfJiABgjhUXllvtNn40eWw54L1C4/8uV0WhSQpi2Yg/6TJjuSe58WB8CnjpumOccY35em9wMpKRU/8AD9coGopTCtmLt3kxfrQ3Nr3j4XCx/6FzPOdnp2qKMskoXnpu5IeC1np6+Hu4Ac+L++d16AP4B4PQ7TvU8zstOq1HbYynLtFCFKZCIiGKjYcwaT0CjA6z4DSc3WqSqSySSotJKDHl8lmf7YFkV2jbJxJo9Wt6//KaZnmMXDmjrtQDEUNPExJ8t2Yl7PluB90xDub4rdY0ewKJS754uoz2dm2dji74C2eF2Iz2lOjiaNH8rOrVohGl6rWjfALBn6xyse+w87C45huwGsgAE0HpeDeURrpVMREThYQ9gnCmvcuGP7y3G2j3+CYsNtcw4ktBmr/Wup5wigk37j2LSgkIAQJMsLXg6o0cLv+e+ecMQANoQ8LMz1uPdBYV+i3S+W70XBeOnoWD8NM++Ffqw75JthwK2y+gBHDvpV6/9RrqW//35JM8+hykAfeH7jXh46hqMebs6hY1VkJdht4VM/hzPjlY4Q59EREQR13C6DZLEhn1HMXPNPmwrLsOMO0+zPIcT5/019RkCdbjc2H6wephdRLDogbMsc+kZixIqnW68OFubi/fQlNUonDjKc86f3vdPv2PTh48PlAaex2b0AJp7dv96bneM1nsgzcmdHU43oG9aDRd3qmM5uXjEZNBERLHBHsAYMPcuTRo71OuYEScEGwreeehYVNrVkJVXefck7So5hh/WH/Da17JxhmWi5DS9NFlZpXVvVKCUPSt2ahVGjFJsfzy1k9852Wnef2MNbN8E487sho7NqoO5sacUAKgOhrYX+88P/csZXRpEkueactUwHRIREUUGewBjwJwAd3g37yHJY47QvXvBkhsnK9+5ZO/M34rvVu8DAPRpG7z2rV0PACd+u87yuDmXoM20aOS37SVe57XKyfB7bmaad9B2Wnf/Ieheem1eh/57sfOQfwCYqEOlgRa+EBFRdIXsARSRLBF5UETe1Le7icgF0W9a4qo0rXw0r0IFgIoITIqfvW4fLn91ATbuO1rnazUUk+YXem0bwR8AvOPTy+rLGAJeY5p32dg03664rHqI1+VWAXsErVbiGr2LhnS7/3854/s79N8LY0j56uPbe845FGZC64bixM55AMJb9ERERJEXzhDwOwAqARiz1XcBeDxqLUoClUF6+YwewLp8LP5+0mIs3nYI5zw/rw5XaVjWBwl2Q+XI8w3SAOBopdOTSmaHPuQ+tKApgOqgpWmW93zCiwe287uOEdwZzu3d2u8cowfSGAL+/LddAIDx5/cynWORH6gBm3BBHwCAm0PAREQxEU4A2EUp9TQABwAopcoBJNanUT2rDJL7zDOUafG5OO6Mrjindyv0ahN8SJO8iVVyRRO7RQAIVFdfGfuOtoK3bRMtdYsxhF9mStrdq02OX28u4D1kPOakjuja0n/FrvH9b3p3MQrGT8M8PWF0bqYd390xHABw+XH5QV9DQ6OXAwbXgBARxUY4AWCViGRCD0lEpAu0HkGqpWDzucxzAI9UOPDBwm2e7TZNMpAinDfl6/aPlwY89uhFfUI+39y71j8/F69cOxiA/8/ZyBNYVFqJKqfbK3H0gPzcANeu/i+2YV+p5Tlpqdr3N69aHqTXCe7RujEKJ47CyV2aWz63obLpQTl7AImIYiOcRSAPAZgOoL2IfADgFAA3RrNRiexYlQsj/qUNzX74hxMsjmvBoQLQ/+EZXseuHtoB8zcVBfzQNOeoqw1jbluoHrN4UuV0Y/Ky3QGP+67CtWIO0gbkN0GHvCwAwGGfMnJGQuZfthzEWT1beh0rDbCC2Nwp6AyQwLFZtv8Q9VKfBSaJxugtZQBIRBQbIXsAlVIzAVwKLej7CMAQpdTc6DYrcZmDitws/5x06/Zqc9msFhqkpAhEJGqpM/70/hJ0uu+bqFw7EopLK1Ewfhq+XLrTs8/cY9o213sVbqucdFwwoE3I65rn6WWm2TwVN16YvRGA1kPYrkkmHrygNwCgU/MsT8B3fl9tTl+gFDLmYPq5KwZantPbYpVyempiZ2gyegC5CISIKDbCWQV8CQCnUmqaUuprAE4RuTj6TUtM5sS3jSwqO/y4sQhA4F44mwii1WkyY82+0CfF0O6SCgDAm/O2evaZA4hbz+rmyakHAM9fMRDpqaFz54lpSmuG3eYJzFft0lYFt2ycgRM7N0Ov1o0BaCXgtum5+s7t0wrn922NCaMDDzXfdlY3nN2rJdrrPYu+7LYUTBl3ite+YPNEE4ExN5IBIBFRbITTzfCQUuqwsaGUKoE2LEy1YP5g980R58tq5WeKWH9obisuq3vj4pxdnytnHko1B9TNstPwkCkQC/XzNbQ29RwWNMvyqhZS5XSjvMqJrDQb0vReuY8W7cB1by0EAKTZbHj1uuOCVum465zu+M+Y4Klo+uc3wYg+rTzbVwxJrEUfvjgETEQUW+EEgFbnMIF0LVWZA8AglR22FpXBHOfdd35PANoHp9WH5hd66pDaMgeV8brIxOnyb5f55+mbDNoqL18obXIzvbY37S/FoXIHstJslquFB7S3XvxRG69fPwT3j9Tu82MX943YdeNR9RBwjBtCRJSkwgkAF4vIcyLSRf96DoB/YVQKi7nHKlgACHgHZcaQWYqIZYBmFbI1Tk/F5GW7cPwTszw57XwdLnfg583FXnMT47U8l1UNZPPPc+8RbYh4WFdtxay53Food53THQBwUpdmAIDhesWOkS/8CADYfbjC0wNo1q5Jpt++urh5eBcUThwV1tB1Q+ZJAxOnv2tERIkunADwVgBVAD7RvyoB/CWajUpk5tQhqXqPUk5G6A5VY+jYJgLf+O/wMQde+H6j5fe657MV2H+0EluLrIeIb/9kKa5+8xfsLqmuLxyv87KMUm0b9pV6Alqvn6ceJL9941CsfPjcGl37trO6oXDiKM/273zy7i3fUeK5vllDWjEdTzxpYOL0d42IKNGFswq4TCk1Xik1RP+6TymV+BPOosQYshzSsaln31s3Bp8fBgCfL9FWvqakaHPgVu/2TMvE6Bd/snxOpdPt+X7Pzljvd7ywqAxz12tJh831Z+MxANxyoBS/Fh7ybP/xvcWocLjgcFa39cIBbQEAaakpaJzhv8K6JnxX4fZq09irhjPVjY1zAImIYipgACgi/9L/nSoiU3y/6q+JieX7tfsBAPePqi7zNbhDU5ysDz0G4tAXPqSIoKi0CqNe+AlLt2sBkTmBcCA5mf4B0aKtBz2Ppy7f43lsDnQqHC4UjJ+Gse8sCvk9oqXC4cKZz/7gte/HjUXo+eB0Tw/glUPao2VOhtXTayXdZ3j+iUv6oae+CpjqTpgGhogopoL1AL6v//sMgGctvqgW3p6vpTAx15+1pQgmXto/6POMlanmEce9hyu8FkEAwN/O62H5/OML8vz2pdur22AkOQaAAY/MwC59SNgogzZH7ymMhUpH4JUCxuu/aFDbCH9P7/mGTbPSICL482ldMO6MrhH9XsmIPYBERLEVMABUSi0RERuAm5VSP/h+1WMbE8KRCgeOmVap+g4x2ixSvpi9fI1WnmzOuupALCVF8M78rV7ndWnhX2sWsK5UEeyz960ftev+vKXYs+9YlfVCkmizWvxhmLVWy13YOL1uQ76+fH80RsAy/vyeXrkGqXa4CpiIKLaCrj5QSrlEpKOIpCmlquqrUYmo/8MzvCpV+KYUsYVYTGCUJzNXCLGJ+AV2TbOsU588Pm0t/nBq57DbW+XyD7oKi8vQq41/1YpoqwjSA/jWT1qgmpMZ2cxE5/Rqhccu7osOeVnY7pNjsVEYi3YoOGMVMHsAiYhiI5xPsi0A5uvz/jyfhEqp56LWqgQzdblWq3b34QrPPt+UIikhluMYiXPNyY1temk4M6tUJYEon36uTs2zPauFUywC0o37S2MTAAbpATRYVVWpi5QUwfUndtS3WngdS/QULfUhVf+F5xxAIqLYCCda2Azga/3cxqYvCtOtHy312+ebpDg1VASoyzYFOiJaZZBwnNqtud8+384XczqavOw07D9S4XX8NovXUR985wBa1ckN1PNJ8cn4veXKaiKi2AjabSIiLQBMA7BJLwFHEXB8QR4yfFaZhhoCNth9Fo+Y69j+788nweW2Hi61qqKx70il13ZppRODOzTBb9tL4HYrrN17NKw2RdvKXYe9tn3r5E68tJ+nh7S+vHbdYOQ3ta7tS6GJCGwpEvD3lYiIoitYGpg/AFgN4EUA60TkwnprVYI7q1dLv31hdgB6zQFUyrsHcGhBHhwWgd4pXZuhvMp7ruBjX6/BU9PXee3bfKAMX/zfKdoHs1KelbDdWjbCKV2b+X3/+lIYos7xJYPb1VNLqp3Xtw36totcGbhkpAWAsW4FEVFyChZ23AGgj1LqJAAnA7ivfpqU+Hx7/4DqVaYAcOPJBQGf+9v26o5Yp9sN345DI1fdBf3b/H979x3fVnX/f/z1sbxiO3svsgeBJCSEEEIIhLBCKJsWKKNASxf9MrrCammBQmlLW3Ypmx+UVVbZgbAhhAQyyCIhO2Q42xne5/eHrmRJliU5sWzJej8fDz1077n3yke5jvTxGZ8DwGkjutMqP4c5a7YHV9KAmskT0WQZVLualrZ7zxvJx0v9s4Ff9sYzNqb7P1gW83hulDV6JfVlqwVQRKTJxPrmLHfOFQM455YBeY1TpeYv2hrAoQHgDScfkNDr/P7l+cFg8jovsXSbglxW3Do5OOYvO8soyPX39N/3/jcJvW5gveFAjr1cX019128vreuyRtEix1drPKOWY0tPPjONARQRaSKxAsAeZnZH4BFlX2IIDaAihSZgDkh0DOCUSYOD26u37AlO5Dh79H5h5wW6grN9WRTk1j1rdUiUWb1lldW8OHttsAUwtL57KpomF2BAWWUV/zx7BH//3vAmrYfsO5/PtBawiEgTiTUJ5NcR+7OSWZHm5qpnZvPi7G9ZcevkWsfidQHH8pMj+/H+4uJggubAUmjZEddXeOU5Pov68wKG92zNgnU7apVv2FEWTMAcOuu2qQPAdoV5tCvM5bQRPTh2SJeoM4IlPWSZ8einK/ntpMHBVmoREWkcsVYCeTTWozErmY5enF0zVi6yyzdaQFZXN+blEwcw87pjwsquOm5gcDvYShcRCJ1wYBdat8jh/DG9eHP++jrrGVhiLppgF3BoAFhexfF//4DrXpxX53UNKXLSyQ/G9gpuF+Vl10qoLeljyy5/bvnQsakiItI49Gd3kjnn6NG2BUs27gyWFeUlnkj4ymMH1ioL7Ta7450lQO0AsmvrFsz5/XEAbN5Z9yIusVrQyoJjAGvOKSmtZPGGEhZvKOGmU4cm8A72TWCM2K+OG8gl4/qSH6X7XNLbtt0VTV0FEZGMo2/TJPjH218Ht6uqXa2B7kX7uG5tZBLpeHq0bVHnsRxfFq/93xEAHDukc9ixssoqsrOMbF8WHYr8c4B27GncL+tSr8s5P8dHi1yfJnyIiIg0AAWASfDAhzUpVg790zvB5dUCos0CjjS6dzvOG7Nf1GMDOvtTvVwyrk9C9Tk9Ik/eJ0s3BbdzsrMY0q0VM66dyF3njgDgrIN70DI/m7KK6mD3b4cif9DZ2GMAA+sA5yXwbyYiIiKJidsFXMeM3+3ATOfcSw1fpfTXukUOO8v8iZc376rd/ZqTHb8V65mfHBb3nAc/Wk7bghwGd4m9Pu+PjujLonUlPP/lWkorqsJy+QW6dzu1zA+WFeZlU1JayYrNu4NdxC29ZeJKSsMTSidboAVQkz2aL80DFhFpfIl8q+YDBwFLvMcwoAdwiZn9I4l1S1vR0q6ETqSoK3HxH04+gBd+NrZeP2vr7oqw147GzIIzfW+f+nVw5jD4WwAjZXndrG8v3EBetv+93HnOSADaFzXumruBmcixZjKLiIhI/SQyCWQYcLhzrgrAzO4FPgTGAY0zFTSNbN9TETbhI6BVfg6bdvrX3o0WdAFcGGMFkFhyfPFbFAMtd5t3lvP8F2uD5blRrg3NKBPIAdiltb+F8L3FxcFjW3aV13s8Yn3tKvMCQLUANluvzv2W/835llnXHUP7IuWbFxFpDIl8q7YFikL2C4F2XkBYVtdFZpZvZjPMbI6ZzTezP3jlfczsMzNbamZPm1muV57n7S/1jvfe63fVhIb/4a2o5ft3bRncbuilyxLJITjIWyIu0JUb0KV17QkioZNWYtV1ZyN0B//siS8A/won0jwFft3irfksIiINJ5FI5DZgtpk9bGaPAF8CfzGzQuDtGNeVAUc754bj70I+wczGAH8G/u6c6w9sBS7xzr8E2OqV/907r9moCgmqGjp3XSIB4J9O86ds6dmuIFh22xnDOLxf+1rnBsYvQvgqIJFLsIWelyxrt+0BUPqXDBC65KCIiCRX3G9V59yDwFjgReAFYJxz7gHn3C7nXORqIaHXOedcoC80x3s44GjgOa/8UeBUb/sUbx/v+ERrRjk/qkMSGie66keijPiv16qFv+WvMmT831mjepAdJRh9btaa4HZgDCDUbg1sjACwX8dC77kozpmS7uKNZRURkYaT6CduFlCMv8Wuv5mNT+QiM/OZ2WxgIzAV+AbY5pwLRA5rgECOku7AagDv+HagVvOUmV1qZjPNbGZxcXHk4ZTlkjjV8atvt8c9J9DqWBESACYSX4cGfZGB686y5OcEHNuvA+0KcynMU87y5q6yOvra2SIi0vASSQPzZ+B7wHwg8AntgA/iXeuNEzzIzNrgbz0cvPdVDb7m/cD9AKNGjUqbDBIOOHpwJ6Yt2tjgr71y8+645wTWCq6ocnRv04JOreoebN+2IIet3uoMoV3AkV3XyUwJ8/+mr6Rvx0K276lIaJKLpL+q6rT57ywikvYSaVY5FRjknKtzwkc8zrltZvYucBjQxsyyvVa+HkBgSupaoCewxsyygdbA5r39mSnHwb/OPzi4vNq+umRcHx78aHn8Ez1mRo7PqKiqJttn7BcyFjDS7d87iIse/hwIXys4sgUwWQHghh2lXPfiV8H9WCuZSPMRuWKOiIgkTyJdwMvwj9+rFzPr6LX8YWYtgGOBhcC7wJneaRcCgWTSL3v7eMenOZfMjtN9d9MrCzjj3k+C+7GqW+0cOb4sipqwKzM7K4vKakdllYs5DnHCoE6celA3gLCu18h3l6wxgKHd1NDws6YlNakFUESk8SQSjezGPwv4HULSvjjn/i/OdV2BR83Mhz/QfMY594qZLQCeMrOb8M8oftA7/0HgcTNbCmwBzq7fW2l8D0S0wMX6AkuFr7Ycn7Ftd7l/Zm2cCgVWC/li5dZgWXVEgLt6y25Wb9kdNrO4IUQOBSuv0tiwTBAZ+IuISPIkEgC+7D3qxTk3FxgRpXwZMDpKeSlwVn1/TiqYsXwLo/u0i9mFFRk8NYXc7Cyememf4ftOnLGIgbcSSF4NUB3y/lq3yOGJz1bxxGerWHHr5AatZ2D1j4A1W/c06OtLalILoIhI44kbADrnHo13Tqb7/gPTWXLziTFbMFIg/iM7q6YrtTrBL9vQs0K7g1vmZ7N9T3JmAV/86OdJeV1JLScP7xa2LrXGAIqINJ46B1eZ2TPe8zwzmxvymGdmcxuviqmvosr/xVXpPQ/v0brWOT+f0L9R6xRNTnb9Z9OGjmu8fvKQ4PauJOYAXL1FLX6Z4I5zRoStm11VpQBQRKSxxGoBvNx7PqkxKpLqNu4oZeLt7/PMjw9j/66top5T4Q1eG9mrLXPW1OTme/yS0RwxoGOj1DOWnKz6T6YIXSqudUHNXKBAmpj66D3lVQCW33JiQjkIJbMoD6CISOOpMyJwzq3zNjcBq51zK4E8YDjwbV3XNVfvLt5ISWklD8VIvRJoARzUuSVLbp7EWG+ZtawkBDuhr9g5Rk6/UKF5/Hp3KIx57o+O6APAfeeNDCv//XeGcMUxA8LK6jtZu77B49goy9VJ86MuYBGRxpNIk9AHQL6ZdQfeAs4HHklmpVJRYPzcs7PW8MjH0YPAPRX+yQu+LCPHlxWc+JGMtq7AV2VBro9PpkxM6JrskITKD144Kua5Uybtz4xrJtKrfXigeNHhfbjimIGM6dsuWJbILN3QMYclpYkFgD+f0I/CXB+XTxwQ/2RJS6F/O2gSiIhI40kkADTn3G7gdOAe59xZwAHJrVbqyQlZp/SG/y2Ies5d05YC8Ob89UDIl1sSezuvPGZgwmsLB1oAC3J9dGqVH/NcX5bFPGdWSHqY8gSSW1eEdO/NXLGVddvrHufXs52/2/nXxw9m/h9P4NC+agFsrkJnfFdqDKCISKNJKAA0s8OA7wOvemW+GOc3S7lxliOrqKpmY0kpAFt2lQNw1KBOAPRs27B58mDvYsrAkmq52fueWDm0sSbe6iabdpbxvX9ND+7/8tk5HHbLNJ6ZuTpqq0+PNgUc0rvtPtdRUl/o7dcYQBGRxpNIHsArgKuBF5xz882sL/7VPDJKdsQEitKK8Fx1xSVlXqC3mYGdWwLwkyP7cubBPejYMrExeskWaAFsiJU1urTK9yeUJn4A+MzM1cxeva1W+W+em0tZZTXnj+kVLNu8s4xPlzWfFQAlcRoDKCLSeOJGAs65951zJwN3m1mRc25ZAquANDuRiZwHX/9G2P7Vz8/jMG+ywg+9CRRmljLBH0B2IABsgBbAm049MLhdFhEMR3p5dt1zhjZsLw1uV1U7pi7YsM91k/SkMYAiIo0nbiRgZkPN7EtgPrDAzGaZWcaNAYzXOrGxpCz4BZaTomvX5jZgF/BRg2rS2sRrAQy0iEYTutLIX99azJTn5+1z3SQ9PfnZqnrPKBcRkb2TSCTwL+Aq51wv59x+wC+Bfye3Wqkn3jqlC9ftCAaJiU7KaGyBbuyG6AIOzeMXLwCsivGl/tTnq4Pbn35T0/XbEHWU9LJofQlvzlcLsIhIY0jkW7bQORcc8+ecew+InUSuGfrPjFVxzwm0AEaOF0yG/Bz/PJycOJNTQgVmMuflNMwcnkkHdgHidwGXlsc+Hs1Llx2+V3WS9LYjScsLiohIuEQilWVmdr2Z9fYe1wHLkl2xVLJ9TwXTl22JeqxVfs08msZsAfzZhH78fEI/zjl0v4SvyfHqVdBAAWBgrON7XxfHPG9PnAAxILSdsHvbFnWeJ83HEQM6hO1HjrUVEZHkSCQAvBjoCDzvPTp6ZRnjltcW1nnsF0fXJCmu8rqJsxshACzIzebXxw8mLzvxYC4wNrEwr2ECwEAr5L3vfcPcNbVn+QZEzphORKv8nPgnSdobuV94uh/NAxERaRxx08A457YCGTfrN1ToOLVIoZMY1u3wz2j11aNbtjHlZPvr1SI3kew/8bXMqwnSikvK6jxvZ1llQq+XSEJpaV5+cXR/xvRtzzn/rskT+dXa7cxevY3zQtIDiYhIw6ozEjCz/xHeKxfGSw2T8bbuLmf/rq1YuG4H/3rf3zPeGC2AeyMwNrEwt6FaAGsakGPNkt4WZ+1f5xxmxpINJQ1SL0kf2b6sYPok8P/fOenOjwAUAIqIJFGsLuC/An+L8chY4wfWpEDJzc7izIN7hB3PstQMAAPpX1q3aJju1dCxjnUt4/Xttj1sDGkdfOvK8RzQrVXYOYHgMfLfUTLHMz8+DAhfGq5a/cEiIkkTKwBcABR7iaCDD6DYO5YxTj2oW9j+384aHtz+7QmDaRExqSJVWwADWiUjAKxjGa+xt04L2x/YuSW9O4RPIg/MsLYUDZwl+YZ4fxSErjFdWln/saMiIpKYWAHgnUCHKOXtgX8mpzqpqU1BbnB7+S0nhq3u0TI/J6wrFFI3D2BDx1dZIe+zPqs4fLNxZ9j+suJdAOwuT2ysoDQ/+V7r9Ishq8ZU1NGqLCIi+y5WANjfOfdBZKFz7kNgWPKqlHpCW7eitVJFtgCmakuWz6tXQ3Wt+ax2F/D5D37GDx6eEfO66yYPAWpSgLQr9AfYu8rU4pOpsqMk/q6Mk3xdRET2XqwAsO71uyCjcnQEgpuHf3BI1OP5DTSpItkC8VpDtauEdwH7X/XDJZt4b3HtvIBm8NAPRgEwbkAHVtw6mT+e4l9P+PapXwNqAcx0I/drE7avtYFFRJInVgC41MxOjCw0s0lkWCLoiipH9zYtmDC4U9TjkS2AqSowOaWhcu36wrqAo7fWtCnw/60wrEcbjh7cOaI+4efu8lYM6d+pqGEqKGmlMC88KUGFAkARkaSJlRDuCuBVM/suMMsrGwUcBpyU7Iqlkqrq6pjj+oryGiavXrIFuqZdA7UBhnYBl9cxXmt4jza8/3Uxd587otaxlhHJnneVVXLi0C7c8/2DG6R+kl4i/49VaQygiEjS1NkC6JxbAgwF3gd6e4/3gWHOua8bo3KpoqLakR0juXOX1vmNWJu9F/h+baiGldBJIDe+siBsxY9AOo9q5xi5Xxt6tC2odX27wlx6ty/gmP39LYO7yyopaKAk1ZJ+ItcBrqijVVlERPZdzG9b51wZ8HAj1SVlVVZVk5NVd295IL9eqjMCXcAN17Ly4W8mcMRt7wKweVd5sLyktJK8Ih8VVdXBBNTRZJnx9sINAOyuqEqb7nRpeKu27Anb1xhAEZHkSY/IpYlVVsVuAcyNMoMxFVmwBbDhvlhDWz9Xbt4V3A60BlbFaT0N1OnEf37Itt0VaRPyBg7eAAAgAElEQVRMS8M7alDHsP0KzQIWEUkafdsmwN8FXPc/VU6aBICBHtsGjP/C3ntoGpfSCv+Xd2W1izl+MrCqyoJ1O8LqKJknMu2LWgBFRJInbuRiZt8xs/SIcJKkqrq61uoen197DJ9MORpI3cTPkQZ18a+2MLhrqzhn1s9tZ/rTQt45bUmwLNACWFnlYq6MErks3U7lAsxYkYmflQhaRCR5EgnsvgcsMbPbzGxwsiuUiiqiBDEdW+bRrU2LWueO6tW2sapVb8cO6czUK8dz8vBu8U+uhw5F/kTO324rDZYFA8Bqhy/GGMBurcP/DdOkMVWSoFwtgCIijSbu161z7jxgBPAN8IiZfWpml5pZrETRzUplVXXC3bzP/XRskmuzbwZ0bvjbFphcEpoLsKSsMliWE2MMYCBPYIC+8zNXZMBXFrEW8PY9FVzzwjxKSsNnC4uISP0lFNU453YAzwFPAV2B04AvzOwXSaxbyqiIMwkk0wUmcoR+gW/c4W8NrKyKPQYwL2LWb0POUJb0cuOpB4btbwmZVQ5w6+uLePKzVQy94a3GrJaISLOUyBjAk83sBeA9/EvAjXbOTQKGA79MbvVSw67yylqrFETq17GQHx3Rp5FqlFoCCaaPHdIlWBaI4yqrY48BjDym1G+Zq3vEkIqNO8rC9rfvCQ8IRURk7yWSdfcM4O/OuQ9CC51zu83skuRUK7XsLK2kZZwA8J1fHtU4lUlBgRhu9ZbdwbJAY2BVnBnUkSlpGjJFjaS3m19byI/G9w3uxxpLKiIi9RM3AHTOXRjj2DsNW53UdOc5I2hTkNvU1UhZgTWGZ6zYEiwLBHKVUWZQh4oc99W+KC8JNZTmQIMwREQaTp0BoJmVQNiisebtG+Cccw2bSySFHdq3fVNXIaVF+2IOjOWLNwawX8ciAG45fSi7yio5b0yvZFRRmgG1DYuINJw6A0DnXMbM8pV9ExgDGKo6ZAxgrBnUPdsV8PVNk7QCiET148dn8q/zRwG1E0WLiMjeq/Nb18xaec/toj0ar4qS6qLEf0xftpk95VWUVlTFTZSt4E8CAr8qg7v4//58c/6G4LGySgWAIiINJdYYwCeBk4BZ1HT9Bjigb7SLJPNkRYkAX/9qPa9/9QZQe6avSF18WUZ1lWPR+pJaxyLzAoqIyN6rs+nFOXeS99zHOdfXew48FPxJULQWwFDKoSiJCgwnuGxC/1rHPl66ubGrIyLSbCWSBgYzawsMAPIDZZFpYSRzhTbwDercksUbwltvlL5DEuXzAsCDerap8xwz/ySjaGNPRUQkMXEDQDP7IXA50AOYDYwBPgWOTm7VJH3UfBFH+05WF7AkKvCr0rdjYVh5ecj4P+cC+SX1eyUisrcSaZq5HDgEWOmcm4B/XeBtSa2VpJV48Z2+qCVRWd4vU+TM8YHXvR62X64ZwSIi+ySRALDUOVcKYGZ5zrlFwKDkVkvSSWhXXLRuObUASqICvylZWcY5o3vSqWUee8prJn8U5PrXji7XjGARkX2SSAC4xszaAC8CU83sJWBlcqsl6SQ0vosW6mkMoCQqkDLIZ0aOL4uKquqwMaVdW/uHIe8sq2yS+omINBdxv5mdc6c557Y5524ArgceBE5NdsUkfVhI2Bct51+OuoAlQXd/fyRHDOhAu8JcLwB0YX9UtMzPAeC0ez5pmgqKiDQTiUwCGQoM9nYXOufeT26VJN2E9vpmGZw+ojvPf7k2WBYvEbRIwNh+HRjbrwPgHwdYXlVNZXVNd29Rnv8jq7ikLO5rLfFaDgd01qJGIiKRYq0E0trM3gNeAs4Fvg+8ZGbvBlYJEYHwANABt3/voLDjGgMoeyPXZ1RUVVNRVbMKcP9ORQlff+zfP+DYvytblYhINLG6gG8EZgL9vW7gU/HnAvwcuLkxKifpIdpKIKE0BlD2Ro4vC+fg7PunB8uqnYtxhYiIJCpWF/AxwDDnXLD/xTlXbWbXAPOSXjNJG6HxX7RZwBoDKHsjJ8oa0f06+lsA1aosIrJvYjXNlDvnak2188riDsAxs55ed/ECM5tvZpd75e3MbKqZLfGe23rlZmZ3mNlSM5trZiP39k1J4wptAYz2vawxgLI3ogV57YtyOahnG8b279AENRIRaT5itQDmm9kIamf2MCAvgdeuBH7pnPvCzFoCs8xsKvAD4B3n3K1mNgWYAvwWmIS/i3kAcChwr/csKS70FyRad7BFTQ4jEltkMuiAvOwsyiqqoh4TEZHExAoA1wG313FsfbwXds6t814D51yJmS0EugOnAEd5pz0KvIc/ADwFeMw554DpZtbGzLp6ryMpzOK0AH6+YguTh3VtxBpJcxAtAMzOyiI3O4uSUuUBFBHZF3UGgN6ybw3CzHrjX0LuM6BzSFC3HujsbXcHVodctsYrUwCY4uKNAYwzR0QkqmhLCPbvVEheto85xdsoragiP8fXBDUTEUl/SZ+eaWZFwH+BK5xzO0KPea199ZrWZ2aXmtlMM5tZXFzcgDWVvRVvDKAG7MveiPy9+X+XHEr/Ti3Jy8liR2klP3h4RhPVTEQk/SU1ADSzHPzB3xPOuee94g1m1tU73hXY6JWvBXqGXN7DKwvjnLvfOTfKOTeqY8eOyau8JMzCtmsHe/HSxIhEs6x4V9h+r/YFAGzdVQ7A9GVbGr1OIiLNRdICQPP3BT6If/WQ0LGELwMXetsX4k80HSi/wJsNPAbYrvF/6SE0wGtb6F+qa1zILM3vHdKz1jUi8UwYHP4HXmA2+SffbG6K6oiINCt1jgGMl4bFOfdFnNc+HDgfmGdms72ya4BbgWfM7BJgJfBd79hrwInAUmA3cFHc2ktKCG3gu+W0YQA8fsloNpaU8dnyLfTtmPjqDSIBhXnhH08aSiAi0nBizQL+m/ecD4wC5uDv7RuGf4WQw2K9sHPuI2qnkAmYGOV8B/w8Tn0lBQUCwI4t82hdkOOVGZ1b5XPy8G5NWDNJZ5GzgKPlk6yoqibHl8UXq7bSs20BHVsmkqFKRETq7AJ2zk3wZgKvA0Z64+4Oxj+bt9bYPMlcgZm/aqGRhpQbEQBmR0kLs9NLB3P6PZ9w8l0fBctf/FIfUSIisSQyBnCQcy649Jtz7itg/+RVSdJNdbV/Ircme0hDyo1YCi4/x78/53fHBfNKXvXM7ODxddtLg9tXPD0bERGpWyIB4Fwze8DMjvIe/wbmJrtikj6qvABQS75JQ4rsAg60CLYuyOHIgf4JIu8uLg7+/gX87qWvGqeCIiJpLNYYwICLgJ8Cl3v7H+Bfpk0EgErvC1hdwNKQciISQYcmGQ/tHi6vrA4777FPVya3YiIizUDcANA5V2pm9wGvOecWN0KdJM1UO38AWNfarSJ7I7QLuH+n8Jnk5VU1Qd+2PeXB7ZteWZD8iomINANxv7HN7GRgNvCGt3+Qmb2c7IpJ+ujfsYhLxvXhX+cf3NRVkWYkJ6vm42lsv/ZhxxZ8W7Oo0MYdZcHtBz5anvyKiYg0A4l0Af8eGA28B+Ccm21mfZJZKUkvWVnG9ScNaepqSDOTFTKk4MyDe4QdCx1usLOsstHqJCLSXCTSZ1fhnNseUVav9XtFRPZF5Azz0AlHJaUKAEVE6iuRAHC+mZ0L+MxsgJndCXyS5HqJiNRp/MCaZeK27S6PcaaIiESTSAD4C+AAoAx4EthOzYxgEZGkC0w0ChixX5vg9uZdCgBFROorkQBwsnPuWufcId7jOuDkZFdMRGRYj9YARKT6C5txvivOGEDnNGJFRCRSIgHg1QmWiYg0qEDuv8gWwBxfFo9fMhqAVVt2x3yNa16YF/O4iEgmqnMWsJlNAk4EupvZHSGHWgEadS0iSReY6xGtEa8g1wfAK3PXxXyN/8xYzS2nD2voqomIpLVYaWC+BWbi7+6dFVJeAlyZzEqJiAAE5vpG68bdXV7VuJUREWlG6gwAnXNzgDlm9qRzrgLAzNoCPZ1zWxurgiKSubq3LeCLVdvIz/HVOnZYX39y6CyrPUZQRERiSyQR9FRvNZBs/C2BG83sE+ecWgFFJKluOX0oEwd34sDurWsdy/Zl0a11Plt2l1NaUR3lahERqUsik0BaO+d2AKcDjznnDgUmJrdaIiJQlJfNqSO613k8JztLwZ+IyF5IJADMNrOuwHeBV5JcHxGRhOX6EvkIExGRSIl8ev4ReBNY6pz73Mz6AkuSWy0RkfhyFACKiOyVuGMAnXPPAs+G7C8DzkhmpUREEpHts1plPdq2YM3WPU1QGxGR9BE3ADSzh4Fac+yccxcnpUYiIgmau2Z7cPsvZw5jwuBO7C6rYvxf3m3CWomIpL5EZgGHjvvLB07DnyNQRCRlTBjciQ5FeRS7sqauiohIykukC/i/oftm9h/go6TVSERkL/i8ZeOyavcKi4hIhL0ZQT0A6NTQFRER2RdZWYEAUBGgiEg8cQNAMysxsx2BZ+B/wG+TXzURkdiuOnZgcDtbAaCISMLiBoDOuZbOuVYhzwMju4VFRJrCScO6Brd9XgBoygwjIhJXnWMAzWywc26RmY2MctgBW5xzK5NXNRGR2Pp2LApuZ5laAEVEEhVrEsgvgR8Bf6vjeHszm+OcO7/hqyUiUj++LE0CERFJVJ0BoHPuR97zhLrOMbO3klEpEZH6CgR+agEUEYkvVhfw6bEudM4975w7ruGrJCJSf6bAT0QkYbG6gL/jPXcCxgLTvP0JwCfA80msl4jIXsnLrj0LZPvuCloX5DRBbUREUlOd8+Wccxc55y4CcoAhzrkznHNnAAd4ZSIiKSdaS+CJd3xIcYlWCBERCUgkYUJP59y6kP0NwH5Jqo+ISINbu20Pd7+7tKmrISKSMhJZC/gdM3sT+I+3fzbwdvKqJCLS8LI1PVhEJCiRtYAvM7PTgPFe0b+ccy8kt1oiIg3L51MAKCISkEgLIF7A9wKAmR1hZnc7536e1JqJiCTgvz8dy/xvt8c9Ty2AIiI1EgoAzWwEcA7wXWA5mgEsIini4F5tObhX27jn5WX7GqE2IiLpIVYewIH4g75zgE3A04DFSgwtIpIK5v/heL5YtZXzH5wRLIuWHkZEJFPFagFcBHwInOScWwpgZlc2Sq1ERPZBYV52rRa//By1AIqIBMT6k/h0YB3wrpn928wmAhpEIyJpSS2AIiI1YiWCftE5dzYwGHgXuALoZGb3mpmWgBORtOKaugIiIikk7p/EzrldzrknnXPfAXoAXwK/TXrNREQaUFW1QkARkYB69Yk457Y65+53zk1MVoVERBpC7/YFYfsKAEVEamhQjIg0S51a5bPwjycE9xUAiojUUAAoIs1WbsjEj2qnAFBEJEABoIg0W76Q1T/UAigiUkMBoIhkhF1llU1dBRGRlKEAUEQywh3TljZ1FUREUoYCQBEREZEMowBQRJq1xy8Z3dRVEBFJOUkLAM3sITPbaGZfhZS1M7OpZrbEe27rlZuZ3WFmS81srpmNTFa9RCSzHDGgI0O7t2bCoI5NXRURkZSRzBbAR4ATIsqmAO845wYA73j7AJOAAd7jUuDeJNZLRDJMfk4WZZXVTV0NEZGUkbQA0Dn3AbAlovgU4FFv+1Hg1JDyx5zfdKCNmXVNVt1EJLPkZfsorahq6mqIiKSMxh4D2Nk5t87bXg909ra7A6tDzlvjldViZpea2Uwzm1lcXJy8mopIs5GXrRZAEZFQTTYJxDnngHpnZvXWIh7lnBvVsaPG9IhIfPk5PgWAIiIhGjsA3BDo2vWeN3rla4GeIef18MpERPZZXnaWuoBFREI0dgD4MnCht30h8FJI+QXebOAxwPaQrmIRkX2Sp0kgIiJhspP1wmb2H+AooIOZrQF+D9wKPGNmlwArge96p78GnAgsBXYDFyWrXiKSeTQJREQkXNICQOfcOXUcmhjlXAf8PFl1EZHMphZAEZFwWglERJq94h1llFdWU64gUEQEUAAoIhlgycadACz1nkVEMp0CQBFp9n4+oR8Arv6Zp0REmiUFgCLS7OXn+AAorVAXsIgIKAAUkQyQl+0PAMsqNRNYRAQUAIpIBsjP8X/UfbNxJwvX7Wji2oiINL2kpYEREUkVgS7g61+aD8CKWyc3ZXVERJqcWgBFpNnLyw7/qPt2254mqomINITNO8voPeVV/vzGoqauStpSACgizZ4vy8L2f/Pc3CaqiYjsrZWbd7GzrBKAix+dCcC9731D7ymvMn3Z5qasWlpSACgizV6WhQeAu8orm6gmIpII5xyfLdtMZVV1cP/Iv7zHgb9/k4l/e485q7eFnX/2/dN5ec639f457yzcwBtfrWuQOofatLOMtxdsiHps9uptrNi0q8F/Zn1pDKCINHuRLYCbd5Y3UU1EJBEvzf6WK56eHdy/7Yxhwe1viqMHT//3ny+ZPLQrviyjsqqaZZt2MbBzy1rnPfHZSob3aENFVTWXeC2JfzptKOceul+96+mcY09FFQW5NeHUKXd/HAxQn750DIf2bc/2PRXsKa+i2jlOvftjxvZrz5M/GlPvn9eQFACKSLOXHREArtqym1krt3Bwr3ZNVCMRiSWyNe83/w0ftnFQzzZs2VXOqi27w8pvenUBfToUUlJayV/eXMzfzhrOGQf3CB7vPeXVqD/vmhfmcdwBnelQlJdwHWeu2MKZ930KwPSrJ9KldT6rNu8Oa5186vPVHNq3PcP/8FbYtYGu7KakLmARafayIgJAgDPu/bQJaiIi8TwzczXTFm2MemzeDcex4tbJvPjzw3n2J4cB8NSlY/jvT8cC8PDHK/jdS/N58rNVAPzy2TnBa/8Xp4t41E1vs3lnWcL1DAR/AI98soLF60sY/5d3ATh/TC+K8rIpKa2Iugb57d8dnvDPSRYFgCLS7PmsdgAoIk2voqqa0ooqjrhtGv94+2vWbtsTnKR117kjePHnh7PsTydy2YT+3HHOCFrm5wSv7dwqnxW3TmZM3/YM6FwU9rprQ2b6T/zbezz+6Qp+8Z8vw845YkAHAB656JBg2cE3vc1d05bErHNZZRXV1eHLSt73/jcc/48Pgvu/nTSYnWWVvL1wIw99vLzWa/TvVLtrurGpC1hEmr1oLYAi0rSWb9rFhL++F9z/x9tL+Mfb/uBrQKciThrWLXjsV8cPivlaLfNqhzPDe7RmzprtfFO8K5gDFGDRjScw/9vtwSEgzjk6t8pjww5/699f3/qar9bu4L7zDw5e45xj/rc7eGvBBp7+fFXw3MlDu/LqvPBJJGeM7EFRSH1ufd2fquauc0dw2xuLufWMoTHfS2NRACgizV7kGMCAiqpqcnzqCBFpbM45Pl66qc7j10zev16vZ2a88otxbCwp5ejBndm6q5wVm3dx2j2fhJ330s8PJz/HFzb+18y4etL+YZNO3pi/nsXrSxjUpSU3vrKABz+q3YoH/sA0NAC877yRnHBgVwA+mXI0Y2+dFjx2zP6dw4LapqYAUESavchZwAG7y6poXaAAUKSxnXTnR8z/1r8s4/5dW/Gzo/qR48ti/fY9VDkYP6BjvV/zwO6tgdYAtC3MpW1hLm9fNZ5+HYt4dtYaJg7uRPs6JnkM7lq7S3bTzjJab8+pM/i78LBe9OlQyIpbJ3PxI58zbdFGencoDB7v1qZF2PmBFYlShQJAEWn2IvMABlRW1x6cLSL7zjnHxpIy8rN9tC6oGbd3/wff8KfXalbvOPWgbvzj7BFJq0dgrN13R/WMed7gLq1YdOMJ+LKMAde+DsDmXeXsKgvPN3jHOSP4P28sYXZI78E93x/J4vUlDO7SKuz8J394KF+s2sp5Y3rt83tpaAoARaTZC20BXH7LiTw5YxXXvvAVVREDuUWk/h7/dEVwjN2MayaSl+MLS3tyzP6dueKYAbw6bx33vvdNsPy2M4dx2ojujV3dOgVa6GZddwwH3/Q2W3aW4fOCvBnXTKRTq3wAxvRpx8+f/ILfnDAo7NrhPdvUes2x/Tswtn+HRqh9/SkAFJFmL7QH2MyCYwIrFABKGvly1VZOu+cT/nzGUE4b0YPc7KYfvvDFqq1hEywOveUdrpkUPn7v7YUbeHth+KoYI/Zrw6kHdU/JMbhtCnLJ9WXx7fZSsrOMLCOs67hTq3ye/cnYJqxhw1AAKCLNnkV0AS9cVwLAjOWbOW1Ej2iXiKQE5xxPf76aVi1ygrntfvvfefz2v/NYdOMJTTqurLracXrEJAvn4ObXFgL+XHdXPTMn7Pg7vzyS3u0L6xyXmwp8Wcbgri15e8EGlm3aRc92LVK6vntLAaCIZJz3vy4G4N1FxQoAJWjb7nJat8ip9QdDQ7ntjUW0yPHxi4kDEjp/9ZbdHHHbu3Ue/3jpJibu3zm4v7Oskr++uZjjDuhMz7YF9GxXsM91jmXMLe8Et5ffciLPzloTzOGXnWWcPrJHcCm2978uJj/HR7+ORVFfK9WcPqI7N/xvAQCDOreKc3Z6UgAoIhnntBHduX3q1xwUZcyOpCfnHFXVLmxgfiLKKqvIy/axdGMJx9zuT+S74tbJ+1SXDTtK2bKrnP27tqKyqpq/Tf2aV+Z+y+ot/uTEf5v6NbedOSw4MWHV5t1c++I8jh7ciZOGdePBj5Zz3/vfRH3tqycN5vD+HTjpzo94+OMVwQCwvLKaA3//JuBflQJgdJ92PH3pmKQEtDtKK9hY4s+F9+Mj+2JmnDy8G2/NX0/rFrn88ZQDgMDM3JrndDEuZBbyQT3Tq+6JUgAoIhnnuAM6c/vUr+naOn+vX6O4pIwvV23luAO6NGDNZG9d9uSXvDpvHR/+ZgI92xUE13ztUJTHR7+dwO7yKl6dt45zR+8X7M4LrOXaMi+bkpC1WZ1zexU0bd9TwQ8ensGXq2pmjh4xoAMfLqmd7+6vby7mu6N6smrz7uDyYR8u2cQfvFanUM//bCw/eXwWG0vKGNilJUO6+lukPlq6iYHXvc6rvxjHsX//oNZ1M5Zvoc/Vr7H05kn1DozjeenLtQCccEAXrvbG/OXn+HjgwkNiXZY2+oakc/nZUf2bsCbJowBQRDJOQ0wCOf/Bz1i0viQ4Dmvttj10aZVf77FCVdWuwcYXjfvzNNZs3bPPLVjp5rR7Pg4GXUfc9i5/OXNY8NimnWUMvv6N4H6LHB93TVvCgd1b88pcfwLf0OAP/N2VvdsXUpSfzevz1tGrfSHjB4bnpSutqCI/x0dlVTXTl21h864yHvxoOXPXbA87LxD8/e2s4WzeVRZMgbKxpIwtu8qDwV80z/9sLCP3awvAG1eM57lZqxk/oGPYyjblldVhwd8/zz6IIV1bhZVNX7aFcQMaZibq5p1lfLR0U/B93HzagQ3yuqkm8G/cr2Nhs11JSAGgiGSc7Cx/a0hl1d7nAVy03j+RZMXmXSxaV8IVT8/m8okDuPLYgQm/RqCVau4Nx9EqZI3T+iouKWPhuh2s2bon7HVDA4jmavvuirAWN4Bfe+PQ7jvvYH7y/2aFHfvVs/5JCSs27w4rv/jwPvzkqL6MvvkdfvDw57V+zrUn7s+mnWX86vhBfLFyK9+7fzo/HNeHD5YU8/WGnWHn/vWs4bQvyuUi73X+fcEojh3SGecc7QrzeHP+eqYu2MDIG6cGr/nH9w4CYPbqbVw3ef9aLXbtCnO5dHy/4H5udhblleG/v69ffgT7e62D7//6KB76aDmPfrqSz5Zv3qcAcPWW3dw5bQkXHNabCx+aweZd5WH1aq5m/+7YlJhpnSwKAEUk42T7/H/RVzZAGpgT/vFhcPuTbzYlHACGLib/2bItHDukc4yz61ZcUsYhN78d9djp93zCB7+ewH7tkzsZoDE9NWMVU56fx8M/OARflnHBQzMAOPuQnhx3QGcufmQmAEV52ZxwYBceuGAUP3zMX9amIIdtuysA6Ngyj+KSMr6+aVJCX/KBma3/+mBZsOyBKCtEPPHDQzncy/v25hXjqaiqDo5/MzPOPLgHxx/QmaE31OTJm3fDcbT0/gA4NcG8eHN/fxwASzbs5IKHPmPqVUfSISRVSa/2hfzhlAN59NOV3DltKb88rvZauqHdz8cf0Jk3528IdqGD/w+k8x+cwafLNgPwzMw1wWtPHNqFHm0LkjZhJhW0KWi+wS0oABSRDBTIPVZZtXcBYF0JpJdv2pXwayxcvyO4ffvUr+sdAC7ZUMKO0grmrK7pcjxyYEcWry+htLIqGOhE62JcfsuJaffFXVXtePHLtcEJDhc9Et5K96fThoZ11U371ZEAHDOkMwv+eDy+LCMv28fHSzfRvU0LencojDrW77cnDObPbyzigQtG8daC9cxYvqVWayHAScO6BruQr5u8Pwd2b80B3VoFAzmAQV1qLy8G0DI/h+E9WjNnzXbuO29k2DWJCqR/GdqjNV/+7ri45+8ur6QgN/wr/653lwS335zvz9N34j8/5LFLRvPCl2t57NOVUV+ruf1RkakUAIpIxgmMAdzbpeC27S6PWr5pZzlvzl/Pmq17uPCwXnUOvK+qdlzzwlfB/YXrdoQd31NexafLNnH04NpBoXOOkrLKWoP+//OjMRzWr31wP1YKkUXrS9i/ayuqqh0vzV7L5GFdyctOrXVKA6Yv28yc1du45fVFdZ7z1KVjgsHfPd8fSVW1o1PLmgk+oYHP4SGrMkQLgn88vi/njO5Jm4JcjvGC8l1llTz/5Vq+O6oHZZXVFOT4yPZlcde5e/++Xrps3N5fXA8/GNubRz5ZwSOfrOCnR/Zj2qKNXPLoTDoU5bFpZ1mt80vKKjktIrffx1OOpnubFuwur+TbbaUK/pqJ5tu5LSJSh8AYwN+9NJ8F3+6Ic3ZtKzb7W/o6FNV0ET168WgAfvz4LG58ZQEn/PPDqNd+U7yTfte8xpzV4ePWrnx6dnD7n+8s4eJHZtJ7yquccvfHwfKqakefq19jWEj3IcDh/duHBX8APdsVsPCPJ3Bon3a0bpHDbWcM4/9dcigAk/75IYvXl/DU56u46iaX9FIAAA83SURBVJk5nHFv+Bd+qti8s4yz759eK/j71XE13exLb57EmL417/3EoV35zvBue/0zs7KsVtdfYV4254/pRV62j1b5OQ0+ozaZTh/p71K+7Y3F3P3uUi551N8dHgj+fjy+L5dN6M/xB3TmxlPDJ3QM7d6aP5x8AN3btAD8gXT/TumRx0/iUwugiGScwBhAgBPv+DCsS/SmVxbwwEfL+cHY3pjB779zQK3rz7j3UwAuHd+XP722iP9dNo7eHcJbRZZu3Mn9H3wTNnAf4Jrn5wW3W+Vnc/WJ+3P18/N44cu1vOCl1gg1Z/U2Vm7exdn3T2fd9tKo76euhe5b5Pp4+seHRT12/D8+CAawX63dwe9e+oo/npI6Mzo3lpQy+uZ3wsomDu7EO4s2cubBPTlrVE98WZZWwVhTCA3Y/vrW17WOD+nWilMO8geJpRVVXP9iTcv0/37ROK2U0jQUAIpIxgkNAAE+WLKJI700H4GB/YGxZqs27+aBC0cFA8TQ7t8fjusbFuAN69GauWu2c+MpB3D9S/P502uLagWAoSlf3rhiPG0Kcrg6JCiM5si/vFer7MkfHsph/dqzaWc5HVvm1b6oDvNuOC44AWHTzpr38tinKzl5eDdG9W6X8GuF2ryzjEn//JCrjh3I2aP3q/f1f3lzEXe/609+/MX1x3L4rdOCx5bcPCkl14xNBwW52bVyEd77/ZFMGNyJ6cs2Mz4k4XF+jo+LD+/DQx8v591fHdUEtZXGpP9RIpIR+ncq4mSvazA3Iph4zAv2onln0UbuDVmVIXSiR2R+sJcvG8eKWydz/mG96dLKPwat95RXGXjd6zjnnzjSxUs+Pft3x9KtTQsKcrP561nDa/3ciw7vzdKbJ3Fg95plqDoU5fHTo/qx4tbJjO3fATOrV/AH/gkIr/3fEcH9J354aHD7/pAZrvV15F/eY2NJGVOen8fMFVvqda1zLhj8AYy8cSoV3gSdz689RsHfPnr8kkM5oJv/9+jQPu2YNLQr+Tk+jhrUqdbv8G8nDeJ/l42jT0giZGme1AIoIhnh7auODG5HDv5/Z9HGmNfe9sZiTjywK707FLJtj3927X3njYx5zWkju3Pve/6gpryymqE3vMVOL+Hw6N7twsaZTTqwCzNXbCE3O4vzx/SifVFeML/a/y4bxy+fncP4AR0TThESz5Burfj3BaM4vH97CnKzWXHrZHpPeZXWLWrPRl26sYRPvtnMBYf1rnVs884yrnh6NkcO7Bh8bwBn3vcphbk+5t5wfMwk1ztKK2qNZwx17/dH1jvAleiOG9KF+d/u4KZTY3fz52X7GNqjeS59JuEUAIpIxkskI8rzX6zh3EN78cT0VQAM6hJ7gfhNJeEzLEMDpLNHh4/ZK8zL5tYzhhGNmXH7dw+KX8F6ikw7074wl3lrt1Nd7cJahQLr4555cI+w2bRrtu7muhe/4sMlm4Ldi8fs35m3F/rTiewqr+K6F7/iltOH1lmHyJbXt64cT0lpBX96bRGVVdUcNajTPr1HqXHZ0f2ZPKwL/TtFT00jmccC3RLpaNSoUW7mzJlNXQ0RSUOB1TJa5mdzaJ/2HNK7ba3ZpneeM4LJQ7vS95rXal0fWAKuLh8uKeb8B2dw7JDOzFi+he1ey+FTl44Jm7WaKgL/HgDnj+nFjaceSGlFVdgyap9MORozf/7EaClm3v/1UazYvJsPvi7mQW8sZV3r0F7/4lc8Pt2fZ26/dgXcdOqBtZZbE5F9Z2aznHOjIsvVAigiGW1wl5bsKquMmmeufVEuWVlGixwfeyqqguWje7eLGfwBHDGgY3BN3o07Spn/7Q7aF+UyrEebhn0DSfD49JV0KMrj72+Hzxod603MuOjw3sGyyUO7cssZQ4NL2fVqX8iRAzuyfU8Fz81aw6L1JXy0dBP3vvcNM6/zj+e75oV5PPmZvyX18P7teeKHYxrnjYlIkAJAEclYWebvfl0RZQWPY/bvzNh+/qTBX/3heMb9eVowDUt+bv2SJndqlU+nVvnxT0whkcFfqIc/XgHAuP4duPv70cdCXj5xAM/NWsNJd34ULBtw7eth5wzv0Zp7zj143ysrIvWmqVUikpFmXncMX15/HIvWldRa6utvZw3ngQtrekx8WRa2rNfFIS1gzcW8G44LS2wdavbvjq1VNrhLy2Dy62gC68nW5bmfHMZLl42jdUH9l0ETkX2nFkARyUgdivyzS4ujLId1xsE9apU9dOEhPP/lWk4b0T3mzNZ01TI/h2m/Oortuyt4/+tirvMSAl8+cUDYjOX2hbns176A534yNu6/w4xrJ/KjR2fSt2MRfz1rOP98Zwn/nbWG331nyF7nGxSRhqFJICKS0Ub88S227q4I7n9vVE/+fGb0GbmZoqraceXTsykuKePJHx2KmQXX5P3xkf3iv4CIpAxNAhERiSL0T+Bjh3TO+OAP/F3ed5wzIqxsTN/2KTl7WUT2jsYAikhGu+PsmkCnsJ6TO0RE0pUCQBHJaOMHdgyugBEYFygi0twpABSRjBdI0tyno9Y/FZHMoABQRMSjFkARyRQKAEVEPO0Ko+fBExFpbhQAikjGu+vcEQzt3jos2bOISHOmNDAikvFOGtaNk4Z1a+pqiIg0GrUAioiIiGSYlAsAzewEM1tsZkvNbEpT10dERESkuUmpANDMfMDdwCRgCHCOmQ1p2lqJiIiINC8pFQACo4Glzrllzrly4CnglCauk4iIiEizkmoBYHdgdcj+Gq8syMwuNbOZZjazuLi4USsnIiIi0hykWgAYl3PufufcKOfcqI4dOzZ1dURERETSTqoFgGuBniH7PbwyEREREWkgqRYAfg4MMLM+ZpYLnA283MR1EhEREWlWUioRtHOu0swuA94EfMBDzrn5TVwtERERkWYlpQJAAOfca8BrTV0PERERkeYq1bqARURERCTJFACKiIiIZBhzzjV1HfaamRUDKxvpx3UANjXSz5K9p/uUHnSf0oPuU3rQfUoPTXWfejnnauXNS+sAsDGZ2Uzn3KimrofEpvuUHnSf0oPuU3rQfUoPqXaf1AUsIiIikmEUAIqIiIhkGAWAibu/qSsgCdF9Sg+6T+lB9yk96D6lh5S6TxoDKCIiIpJh1AIoIiIikmEUAIqIiIhkGAWAcZjZCWa22MyWmtmUpq5PpjGzh8xso5l9FVLWzsymmtkS77mtV25mdod3r+aa2ciQay70zl9iZhc2xXtpzsysp5m9a2YLzGy+mV3uletepRAzyzezGWY2x7tPf/DK+5jZZ979eNrMcr3yPG9/qXe8d8hrXe2VLzaz45vmHTVvZuYzsy/N7BVvX/cpxZjZCjObZ2azzWymV5Yen3vOOT3qeAA+4BugL5ALzAGGNHW9MukBjAdGAl+FlN0GTPG2pwB/9rZPBF4HDBgDfOaVtwOWec9tve22Tf3emtMD6AqM9LZbAl8DQ3SvUuvh/XsXeds5wGfev/8zwNle+X3AT73tnwH3edtnA09720O8z8M8oI/3Oelr6vfX3B7AVcCTwCvevu5Tij2AFUCHiLK0+NxTC2Bso4Glzrllzrly4CnglCauU0Zxzn0AbIkoPgV41Nt+FDg1pPwx5zcdaGNmXYHjganOuS3Oua3AVOCE5Nc+czjn1jnnvvC2S4CFQHd0r1KK9++909vN8R4OOBp4ziuPvE+B+/ccMNHMzCt/yjlX5pxbDizF/3kpDcTMegCTgQe8fUP3KV2kxeeeAsDYugOrQ/bXeGXStDo759Z52+uBzt52XfdL97ERed1PI/C3LulepRivW3E2sBH/F803wDbnXKV3Sui/efB+eMe3A+3RfWoM/wB+A1R7++3RfUpFDnjLzGaZ2aVeWVp87mUn+weIJJNzzpmZchmlCDMrAv4LXOGc2+FvhPDTvUoNzrkq4CAzawO8AAxu4ipJBDM7CdjonJtlZkc1dX0kpnHOubVm1gmYamaLQg+m8ueeWgBjWwv0DNnv4ZVJ09rgNZvjPW/0yuu6X7qPjcDMcvAHf0845573inWvUpRzbhvwLnAY/q6oQINA6L958H54x1sDm9F9SrbDgZPNbAX+oUdHA/9E9ynlOOfWes8b8f9BNZo0+dxTABjb58AAb+ZVLv7BtS83cZ3Efw8Cs6QuBF4KKb/Am2k1BtjuNcO/CRxnZm292VjHeWXSQLzxRg8CC51zt4cc0r1KIWbW0Wv5w8xaAMfiH6/5LnCmd1rkfQrcvzOBac4/av1l4Gxv9mkfYAAwo3HeRfPnnLvaOdfDOdcb//fONOfc99F9SilmVmhmLQPb+D+vviJdPveaYtZMOj3wz9r5Gv84mWubuj6Z9gD+A6wDKvCPi7gE/9iWd4AlwNtAO+9cA+727tU8YFTI61yMfwD0UuCipn5fze0BjMM/FmYuMNt7nKh7lVoPYBjwpXefvgJ+55X3xR8YLAWeBfK88nxvf6l3vG/Ia13r3b/FwKSmfm/N9QEcRc0sYN2nFHp492OO95gfiBHS5XNPS8GJiIiIZBh1AYuIiIhkGAWAIiIiIhlGAaCIiIhIhlEAKCIiIpJhFACKiIiIZBitBCIiEoOZVeFP2ZADVAKPAX93zlXHvFBEJIUpABQRiW2Pc+4gAG+5pyeBVsDvm7RWIiL7QF3AIiIJcv7lni4FLvOy+fc2sw/N7AvvMRbAzB4zs1MD15nZE2Z2ipkdYGYzzGy2mc01swFN9V5EJLMpEbSISAxmttM5VxRRtg0YBJQA1c65Ui+Y+49zbpSZHQlc6Zw71cxa418ZZQDwd2C6c+4Jb3lJn3NuT+O+IxERdQGLiOyLHOAuMzsIqAIGAjjn3jeze8ysI3AG8F/nXKWZfQpca2Y9gOedc0uarOYiktHUBSwiUg9m1hd/sLcRuBLYAAwHRgG5Iac+BpwHXAQ8BOCcexI4GdgDvGZmRzdezUVEaqgFUEQkQV6L3n3AXc4553XvrnHOVZvZhYAv5PRHgBnAeufcAu/6vsAy59wdZrYfMAyY1qhvQkQEBYAiIvG0MLPZ1KSBeRy43Tt2D/BfM7sAeAPYFbjIObfBzBYCL4a81neB882sAlgP/KkR6i8iUosmgYiIJIGZFeDPHzjSObe9qesjIhJKYwBFRBqYmR0DLATuVPAnIqlILYAiIiIiGUYtgCIiIiIZRgGgiIiISIZRACgiIiKSYRQAioiIiGQYBYAiIiIiGeb/A6jCTFpuNt3lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Adjusted Daily Closing Price with respect to time.\n",
    "days = list(range(len(df)))\n",
    "\n",
    "fig, ax = plt.subplots(len(tickers), 1, figsize=(9, 20), tight_layout=True)\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    t = tickers[i]\n",
    "    adj_close_t = df.sort_values(by='timestamp', ascending=True)['_'.join(['adjusted_close', t])].tolist()\n",
    "    \n",
    "    ax[i].plot(days, adj_close_t)\n",
    "    ax[i].set_title('Adjusted Daily Closing Price for {}'.format(t))\n",
    "    ax[i].set_xlabel('Days')\n",
    "    ax[i].set_ylabel('Adjusted Daily Closing Price')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is an upward trend in all 4 stocks initially until about day 2300, then a sharp almost instaneous downward trend, followed by a slow upward trend until day 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5031.000000\n",
      "mean       28.466109\n",
      "std        13.482288\n",
      "min         6.276300\n",
      "25%        18.580600\n",
      "50%        23.314900\n",
      "75%        43.126300\n",
      "max        62.175200\n",
      "Name: adjusted_close_WFC, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5031.000000\n",
      "mean       42.769751\n",
      "std        26.031430\n",
      "min         9.534400\n",
      "25%        26.027500\n",
      "50%        32.438100\n",
      "75%        51.375000\n",
      "max       124.790000\n",
      "Name: adjusted_close_JPM, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5031.000000\n",
      "mean       21.351440\n",
      "std         9.760418\n",
      "min         2.831100\n",
      "25%        13.766300\n",
      "50%        19.427200\n",
      "75%        28.884400\n",
      "max        43.195000\n",
      "Name: adjusted_close_BAC, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5031.000000\n",
      "mean      174.771051\n",
      "std       149.176072\n",
      "min         9.480500\n",
      "25%        44.343800\n",
      "50%        68.622900\n",
      "75%       333.506650\n",
      "max       474.080800\n",
      "Name: adjusted_close_C, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plotting the distribution of Adjusted Daily Closing Prices\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    data = df['_'.join(['adjusted_close', tickers[i]])]\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.hist(data.tolist(), bins=500)\n",
    "    ax.set_title('Sample Distribution of Adjusted Daily Closing Prices for {}'.format(tickers[i]))\n",
    "    ax.set_xlabel('Adjusted Daily Closing Prices')\n",
    "    ax.set_ylabel('Counts')\n",
    "    plt.show()\n",
    "    print('Statistics for Above Distribution')\n",
    "    print(data.describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of Adjusted Daily Closing Prices appears log-normal which is the distribution type that prices should approximately follow in theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the log adjusted closing prices, and log adjusted daily returns\n",
    "\n",
    "for t in tickers:\n",
    "    df['_'.join(['log_adj_close', t])] = np.log(df['_'.join(['adjusted_close', t])])\n",
    "    df['_'.join(['log_adj_daily_returns', t])] = df['_'.join(['log_adj_close', t])].shift(1) - df['_'.join(['log_adj_close', t])]\n",
    "    df = df.dropna(subset=['_'.join(['log_adj_daily_returns', t])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calculating the log of Adjusted Daily Closing Price as well as the difference between the logs of Adjusted Daily Closing Price because if Adjusted Daily Closing Price is log-normal distributed, then the distributions of these values should be normally distributed. This is because the log of a log-normally distributed variable should be normally distributed, and the sum (or difference) of independently normally distributed variables should also be normally distributed. (We are assuming each Adjusted Daily Closing Price is independently distributed from others, which is approximately true.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        3.238465\n",
      "std         0.467642\n",
      "min         1.836781\n",
      "25%         2.921639\n",
      "50%         3.148505\n",
      "75%         3.763072\n",
      "max         4.129956\n",
      "Name: log_adj_close_WFC, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        3.607864\n",
      "std         0.517362\n",
      "min         2.254906\n",
      "25%         3.259085\n",
      "50%         3.478967\n",
      "75%         3.938404\n",
      "max         4.787158\n",
      "Name: log_adj_close_JPM, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        2.944008\n",
      "std         0.505067\n",
      "min         1.040665\n",
      "25%         2.622216\n",
      "50%         2.962227\n",
      "75%         3.362836\n",
      "max         3.765725\n",
      "Name: log_adj_close_BAC, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        4.692818\n",
      "std         1.019300\n",
      "min         2.249237\n",
      "25%         3.791923\n",
      "50%         4.228532\n",
      "75%         5.809912\n",
      "max         6.161378\n",
      "Name: log_adj_close_C, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plotting the distribution of Log Adjusted Daily Closing Price\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    data = df['_'.join(['log_adj_close', tickers[i]])]\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.hist(data.tolist(), bins=500)\n",
    "    ax.set_title('Sample Distribution of Log Adjusted Daily Closing Price for {}'.format(tickers[i]))\n",
    "    ax.set_xlabel('Log Adjusted Daily Closing Price')\n",
    "    ax.set_ylabel('Counts')\n",
    "    plt.show()\n",
    "    print('Statistics for Above Distribution')\n",
    "    print(data.describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        0.000269\n",
      "std         0.023491\n",
      "min        -0.272103\n",
      "25%        -0.007963\n",
      "50%         0.000152\n",
      "75%         0.008262\n",
      "max         0.283404\n",
      "Name: log_adj_daily_returns_WFC, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        0.000284\n",
      "std         0.024241\n",
      "min        -0.232277\n",
      "25%        -0.008984\n",
      "50%         0.000175\n",
      "75%         0.009647\n",
      "max         0.223916\n",
      "Name: log_adj_daily_returns_JPM, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean        0.000112\n",
      "std         0.028746\n",
      "min        -0.342067\n",
      "25%        -0.009586\n",
      "50%         0.000215\n",
      "75%         0.009974\n",
      "max         0.302101\n",
      "Name: log_adj_daily_returns_BAC, dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Above Distribution\n",
      "count    5027.000000\n",
      "mean       -0.000241\n",
      "std         0.030368\n",
      "min        -0.494698\n",
      "25%        -0.009880\n",
      "50%         0.000000\n",
      "75%         0.010000\n",
      "max         0.456316\n",
      "Name: log_adj_daily_returns_C, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plotting the distribution of Log Adjusted Daily Returns\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    data = df['_'.join(['log_adj_daily_returns', tickers[i]])]\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.hist(data.tolist(), bins=500)\n",
    "    ax.set_title('Sample Distribution of Log Adjusted Daily Returns for {}'.format(tickers[i]))\n",
    "    ax.set_xlabel('Log Adjusted Daily Returns')\n",
    "    ax.set_ylabel('Counts')\n",
    "    plt.show()\n",
    "    print('Statistics for Above Distribution')\n",
    "    print(data.describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the distribution of log Adjusted Daily Closing Price doesn't appear to be too normal, the distribution of Log Adjusted Daily Returns appears to visually fit a normal distribution well. Therefore we are probably safe in make our assumptions about log-normal prices, and independently distributed prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Adjusted Daily Returns with respect to time\n",
    "\n",
    "days = list(range(len(df)))\n",
    "fig, ax = plt.subplots(len(tickers), 1, figsize=(9, 20), tight_layout=True)\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    log_adj_close_t = df.sort_values(by='timestamp', ascending=True)['_'.join(['log_adj_close', tickers[i]])].tolist()\n",
    "    ax[i].plot(days, log_adj_close_t)\n",
    "    ax[i].set_title('Log Adjusted Daily Closing Price for {}'.format(tickers[i]))\n",
    "    ax[i].set_xlabel('Days')\n",
    "    ax[i].set_ylabel('Log Adjusted Daily Closing Price')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Adjusted Daily Returns with respect to time\n",
    "days = list(range(len(df)))\n",
    "fig, ax = plt.subplots(len(tickers), 1, figsize=(9, 20), tight_layout=True)\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    log_adj_daily_returns_t = df.sort_values(by='timestamp', ascending=True)['_'.join(['log_adj_daily_returns', tickers[i]])].tolist()\n",
    "    ax[i].plot(days, log_adj_daily_returns_t)\n",
    "    ax[i].set_title('Log Adjusted Daily Returns for {}'.format(tickers[i]))\n",
    "    ax[i].set_xlabel('Days')\n",
    "    ax[i].set_ylabel('Log Adjusted Daily Returns')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series of log Adjusted Daily Closing Price appears similar to the time series of Adjusted Daily Closing Price. This is as expected and not unusual because we are just taking a log a variable and thus the overall shape of the graph should not be affected. On the other hand the time series of log Adjusted Daily Returns appears to fluctuate about zero where the magnitude of the fluctuation does not change too much except for at a few pivitol days. This makes sense with respect to its Gaussian distribution, because the Gaussian distribution alots small probabilities to large magnitudes of log Adjusted Daily Return which means there should not be too many days where we see a huge value for log Adjusted Daily Return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Distribution\n",
      "count    20108.000000\n",
      "mean         0.000106\n",
      "std          0.026869\n",
      "min         -0.494698\n",
      "25%         -0.009072\n",
      "50%          0.000000\n",
      "75%          0.009399\n",
      "max          0.456316\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Plotting the distribution of Log Adjusted Daily Returns for all Tickers\n",
    "\n",
    "data = []\n",
    "for i in range(len(tickers)):\n",
    "    data = data + df['_'.join(['log_adj_daily_returns', tickers[i]])].tolist()\n",
    "data = pd.Series(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "ax.hist(data.tolist(), bins=500)\n",
    "ax.set_title('Sample Distribution of Log Adjusted Daily Returns for all tickers')\n",
    "ax.set_xlabel('Log Adjusted Daily Returns')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()\n",
    "print('Statistics for Distribution')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will check are the lengths of our raw documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing doc_lengths: a list of lengths of all 8-K forms before they are normalized\n",
    "doc_lengths_paths_dict = {}\n",
    "\n",
    "for t in [ticker] + competitors:\n",
    "    t_docs_path = os.path.join(path_to_docs, t)\n",
    "    t_doclist = os.listdir(t_docs_path)\n",
    "    if 'normalized' in t_doclist:\n",
    "        t_doclist.remove('normalized')\n",
    "    for doc_name in t_doclist:\n",
    "        doc_path = os.path.join(t_docs_path, doc_name)\n",
    "        with open(doc_path, 'r') as f:\n",
    "            raw_doc_text = f.read()\n",
    "        doc_lengths_paths_dict[len(raw_doc_text)] = doc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest document has: 125997383 charcters\n",
      "Smallest document has: 3548 charcters\n"
     ]
    }
   ],
   "source": [
    "print(\"Largest document has: {} charcters\".format(max(doc_lengths_paths_dict.keys())))\n",
    "print(\"Smallest document has: {} charcters\".format(min(doc_lengths_paths_dict.keys())))\n",
    "largest_doc_path = doc_lengths_paths_dict[max(doc_lengths_paths_dict.keys())]\n",
    "smallest_doc_path = doc_lengths_paths_dict[min(doc_lengths_paths_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(doc_lengths_paths_dict.keys(), bins=50)\n",
    "ax.set_title('Document Lengths Histogram')\n",
    "ax.set_xlabel('Length of Document')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(doc_lengths_paths_dict.keys(), bins=50, log=True)\n",
    "ax.set_title('Document Lengths Histogram Log Scale')\n",
    "ax.set_xlabel('Length of Document')\n",
    "ax.set_ylabel('Log Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above histograms, it appears very few of our documents contain over 30 million characters. Most of our documents seem to have 10 million characters or less with a large emphasize on documents with less than 1 million characters. Since a single characters is about 1 byte in memory, our largest document should be about 125 MB. Therefore we should expect all of our documents to be able to fit into our RAM of 32 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess our text data, we will first strip it of its x/html tags if the data is encoded this way. Next we will un accent its accented characters, lower case the entire document, and replace all newline/carriage returns with spaces. Next we will strip it of its characters that are not alphanumeric, periods, dollar symbols, or percent symbols. Afterwards we will reduce all words to their dictionary lemmas, and strip the document of its stop words (see stop word list for spacy en_cor_web_sm model). Finally we will replace all whitespace characters with regular space characters, and drop words that are longer in length than a certian cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of our 8-K filing document involves an xml SEC document header packed with metadata about the filing, and one or multiple xml `<DOCUMENT>` tags. These `<DOCUMENT>` tags contain different types of data that are bundled up into the complete submission for the 8-K filing. The data types stored in these `<DOCUMENT>` tags can range from everything including: regular text data such as html, to binary blob data such as jpg images and pdfs. The structure of these `<DOCUMENT>` tags involve a few meta data tags, none of which involve specifying the encoding type of the data that `<DOCUMENT>` tag stores, and a `<TEXT>` tag that stores the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the inclusion of binary blobs in the markdown prevents easy parsing of the filing structure with lxml, we will result to python re statements to extract the relevant `<DOCUMENT>` tags. Though because the meta data tags enclosed in a `<DOCUMENT>` tag do not specify the encoding type of the data enclosed in the `<TEXT>` tag, there does not appear to be an easy quick general solution that extracts the text data `<DOCUMENT>` tags and avoids the binary blob like `<DOCUMENT>` tags. Because of the above issues we will have to suffice ourselves with extracting only the `<DOCUMENT>` tag that contain's the meta data open tag `<TYPE>8-K`. This specific `<DOCUMENT>` tag always contains text data, and represents the data that is used to generate the SEC 8-K form containing the information that is mandated by the SEC, and excluding the exhibit information that is not mandated by the SEC and is given by the company's discretion. Since this `<DOCUMENT>` tag contains all the mandated information by the SEC for a given 8-K filing, we are still extracting the important information bundled in the filing even though we are not extracting all of the textual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining Functions and Classes\n",
    "\n",
    "def extract_8k(doc):\n",
    "    eight_k = re.findall('<DOCUMENT>\\n<TYPE>8-K.*?<SEQUENCE>1(.*?)</DOCUMENT>', doc, re.DOTALL | re.IGNORECASE)\n",
    "    text = re.findall('<TEXT>(.*?)</TEXT>', eight_k[0], re.DOTALL | re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def extract_html(doc):\n",
    "    html = re.findall('<HTML(?:>| .*?>).*?</HTML>', doc, re.DOTALL | re.IGNORECASE)\n",
    "    return html\n",
    "\n",
    "def strip_tags(doc):\n",
    "    # extracting 8-K <DOCUMENT> tag from the filing\n",
    "    eight_k = extract_8k(doc)\n",
    "    assert len(eight_k) == 1, 'Check re for 8-K extraction, either multiple 8-K DOCUMENT tags or bad re'\n",
    "    \n",
    "    # extracting <html> tag if any\n",
    "    html = extract_html(eight_k[0])\n",
    "    assert 0 <= len(html) <= 1, 'Check re for extracting html tags'\n",
    "    \n",
    "    # if html exists\n",
    "    if len(html) == 1:\n",
    "        html = html[0]\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        stripped = soup.get_text()\n",
    "    else:\n",
    "        soup = BeautifulSoup(eight_k[0], 'lxml')\n",
    "        stripped = soup.get_text()\n",
    "    \n",
    "    return stripped\n",
    "\n",
    "def strip_accented_chars(doc):\n",
    "    doc = unicodedata.normalize('NFKD', doc).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return doc\n",
    "\n",
    "def strip_special_chars(doc):\n",
    "    doc = re.sub('[^$A-Za-z0-9%\\s.\\']', '', doc)\n",
    "    return doc\n",
    "\n",
    "def lemmatize(doc):\n",
    "    document = nlp(doc)\n",
    "    doc = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in document])\n",
    "    return doc\n",
    "\n",
    "def strip_stop_words(doc):\n",
    "    document = nlp(doc)\n",
    "    doc = ' '.join([word.text for word in document if not word.is_stop])\n",
    "    return doc\n",
    "\n",
    "def strip_large_words(doc, cut_off=20):\n",
    "    return ' '.join([word for word in doc.split() if len(word) <= cut_off])\n",
    "\n",
    "def normalize_document(doc, tags_strip=True, accent_char_strip=True, lower_case=True,\n",
    "                       no_newlines=True, special_char_strip=True, space_nums=True,\n",
    "                       lemmatize_words=True, remove_stop_words=True, strip_extra_spaces=True,\n",
    "                       remove_large_words=False, debug=False):\n",
    "    '''\n",
    "    Preprocesses the document :param doc: and returns the normalized document.\n",
    "    \n",
    "    :param doc: string, document to normalize\n",
    "    :param xml_strip: bool, set to True to strip the xml tags\n",
    "    :param accent_char_strip: bool, set to True to replace accented characters with their non accented versions\n",
    "    :param lower_case: bool, set to True to lower case the document.\n",
    "    :param no_newlines: bool, set to True to remove all newlines characters and replace them with spaces\n",
    "    :param special_char_strip: bool, set to True to remove all characters that are \n",
    "                                     not letters, numbers, $, ., %, or spaces\n",
    "    :param lemmatize_words: bool, set to True to map each word to its lemma\n",
    "    :param remove_stop_words: bool, set to True to remove stop words\n",
    "    :param strip_extra_spaces: bool, set to True to replace multiple spaces with one\n",
    "    :param remove_large_words: int, set to the integer cutoff where words larger than :param remove_large_words:\n",
    "                               are removed from the text. Set to False if there is no cutoff\n",
    "    \n",
    "    ---> string, normalized document\n",
    "    '''\n",
    "    if debug:\n",
    "        print('raw length of doc: {}'.format(len(doc)))\n",
    "        \n",
    "    # stripping tags\n",
    "    if tags_strip:\n",
    "        doc = strip_tags(doc)\n",
    "    if debug:\n",
    "        print('stripped tag length: {}'.format(len(doc)))\n",
    "    \n",
    "    # stripping accented characters\n",
    "    if accent_char_strip:\n",
    "        doc = strip_accented_chars(doc)\n",
    "    if debug:\n",
    "        print('altered accents length: {}'.format(len(doc)))\n",
    "        \n",
    "    # lower casing the document\n",
    "    if lower_case:\n",
    "        doc = doc.lower()\n",
    "    if debug:\n",
    "        print('lower casing length: {}'.format(len(doc)))\n",
    "    \n",
    "    # removing new lines and carriage returns and replacing them with spaces\n",
    "    if no_newlines:\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ', doc)\n",
    "    if debug:\n",
    "        print('removing newlines length: {}'.format(len(doc)))\n",
    "    \n",
    "    # removing special characters\n",
    "    if special_char_strip:\n",
    "        doc = strip_special_chars(doc)\n",
    "    if debug:\n",
    "        print('strip special char length: {}'.format(len(doc)))\n",
    "    \n",
    "    # lemmatizing the words\n",
    "    if lemmatize_words:\n",
    "        doc = lemmatize(doc)\n",
    "    if debug:\n",
    "        print('lemmatized doc length: {}'.format(len(doc)))\n",
    "    \n",
    "    # stripping stop words\n",
    "    if remove_stop_words:\n",
    "        doc = strip_stop_words(doc)\n",
    "    if debug:\n",
    "        print('removed stop word length: {}'.format(len(doc)))\n",
    "    \n",
    "    # adding spaces in between numbers and remaining special characters\n",
    "    if space_nums:\n",
    "        doc = re.sub(r'([\\d$%.])', r' \\1 ', doc)\n",
    "    if debug:\n",
    "        print('spaced num char length: {}'.format(len(doc)))\n",
    "        \n",
    "    # Removing large words\n",
    "    if remove_large_words:\n",
    "        doc = strip_large_words(doc, cut_off=remove_large_words)\n",
    "    if debug:\n",
    "        print('large words removed char length: {}'.format(len(doc)))\n",
    "        \n",
    "    # removing extra whitespace\n",
    "    if strip_extra_spaces:\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "    if debug:\n",
    "        print('removed extra space length: {}'.format(len(doc)))\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will need to confirm is if the re's we constructed for extracting a documents 8-K component, and the html tag (if they exist) works/still works. For the time being the data we will use from each document will only be the text embedded in the 8-K component of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The re in extract_8k seems to checkout.\n"
     ]
    }
   ],
   "source": [
    "# Checking the extract_8k function\n",
    "checksout = True\n",
    "for t in [ticker] + competitors:\n",
    "    t_docs_path = os.path.join(path_to_docs, t)\n",
    "    t_doclist = os.listdir(t_docs_path)\n",
    "    if 'normalized' in t_doclist:\n",
    "        t_doclist.remove('normalized')\n",
    "    for doc_name in t_doclist:\n",
    "        doc_path = os.path.join(t_docs_path, doc_name)\n",
    "        with open(doc_path, 'r') as f:\n",
    "            raw_doc_text = f.read()\n",
    "        num_of_8k = len(extract_8k(raw_doc_text))\n",
    "        if num_of_8k != 1:\n",
    "            checksout = False\n",
    "            print('Filing: {0}, contains: {1} 8-K portions, check re of extract_8k, and document.'.format(doc_path, num_of_8k))\n",
    "\n",
    "if checksout:\n",
    "    print('The re in extract_8k seems to checkout.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The re in extract_html seems to checkout.\n"
     ]
    }
   ],
   "source": [
    "# Checking the extract_html function\n",
    "checksout = True\n",
    "for t in [ticker] + competitors:\n",
    "    t_docs_path = os.path.join(path_to_docs, t)\n",
    "    t_doclist = os.listdir(t_docs_path)\n",
    "    if 'normalized' in t_doclist:\n",
    "        t_doclist.remove('normalized')\n",
    "    for doc_name in t_doclist:\n",
    "        doc_path = os.path.join(t_docs_path, doc_name)\n",
    "        with open(doc_path, 'r') as f:\n",
    "            raw_doc_text = f.read()\n",
    "        eight_k = extract_8k(raw_doc_text)[0]\n",
    "        num_html_tags = len(extract_html(eight_k))\n",
    "        if not (0 <= num_html_tags <= 1):\n",
    "            checksout = False\n",
    "            print('Filing: {0}, contains: {1} html tags, check re of extract_html, and document.'.format(doc_path, num_html_tags))\n",
    "\n",
    "if checksout:\n",
    "    print('The re in extract_html seems to checkout.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each 8-K filing there should be only one `<DOCUMENT>...</DOCUMENT>` tag that contains a:`<TYPE>8-K` tag. There should also be ONLY one `<html ...>...</html>` tag if the document tag contains an html tag. The above cells verify if any of these conditions are violated on the current dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we will investigate are the lengths of our normalized texts with no word length cut offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing norm_doc_lengths: a list of lengths of Intel's 8-K forms after they are normalized\n",
    "norm_doc_lengths_paths_dict = {}\n",
    "\n",
    "for t in [ticker] + competitors:\n",
    "    t_docs_path = os.path.join(path_to_docs, t)\n",
    "    t_doclist = os.listdir(t_docs_path)\n",
    "    if 'normalized' in t_doclist:\n",
    "        t_doclist.remove('normalized')    \n",
    "    for doc_name in t_doclist:\n",
    "        doc_path = os.path.join(t_docs_path, doc_name)\n",
    "        with open(doc_path, 'r') as f:\n",
    "            raw_doc_text = f.read()\n",
    "        norm_doc = normalize_document(raw_doc_text)\n",
    "        norm_doc_lengths_paths_dict[len(norm_doc)] = doc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest document has: 610674 charcters\n",
      "Smallest document has: 947 charcters\n"
     ]
    }
   ],
   "source": [
    "print(\"Largest document has: {} charcters\".format(max(norm_doc_lengths_paths_dict.keys())))\n",
    "print(\"Smallest document has: {} charcters\".format(min(norm_doc_lengths_paths_dict.keys())))\n",
    "largest_norm_doc_path = norm_doc_lengths_paths_dict[max(norm_doc_lengths_paths_dict.keys())]\n",
    "smallest_norm_doc_path = norm_doc_lengths_paths_dict[min(norm_doc_lengths_paths_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(norm_doc_lengths_paths_dict.keys(), bins=100)\n",
    "ax.set_title('Normalized Document Lengths Histogram')\n",
    "ax.set_xlabel('Length of Document')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(norm_doc_lengths_paths_dict.keys(), bins=100, log=True)\n",
    "ax.set_title('Normalized Document Lengths Histogram Log Scale')\n",
    "ax.set_xlabel('Length of Document')\n",
    "ax.set_ylabel('Log Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Nothing seems to stand out in these histograms so far. The next things we will check are the documents that correspond to the extremums of our histograms just to see if anything stands out about these normalized documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw length of doc: 78927377\n",
      "stripped tag length: 731646\n",
      "altered accents length: 728747\n",
      "lower casing length: 728747\n",
      "removing newlines length: 728742\n",
      "strip special char length: 705357\n",
      "lemmatized doc length: 686438\n",
      "removed stop word length: 559678\n",
      "spaced num char length: 708948\n",
      "large words removed char length: 708948\n",
      "removed extra space length: 610674\n",
      "\n",
      "/media/Data/Programs/FinTech/data/documents/JPM/0000019617-11-000266.txt\n",
      "\n",
      " exhibit 9 9 2 q 1 1 1 0 q item 1 2 exhibit 9 9 jpmorgan chase co . consolidate financial highlight unaudite million share headcount ratio datum month end june 3 0 as period end 2 q 1 1 1 q 1 1 4 q 1 0 3 q 1 0 2 q 1 0 2 0 1 1 2 0 1 0 selected income statement datum total net revenue $ 2 6 7 7 9 $ 2 5 2 2 1 $ 2 6 0 9 8 $ 2 3 8 2 4 $ 2 5 1 0 1 $ 5 2 0 0 0 $ 5 2 7 7 2 total noninter expense 1 6 8 4 2 1 5 9 9 5 1 6 0 4 3 1 4 3 9 8 1 4 6 3 1 3 2 8 3 7 3 0 7 5 5 preprovision profita 9 9 3 7 9 2 2 6 1 0 0 5 5 9 4 2 6 1 0 4 7 0 1 9 1 6 3 2 2 0 1 7 provision credit loss 1 8 1 0 1 1 6 9 3 0 4 3 3 2 2 3 3 3 6 3 2 9 7 9 1 0 3 7 3 income income tax expense 8 1 2 7 8 0 5 7 7 0 1 2 6 2 0 3 7 1 0 7 1 6 1 8 4 1 1 6 4 4 income tax expense 2 6 9 6 2 5 0 2 2 1 8 1 1 7 8 5 2 3 1 2 5 1 9 8 3 5 2 3 net income $ 5 4 3 1 $ 5 5 5 5 $ 4 8 3 1 $ 4 4 1 8 $ 4 7 9 5 $ 1 0 9 8 6 $ 8 1 2 1 per common share data net income share basic $ 1 . 2 8 $ 1 . 2 9 $ 1 . 1 3 $ 1 . 0 2 $ 1 . 1 0 $ 2 . 5 7 $ 1 . 8 4 diluted 1 . 2 7 1 . 2 8 1 . 1 2 1 . 0 1 1 . 0 9 2 . 5 5 1 . 8 3 cash dividend declare shareb 0 . 2 5 0 . 2 5 0 . 0 5 0 . 0 5 0 . 0 5 0 . 5 0 0 . 1 0 book value share 4 4 . 7 7 4 3 . 3 4 4 3 . 0 4 4 2 . 2 9 4 0 . 9 9 4 4 . 7 7 4 0 . 9 9 common share outstanding average basic 3 9 5 8 . 4 3 9 8 1 . 6 3 9 1 7 . 0 3 9 5 4 . 3 3 9 8 3 . 5 3 9 7 0 . 0 3 9 7 7 . 0 diluted 3 9 8 3 . 2 4 0 1 4 . 1 3 9 3 5 . 2 3 9 7 1 . 9 4 0 0 5 . 6 3 9 9 8 . 6 4 0 0 0 . 2 common share periodend 3 9 1 0 . 2 3 9 8 6 . 6 3 9 1 0 . 3 3 9 2 5 . 8 3 9 7 5 . 8 3 9 1 0 . 2 3 9 7 5 . 8 share pricec high $ 4 7 . 8 0 $ 4 8 . 3 6 $ 4 3 . 1 2 $ 4 1 . 7 0 $ 4 8 . 2 0 $ 4 8 . 3 6 $ 4 8 . 2 0 low 3 9 . 2 4 4 2 . 6 5 3 6 . 2 1 3 5 . 1 6 3 6 . 5 1 3 9 . 2 4 3 6 . 5 1 close 4 0 . 9 4 4 6 . 1 0 4 2 . 4 2 3 8 . 0 6 3 6 . 6 1 4 0 . 9 4 3 6 . 6 1 market capitalization 1 6 0 0 8 3 1 8 3 7 8 3 1 6 5 8 7 5 1 4 9 4 1 8 1 4 5 5 5 4 1 6 0 0 8 3 1 4 5 5 5 4 selected ratio return common equity roe 1 2 % 1 3 % 1 1 % 1 0 % 1 2 % 1 3 % 1 0 % return tangible common equity rotce 1 7 1 8 1 6 1 5 1 7 1 8 1 5 return asset roa 0 . 9 9 1 . 0 7 0 . 9 2 0 . 8 6 0 . 9 4 1 . 0 3 0 . 8 0 overhead ratio 6 3 6 3 6 1 6 0 5 8 6 3 5 8 depositstoloans ratio 1 5 2 1 4 5 1 3 4 1 3 1 1 2 7 1 5 2 1 2 7 tier 1 capital ratio 1 2 . 4 1 2 . 3 1 2 . 1 1 1 . 9 1 2 . 1 total capital ratio 1 5 . 7 1 5 . 6 1 5 . 5 1 5 . 4 1 5 . 8 tier 1 leverage ratio 7 . 0 7 . 2 7 . 0 7 . 1 6 . 9 tier 1 common capital ratiod 1 0 . 1 1 0 . 0 9 . 8 9 . 5 9 . 6 select balance sheet data periodende trading asset $ 4 5 8 7 2 2 $ 5 0 1 1 4 8 $ 4 8 9 8 9 2 $ 4 7 5 5 1 5 $ 3 9 7 5 0 8 $ 4 5 8 7 2 2 $ 3 9 7 5 0 8 securities 3 2 4 7 4 1 3 3 4 8 0 0 3 1 6 3 3 6 3 4 0 1 6 8 3 1 2 0 1 3 3 2 4 7 4 1 3 1 2 0 1 3 loan 6 8 9 7 3 6 6 8 5 9 9 6 6 9 2 9 2 7 6 9 0 5 3 1 6 9 9 4 8 3 6 8 9 7 3 6 6 9 9 4 8 3 total asset 2 2 4 6 7 6 4 2 1 9 8 1 6 1 2 1 1 7 6 0 5 2 1 4 1 5 9 5 2 0 1 4 0 1 9 2 2 4 6 7 6 4 2 0 1 4 0 1 9 deposits 1 0 4 8 6 8 5 9 9 5 8 2 9 9 3 0 3 6 9 9 0 3 1 3 8 8 8 7 8 0 5 1 0 4 8 6 8 5 8 8 7 8 0 5 longterm debte 2 7 9 2 2 8 2 6 9 6 1 6 2 7 0 6 5 3 2 7 1 4 9 5 2 6 0 4 4 2 2 7 9 2 2 8 2 6 0 4 4 2 common stockholder equity 1 7 5 0 7 9 1 7 2 7 9 8 1 6 8 3 0 6 1 6 6 0 3 0 1 6 2 9 6 8 1 7 5 0 7 9 1 6 2 9 6 8 total stockholder ' equity 1 8 2 8 7 9 1 8 0 5 9 8 1 7 6 1 0 6 1 7 3 8 3 0 1 7 1 1 2 0 1 8 2 8 7 9 1 7 1 1 2 0 headcount 2 5 0 0 9 5 2 4 2 9 2 9 2 3 9 8 3 1 2 3 6 8 1 0 2 3 2 9 3 9 2 5 0 0 9 5 2 3 2 9 3 9 credit quality metric allowance credit loss $ 2 9 1 4 6 $ 3 0 4 3 8 $ 3 2 9 8 3 $ 3 5 0 3 4 $ 3 6 7 4 8 $ 2 9 1 4 6 $ 3 6 7 4 8 allowance loan loss total retained loan 4 . 1 6 % 4 . 4 0 % 4 . 7 1 % 4 . 9 7 % 5 . 1 5 % 4 . 1 6 % 5 . 1 5 % allowance loan loss retain loan exclude purchase creditimpaire loansf 3 . 8 3 4 . 1 0 4 . 4 6 5 . 1 2 5 . 3 4 3 . 8 3 5 . 3 4 nonperforming asset $ 1 3 2 4 0 $ 1 4 9 8 6 $ 1 6 5 5 7 $ 1 7 6 5 6 $ 1 8 1 5 6 $ 1 3 2 4 0 $ 1 8 1 5 6 net chargeoffsg 3 1 0 3 3 7 2 0 5 1 0 4 4 9 4 5 5 7 1 4 6 8 2 3 1 3 6 2 4 net chargeoff rateg 1 . 8 3 % 2 . 2 2 % 2 . 9 5 % 2 . 8 4 % 3 . 2 8 % 2 . 0 2 % 3 . 8 8 % wholesale net chargeoff rate 0 . 1 4 0 . 3 0 0 . 4 9 0 . 4 9 0 . 4 4 0 . 2 1 1 . 1 4 consumer net chargeoff rateg 2 . 7 4 3 . 1 8 4 . 1 2 3 . 9 0 4 . 4 9 2 . 9 6 5 . 0 3 apreprovision profit total net revenue noninterest expense . firm believe financial measure useful assess ability lending institution generate income excess provision credit losses . bon march 1 8 2 0 1 1 board director increase firm quarterly common stock dividend $ 0 . 0 5 $ 0 . 2 5 share . cshare price jpmorgan chase common stock new york stock exchange . jpmorgan chase common stock list trade london stock exchange tokyo stock exchange . dtier 1 common capital ratio tier 1 common ratio tier 1 common divide riskweighte asset . firm use tier 1 common capital tier 1 common capital measure assess monitor capital position . discussion regulatory capital page 5 7 6 0 form 1 0 q . eeffective january 1 2 0 1 1 longterm portion advance federal home loan bank fhlb reclassify borrow fund longterm debt . prior period revise conform current presentation . fexclude impact home lending purchase creditimpaire pci loan . discussion allowance credit loss page 8 6 8 8 form 1 0 q . gnet chargeoff net chargeoff rate fourth quarter 2 0 1 0 include effect $ 6 3 2 million chargeoff relate estimate net realizable value collateral underlie delinquent residential home loan . loss previously recognize provision allowance loan loss adjustment impact firm net income . 3 managements discussion analysisof financial condition result operationsthis section form 1 0 q provide management discussion analysis mda financial condition result operation jpmorgan chase co . jpmorgan chase firm . glossary term page 1 8 6 1 8 9 definition term use form 1 0 q . mda include form 1 0 q contain statement forwardlooke meaning private security litigation reform act 1 9 9 5 . statement base current belief expectation jpmorgan chase management subject significant risk uncertainty . risk uncertainty cause firm actual result differ materially set forth forwardlooking statement . discussion risk uncertainty forwardlooke statement page 9 7 ii item 1 a risk factor page 1 9 2 1 9 3 form 1 0 q item 1 a risk factor page 5 1 2 jpmorgan chase annual report form 1 0 k year end december 3 1 2 0 1 0 file u . s . security exchange commission sec retrospectively revise current report form 8 k file sec november 4 2 0 1 1 2 0 1 0 annual report 2 0 1 0 form 1 0 k reference . reference 2 0 1 0 annual report 2 0 1 0 form 1 0 kin form 8 k firm 2 0 1 0 form 1 0 k retrospectively revise form 8 k file november 4 2 0 1 1 . introductionjpmorgan chase co . financial hold company incorporate delaware law 1 9 6 8 lead global financial service firm large banking institution united state america u . s . $ 2 . 2 trillion asset $ 1 8 2 . 9 billion stockholder equity operation 6 0 country june 3 0 2 0 1 1 . firm leader investment bank financial service consumer small business commercial banking financial transaction processing asset management private equity . j . p . morgan chase brand firm serve million customer u . s . world prominent corporate institutional government client . jpmorgan chase principal bank subsidiary jpmorgan chase bank national association jpmorgan chase bank n . a . national bank branch 2 3 state u . s . chase bank usa national association chase bank usa n . a . national bank firm credit card issue bank . jpmorgan chase principal nonbank subsidiary j . p . morgan security llc jpmorgan securitie firm u . s . investment banking firm . jpmorgan chase activity organize management reporting purpose business segment corporateprivate equity . firm wholesale business comprise investment bank commercial banking treasury security service asset management segment . firm consumer business comprise retail financial service card service auto segment . description firm business segment product service provide respective client basis follow . investment bank j . p . morgan world lead investment bank deep client relationship broad product capability . client investment bank ib corporation financial institution government institutional investor . firm offer range investment banking product service major capital market include advise corporate strategy structure capitalraising equity debt market sophisticated risk management marketmaking cash security derivative instrument prime brokerage research . retail financial service retail financial service rfs serve consumer business personal service bank branch atms online banking telephone banking . customer use 5 3 0 0 bank branch thirdlargest nationally 1 6 4 0 0 atms secondlargest nationally online mobile banking clock . 3 0 9 0 0 branch salesperson assist customer checking saving account mortgage home equity business loan investment 2 3 state footprint new york florida california . card service auto card service auto card nation large credit card issuer $ 1 2 5 billion credit card loan 6 5 million open credit card account exclude commercial card portfolio . month end june 3 0 2 0 1 1 customer use chase credit card exclude commercial card portfolio meet $ 1 6 3 billion spending need . merchant acquire business chase paymentech solution card global leader payment processing merchant acquire . consumer obtain loan 1 6 5 0 0 auto dealership student loan certify 1 9 0 0 school universitie nationwide . commercial banking commercial banking cb deliver extensive industry knowledge local expertise dedicated service nearly 2 5 0 0 0 client nationally include corporation municipality financial institution notforprofit entity annual revenue generally range $ 1 0 million $ 2 billion nearly 3 5 0 0 0 real estate investorsowner . cb partner firm business provide comprehensive solution include lending treasury service investment banking asset management meet client domestic international financial need . 4 treasury security service treasury security service tss global leader transaction investment information service . ts world large cash management provider lead global custodian . treasury service ts provide cash management trade wholesale card liquidity product service small midsized company multinational corporation financial institution government entity . ts partner ib cb rfs asset management business serve client firmwide . certain ts revenue include segment result . worldwide security service hold value clear service security cash alternative investment investor brokerdealer manage depositary receipt program globally . asset management asset management asset supervision $ 1 . 9 trillion global leader investment wealth management . client include institution retail investor highnetworth individual major market world . offer global investment management equity fix income real estate hedge fund private equity liquidity product include moneymarket instrument bank deposit . provide trust estate banking brokerage service highnetworth client retirement service corporation individual . majority ams client asset actively manage portfolio . 5 executive overview executive overview mda highlight select information contain information important reader form 1 0 q . complete description event trend uncertainty capital liquidity credit market risk critical accounting estimate affect firm line business form 1 0 q read entirety . economic environmentthe u . s . economic recovery continue second quarter 2 0 1 1 pace slow major disruption global supply chain auto industry result earthquake tsunami japan sharp rise oil price half year . labor market indicator weak anticipate second quarter struggle housing construction sector remain depressed . household spending business investment equipment software continue expand . promote fast pace economic recovery federal reserve maintain exist policy reinveste principal payment security holding complete purchase $ 6 0 0 billion longerterm treasury security second quarter . federal reserve hold target range federal fund rate zero onequarter percent continue indicate economic condition likely warrant low federal fund rate extended period . financial performance jpmorgan chase month end june 3 0 month end june 3 0 million share datum ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeselected income statement datum total net revenue $ 2 6 7 7 9 $ 2 5 1 0 1 7 % $ 5 2 0 0 0 $ 5 2 7 7 2 1 % total noninter expense 1 6 8 4 2 1 4 6 3 1 1 5 3 2 8 3 7 3 0 7 5 5 7 preprovision profit 9 9 3 7 1 0 4 7 0 5 1 9 1 6 3 2 2 0 1 7 1 3 provision credit losses 1 8 1 0 3 3 6 3 4 6 2 9 7 9 1 0 3 7 3 7 1 net income 5 4 3 1 4 7 9 5 1 3 1 0 9 8 6 8 1 2 1 3 5 diluted earning share 1 . 2 7 1 . 0 9 1 7 2 . 5 5 1 . 8 3 3 9 return common equity 1 2 % 1 2 % 1 3 % 1 0 % capital ratio tier 1 capital 1 2 . 4 1 2 . 1 tier 1 common 1 0 . 1 9 . 6 business overviewjpmorgan chase report secondquarter 2 0 1 1 net income $ 5 . 4 billion $ 1 . 2 7 share net revenue $ 2 6 . 8 billion . net income 1 3 % compare net income $ 4 . 8 billion $ 1 . 0 9 share second quarter 2 0 1 0 . roe quarter 1 2 % unchanged prior year . currentquarter result include $ 1 . 0 billion pretax $ 0 . 1 5 share aftertax benefit reduction allowance loan loss card service auto $ 8 3 7 million pretax $ 0 . 1 2 share aftertax benefit security gain corporate $ 1 . 0 billion pretax $ 0 . 1 5 share aftertax expense estimate cost foreclosurerelated matter retail financial service $ 1 . 3 billion pretax $ 0 . 1 9 share aftertax additional litigation reserve predominantly mortgagerelated matter corporate . the increase net income second quarter 2 0 1 1 drive high net revenue significantly low provision credit loss largely offset high noninterest expense . net revenue growth result high level principal transaction revenue investment banking fee asset management administration commission revenue partially offset low net interest income low security gain . decrease provision credit loss reflect improvement credit environment . increase noninter expense drive high noncompensation expense additional litigation reserve predominantly mortgagerelate matter expense estimate cost foreclosurerelated matters . the firm secondquarter result reflect strong earning solid client flow investment bank record revenue continued loan growth commercial banking solid performance business . consumer business banking retail financial service continue demonstrate good underlying performance rfs overall continue negatively affect high expense mortgagerelate issue include $ 1 . 0 billion expense estimate litigation cost foreclosurerelated matter . result second quarter reflect continued improvement credit trend consumer wholesale portfolio . respect credit card portfolio delinquency net chargeoff improve firm reduce loan loss reserve $ 1 . 0 billion estimate loss decline . respect mortgage portfolio delinquency net chargeoff trend improve modestly compare prior quarter net chargeoff remain high credit loss expect remain elevated . 6 jpmorgan chase balance sheet remain strong end second quarter basel tier 1 common ratio 1 0 . 1 % . strong grow capital base enable firm repurchase $ 3 . 5 billion common stock quarter . total firmwide credit reserve quarterend $ 2 9 . 1 billion result firmwide loan loss coverage ratio 3 . 8 3 % exclude purchase creditimpaire loan . total stockholder equity june 3 0 2 0 1 1 $ 1 8 2 . 9 billion . net income month 2 0 1 1 $ 1 1 . 0 billion $ 2 . 5 5 share compare $ 8 . 1 billion $ 1 . 8 3 share half 2 0 1 0 . increase drive significantly low provision credit loss partially offset high noninterest expense low net revenue . low provision credit loss reflect improved credit environment . modest decline net revenue month year drive low net interest income mortgage fee related income security gain largely offset high level principal transaction revenue investment banking fee asset management administration commission revenue . increase noninter expense compare month 2 0 1 0 drive expense estimate cost foreclosurerelated matter rfs high compensation expense . month 2 0 1 1 jpmorgan chase provide credit raise capital $ 9 9 0 billion client . firm originate mortgage 3 6 0 0 0 0 people provide credit card approximately 4 . 6 million people lend increase credit 1 6 8 0 0 small business lend 8 0 0 notforprofit government entity include state municipality hospital university extend increase loan limit approximately 3 0 0 0 middlemarket company lend raise capital 5 0 0 0 corporation . jpmorgan chase 1 small business administration lender u . s . loan lender . 2 0 0 9 2 0 1 0 firm lend $ 7 billion $ 1 0 billion respectively small business commit lend $ 1 2 billion 2 0 1 1 . firm remain committed help homeowner prevent foreclosure beginning 2 0 0 9 jpmorgan chase offer 1 1 7 7 0 0 0 trial modification struggle homeowners . the discussion follow highlight performance business segment compare prioryear quarter present result manage basis . information manage basis nongaap financial measure use management evaluate performance line business page 1 4 1 6 form 1 0 q . investment bank net income increase prior year reflect high net revenue lower noninter expense partially offset low benefit provision credit loss . increase net revenue largely drive high investment banking fee solid client revenue fix income equity market . credit portfolio revenue loss primarily reflect negative net impact creditrelated valuation adjustment largely offset net interest income fee retained loan . provision credit loss small benefit second quarter 2 0 1 1 compare second quarter 2 0 1 0 reflect reduction allowance loan loss largely net repayment . noninterest expense decrease drive low compensation expense . prioryear result include impact u . k . bank payroll tax . retail financial service net income decrease compare prior year high noninter expense largely offset low provision credit loss high net revenue . increase net revenue drive high mortgage fee related income deposit balance debit card income depositrelate fee investment sale revenue partially offset low loan balance portfolio runoff . provision credit loss decrease delinquency trend net chargeoff modestly improve compare prior year . currentquarter provision continue reflect elevated loss mortgage home equity portfolio . noninter expense increase drive elevated foreclosure defaultrelated cost include $ 1 . 0 billion estimate litigation cost foreclosurerelated matter . card service auto net income increase compare second quarter 2 0 1 0 drive low provision credit loss partially offset low net revenue . decrease net revenue drive decline net interest income reflect low average loan balance include impact kohls portfolio sale impact legislative change decrease level fee . decrease largely offset low revenue reversal associate low net chargeoff . provision credit loss decrease prior year reflect low net chargeoff $ 1 . 0 billion reduction allowance loan loss low estimate loss . noninter expense increase high marketing expense inclusion commercial card business . credit card sale volume exclude washington mutual commercial card portfolio $ 8 3 . 1 billion increase 1 0 % prior year . commercial bank net income decrease drive increase provision credit loss partially offset record net revenue . record net revenue drive growth liability balance wide loan spread high investment banking revenue growth loan balance partially offset spread compression liability product . provision credit loss expense compare benefit prioryear . noninterest expense increase primarily reflect high headcountrelate expense . endofperiod loan $ 1 0 2 . 7 billion 7 % compare second quarter 2 0 1 0 increase consecutive quarter . average liability balance $ 1 6 2 . 8 billion increase 1 9 % second quarter 2 0 1 0 . treasury security service net income increase prior year drive high net revenue credit allocation benefit relate global corporate bank gcb partially offset high noninterest expense . worldwide security service net revenue increase drive high market level high net interest income net inflow asset custody . asset 7 under custody record $ 1 6 . 9 trillion increase 1 4 % prior year . treasury service net revenue relatively flat high trade loan volume high deposit balance largely offset effect transfer commercial card business card low spread deposit . high noninter expense drive continued investment new product platform primarily relate international expansion partially offset transfer commercial card business card . asset management net income increase prior year reflect high net revenue predominantly offset high noninterest expense . growth net revenue drive effect high market level net inflow product high margin high valuation seed capital investment high deposit loan balance high performance fee . increase revenue partially offset narrow deposit spread . asset supervision $ 1 . 9 trillion increase 1 7 % prior year effect high market level net inflow longterm product partially offset net outflow liquidity product . noninter expense increase largely result increase headcount high performancebase compensation . corporateprivate equity net income decrease compare second quarter 2 0 1 0 . private equity revenue increase primarily drive gain sale net increase investment valuation . net interest income security gain decrease prior year . noninterest expense high include $ 1 . 3 billion additional litigation reserve predominantly mortgagerelated matter . noninter expense prior year include $ 6 9 4 million additional litigation reserves . 2 0 1 1 business outlook follow forwardlooke statement base current belief expectation jpmorgan chase management subject significant risk uncertainty . risk uncertainty cause firm actual result differ materially set forth forwardlooking statement . forwardlooke statement page 9 7 risk factor page 1 9 2 1 9 3 form 1 0 q . jpmorgan chase outlook second half 2 0 1 1 view backdrop global u . s . economie financial market activity geopolitical environment competitive environment client activity level regulatory legislative development u . s . country firm business . link factor affect performance firm line business . mortgage production service business rfs mortgage interest rate remain current level rise future management anticipate loan production margin negatively affect result low revenue business fullyear 2 0 1 1 compare 2 0 1 0 . addition revenue 2 0 1 1 continue negatively affect continue elevated level repurchase mortgage previously sell predominantly u . s . governmentsponsored entity gse . management estimate realize repurchase loss approximately $ 1 . 2 billion annualize basis remainder 2 0 1 1 . firm expect noninter expense mortgage production servicing remain remainder year elevated level similar incur half 2 0 1 1 exclude $ 1 . 7 billion expense incur half 2 0 1 1 estimate cost relate foreclosure delay potential settlement federal state official . high level noninter expense expect light increase service cost enhance firm mortgage servicing process particularly loan modification foreclosure procedure comply consent order enter banking regulator . enhancement mortgage servicing page 8 4 8 5 note 2 3 page 1 7 2 1 7 9 form 1 0 q information consent order . possible firm incur additional fee assessment relate foreclosure delay cost connection potential settlement governmental investigation relate firm mortgage service procedures . in real estate portfolio business rfs management believe base current outlook delinquency loss severity total quarterly net chargeoff approximately $ 1 . 2 billion . current origination production level combine management current estimate portfolio runoff level residential real estate portfolio expect decline approximately 1 0 % 1 5 % annually foreseeable future . annual reduction residential real estate portfolio expect reduce net interest income period include reduction approximately $ 7 0 0 million fullyear 2 0 1 1 2 0 1 0 level assume change interest rate year . time reduction net interest income expect offset improvement credit cost low expense . portfolio continue run management anticipate approximately $ 1 . 0 billion capital available redeployment year subject capital requirement associate remain portfolio . in card current high repayment rate management expect endofperiod outstanding chase credit card portfolio exclude washington mutual commercial card portfolio $ 1 1 5 billion $ 1 2 0 billion end 2 0 1 1 . management estimate washington mutual credit card portfolio decline $ 1 0 billion end 2 0 1 1 . net chargeoff rate chase washington mutual credit card portfolio anticipate continue improve . current delinquency trend continue management anticipate net chargeoff rate chase credit card portfolio exclude 8 the washington mutual commercial card portfolio approximately 4 . 5 % quarter 2 0 1 1 . recent reserve release credit card allowance loan loss reflect continued improvement credit cycle . management anticipate credit card net chargeoff begin stabilize normal throughthecycle level release allowance decline eventually abate . economic datum half 2 0 1 1 imply u . s . economic growth slow high unemployment rate difficult housing market persistent . ongoing weak economic condition combine elevated delinquency ongoing discussion regard mortgage foreclosurerelated matter federal state official continue result high level uncertainty residential real estate portfolio . decline u . s . housing price increase unemployment rate remain possible occur currently anticipate result rfs card adversely affect . ib tss revenue affect market level volume volatility influence client flow asset management supervision custody . addition wholesale credit environment influence level chargeoff repayment provision credit loss ib cb tss . in private equity corporateprivate equity segment earning likely continue volatile influence capital market activity market level performance broad economy investmentspecific issue . corporate net interest income level generally trend size duration investment security portfolio . corporate net income exclude private equity exclude significant litigation expense significant nonrecurring item anticipate trend approximately $ 3 0 0 million quarter . furthermore continued repositioning investment security portfolio corporate change mix loan consumer loan portfolio factor include continue low interest rate result downward pressure firm net interest margin quarter 2 0 1 1 . the firm face litigation role issuer andor underwriter mortgagebacke security mbs offering primarily relate offering involve party gse . possible matter number year resolve ultimate resolution inherently uncertain reserve litigation matter need increase future . management firm board director continually evaluate way deploy firm strong capital base order enhance shareholder value . alternative include repurchase common stock warrant increase common stock dividend pursue alternative investment opportunity . firm expect utilize authorize $ 1 5 . 0 billion multiyear common equity repurchase program $ 8 . 0 billion approve federal reserve 2 0 1 1 minimum repurchase share issue employee stockbase incentive award . firm intend repurchase common equity firm generate capital excess need fund organic growth management judgment repurchase provide excellent value firm exist shareholder . management board continue assess decision regard alternative deploy capital appropriate course year . planned future dividend increase current level plan use repurchase program repurchase approve 2 0 1 1 review firm banking regulator action . 9 regulatory development jpmorgan chase subject regulation state federal law u . s . applicable law jurisdiction outside u . s . firm business . firm currently experience period unprecedented change regulation change significant impact firm conduct business . firm continue work diligently assess understand implication regulatory change face devote substantial resource implement new rule regulation meet need expectation client . firm preliminary assessment likely impact certain anticipate change fully describe firm current status regulatory development quantify possible effect business operation significant change underway . risk factor page 1 9 2 1 9 3 form 1 0 q additional information . february 2 0 1 1 pursuant doddfrank wall street reform consumer protection act doddfrank act fdic issue final rule change methodology calculate deposit insurance assessment rate large bank . new rule change assessment base insured deposit average consolidated total asset average tangible equity change assessment rate calculation . change effective april 1 2 0 1 1 base firm understanding final rule expect result aggregate annualize increase approximately $ 5 0 0 million assessment firm bank subsidiary pay fdic . in june 2 0 1 1 board governor federal reserve system federal reserve adopt rule implement durbin amendment provision doddfrank act limit firm charge debit card transaction process . base firm current understanding final rule effective october 1 2 0 1 1 anticipate rule result absent mitigation decline aggregate annualize gross revenue consumer business banking approximately $ 1 . 0 billion beginning fourth quarter 2 0 1 1 . firm consider action mitigate anticipate decline revenue time mitigating action expect wholly offset loss revenue . accordingly final effect regulation determine time . the firm affect requirement section 6 1 9 doddfrank act specifically provision prohibit proprietary trading restrict activity involve private equity hedge fund volcker rule . revenue net earning generate firm proprietary trading activity represent de minimis portion revenue net earning ib line business firm overall . firm cease proprietary trading activity 2 0 1 0 plan cease remain proprietary trading activity timeframe mandate volcker rule . addition application volcker rule firm private equity hedge fund activity ib line business corporateprivate equity sector expect significant effect revenue net earning firm line business . firm expect certain private equity hedge fund activity investment expect scope volcker rule redeem liquidate timeframe mandate volcker rule firm currently assess alternative mean exit remain activity investment conform requirement volcker rule timeframe mandate . regulator propose rule implement volcker rule order begin plan implementation firm attempt identify activity expect affect volcker rule . regard firm define proprietary trading trading security derivative future option foregoing predominantly use realize gain shortterm movement price firm account . firm proprietary trading activity typically conduct separately business activity segregate organizationally physically client marketmaking clientdriven business risk management activity . firm definition proprietary trading include client marketmaking long term investment activity risk management activity . remainder implement rule adopt firm know extent volcker rule affect ability engage activities . in june 2 0 1 1 basel committee financial stability board fsb announce certain global systemically important bank gsibs require maintain additional capital basel iii tier 1 common equity minimum range 1 % 2 . 5 % depend bank systemic importance . furthermore order provide disincentive bank face high require level tier 1 common equity increase materially global systemic importance future additional 1 % charge apply . jpmorgan chase estimate basel iii tier 1 common ratio approximately 7 . 6 % end second quarter 2 0 1 1 . level excess require today exist rule great level firm expect require propose rule year include additional buffer gsibs . firm expect strong capital position significant earning power allow actively grow business rapidly meet propose basel iii requirement phase . firm intend capital ratio approximately current level subject regulatory approval management need manage high ratio ahead time . 1 0 consolidated result operationsthe follow section provide comparative discussion jpmorgan chase consolidated result operation reported basis month end june 3 0 2 0 1 1 2 0 1 0 . factor relate primarily single business segment discuss detail business segment . discussion critical accounting estimate use firm affect consolidated result operation page 9 2 9 5 form 1 0 q page 1 4 9 1 5 4 jpmorgan chase 2 0 1 0 annual report . revenuethree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeinvestment banking fees $ 1 9 3 3 $ 1 4 2 1 3 6 % $ 3 7 2 6 $ 2 8 8 2 2 9 % principal transactions 3 1 4 0 2 0 9 0 5 0 7 8 8 5 6 6 3 8 1 9 lending depositrelate fees 1 6 4 9 1 5 8 6 4 3 1 9 5 3 2 3 2 1 asset management administration commissions 3 7 0 3 3 3 4 9 1 1 7 3 0 9 6 6 1 4 1 1 securities gains 8 3 7 1 0 0 0 1 6 9 3 9 1 6 1 0 4 2 mortgage fee related income 1 1 0 3 8 8 8 2 4 6 1 6 1 5 4 6 6 0 credit card income 1 6 9 6 1 4 9 5 1 3 3 1 3 3 2 8 5 6 1 0 other income 8 8 2 5 8 5 5 1 1 4 5 6 9 9 7 4 6 noninterest revenue 1 4 9 4 3 1 2 4 1 4 2 0 2 8 2 5 9 2 6 3 7 5 7 net interest income 1 1 8 3 6 1 2 6 8 7 7 2 3 7 4 1 2 6 3 9 7 1 0 total net revenue $ 2 6 7 7 9 $ 2 5 1 0 1 7 % $ 5 2 0 0 0 $ 5 2 7 7 2 1 % total net revenue second quarter 2 0 1 1 $ 2 6 . 8 billion increase $ 1 . 7 billion 7 % second quarter 2 0 1 0 . revenue growth drive high level principal transaction revenue investment banking fee asset management administration commission revenue largely offset low net interest income . month 2 0 1 1 total net revenue $ 5 2 . 0 billion modest decline compare month 2 0 1 0 low net interest income mortgage fee related income security gain offset revenue growth high level principal transaction revenue investment banking fee asset management administration commission revenue . investment banking fee increase compare second quarter month 2 0 1 0 record month 2 0 1 1 . debt underwriting fee record month 2 0 1 1 . advisory fee debt underwriting fee equity underwriting fee high period comparison industrywide ma capitalraising volume increase 2 0 1 0 level . additional information investment banking fee primarily record ib ib segment result page 1 9 2 2 form 1 0 q . principal transaction revenue increase compare second quarter month 2 0 1 0 primarily drive gain sale net increase investment valuation corporateprivate equity result continued improvement market condition relate certain portfolio investment . trading revenue increase second quarter 2 0 1 1 compare second quarter 2 0 1 0 decrease half 2 0 1 1 compare half 2 0 1 0 . client revenue ib remain solid period comparison reflect strength depth client franchise . additional information principal transaction revenue ib corporateprivate equity segment result page 1 9 2 2 4 6 4 7 respectively note 6 page 1 2 4 1 2 5 form 1 0 q . lende depositrelate fee increase second quarter 2 0 1 1 compare prior year . increase primarily drive introduction new checking account product offering rfs conversion exist check account new product offering partially offset impact nonsufficient fundoverdraft nsfod regulatory policy change . month 2 0 1 1 lending depositrelate fee decline slightly compare prior year reflect lower depositrelated fee rfs associate impact aforementioned regulatory policy change . decline partially offset high lendingrelated fee ib . additional information lending depositrelate fee record rfs cb tss ib rfs page 2 3 3 2 cb page 3 6 3 8 ts page 3 9 4 1 ib segment result page 1 9 2 2 form 1 0 q . asset management administration commission revenue increase second quarter month 2 0 1 0 . increase reflect high asset management fee drive effect high market level net inflow longerterm product high margin . extent high administration fee tss reflect effect high market level net inflow asset custody contribute increase revenue . additional information fee commission segment discussion page 4 2 4 5 ts page 3 9 4 1 form 1 0 q . securities gain decrease second quarter month 2 0 1 0 result primarily repositioning portfolio response change interest rate environment rebalancing exposure . additional information security gain record firm corporate segment corporateprivate equity segment discussion page 4 6 4 7 form 1 0 q . 1 1 mortgage fee related income increase compare second quarter 2 0 1 0 drive increase production revenue reflect wide margin low level repurchase loss increase largely offset decrease net mortgage service revenue low msr risk management revenue . mortgage fee related income decrease compare month 2 0 1 0 decrease drive $ 1 . 1 billion decline fair value msr asset recognize quarter 2 0 1 1 relate revise cost service assumption incorporate valuation reflect estimate impact high servicing cost enhance servicing process particularly loan modification foreclosure procedure high estimate cost comply consent order enter banking regulator . decline fair value msr asset result decrease interest rate . partially offset decrease increase production revenue drive impact high mortgage origination volume wide margin low level repurchase loss . additional information mortgage fee related income record primarily rfs rfs mortgage production service discussion page 2 7 2 9 form 1 0 q . additional information repurchase loss mortgage repurchase liability discussion page 5 3 5 6 note 2 1 page 1 6 7 1 7 1 form 1 0 q . credit card income increase second quarter half 2 0 1 1 . increase quarter largely reflect high net interchange income associate high customer charge volume debit credit card low partner revenueshare contrarevenue item impact kohl portfolio sale . increase month 2 0 1 1 drive high net interchange income partially offset low revenue feebase product . additional information credit card income card rfs segment result page 3 3 3 5 page 2 3 3 2 respectively form 1 0 q . other income increase compare second quarter month 2 0 1 0 drive valuation adjustment certain asset incremental income recent acquisition ib high valuation seed capital investment . high auto operating lease income card result growth lease volume contribute increase . net interest income decrease second quarter month 2 0 1 1 compare prior year . decline period drive low yield security low average loan balance yield primarily card rfs reflect expect runoff credit card balance residential real estate loan low fee credit card receivables reflect impact legislative change low yield deposit . decrease offset partially low revenue reversal associate low credit card chargeoff high average deposit balance . firm average interestearne asset $ 1 . 8 trillion second quarter 2 0 1 1 net yield asset fully taxableequivalent fte basis 2 . 7 2 % decrease 3 4 basis point second quarter 2 0 1 0 . month 2 0 1 1 average interestearne asset $ 1 . 7 trillion net yield asset fte basis 2 . 8 0 % decrease 3 9 basis point month 2 0 1 0 . information impact legislative change consolidated statement income card discussion credit card legislation page 7 9 jpmorgan chase 2 0 1 0 annual report . provision credit lossesthree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changewholesale $ 1 1 7 $ 5 7 2 8 0 % $ 5 0 3 $ 8 0 8 3 8 % consumer exclude credit card 1 1 1 7 1 7 1 4 3 5 2 4 4 6 5 4 4 8 5 5 credit card 8 1 0 2 2 2 1 6 4 1 0 3 6 5 7 3 3 8 2 total consumer 1 9 2 7 3 9 3 5 5 1 3 4 8 2 1 1 1 8 1 6 9 total provision credit losses $ 1 8 1 0 $ 3 3 6 3 4 6 % $ 2 9 7 9 $ 1 0 3 7 3 7 1 % the provision credit loss decrease significantly compare second quarter month 2 0 1 0 . credit card provision prioryear period drive primarily improve delinquency trend reduction allowance loan loss result low estimate loss . consumer exclude credit card provision prioryear period reflect improve delinquency chargeoff trend 2 0 1 1 portfolio absence addition allowance loan loss . wholesale provision reflect low benefit second quarter month 2 0 1 1 compare prioryear period . detailed discussion loan portfolio allowance credit loss segment discussion rfs page 2 3 3 2 card page 3 3 3 5 ib page 1 9 2 2 cb page 3 6 3 8 allowance credit loss section page 8 6 8 8 form 1 0 q . 1 2 noninterest expensethree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changecompensation expensea $ 7 5 6 9 $ 7 6 1 6 1 % $ 1 5 8 3 2 $ 1 4 8 9 2 6 % noncompensation expense occupancy 9 3 5 8 8 3 6 1 9 1 3 1 7 5 2 9 technology communication equipment 1 2 1 7 1 1 6 5 4 2 4 1 7 2 3 0 2 5 professional outside services 1 8 6 6 1 6 8 5 1 1 3 6 0 1 3 2 6 0 1 0 marketing 7 4 4 6 2 8 1 8 1 4 0 3 1 2 1 1 1 6 otherbc 4 2 9 9 2 4 1 9 7 8 7 2 4 2 6 8 6 0 6 amortization intangibles 2 1 2 2 3 5 1 0 4 2 9 4 7 8 1 0 total noncompensation expense 9 2 7 3 7 0 1 5 3 2 1 7 0 0 5 1 5 8 6 3 7 total noninter expense $ 1 6 8 4 2 $ 1 4 6 3 1 1 5 % $ 3 2 8 3 7 $ 3 0 7 5 5 7 % athe month end june 3 0 2 0 1 0 include payroll tax expense relate united kingdom u . k . bank payroll tax certain compensation award december 9 2 0 0 9 april 5 2 0 1 0 relevant banking employees . bincluded litigation expense $ 1 . 9 billion $ 3 . 0 billion month end june 3 0 2 0 1 1 respectively compare $ 7 9 2 million $ 3 . 7 billion month end june 3 0 2 0 1 0 respectively . cinclude foreclosed property expense $ 1 7 4 million $ 3 8 4 million month end june 3 0 2 0 1 1 respectively compare $ 2 4 4 million $ 5 4 7 million month end june 3 0 2 0 1 0 respectively . total noninterest expense second quarter 2 0 1 1 $ 1 6 . 8 billion increase $ 2 . 2 billion 1 5 % compare second quarter 2 0 1 0 . total noninter expense month 2 0 1 1 $ 3 2 . 8 billion $ 2 . 1 billion 7 % compare month 2 0 1 0 . increase period comparison high noncompensation expense include elevated level litigation expense relate mortgagerelate matter increase expense foreclosurerelated matter . high compensation expense contribute increase noninter expense half 2 0 1 1 . compensation expense decrease slightly second quarter 2 0 1 0 prioryear result include impact u . k . bank payroll tax ib . compensation expense increase month 2 0 1 0 high salary benefit expense ib addition sale force employee engage defaultrelate matter associate serviced portfolio rfs office staff increase partially offset aforementioned payroll tax ib 2 0 1 0 . the increase noncompensation expense second quarter 2 0 1 1 high litigation expense include addition $ 1 . 3 billion litigation reserve corporate predominantly mortgagerelate matter $ 1 . 0 billion expense estimate litigation cost foreclosurerelated matter rfs . noncompensation expense month 2 0 1 1 affect item additional $ 6 5 0 million expense estimate litigation cost foreclosurerelated matter rfs quarter 2 0 1 1 . litigation expense half 2 0 1 1 decrease prior year aforementioned charge mortgagerelated matter low incur 2 0 1 0 . discussion litigation expense litigation reserve discussion note 2 3 page 1 7 2 1 7 9 form 1 0 q . addition item mention follow item noncompensation expense high second quarter month 2 0 1 1 professional service expense consent order foreclosurerelated matter rfs continue investment new product platform business marketing expense card expense reflect high fdic assessment 2 0 1 1 additional operating expense relate business activity ib . discussion amortization intangible refer balance sheet analysis page 4 9 5 1 note 1 6 page 1 5 9 1 6 3 form 1 0 q . income tax expensethree month end june 3 0 month end june 3 0 million rate 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 income income tax expense $ 8 1 2 7 $ 7 1 0 7 $ 1 6 1 8 4 $ 1 1 6 4 4 income tax expense 2 6 9 6 2 3 1 2 5 1 9 8 3 5 2 3 effective tax rate 3 3 . 2 % 3 2 . 5 % 3 2 . 1 % 3 0 . 3 % the increase effective tax rate month end june 3 0 2 0 1 1 compare prioryear period primarily result high report pretax income change mix income subject u . s . federal state local taxis low tax benefit recognize resolution tax audits . factor partially offset deferred tax benefit associate state local income taxis . additional information income taxis critical accounting estimate use firm page 9 2 9 5 form 1 0 q . 1 3 explanation reconciliation firm use nongaap financial measuresthe firm prepare consolidated financial statement use accounting principle generally accept u . s . u . s . gaap financial statement appear page 9 8 1 0 1 form 1 0 q . presentation refer report basis provide reader understanding firm result track consistently year year enable comparison firm performance company u . s . gaap financial statements . in addition analyze firm result reported basis management review firm result result line business manage basis nongaap financial measure . firm definition manage basis start reported u . s . gaap result include certain reclassification present total net revenue firm business segment fte basis . accordingly revenue taxexempt security investment receive tax credit present manage result basis comparable taxable security investment . nongaap financial measure allow management assess comparability revenue arise taxable taxexempt source . corresponding income tax impact relate taxexempt item record income tax expense . adjustment impact net income report firm line business . tangible common equity tce nongaap financial measure represent common stockholder equity i . e . total stockholder equity prefer stock goodwill identifiable intangible asset msrs net related deferred tax liability . rotce nongaap financial ratio measure firm earning percentage tce . management view measure meaningful firm analyst investor assess firm use equity facilitate comparison competitor . management use certain nongaap financial measure businesssegment level believe nongaap financial measure provide information investor underlie operational performance trend particular business segment facilitate comparison business segment performance competitor . nongaap financial measure use firm comparable similarly nongaap financial measure use companies . 1 4 the follow summary table provide reconciliation firm report u . s . gaap result manage basis . month end june 3 0 2 0 1 1 million share ratiosreportedresult fully taxequivalent adjustment managedbasisrevenue investment bank fees $ 1 9 3 3 $ $ 1 9 3 3 principal transactions 3 1 4 0 3 1 4 0 lending depositrelate fees 1 6 4 9 1 6 4 9 asset management administration commissions 3 7 0 3 3 7 0 3 securitie gains 8 3 7 8 3 7 mortgage fee related income 1 1 0 3 1 1 0 3 credit card income 1 6 9 6 1 6 9 6 other income 8 8 2 5 1 0 1 3 9 2 noninterest revenue 1 4 9 4 3 5 1 0 1 5 4 5 3 net interest income 1 1 8 3 6 1 2 1 1 1 9 5 7 total net revenue 2 6 7 7 9 6 3 1 2 7 4 1 0 noninterest expense 1 6 8 4 2 1 6 8 4 2 preprovision profit 9 9 3 7 6 3 1 1 0 5 6 8 provision credit losses 1 8 1 0 1 8 1 0 income income tax expense 8 1 2 7 6 3 1 8 7 5 8 income tax expense 2 6 9 6 6 3 1 3 3 2 7 net income $ 5 4 3 1 $ $ 5 4 3 1 diluted earning share $ 1 . 2 7 $ $ 1 . 2 7 return assets 0 . 9 9 % nm 0 . 9 9 % overhead ratio 6 3 nm 6 1 month end june 3 0 2 0 1 0 million share ratiosreportedresult fully taxequivalent adjustment managedbasisrevenue investment banking fees $ 1 4 2 1 $ $ 1 4 2 1 principal transactions 2 0 9 0 2 0 9 0 lending depositrelate fees 1 5 8 6 1 5 8 6 asset management administration commissions 3 3 4 9 3 3 4 9 securitie gains 1 0 0 0 1 0 0 0 mortgage fee related income 8 8 8 8 8 8 credit card income 1 4 9 5 1 4 9 5 other income 5 8 5 4 1 6 1 0 0 1 noninterest revenue 1 2 4 1 4 4 1 6 1 2 8 3 0 net interest income 1 2 6 8 7 9 6 1 2 7 8 3 total net revenue 2 5 1 0 1 5 1 2 2 5 6 1 3 noninterest expense 1 4 6 3 1 1 4 6 3 1 preprovision profit 1 0 4 7 0 5 1 2 1 0 9 8 2 provision credit losses 3 3 6 3 3 3 6 3 income income tax expense 7 1 0 7 5 1 2 7 6 1 9 income tax expense 2 3 1 2 5 1 2 2 8 2 4 net income $ 4 7 9 5 $ $ 4 7 9 5 diluted earning share $ 1 . 0 9 $ $ 1 . 0 9 return assets 0 . 9 4 % nm 0 . 9 4 % overhead ratio 5 8 nm 5 7 1 5 month end june 3 0 2 0 1 1 million share ratiosreportedresult fully taxequivalent adjustment managedbasisrevenue investment bank fees $ 3 7 2 6 $ $ 3 7 2 6 principal transactions 7 8 8 5 7 8 8 5 lending depositrelate fees 3 1 9 5 3 1 9 5 asset management administration commissions 7 3 0 9 7 3 0 9 securitie gains 9 3 9 9 3 9 mortgage fee related income 6 1 6 6 1 6 credit card income 3 1 3 3 3 1 3 3 other income 1 4 5 6 9 6 1 2 4 1 7 noninterest revenue 2 8 2 5 9 9 6 1 2 9 2 2 0 net interest income 2 3 7 4 1 2 4 0 2 3 9 8 1 total net revenue 5 2 0 0 0 1 2 0 1 5 3 2 0 1 noninterest expense 3 2 8 3 7 3 2 8 3 7 preprovision profit 1 9 1 6 3 1 2 0 1 2 0 3 6 4 provision credit losses 2 9 7 9 2 9 7 9 income income tax expense 1 6 1 8 4 1 2 0 1 1 7 3 8 5 income tax expense 5 1 9 8 1 2 0 1 6 3 9 9 net income $ 1 0 9 8 6 $ $ 1 0 9 8 6 diluted earning share $ 2 . 5 5 $ $ 2 . 5 5 return assets 1 . 0 3 % nm 1 . 0 3 % overhead ratio 6 3 nm 6 2 month end june 3 0 2 0 1 0 million share ratiosreportedresult fully taxequivalent adjustment managedbasisrevenue investment banking fees $ 2 8 8 2 $ $ 2 8 8 2 principal transactions 6 6 3 8 6 6 3 8 lending depositrelate fees 3 2 3 2 3 2 3 2 asset management administration commissions 6 6 1 4 6 6 1 4 securities gains 1 6 1 0 1 6 1 0 mortgage fee related income 1 5 4 6 1 5 4 6 credit card income 2 8 5 6 2 8 5 6 other income 9 9 7 8 2 7 1 8 2 4 noninterest revenue 2 6 3 7 5 8 2 7 2 7 2 0 2 net interest income 2 6 3 9 7 1 8 6 2 6 5 8 3 total net revenue 5 2 7 7 2 1 0 1 3 5 3 7 8 5 noninterest expense 3 0 7 5 5 3 0 7 5 5 preprovision profit 2 2 0 1 7 1 0 1 3 2 3 0 3 0 provision credit losses 1 0 3 7 3 1 0 3 7 3 income income tax expense 1 1 6 4 4 1 0 1 3 1 2 6 5 7 income tax expense 3 5 2 3 1 0 1 3 4 5 3 6 net income $ 8 1 2 1 $ $ 8 1 2 1 diluted earning share $ 1 . 8 3 $ $ 1 . 8 3 return assets 0 . 8 0 % nm 0 . 8 0 % overhead ratio 5 8 nm 5 7 average tangible common equity month end month endedin millionsjune 3 0 2 0 1 1 june 3 0 2 0 1 0 june 3 0 2 0 1 1 june 3 0 2 0 1 0 common stockholder equity $ 1 7 4 0 7 7 $ 1 5 9 0 6 9 $ 1 7 1 7 5 9 $ 1 5 7 5 9 0 less goodwill 4 8 8 3 4 4 8 3 4 8 4 8 8 4 0 4 8 4 4 5 less certain identifiable intangible assets 3 7 3 8 4 2 6 5 3 8 3 3 4 2 8 5 add defer tax liabilitiesa 2 6 1 8 2 5 6 4 2 6 0 7 2 5 5 3 tangible common equity $ 1 2 4 1 2 3 $ 1 0 9 0 2 0 $ 1 2 1 6 9 3 $ 1 0 7 4 1 3 arepresent defer tax liability relate taxdeductible goodwill identifiable intangible create nontaxable transaction net goodwill intangible calculate tce . oth financial measuresthe firm disclose allowance loan loss total retained loan exclude home lending pci loan . discussion credit metric allowance credit loss page 8 6 8 8 form 1 0 q . 1 6 business segment resultsthe firm manage line business basis . business segment financial result present reflect current organization jpmorgan chase . major reportable business segment investment bank retail financial service card service auto commercial banking treasury security service asset management corporateprivate equity segment . business segment determine base product service provide type customer serve reflect manner financial information currently evaluate management . result line business present manage basis . subsequent business segment changescommencing july 1 2 0 1 1 firm business segment reorganize followsauto student lending transfer rfs segment report card single segment . retail financial service continue segment organize component consumer business bank retail banking mortgage banking include mortgage production servicing real estate portfolios . the business segment information associate rfs card revise reflect business reorganization retroactive january 1 2 0 1 0 . description business segment report methodologyresult business segment intend reflect segment essentially standalone business . management reporting process derive business segment result allocate income expense use marketbase methodology . discussion methodology business segment result description business segment report methodology page 6 7 6 8 jpmorgan chase 2 0 1 0 annual report . firm continue assess assumption methodology reporting classification use segment reporting refinement implement future period . business segment capital allocation changeseach business segment allocate capital consideration standalone peer comparison economic risk measure regulatory capital requirement . capital assign business refer equity . effective january 1 2 0 1 1 capital allocate card reduce tss increase . information capital change line business equity page 6 0 6 1 form 1 0 q . segment result manage basisa follow table summarize business segment result period indicated . three month end june 3 0 total net revenue noninter expense preprovision profitin million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeinvestment bankb $ 7 3 1 4 $ 6 3 3 2 1 6 % $ 4 3 3 2 $ 4 5 2 2 4 % $ 2 9 8 2 $ 1 8 1 0 6 5 % retail financial services 7 1 4 2 6 9 6 4 3 5 2 7 1 3 9 4 5 3 4 1 8 7 1 3 0 1 9 3 8 card service auto 4 7 6 1 5 0 6 2 6 1 9 8 8 1 7 7 2 1 2 2 7 7 3 3 2 9 0 1 6 commercial banking 1 6 2 7 1 4 8 6 9 5 6 3 5 4 2 4 1 0 6 4 9 4 4 1 3 treasury security services 1 9 3 2 1 8 8 1 3 1 4 5 3 1 3 9 9 4 4 7 9 4 8 2 1 asset management 2 5 3 7 2 0 6 8 2 3 1 7 9 4 1 4 0 5 2 8 7 4 3 6 6 3 1 2 corporateprivate equityb 2 0 9 7 1 8 2 0 1 5 1 4 4 1 1 0 4 6 3 8 6 5 6 7 7 4 1 5 total $ 2 7 4 1 0 $ 2 5 6 1 3 7 % $ 1 6 8 4 2 $ 1 4 6 3 1 1 5 % $ 1 0 5 6 8 $ 1 0 9 8 2 4 % three month end june 3 0 provision credit loss net income return equityin million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 investment bankb $ 1 8 3 $ 3 2 5 4 4 % $ 2 0 5 7 $ 1 3 8 1 4 9 % 2 1 % 1 4 % retail financial services 9 9 4 1 5 4 5 3 6 3 8 3 8 4 9 5 5 6 1 4 card service auto 9 4 4 2 3 9 1 6 1 1 1 1 0 5 3 6 1 0 7 2 8 1 2 commercial banking 5 4 2 3 5 nm 6 0 7 6 9 3 1 2 3 0 3 5 treasury security services 2 1 6 8 8 3 3 3 2 9 2 1 4 1 9 1 8 asset management 1 2 5 1 4 0 4 3 9 3 9 1 1 2 2 7 2 4 corporateprivate equityb 9 2 3 5 0 5 0 2 6 5 3 2 3 nmnmtotal $ 1 8 1 0 $ 3 3 6 3 4 6 % $ 5 4 3 1 $ 4 7 9 5 1 3 % 1 2 % 1 2 % 1 7 six month end june 3 0 total net revenue noninter expense preprovision profitin million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeinvestment bankb $ 1 5 5 4 7 $ 1 4 6 5 1 6 % $ 9 3 4 8 $ 9 3 6 0 % $ 6 1 9 9 $ 5 2 9 1 1 7 % retail financial services 1 2 6 0 8 1 3 9 3 4 1 0 1 0 1 7 1 7 8 4 2 3 0 2 4 3 7 6 0 9 2 6 0 card service auto 9 5 5 2 1 0 3 1 5 7 3 9 0 5 3 5 1 9 1 1 5 6 4 7 6 7 9 6 1 7 commercial banking 3 1 4 3 2 9 0 2 8 1 1 2 6 1 0 8 1 4 2 0 1 7 1 8 2 1 1 1 treasury security services 3 7 7 2 3 6 3 7 4 2 8 3 0 2 7 2 4 4 9 4 2 9 1 3 3 asset management 4 9 4 3 4 1 9 9 1 8 3 4 5 4 2 8 4 7 2 1 1 4 8 9 1 3 5 2 1 0 corporateprivate equityb 3 6 3 6 4 1 4 7 1 2 2 0 0 3 3 3 8 2 4 1 1 6 3 3 7 6 5 1 1 3 total $ 5 3 2 0 1 $ 5 3 7 8 5 1 % $ 3 2 8 3 7 $ 3 0 7 5 5 7 % $ 2 0 3 6 4 $ 2 3 0 3 0 1 2 % six month end june 3 0 provision credit loss net income return equityin million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 investment bankb $ 6 1 2 $ 7 8 7 2 2 % $ 4 4 2 7 $ 3 8 5 2 1 5 % 2 2 % 1 9 % retail financial services 2 1 9 3 5 1 0 4 5 7 1 6 5 5 3 nm 5 card service auto 1 2 9 7 6 0 7 7 7 9 2 6 4 4 3 9 8 nm 3 3 4 commercial banking 1 0 1 2 1 nm 1 1 5 3 1 0 8 3 6 2 9 2 7 treasury security services 2 5 5 nm 6 4 9 5 7 1 1 4 1 9 1 8 asset management 1 7 4 0 5 8 9 0 5 7 8 3 1 6 2 8 2 4 corporateprivate equityb 1 9 1 5 nm 1 2 2 4 8 8 1 3 9 nmnmtotal $ 2 9 7 9 $ 1 0 3 7 3 7 1 % $ 1 0 9 8 6 $ 8 1 2 1 3 5 % 1 3 % 1 0 % arepresent report result taxequivalent basis . bcorporateprivate equity include adjustment offset ibs inclusion credit allocation incomeexpense tss total net revenue tss report credit allocation separate line income statement total net revenue . 1 8 investment bankfor discussion business profile ib page 6 9 7 1 jpmorgan chase 2 0 1 0 annual report introduction page 4 form 1 0 q . selected income statement datathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue investment bank fees $ 1 9 2 2 $ 1 4 0 5 3 7 % $ 3 7 0 1 $ 2 8 5 1 3 0 % principal transactions 2 3 0 9 2 1 0 5 1 0 5 7 0 7 6 0 3 6 5 lending depositrelate fees 2 1 8 2 0 3 7 4 3 2 4 0 5 7 asset management administration commissions 5 4 8 6 3 3 1 3 1 1 6 7 1 1 9 6 2 all incomea 2 3 6 8 6 1 7 4 4 0 2 1 3 5 1 9 8 noninterest revenue 5 2 3 3 4 4 3 2 1 8 1 1 4 0 9 1 0 6 2 3 7 net interest income 2 0 8 1 1 9 0 0 1 0 4 1 3 8 4 0 2 8 3 total net revenueb 7 3 1 4 6 3 3 2 1 6 1 5 5 4 7 1 4 6 5 1 6 provision credit losses 1 8 3 3 2 5 4 4 6 1 2 7 8 7 2 2 noninter expense compensation expense 2 5 6 4 2 9 2 3 1 2 5 8 5 8 5 8 5 1 noncompensation expense 1 7 6 8 1 5 9 9 1 1 3 4 9 0 3 5 0 9 1 total noninter expense 4 3 3 2 4 5 2 2 4 9 3 4 8 9 3 6 0 income income tax expense 3 1 6 5 2 1 3 5 4 8 6 8 1 1 6 0 7 8 1 2 income tax expense 1 1 0 8 7 5 4 4 7 2 3 8 4 2 2 2 6 7 net income $ 2 0 5 7 $ 1 3 8 1 4 9 $ 4 4 2 7 $ 3 8 5 2 1 5 financial ratio return common equity 2 1 % 1 4 % 2 2 % 1 9 % return assets 0 . 9 8 0 . 7 8 1 . 0 8 1 . 1 2 overhead ratio 5 9 7 1 6 0 6 4 compensation expense percentage total net revenuec 3 5 4 6 3 8 4 0 revenue business investment banking fee advisory $ 6 0 1 $ 3 5 5 6 9 $ 1 0 3 0 $ 6 6 0 5 6 equity underwriting 4 5 5 3 5 4 2 9 8 3 4 7 6 7 9 debt underwriting 8 6 6 6 9 6 2 4 1 8 3 7 1 4 2 4 2 9 total investment banking fees 1 9 2 2 1 4 0 5 3 7 3 7 0 1 2 8 5 1 3 0 fixed income marketsd 4 2 8 0 3 5 6 3 2 0 9 5 1 8 9 0 2 7 5 equity marketse 1 2 2 3 1 0 3 8 1 8 2 6 2 9 2 5 0 0 5 credit portfolioaf 1 1 1 3 2 6 nm 3 0 1 2 7 3 nmtotal net revenue $ 7 3 1 4 $ 6 3 3 2 1 6 $ 1 5 5 4 7 $ 1 4 6 5 1 6 aib manage traditional credit exposure relate global corporate bank gcb behalf ib ts . effective january 1 2 0 1 1 ib tss share economic relate firm gcb client . ib recognize sharing agreement income . prioryear period reflect reimbursement tss portion total cost manage credit portfolio behalf tss . btotal net revenue include taxequivalent adjustment predominantly income tax credit relate affordable housing alternative energy investment taxexempt income municipal bond investment $ 4 9 3 million $ 4 0 1 million month end june 3 0 2 0 1 1 2 0 1 0 $ 9 3 1 million $ 8 0 4 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . cthe compensation expense percentage total net revenue ratio second quarter 2 0 1 0 yeartodate 2 0 1 0 exclude payroll tax expense relate u . k . bank payroll tax certain compensation award december 9 2 0 0 9 april 5 2 0 1 0 relevant banking employee nongaap financial measure 3 7 % 3 6 % respectively . ib exclude tax ratio enable comparability period . dfixe income market primarily include revenue relate marketmake global fixed income market include foreign exchange interest rate credit commodity market . eequitie market primarily include revenue relate marketmake global equity product include cash instrument derivative convertible prime service . fcredit portfolio revenue include net interest income fee loan sale activity gain loss security receive loan restructure ibs credit portfolio . credit portfolio revenue include result risk management relate firm lending derivative activity . page 6 7 8 8 credit risk management section form 1 0 q discussion . 1 9 quarterly resultsnet income $ 2 . 1 billion 4 9 % prior year reflect high net revenue lower noninter expense partially offset low benefit provision credit loss . net revenue $ 7 . 3 billion compare $ 6 . 3 billion prior year . investment banking fee 3 7 % $ 1 . 9 billion consisting debt underwriting fee $ 8 6 6 million 2 4 % equity underwriting fee $ 4 5 5 million 2 9 % advisory fee $ 6 0 1 million 6 9 % . fix income equity market revenue $ 5 . 5 billion compare $ 4 . 6 billion prior year reflect solid client revenue . credit portfolio revenue loss $ 1 1 1 million primarily reflect negative net impact creditrelated valuation adjustment largely offset net interest income fee retain loans . the provision credit loss benefit $ 1 8 3 million compare benefit $ 3 2 5 million prior year . currentquarter benefit primarily reflect reduction allowance loan loss largely net repayment . ratio allowance loan loss endofperiod loan retain 2 . 1 0 % compare 3 . 9 8 % prior year drive improved quality loan portfolio . net chargeoff $ 7 million compare net chargeoff $ 2 8 million prior year . noninter expense $ 4 . 3 billion 4 % prior year . decrease drive low compensation expense . prioryear result include impact u . k . bank payroll tax . return equity 2 1 % $ 4 0 . 0 billion average allocate capital . yeartodate resultsnet income $ 4 . 4 billion 1 5 % prior year primarily reflect high net revenue partially offset low benefit provision credit loss . net revenue $ 1 5 . 5 billion compare $ 1 4 . 7 billion prior year . investment banking fee record 3 0 % $ 3 . 7 billion consisting record debt underwriting fee $ 1 . 8 billion 2 9 % advisory fee $ 1 . 0 billion 5 6 % equity underwriting fee $ 8 3 4 million 9 % . fix income equity market revenue $ 1 2 . 1 billion compare $ 1 1 . 5 billion prior year reflect solid client revenue . credit portfolio revenue loss $ 3 0 1 million primarily reflect negative net impact creditrelated valuation adjustment largely offset net interest income fee retain loans . the provision credit loss benefit $ 6 1 2 million compare benefit $ 7 8 7 million prior year . currentyear benefit primarily reflect reduction allowance loan loss largely result net repayment loan sale . net chargeoff $ 1 3 0 million compare net chargeoff $ 7 2 5 million prior year . noninter expense $ 9 . 3 billion approximately flat prior year . compensation expense flat prior year high salary benefit performancebased compensation expense predominantly offset absence u . k . bank payroll tax current period . noncompensation expense approximately flat prior year . return equity 2 2 % $ 4 0 . 0 billion average allocate capital . 2 0 selected metricsthree month end june 3 0 month end june 3 0 million headcount ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeselected balance sheet datum periodend loan loan retaineda $ 5 6 1 0 7 $ 5 4 0 4 9 4 % $ 5 6 1 0 7 $ 5 4 0 4 9 4 % loan heldforsale loan fair value 3 4 6 6 3 2 2 1 8 3 4 6 6 3 2 2 1 8 total loans 5 9 5 7 3 5 7 2 7 0 4 5 9 5 7 3 5 7 2 7 0 4 equity 4 0 0 0 0 4 0 0 0 0 4 0 0 0 0 4 0 0 0 0 select balance sheet datum average total assets $ 8 4 1 3 5 5 $ 7 1 0 0 0 5 1 8 $ 8 2 8 6 6 2 $ 6 9 3 1 5 7 2 0 trading assetsdebt equity instruments 3 7 4 6 9 4 2 9 6 0 3 1 2 7 3 7 1 8 4 1 2 9 0 0 9 1 2 8 trading assetsderivative receivables 6 9 3 4 6 6 5 8 4 7 5 6 8 4 0 9 6 5 9 9 8 4 loans loan retaineda 5 4 5 9 0 5 3 3 5 1 2 5 3 9 8 3 5 5 9 1 2 3 loans heldforsale loan fair value 4 1 5 4 3 5 3 0 1 8 3 9 9 5 3 3 4 1 2 0 total loans 5 8 7 4 4 5 6 8 8 1 3 5 7 9 7 8 5 9 2 5 3 2 adjusted assetsb 6 2 8 4 7 5 5 2 7 5 2 0 1 9 6 1 9 8 0 5 5 1 7 1 3 5 2 0 equity 4 0 0 0 0 4 0 0 0 0 4 0 0 0 0 4 0 0 0 0 headcount 2 7 7 1 6 2 6 2 7 9 5 2 7 7 1 6 2 6 2 7 9 5 credit datum quality statistic net chargeoffs $ 7 $ 2 8 7 5 $ 1 3 0 $ 7 2 5 8 2 nonperforming asset nonaccrual loan nonaccrual loan retainedac 1 4 9 4 1 9 2 6 2 2 1 4 9 4 1 9 2 6 2 2 nonaccrual loan heldforsale loan fair value 1 9 3 3 3 4 4 2 1 9 3 3 3 4 4 2 total nonperforming loans 1 6 8 7 2 2 6 0 2 5 1 6 8 7 2 2 6 0 2 5 derivative receivables 1 8 3 1 5 9 4 1 8 3 1 5 9 4 assets acquire loan satisfactions 8 3 1 5 1 4 5 8 3 1 5 1 4 5 total nonperforme assets 1 7 8 8 2 7 2 6 3 4 1 7 8 8 2 7 2 6 3 4 allowance credit loss allowance loan losses 1 1 7 8 2 1 4 9 4 5 1 1 7 8 2 1 4 9 4 5 allowance lendingrelate commitments 3 8 3 5 6 4 3 2 3 8 3 5 6 4 3 2 total allowance credit losses 1 5 6 1 2 7 1 3 4 2 1 5 6 1 2 7 1 3 4 2 net chargeoff ratead 0 . 0 5 % 0 . 2 1 % 0 . 4 9 % 2 . 6 1 % allowance loan loss periodend loan retainedad 2 . 1 0 3 . 9 8 2 . 1 0 3 . 9 8 allowance loan loss nonaccrual loan retainedacd 7 9 1 1 2 7 9 1 1 2 nonaccrual loan periodend loans 2 . 8 3 3 . 9 5 2 . 8 3 3 . 9 5 market riskaverage trading credit portfolio var 9 5 % confidence level trading activity fix income $ 4 5 $ 6 4 3 0 $ 4 7 $ 6 6 2 9 foreign exchange 9 1 0 1 0 1 0 1 2 1 7 equities 2 5 2 0 2 5 2 7 2 2 2 3 commodities other 1 6 2 0 2 0 1 5 1 8 1 7 diversificatione 3 7 4 2 1 2 3 8 4 6 1 7 total trading varf 5 8 7 2 1 9 6 1 7 2 1 5 credit portfolio varg 2 7 2 7 2 7 2 3 1 7 diversificatione 8 9 1 1 8 9 1 1 total trading credit portfolio var $ 7 7 $ 9 0 1 4 $ 8 0 $ 8 6 7 aloan retain include credit portfolio loan leverage lease accrual loan exclude loan heldforsale loan fair value . badjuste asset nongaap financial measure equal total asset minus 1 security purchase resale agreement security borrow security sell purchase 2 asset consolidated variable interest entity vie 3 cash security segregate deposit regulatory purpose 4 goodwill intangible 5 security receive collateral . adjust asset present assist reader compare ibs asset capital level investment bank security industry . assettoequity leverage ratio commonly use measure assess company capital adequacy . ib believe adjust asset exclude asset discuss consider low risk profile provide meaningful measure balance sheet leverage security industry . callowance loan loss $ 3 7 7 million $ 6 1 7 million hold nonaccrual loan june 3 0 2 0 1 1 2 0 1 0 respectively . dloan heldforsale loan fair value exclude calculate allowance coverage ratio net chargeoff rate . 2 1 eaverage valueatrisk var sum var component describe portfolio diversification . diversification effect reflect fact risk perfectly correlate . risk portfolio position usually sum risk position themselves . ftrading var include substantially trading activity ib include credit spread sensitivity certain mortgage product syndicate lending facility firm intend distribute particular risk parameter certain product fully capture example correlation risk . trading var include debit valuation adjustment dva derivative structured liability reflect credit quality firm . var discussion page 8 8 9 1 dva sensitivity table page 9 1 form 1 0 q details . gcredit portfolio var include derivative credit valuation adjustment cva hedge cva marktomarket mtm hedge retained loan portfolio report principal transaction revenue . var include retained loan portfolio mtm . accorde dealogic month 2 0 1 1 firm rank 1 global investment banking fee generate base revenue 1 global syndicate loan 1 global debt equity equityrelate 2 global announce ma 2 global longterm debt 3 global equity equityrelate base volume . month endedjune 3 0 2 0 1 1 fullyear 2 0 1 0 market share rankingsamarket share ranking market share rankingsglobal investment banking feesb 8 . 8 % 1 7 . 6 % 1 debt equity equityrelate global 6 . 9 1 7 . 2 1 u . s . 1 1 . 5 1 1 1 . 1 1 syndicated loan global 1 2 . 4 1 8 . 5 2 u . s . 2 2 . 8 1 1 9 . 2 2 longterm debtc global 6 . 8 2 7 . 2 2 u . s . 1 1 . 5 1 1 0 . 9 2 equity equityrelate globald 7 . 2 3 7 . 3 3 u . s . 1 1 . 9 2 1 3 . 1 2 announced mae global 2 0 . 5 2 1 6 . 4 3 u . s . 3 3 . 9 1 2 3 . 1 3 asource dealogic . global investment banking fee reflect rank fee market share . remainder ranking reflect transaction volume rank market share . bglobal investment banking fee exclude money market shortterm debt shelf deals . clongterm debt table include investmentgrade highyield supranational sovereigns agency cover bond assetbacke security abs mortgagebacke security exclude money market shortterm debt u . s . municipal securities . dequity equityrelate ranking include right offering chinese ashares . eglobal announce ma base transaction value announcement ranking base transaction proceed credit book managerequal joint . joint assignment market share participant add 1 0 0 % . ma yeartodate 2 0 1 1 fullyear 2 0 1 0 reflect removal withdraw transaction . u . s . announce ma represent u . s . involvement ranking . international metricsthree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changetotal net revenuea europemiddle eastafrica $ 2 4 7 8 $ 1 5 4 4 6 0 % $ 5 0 7 0 $ 4 4 1 9 1 5 % asiapacific 7 6 2 9 0 1 1 5 1 8 8 4 1 8 8 9 latin americacaribbean 3 3 7 2 4 8 3 6 6 6 4 5 5 8 1 9 north america 3 7 3 7 3 6 3 9 3 7 9 2 9 7 7 8 5 2 total net revenue $ 7 3 1 4 $ 6 3 3 2 1 6 $ 1 5 5 4 7 $ 1 4 6 5 1 6 loans retain periodendb europemiddle eastafrica $ 1 5 3 7 0 $ 1 2 9 5 9 1 9 $ 1 5 3 7 0 $ 1 2 9 5 9 1 9 asiapacific 6 2 1 1 5 6 9 7 9 6 2 1 1 5 6 9 7 9 latin americacaribbean 2 6 3 3 1 7 6 3 4 9 2 6 3 3 1 7 6 3 4 9 north america 3 1 8 9 3 3 3 6 3 0 5 3 1 8 9 3 3 3 6 3 0 5 total loans $ 5 6 1 0 7 $ 5 4 0 4 9 4 $ 5 6 1 0 7 $ 5 4 0 4 9 4 aregional revenue base primarily domicile client andor location trading desk . binclude retain loan base domicile customer . exclude loan heldforsale loan fair value . 2 2 retail financial servicesfor discussion business profile rfs page 7 2 7 8 jpmorgan chase 2 0 1 0 annual report introduction page 4 form 1 0 q . effective july 1 2 0 1 1 rfs organize component 1 consumer business bank retail banking 2 mortgage banking include mortgage production servicing real estate portfolio . consumer business banking include branch banking business banking activity . mortgage production servicing include mortgage origination service activity . real estate portfolio comprise residential mortgage home equity loan include purchase creditimpaire portfolio acquire washington mutual transaction . discussion business segment reorganization subsequent business segment change page 1 7 note 2 4 page 1 8 0 1 8 2 form 1 0 q . selected income statement datathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue lending depositrelate fees $ 8 1 3 $ 7 6 5 6 % $ 1 5 4 9 $ 1 5 9 0 3 % asset management administration commissions 4 9 9 4 3 1 1 6 9 8 4 8 8 1 1 2 mortgage fee relate income 1 1 0 0 8 8 6 2 4 6 1 1 1 5 4 1 6 0 credit card income 5 7 2 4 7 9 1 9 1 1 0 9 9 2 9 1 9 other income 1 3 1 1 6 6 2 1 2 4 2 3 0 9 2 2 noninterest revenue 3 1 1 5 2 7 2 7 1 4 4 4 9 5 5 2 5 0 1 4 net interest income 4 0 2 7 4 2 3 7 5 8 1 1 3 8 6 8 4 7 total net revenuea 7 1 4 2 6 9 6 4 3 1 2 6 0 8 1 3 9 3 4 1 0 provision credit losses 9 9 4 1 5 4 5 3 6 2 1 9 3 5 1 0 4 5 7 noninter expense compensation expense 1 9 3 7 1 7 5 4 1 0 3 8 1 3 3 4 3 1 1 1 noncompensation expense 3 2 7 4 2 1 2 2 5 4 6 2 3 8 4 2 7 2 4 6 amortization intangibles 6 0 6 9 1 3 1 2 0 1 3 9 1 4 total noninter expense 5 2 7 1 3 9 4 5 3 4 1 0 1 7 1 7 8 4 2 3 0 income income tax expense 8 7 7 1 4 7 4 4 1 2 4 4 9 8 8 7 5 income tax expense 4 9 4 6 2 5 2 1 2 6 0 4 3 5 4 0 net income loss $ 3 8 3 $ 8 4 9 5 5 $ 1 6 $ 5 5 3 nmfinancial ratio return common equity 6 % 1 4 % % 5 % overhead ratio 7 4 5 7 8 1 5 6 overhead ratio exclude core deposit intangiblesb 7 3 5 6 8 0 5 5 atotal net revenue include taxequivalent adjustment associate taxexempt loan municipality qualified entity $ 1 million $ 3 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 3 million $ 6 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . brfs use overhead ratio exclude amortization core deposit intangible cdi nongaap financial measure evaluate underlie expense trend business . include cdi amortization expense overhead ratio calculation result high overhead ratio early year low overhead ratio later year method result improve overhead ratio time thing remain equal . nongaap ratio exclude consumer business banking cdi amortization expense relate prior business combination transaction $ 6 0 million $ 6 9 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 2 0 million $ 1 3 9 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . quarterly result retail financial service report net income $ 3 8 3 million compare $ 8 4 9 million prior year . net revenue $ 7 . 1 billion increase $ 1 7 8 million 3 % compare prior year . net interest income $ 4 . 0 billion $ 2 1 0 million 5 % reflect impact low loan balance portfolio runoff largely offset increase deposit balance . noninterest revenue $ 3 . 1 billion $ 3 8 8 million 1 4 % drive high mortgage fee related income debit card income depositrelate fee investment sale revenue . the provision credit loss $ 9 9 4 million decrease $ 5 5 1 million prior year . delinquency trend net chargeoff improve compare prior year currentquarter provision continue reflect elevated loss mortgage home equity portfolio . consumer credit portfolio page 7 8 form 1 0 q net chargeoff rate . date chargeoff record pci loans . noninter expense $ 5 . 3 billion increase $ 1 . 3 billion 3 4 % prior year drive elevated foreclosure defaultrelated cost include $ 1 . 0 billion estimate litigation cost foreclosurerelated matter . 2 3 yeartodate result retail financial service report net loss $ 1 6 million compare net income $ 5 5 3 million prior year . net revenue $ 1 2 . 6 billion decrease $ 1 . 3 billion 1 0 % compare prior year . net interest income $ 8 . 1 billion $ 5 7 1 million 7 % reflect impact low loan balance portfolio runoff narrow loan spread . noninterest revenue $ 4 . 5 billion $ 7 5 5 million 1 4 % drive low mortgage fee related income partially offset high debit card income investment sale revenue . the provision credit loss $ 2 . 2 billion decrease $ 2 . 9 billion prior year . delinquency trend net chargeoff improve compare prior year currentyear provision continue reflect elevated loss mortgage home equity portfolio . additionally prior year provision include addition allowance loan loss $ 1 . 2 billion purchase creditimpaire portfolio . consumer credit portfolio page 7 8 form 1 0 q net chargeoff rate . date chargeoff record pci loans . noninter expense $ 1 0 . 2 billion increase $ 2 . 3 billion 3 0 % prior year drive elevated foreclosure defaultrelated cost include $ 1 . 7 billion estimate litigation cost foreclosurerelated matter . select metricsthree month end june 3 0 month end june 3 0 million headcount ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeselected balance sheet datum periodend assets $ 2 8 3 7 5 3 $ 3 0 8 9 3 9 8 % $ 2 8 3 7 5 3 $ 3 0 8 9 3 9 8 % loans loan retained 2 4 1 1 2 7 2 6 7 9 5 9 1 0 2 4 1 1 2 7 2 6 7 9 5 9 1 0 loan heldforsale loan fair valuea 1 3 5 5 8 1 2 3 5 0 1 0 1 3 5 5 8 1 2 3 5 0 1 0 total loans 2 5 4 6 8 5 2 8 0 3 0 9 9 2 5 4 6 8 5 2 8 0 3 0 9 9 deposits 3 7 8 3 7 1 3 5 9 1 1 2 5 3 7 8 3 7 1 3 5 9 1 1 2 5 equity 2 5 0 0 0 2 4 6 0 0 2 2 5 0 0 0 2 4 6 0 0 2 selected balance sheet datum average assets $ 2 8 7 2 3 5 $ 3 1 4 0 2 0 9 $ 2 9 2 5 5 7 $ 3 1 9 9 0 6 9 loans loan retained 2 4 4 0 3 0 2 7 2 9 3 4 1 1 2 4 7 2 1 8 2 7 6 9 5 0 1 1 loan heldforsale loan fair valuea 1 4 6 1 3 1 2 6 2 7 1 6 1 6 0 5 8 1 3 5 3 6 1 9 total loans 2 5 8 6 4 3 2 8 5 5 6 1 9 2 6 3 2 7 6 2 9 0 4 8 6 9 deposits 3 7 8 9 3 2 3 6 1 1 5 6 5 3 7 5 3 7 9 3 5 8 6 5 2 5 equity 2 5 0 0 0 2 4 6 0 0 2 2 5 0 0 0 2 4 6 0 0 2 headcount 1 2 2 7 2 8 1 1 1 8 6 1 1 0 1 2 2 7 2 8 1 1 1 8 6 1 1 0 credit datum quality statistic net chargeoffs $ 1 0 6 9 $ 1 5 9 1 3 3 $ 2 2 6 8 $ 3 8 5 4 4 1 nonaccrual loan nonaccrual loan retained 8 0 8 8 1 0 2 4 4 2 1 8 0 8 8 1 0 2 4 4 2 1 nonaccrual loan heldforsale loan fair value 1 4 2 1 7 6 1 9 1 4 2 1 7 6 1 9 total nonaccrual loansbcd 8 2 3 0 1 0 4 2 0 2 1 8 2 3 0 1 0 4 2 0 2 1 nonperforming assetsbcd 9 1 7 5 1 1 6 2 5 2 1 9 1 7 5 1 1 6 2 5 2 1 allowance loan losses 1 5 4 7 9 1 5 1 0 6 2 1 5 4 7 9 1 5 1 0 6 2 net chargeoff ratee 1 . 7 6 % 2 . 3 4 % 1 . 8 5 % 2 . 8 1 % net chargeoff rate exclude pci loansef 2 . 4 6 3 . 2 7 2 . 5 9 3 . 9 3 allowance loan loss end loan retainede 6 . 4 2 5 . 6 4 6 . 4 2 5 . 6 4 allowance loan loss end loan retain exclude pci loansef 6 . 1 2 6 . 4 4 6 . 1 2 6 . 4 4 allowance loan loss nonaccrual loan retainedbef 1 3 0 1 2 0 1 3 0 1 2 0 nonaccrual loan total loans 3 . 2 3 3 . 7 2 3 . 2 3 3 . 7 2 nonaccrual loan total loan exclude pci loansb 4 . 4 3 5 . 1 2 4 . 4 3 5 . 1 2 aloan fair value consist prime mortgage originate intent sell account fair value classify trading asset consolidated balance sheet . loan total $ 1 3 . 3 billion $ 1 2 . 2 billion june 3 0 2 0 1 1 2 0 1 0 respectively . average balance loan total $ 1 4 . 5 billion $ 1 2 . 5 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 6 . 0 billion $ 1 3 . 3 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively . 2 4 bexcludes pci loan acquire washington mutual transaction account pool basis . pool account single asset single composite interest rate aggregate expectation cash flow pastdue status pool individual loan pool meaningful . firm recognize interest income pool loan consider performing . ccertain loan classify trading asset consolidated balance sheet . dat june 3 0 2 0 1 1 2 0 1 0 nonperforme asset exclude 1 mortgage loan insure u . s . government agency $ 9 . 1 billion $ 8 . 9 billion respectively 9 0 day past 2 real estate insure u . s . government agency $ 2 . 4 billion $ 1 . 4 billion respectively . exclude reimbursement insured proceed normally . discussion note 1 3 page 1 3 4 1 4 8 form 1 0 q summarize loan delinquency information . eloan heldforsale loan account fair value exclude calculate allowance coverage ratio net chargeoff rate . fexclude impact pci loan acquire washington mutual transaction . loan account fair value acquisition date incorporate management estimate date credit loss remain life portfolio . allowance loan loss $ 4 . 9 billion $ 2 . 8 billion record loan june 3 0 2 0 1 1 2 0 1 0 respectively exclude applicable ratio . date chargeoff record loans . consumer business bankingselecte income statement datathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changenoninter revenue $ 1 8 8 9 $ 1 6 8 9 1 2 % $ 3 6 4 6 $ 3 4 3 6 6 % net interest income 2 7 0 6 2 7 1 2 5 3 6 5 5 4 4 7 2 total net revenue 4 5 9 5 4 4 0 1 4 9 0 1 1 8 8 8 3 1 provision credit losses 4 2 1 6 0 7 4 1 6 1 3 8 8 5 9 noninterest expense 2 7 1 3 2 6 4 0 3 5 5 1 2 5 2 4 3 5 income income tax expense 1 8 4 0 1 6 0 1 1 5 3 3 3 8 3 2 5 2 3 net income $ 1 0 9 8 $ 9 1 6 2 0 $ 1 9 9 1 $ 1 8 6 1 7 overhead ratio 5 9 % 6 0 % 6 1 % 5 9 % overhead ratio exclude core deposit intangiblesa 5 8 5 8 6 0 5 7 aconsumer business banking use overhead ratio exclude amortization cdi nongaap financial measure evaluate underlie expense trend business . include cdi amortization expense overhead ratio calculation result high overhead ratio early year low overhead ratio later year method result improve overhead ratio time thing remain equal . nongaap ratio exclude consumer business banking cdi amortization expense relate prior business combination transaction $ 6 0 million $ 6 9 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 2 0 million $ 1 3 9 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . quarterly result consumer business banking report net income $ 1 . 1 billion increase $ 1 8 2 million 2 0 % compare prior year . net revenue $ 4 . 6 billion 4 % prior year . net interest income $ 2 . 7 billion flat prior year impact high deposit balance offset predominantly effect low deposit spread . noninterest revenue $ 1 . 9 billion increase 1 2 % drive high debit card revenue depositrelate fee investment sale revenue . provision credit loss $ 4 2 million compare $ 1 6 0 million prior year . net chargeoff $ 1 1 7 million compare $ 2 0 6 million prior year . noninterest expense $ 2 . 7 billion 3 % prior year sale force increase new branch build . yeartodate result consumer business banking report net income $ 2 . 0 billion increase $ 1 3 0 million 7 % compare prior year . net revenue $ 9 . 0 billion 1 % prior year . net interest income $ 5 . 4 billion 2 % prior year impact high deposit balance offset predominantly effect low deposit spread . noninterest revenue $ 3 . 6 billion increase 6 % drive high debit card investment sale revenue . provision credit loss $ 1 6 1 million compare $ 3 8 8 million prior year . net chargeoff $ 2 3 6 million compare $ 3 8 8 million prior year . noninterest expense $ 5 . 5 billion 5 % prior year result sale force increase new branch build . 2 5 selected metricsthree month end june 3 0 month end june 3 0 billion ratio noted 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changebusiness metric business banking origination volume millions $ 1 5 7 3 $ 1 2 2 2 2 9 % $ 2 9 9 8 $ 2 1 2 7 4 1 % endofperiod loan owned 1 7 . 1 1 6 . 6 3 1 7 . 1 1 6 . 6 3 endofperiod deposit checking 1 3 6 . 3 1 2 3 . 6 1 0 1 3 6 . 3 1 2 3 . 6 1 0 savings 1 8 2 . 1 1 6 5 . 8 1 0 1 8 2 . 1 1 6 5 . 8 1 0 time other 4 2 . 0 5 0 . 6 1 7 4 2 . 0 5 0 . 6 1 7 total endofperiod deposits 3 6 0 . 4 3 4 0 . 0 6 3 6 0 . 4 3 4 0 . 0 6 average loan owned $ 1 7 . 1 $ 1 6 . 7 2 $ 1 7 . 0 $ 1 7 . 2 1 average deposit checking $ 1 3 6 . 6 $ 1 2 3 . 7 1 0 $ 1 3 4 . 3 $ 1 2 1 . 9 1 0 savings 1 8 0 . 9 1 6 6 . 8 8 1 7 8 . 0 1 6 4 . 7 8 time other 4 3 . 0 5 1 . 6 1 7 $ 4 4 . 0 5 3 . 7 1 8 total average deposits 3 6 0 . 5 3 4 2 . 1 5 3 5 6 . 3 3 4 0 . 3 5 deposit margin 2 . 8 3 % 3 . 0 1 % 2 . 8 6 % 2 . 9 9 % average assets $ 2 9 . 0 $ 2 9 . 2 1 $ 2 9 . 2 $ 2 9 . 8 2 credit datum quality statistic million ratio net chargeoffs $ 1 1 7 $ 2 0 6 4 3 $ 2 3 6 $ 3 8 8 3 9 net chargeoff rate 2 . 7 4 % 4 . 9 5 % 2 . 8 0 % 4 . 5 5 % nonperforme assets $ 7 8 4 $ 9 2 0 1 5 $ 7 8 4 $ 9 2 0 1 5 retail branch business metric investment sale volume millions $ 6 3 3 4 $ 5 7 5 6 1 0 $ 1 2 9 1 8 $ 1 1 7 1 2 1 0 number branches 5 3 4 0 5 1 5 9 4 5 3 4 0 5 1 5 9 4 atms 1 6 4 4 3 1 5 6 5 4 5 1 6 4 4 3 1 5 6 5 4 5 personal bankers 2 3 3 0 8 2 0 1 7 0 1 6 2 3 3 0 8 2 0 1 7 0 1 6 sales specialists 7 6 3 0 6 7 8 5 1 2 7 6 3 0 6 7 8 5 1 2 active online customer thousands 1 8 0 8 5 1 6 5 8 4 9 1 8 0 8 5 1 6 5 8 4 9 checking account thousands 2 6 2 6 6 2 6 3 5 1 2 6 2 6 6 2 6 3 5 1 2 6 mortgage production servicingselecte income statement datathree month end june 3 0 month end june 3 0 million ratio 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changenoninterest revenue $ 1 2 0 6 $ 9 8 6 2 2 % $ 8 2 1 $ 1 7 3 0 5 3 % net interest income 1 2 4 2 1 2 8 2 1 4 2 7 4 4 3 9 5 4 2 8 8 total net revenue 1 3 3 0 0 . 0 0 0 2 7 1 1 1 9 8 2 3 2 1 1 0 . 0 0 0 2 1 6 1 2 1 6 2 1 5 8 4 4 provision credit losses 2 1 3 nm 2 1 9 8 9 noninterest expense 2 1 8 7 9 0 0 1 4 3 3 9 3 3 1 7 7 5 1 2 2 incomeloss income tax expensebenefit 8 5 5 2 8 5 nm 2 7 1 9 3 6 4 nmnet incomeloss $ 6 4 9 $ 1 6 9 nm $ 1 7 7 9 $ 2 1 4 nmoverhead ratio 1 6 4 % 7 5 % 3 2 3 % 8 2 % quarterly result mortgage production servicing report net loss $ 6 4 9 million compare net income $ 1 6 9 million prior year . net revenue $ 1 . 3 billion increase $ 1 3 2 million 1 1 % prior year . net revenue second quarter 2 0 1 1 include $ 1 . 1 billion mortgage fee related income $ 1 2 4 million net interest income $ 1 0 6 million noninter revenue . mortgage fee related income comprise $ 5 4 4 million net production revenue $ 5 3 3 million service operate revenue $ 2 3 million msr risk management revenue . production revenue excluding repurchase loss $ 7 6 7 million increase $ 9 1 million reflect wide margin . total production revenue reduce $ 2 2 3 million repurchase loss compare repurchase loss $ 6 6 7 million prior year . service operate revenue decline 6 % prior year runoff servicing portfolio . msr risk management revenue decline $ 2 8 8 million prior year . noninter expense $ 2 . 2 billion $ 1 . 3 billion prior year . increase drive $ 1 . 0 billion estimate litigation cost foreclosurerelated matter increase defaultrelate expense serviced portfolio . yeartodate result mortgage production servicing report net loss $ 1 . 8 billion compare net income $ 2 1 4 million prior year . net revenue $ 1 . 2 billion decrease $ 9 4 2 million 4 4 % prior year . net revenue half 2 0 1 1 include $ 6 1 1 million mortgage fee related income $ 3 9 5 million net interest income $ 2 1 0 million noninter revenue . mortgage fee related income comprise $ 8 0 3 million net production revenue $ 1 . 0 billion service operate revenue $ 1 . 2 billion msr risk management loss . production revenue excluding repurchase loss $ 1 . 4 billion increase $ 3 3 7 million reflect high mortgage origination volume wide margin . total production revenue reduce $ 6 4 3 million repurchase loss compare repurchase loss $ 1 . 1 billion prior year . service operate revenue decline 4 % prior year . msr risk management revenue decline $ 1 . 7 billion prior year reflect $ 1 . 1 billion decline fair value msr asset recognize quarter 2 0 1 1 relate revise cost service assumption incorporate valuation reflect estimate impact high servicing cost enhance servicing process particularly loan modification foreclosure procedure high estimate cost comply consent order enter banking regulator . decline fair value msr asset result decrease interest rates . noninterest expense $ 3 . 9 billion $ 2 . 2 billion 1 2 2 % prior year drive $ 1 . 7 billion record estimate litigation cost foreclosurerelated matter increase defaultrelate expense service portfolio . 2 7 selected metricsthree month end june 3 0 month end june 3 0 billion ratio noted 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changebusiness metric endofperiod loan prime mortgage include option armsa $ 1 4 . 3 $ 1 3 . 2 8 % $ 1 4 . 3 $ 1 3 . 2 8 % average loan prime mortgage include option armsab 1 4 . 1 1 3 . 6 4 1 4 . 1 1 3 . 0 8 credit datum quality statistic million ratio net chargeoffsrecoverie prime mortgage include option arms $ 2 $ 1 3 nm $ 2 $ 1 9 8 9 net chargeoffrecovery rate prime mortgage include option armsb 0 . 0 6 % 0 . 3 9 % 0 . 0 3 % 0 . 3 0 % 3 0 day delinquency ratecd 3 . 3 0 3 . 2 2 3 . 3 0 3 . 2 2 nonperforme asset millionse $ 6 6 2 $ 7 3 1 9 $ 6 6 2 $ 7 3 1 9 origination volume mortgage origination volume channel retail $ 2 0 . 7 $ 1 5 . 3 3 5 $ 4 1 . 7 $ 2 6 . 7 5 6 wholesalef 0 . 1 0 . 4 7 5 0 . 3 0 . 8 6 3 correspondentf 1 0 . 3 1 4 . 7 3 0 2 3 . 8 3 0 . 7 2 2 cnt negotiate transactions 2 . 9 1 . 8 6 1 4 . 4 5 . 7 2 3 total mortgage origination volume 3 4 . 0 3 2 . 2 6 7 0 . 2 6 3 . 9 1 0 application volume mortgage application volume channel retail $ 3 3 . 6 $ 2 7 . 8 2 1 $ 6 4 . 9 $ 4 8 . 1 3 5 wholesalef 0 . 3 0 . 6 5 0 0 . 6 1 . 4 5 7 correspondentf 1 4 . 9 2 3 . 5 3 7 2 8 . 5 4 1 . 7 3 2 total mortgage application volume $ 4 8 . 8 $ 5 1 . 9 6 $ 9 4 . 0 $ 9 1 . 2 3 average mortgage loan heldforsale loan fair valueg $ 1 4 . 6 $ 1 2 . 6 1 6 $ 1 6 . 1 $ 1 3 . 5 1 9 average assets 5 8 . 1 5 4 . 5 7 5 9 . 7 5 4 . 9 9 repurchase reserve ending 3 . 2 2 . 0 6 0 3 . 2 2 . 0 6 0 thirdparty mortgage loan service ending 9 4 0 . 8 1 0 5 5 . 2 1 1 9 4 0 . 8 1 0 5 5 . 2 1 1 thirdparty mortgage loan service average 9 4 7 . 0 1 0 6 3 . 7 1 1 9 5 2 . 9 1 0 7 0 . 1 1 1 msr net carry value ending 1 2 . 2 1 1 . 8 3 1 2 . 2 1 1 . 8 3 ratio msr net carry value end thirdparty mortgage loan service ending 1 . 3 0 % 1 . 1 2 % 1 . 3 0 % 1 . 1 2 % ratio annualize loan service revenue thirdparty mortgage loan service average 0 . 4 3 0 . 4 5 0 . 4 4 0 . 4 3 msr revenue multipleh 3 . 0 2 x 2 . 4 9 x 2 . 9 5 x 2 . 6 0 x 2 8 month end june 3 0 month end june 3 0 supplemental mortgage fee related income detailsin millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changenet production revenue production revenue $ 7 6 7 $ 6 7 6 1 3 % $ 1 4 4 6 $ 1 1 0 9 3 0 % repurchase losses 2 2 3 6 6 7 6 7 6 4 3 1 0 9 9 4 1 net production revenue 5 4 4 9 nm 8 0 3 1 0 nmnet mortgage service revenue operate revenue loan service revenue 1 0 1 1 1 1 8 6 1 5 2 0 6 3 2 2 9 3 1 0 other change msr asset fair value 4 7 8 6 2 0 2 3 1 0 4 1 1 2 2 5 1 5 total operate revenue 5 3 3 5 6 6 6 1 0 2 2 1 0 6 8 4 risk management change msr asset fair value input assumption modeli 9 6 0 3 5 8 4 7 3 1 7 1 1 3 6 8 0 5 4 derivative valuation adjustment other 9 8 3 3 8 9 5 7 5 4 9 7 4 1 4 3 8 8 total risk management 2 3 3 1 1 9 3 1 2 1 4 4 6 3 nmtotal net mortgage service revenue 5 5 6 8 7 7 3 7 1 9 2 1 5 3 1 nmmortgage fee relate income $ 1 1 0 0 $ 8 8 6 2 4 $ 6 1 1 $ 1 5 4 1 6 0 apredominantly represent prime loan repurchase government national mortgage association ginnie mae pool insure u . s . government agency . discussion loan repurchase ginnie mae pool mortgage repurchase liability page 5 3 5 6 form 1 0 q . baverage loan include loan heldforsale $ 7 6 million $ 1 1 4 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 0 4 million $ 2 0 2 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . exclude calculate net chargeoff rate . cat june 3 0 2 0 1 1 2 0 1 0 endofperiod loan include loan heldforsale $ 2 2 1 million $ 1 8 5 million respectively . exclude calculate 3 0 day delinquency rate . dat june 3 0 2 0 1 1 2 0 1 0 exclude mortgage loan insure u . s . government agency $ 1 0 . 1 billion $ 9 . 8 billion respectively . exclude reimbursement insured proceed normally . eat june 3 0 2 0 1 1 2 0 1 0 nonperforme asset exclude 1 mortgage loan insure u . s . government agency $ 9 . 1 billion $ 8 . 9 billion respectively 9 0 day past 2 real estate insure u . s . government agency $ 2 . 4 billion $ 1 . 4 billion respectively . exclude reimbursement insured proceed normally . finclude rural housing loan source broker correspondent underwrite rural housing authority guidelines . gloan fair value consist prime mortgage originate intent sell account fair value classify trading asset consolidated balance sheet . average balance loan total $ 1 4 . 5 billion $ 1 2 . 5 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 6 . 0 billion $ 1 3 . 3 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively . hrepresent ratio msr net carry value end thirdparty mortgage loan service end divide ratio annualize loan service revenue thirdparty mortgage loan service average . iof total decrease recognize month end june 3 0 2 0 1 1 $ 1 . 1 billion relate revise cost service assumption incorporate valuation quarter 2 0 1 1 reflect estimate impact high servicing cost enhance servicing process particularly relate loan modification foreclosure procedure high estimate cost comply consent order enter banking regulator . $ 1 . 7 billion change change input assumption include decrease fair value msr asset result decrease interest rate . decline interest rate effect decrease fair value msr asset increase fair value derivative use risk management purpose . additional information msrs note 3 note 1 6 page 1 0 2 1 1 4 1 5 9 1 6 3 respectively form 1 0 q . 2 9 real estate portfoliosselecte income statement datathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changenoninter revenue $ 2 0 $ 5 2 6 2 % $ 2 8 $ 8 4 6 7 % net interest income 1 1 9 7 1 3 1 3 9 2 3 5 3 2 8 0 9 1 6 total net revenue 1 2 1 7 1 3 6 5 1 1 2 3 8 1 2 8 9 3 1 8 provision credit losses 9 5 4 1 3 7 2 3 0 2 0 3 0 4 6 9 7 5 7 noninter expense 3 7 1 4 0 5 8 7 2 6 8 2 4 1 2 incomeloss income tax expensebenefit 1 0 8 4 1 2 7 4 3 7 5 2 6 2 8 8 6 net incomeloss $ 6 6 $ 2 3 6 7 2 $ 2 2 8 $ 1 5 2 2 8 5 overhead ratio 3 0 % 3 0 % 3 0 % 2 8 % quarterly result real estate portfolio report net loss $ 6 6 million compare net loss $ 2 3 6 million prior year . improvement drive low provision credit loss partially offset low net revenue . net revenue $ 1 . 2 billion $ 1 4 8 million 1 1 % prior year . decrease drive decline net interest income result low loan balance portfolio runoff partially offset wide loan spreads . the provision credit loss $ 9 5 4 million compare $ 1 . 4 billion prior year . currentquarter provision reflect $ 4 1 8 million reduction net chargeoff drive modest improvement delinquency trends . noninterest expense $ 3 7 1 million $ 3 4 million 8 % prior year reflect decrease foreclose asset expense . yeartodate result real estate portfolio report net loss $ 2 2 8 million compare net loss $ 1 . 5 billion prior year . improvement drive low provision credit loss partially offset low net revenue . net revenue $ 2 . 4 billion $ 5 1 2 million 1 8 % prior year . decrease drive decline net interest income result low loan balance portfolio runoff narrow loan spreads . the provision credit loss $ 2 . 0 billion compare $ 4 . 7 billion prior year . currentyear provision reflect $ 1 . 4 billion reduction net chargeoff drive improve delinquency trend . prioryear provision include addition allowance loan loss $ 1 . 2 billion washington mutual pci portfolio . noninterest expense $ 7 2 6 million $ 9 8 million 1 2 % prior year reflect decrease foreclose asset expense . 3 0 selected metricsthree month end june 3 0 month end june 3 0 billions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeloan exclude pcia endofperiod loan home equity $ 8 2 . 7 $ 9 4 . 8 1 3 % $ 8 2 . 7 $ 9 4 . 8 1 3 % prime mortgage include option arms 4 7 . 0 5 3 . 1 1 1 4 7 . 0 5 3 . 1 1 1 subprime mortgage 1 0 . 4 1 2 . 6 1 7 1 0 . 4 1 2 . 6 1 7 other 0 . 8 1 . 0 2 0 0 . 8 1 . 0 2 0 total endofperiod loan owned $ 1 4 0 . 9 $ 1 6 1 . 5 1 3 $ 1 4 0 . 9 $ 1 6 1 . 5 1 3 average loan home equity $ 8 4 . 0 $ 9 6 . 3 1 3 $ 8 5 . 5 $ 9 7 . 9 1 3 prime mortgage include option arms 4 7 . 6 5 4 . 3 1 2 4 8 . 4 5 5 . 5 1 3 subprime mortgage 1 0 . 7 1 3 . 1 1 8 1 0 . 9 1 3 . 4 1 9 other 0 . 8 1 . 0 2 0 0 . 8 1 . 0 2 0 total average loan owned $ 1 4 3 . 1 $ 1 6 4 . 7 1 3 $ 1 4 5 . 6 $ 1 6 7 . 8 1 3 pci loansa endofperiod loan home equity $ 2 3 . 5 $ 2 5 . 5 8 $ 2 3 . 5 $ 2 5 . 5 8 prime mortgage 1 6 . 2 1 8 . 5 1 2 1 6 . 2 1 8 . 5 1 2 subprime mortgage 5 . 2 5 . 6 7 5 . 2 5 . 6 7 option arms 2 4 . 1 2 7 . 3 1 2 2 4 . 1 2 7 . 3 1 2 total endofperiod loan owned $ 6 9 . 0 $ 7 6 . 9 1 0 $ 6 9 . 0 $ 7 6 . 9 1 0 average loan home equity $ 2 3 . 7 $ 2 5 . 7 8 $ 2 3 . 9 $ 2 6 . 0 8 prime mortgage 1 6 . 5 1 8 . 8 1 2 1 6 . 7 1 9 . 1 1 3 subprime mortgage 5 . 2 5 . 8 1 0 5 . 3 5 . 8 9 option arms 2 4 . 4 2 7 . 7 1 2 2 4 . 8 2 8 . 2 1 2 total average loan owned $ 6 9 . 8 $ 7 8 . 0 1 1 $ 7 0 . 7 $ 7 9 . 1 1 1 total real estate portfolio endofperiod loan home equity $ 1 0 6 . 2 $ 1 2 0 . 3 1 2 $ 1 0 6 . 2 $ 1 2 0 . 3 1 2 prime mortgage include option arms 8 7 . 3 9 8 . 9 1 2 8 7 . 3 9 8 . 9 1 2 subprime mortgage 1 5 . 6 1 8 . 2 1 4 1 5 . 6 1 8 . 2 1 4 other 0 . 8 1 . 0 2 0 0 . 8 1 . 0 2 0 total endofperiod loan owned $ 2 0 9 . 9 $ 2 3 8 . 4 1 2 $ 2 0 9 . 9 $ 2 3 8 . 4 1 2 average loan home equity $ 1 0 7 . 7 $ 1 2 2 . 0 1 2 $ 1 0 9 . 4 $ 1 2 3 . 9 1 2 prime mortgage include option arms 8 8 . 5 1 0 0 . 8 1 2 8 9 . 9 1 0 2 . 8 1 3 subprime mortgage 1 5 . 9 1 8 . 9 1 6 1 6 . 2 1 9 . 2 1 6 other 0 . 8 1 . 0 2 0 0 . 8 1 . 0 2 0 total average loan owned $ 2 1 2 . 9 $ 2 4 2 . 7 1 2 $ 2 1 6 . 3 $ 2 4 6 . 9 1 2 average assets $ 2 0 0 . 1 $ 2 3 0 . 3 1 3 $ 2 0 3 . 6 $ 2 3 5 . 2 1 3 home equity origination volume 0 . 3 0 . 3 0 . 5 0 . 6 1 7 apci loan represent loan acquire washington mutual transaction deterioration credit quality occur origination date jpmorgan chase acquisition date . loan initially record fair value accrete interest income estimate life loan long cash flow reasonably estimable underlie loan contractually past . include real estate portfolio pci loan firm acquire washington mutual transaction . pci loan excess undiscounted gross cash flow expect collect carry value loan accretable yield accrete interest income level rate return expect life loan . net spread pci loan related liability expect relatively constant time basis risk residual interest rate risk remain certain change accretable yield percentage e . g . extended loan liquidation period prepayment . june 3 0 2 0 1 1 remain weightedaverage life pci loan portfolio expect 6 . 9 year . information note 1 3 pci loan page 1 4 5 1 4 6 form 1 0 q . loan balance expect decline rapidly early year troubled loan liquidate slowly remain troubled borrower limit refinance opportunity . similarly default servicing expense expect high early year decline time liquidation slow . date impact pci loan real estate portfolio net income modestly negative . current net spread portfolio provision loan loss recognize subsequent acquisition high level default service expense associate portfolio . time firm expect portfolio contribute positively net income . 3 1 credit datum quality statisticsthree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changenet chargeoff exclude pci loansa home equity $ 5 9 2 $ 7 9 6 2 6 % $ 1 3 1 2 $ 1 9 2 2 3 2 % prime mortgage include option arms 1 9 8 2 7 3 2 7 3 5 9 7 4 9 5 2 subprime mortgage 1 5 6 2 8 2 4 5 3 4 2 7 3 9 5 4 other 8 2 1 6 2 1 7 3 7 5 4 total net chargeoffs $ 9 5 4 $ 1 3 7 2 3 0 $ 2 0 3 0 $ 3 4 4 7 4 1 net chargeoff rate exclude pci loansa home equity 2 . 8 3 % 3 . 3 2 % 3 . 0 9 % 3 . 9 6 % prime mortgage include option arms 1 . 6 7 2 . 0 2 1 . 5 0 2 . 7 2 subprime mortgage 5 . 8 5 8 . 6 3 6 . 3 3 1 1 . 1 2 other 4 . 0 1 8 . 4 2 4 . 2 9 7 . 4 6 total net chargeoff rate exclude pci loans 2 . 6 7 3 . 3 4 2 . 8 1 4 . 1 4 net chargeoff rate report home equity 2 . 2 0 % 2 . 6 2 % 2 . 4 2 % 3 . 1 3 % prime mortgage include option arms 0 . 9 0 1 . 0 9 0 . 8 1 1 . 4 7 subprime mortgage 3 . 9 4 5 . 9 8 4 . 2 6 7 . 7 6 other 4 . 0 1 8 . 4 2 4 . 2 9 7 . 4 6 total net chargeoff rate reported 1 . 8 0 2 . 2 7 1 . 8 9 2 . 8 2 3 0 day delinquency rate exclude pci loansb 5 . 9 8 % 6 . 8 8 % 5 . 9 8 % 6 . 8 8 % allowance loan losses $ 1 4 6 5 9 $ 1 4 1 2 7 4 $ 1 4 6 5 9 $ 1 4 1 2 7 4 nonperforming assetsc 7 7 2 9 9 9 7 4 2 3 7 7 2 9 9 9 7 4 2 3 allowance loan loss end loan retained 6 . 9 8 % 5 . 9 3 % 6 . 9 8 % 5 . 9 3 % allowance loan loss end loan retain exclude pci loansa 6 . 9 0 7 . 0 1 6 . 9 0 7 . 0 1 aexclude impact pci loan acquire washington mutual transaction . loan account fair value acquisition date incorporate management estimate date credit loss remain life portfolio . allowance loan loss $ 4 . 9 billion $ 2 . 8 billion record loan june 3 0 2 0 1 1 2 0 1 0 respectively exclude applicable ratio . date chargeoff record loans . bat june 3 0 2 0 1 1 2 0 1 0 delinquency rate pci loan 2 6 . 2 0 % 2 7 . 9 1 % respectively . cexclude pci loan acquire washington mutual transaction account pool basis . pool account single asset single composite interest rate aggregate expectation cash flow pastdue status pool individual loan pool meaningful . firm recognize interest income pool loan consider performing . 3 2 card service autofor discussion business profile card page 7 9 8 1 jpmorgan chase 2 0 1 0 annual report introduction page 4 form 1 0 q . effective july 1 2 0 1 1 card include auto student lending . discussion business segment reorganization subsequent business segment change page 1 7 note 2 4 page 1 8 0 1 8 2 form 1 0 q . selected income statement dataathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue credit card income $ 1 1 2 3 $ 9 0 9 2 4 % $ 2 0 2 1 $ 1 7 2 2 1 7 % incomeb 1 8 3 2 1 7 1 6 3 3 2 3 9 1 1 5 noninterest revenuec 1 3 0 6 1 1 2 6 1 6 2 3 5 3 2 1 1 3 1 1 net interest income 3 4 5 5 3 9 3 6 1 2 7 1 9 9 8 2 0 2 1 2 total net revenued 4 7 6 1 5 0 6 2 6 9 5 5 2 1 0 3 1 5 7 provision credit losses 9 4 4 2 3 9 1 6 1 1 2 9 7 6 0 7 7 7 9 noninter expense compensation expense 4 4 8 4 1 5 8 9 0 7 8 3 8 8 noncompensation expense 1 4 3 6 1 2 3 3 1 6 2 7 8 8 2 4 3 4 1 5 amortization intangibles 1 0 4 1 2 4 1 6 2 1 0 2 4 7 1 5 total noninter expensee 1 9 8 8 1 7 7 2 1 2 3 9 0 5 3 5 1 9 1 1 income income tax expense 1 8 2 9 8 9 9 1 0 3 4 3 5 0 7 1 9 nmincome tax expense 7 1 9 3 6 3 9 8 1 7 0 6 3 2 1 4 3 1 net income $ 1 1 1 0 $ 5 3 6 1 0 7 $ 2 6 4 4 $ 3 9 8 nmfinancial ratiosa return common equity 2 8 % 1 2 % 3 3 % 4 % overhead ratio 4 2 3 5 4 1 3 4 aeffective january 1 2 0 1 1 commercial card business previously tss transfer card . material impact financial data prioryear period revise . commercial card portfolio exclude business metric supplemental information noted . binclude impact revenue sharing agreement jpmorgan chase business segment . cinclude commercial card noninter revenue $ 7 5 million $ 1 4 7 million month end june 3 0 2 0 1 1 respectively . dtotal net revenue include taxequivalent adjustment associate taxexempt loan certain qualified entity $ 1 million $ 2 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 2 million $ 4 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . einclude commercial card noninter expense $ 6 9 million $ 1 4 4 million month end june 3 0 2 0 1 1 respectively . quarterly result net income $ 1 . 1 billion compare $ 5 3 6 million prior year . improve result drive low provision credit loss partially offset low net revenue . endofperiod loan $ 1 8 6 . 3 billion decrease $ 1 9 . 3 billion 9 % prior year . average loan $ 1 8 6 . 1 billion decrease $ 2 4 . 3 billion 1 2 % prior year . decline endofperiod average total loan predominantly relate credit card portfolio consistent expectation . credit card endofperiod average loan total reflect impact firm sale $ 3 . 7 billion kohls portfolio april 1 2 0 1 1 . net revenue $ 4 . 8 billion decrease $ 3 0 1 million 6 % prior year . net interest income $ 3 . 5 billion $ 4 8 1 million 1 2 % . decrease net interest income drive low average loan balance include impact kohls portfolio sale impact legislative change decrease level fee . decrease largely offset low revenue reversal associate low chargeoff . noninterest revenue $ 1 . 3 billion increase $ 1 8 0 million 1 6 % prior year . increase drive low partner revenueshare impact kohls portfolio sale high net interchange income transfer commercial card business card tss quarter 2 0 1 1 . exclude impact commercial card business noninter revenue increase 9 % . provision credit loss $ 9 4 4 million compare $ 2 . 4 billion prior year . currentquarter provision reflect low net chargeoff reduction $ 1 . 0 billion allowance loan loss low estimate loss . prioryear provision include reduction $ 1 . 5 billion allowance loan loss . net chargeoff rate 4 . 2 4 % 7 . 4 8 % prior year . 3 0 day delinquency rate 2 . 3 8 % 3 . 7 7 % prior year . card service ' exclude washington mutual commercial card portfolio net chargeoff rate 1 5 . 2 8 % 9 . 0 2 % prior year 3 0 day delinquency rate 2 . 7 3 % 4 . 4 8 % prior year . auto loan net chargeoff rate 0 . 1 6 % 0 . 4 9 % prior year . student loan net chargeoff rate 3 . 8 3 % 3 . 0 1 % prior year . noninter expense $ 2 . 0 billion increase $ 2 1 6 million 1 2 % prior year high marketing expense inclusion commercial card business . exclude impact commercial card business noninter expense increase 8 % . 3 3 yeartodate result net income $ 2 . 6 billion compare $ 3 9 8 million prior year . improve result drive low provision credit loss partially offset low net revenue . average loan $ 1 9 0 . 4 billion decrease $ 2 5 . 0 billion 1 2 % prior year . decline average total loan predominantly relate credit card portfolio consistent expectation reflect impact firm sale $ 3 . 7 billion kohls portfolio april 1 2 0 1 1 . net revenue $ 9 . 6 billion decrease $ 7 6 3 million 7 % prior year . net interest income $ 7 . 2 billion $ 1 . 0 billion 1 2 % . decrease net interest income drive low average loan balance include impact kohls portfolio sale impact legislative change decrease level fee . decrease largely offset low revenue reversal associate low chargeoff . noninterest revenue $ 2 . 4 billion increase $ 2 4 0 million 1 1 % prior year . increase drive transfer commercial card business card tss quarter 2 0 1 1 high net interchange income partially offset low revenue feebase product . exclude impact commercial card business noninter revenue increase 4 % . provision credit loss $ 1 . 3 billion compare $ 6 . 1 billion prior year . currentyear provision reflect low net chargeoff reduction $ 3 . 0 billion allowance loan loss low estimate loss . prioryear provision include reduction $ 2 . 5 billion allowance loan loss . net chargeoff rate 4 . 6 1 % 8 . 1 1 % prior year . card service ' exclude washington mutual commercial card portfolio net chargeoff rate 1 5 . 7 5 % 9 . 8 0 % prior year . auto loan net chargeoff rate 0 . 2 8 % 0 . 6 8 % prior year . student loan net chargeoff rate 3 . 0 4 % 2 . 4 8 % prior year . noninter expense $ 3 . 9 billion increase $ 3 8 6 million 1 1 % prior year inclusion commercial card business high marketing expense . exclude impact commercial card business noninter expense increase 7 % . information credit card legislative change card discussion page 7 9 jpmorgan chase 2 0 1 0 annual report . 1 credit card include loan heldforsale nongaap financial measure provide meaningful measure enable comparability withprior periods . selecte metricsthree month end june 3 0 month end june 3 0 million headcount ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeselected balance sheet datum periodenda loan credit card $ 1 2 5 5 2 3 $ 1 4 2 9 9 4 1 2 % $ 1 2 5 5 2 3 $ 1 4 2 9 9 4 1 2 % auto 4 6 7 9 6 4 7 5 4 8 2 4 6 7 9 6 4 7 5 4 8 2 student 1 4 0 0 3 1 5 0 7 1 7 1 4 0 0 3 1 5 0 7 1 7 total loansb 1 8 6 3 2 2 2 0 5 6 1 3 9 1 8 6 3 2 2 2 0 5 6 1 3 9 equity 1 6 0 0 0 1 8 4 0 0 1 3 1 6 0 0 0 1 8 4 0 0 1 3 selected balance sheet datum averagea total assets $ 1 9 8 0 4 4 $ 2 1 4 7 0 2 8 $ 2 0 1 2 2 5 $ 2 1 9 8 1 2 8 loans credit card 1 2 5 0 3 8 1 4 6 3 0 2 1 5 1 2 8 7 6 7 1 5 1 0 2 0 1 5 auto 4 6 9 6 6 4 7 4 5 5 1 4 7 3 2 6 4 7 1 6 3 student 1 4 1 3 5 1 6 7 1 8 1 5 1 4 2 7 2 1 7 2 1 6 1 7 total loansc 1 8 6 1 3 9 2 1 0 4 7 5 1 2 1 9 0 3 6 5 2 1 5 3 9 9 1 2 equity 1 6 0 0 0 1 8 4 0 0 1 3 1 6 0 0 0 1 8 4 0 0 1 3 headcountd 2 6 8 7 4 2 6 5 4 7 1 2 6 8 7 4 2 6 5 4 7 1 credit quality statistic retaineda net chargeoff credit card $ 1 8 1 0 $ 3 7 2 1 5 1 $ 4 0 3 6 $ 8 2 3 3 5 1 auto 1 9 5 8 6 7 6 6 1 6 0 5 9 student 1 3 5 1 1 2 2 1 2 1 5 1 8 5 1 6 total net chargeoffs 1 9 6 4 3 8 9 1 5 0 4 3 1 7 8 5 7 8 5 0 net chargeoff rate credit card e 5 . 8 2 % 1 0 . 2 0 % 6 . 4 0 % 1 0 . 9 9 % auto 0 . 1 6 0 . 4 9 0 . 2 8 0 . 6 8 student f 3 . 8 3 3 . 0 1 3 . 0 4 2 . 4 8 total net chargeoff rate 4 . 2 4 7 . 4 8 4 . 6 1 8 . 1 1 3 4 selected metricsthree month end june 3 0 month end june 3 0 million ratio noted 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changedelinquency rate 3 0 day delinquency rate credit card 2 . 9 8 % 4 . 9 6 % 2 . 9 8 % 4 . 9 6 % auto 0 . 9 8 0 . 9 4 0 . 9 8 0 . 9 4 student gh 1 . 7 0 1 . 4 3 1 . 7 0 1 . 4 3 total 3 0 day delinquency rate 2 . 3 8 3 . 7 7 2 . 3 8 3 . 7 7 9 0 day delinquency rate credit card 1 . 5 5 2 . 7 6 1 . 5 5 2 . 7 6 nonperforme assetsi $ 2 3 3 $ 2 8 5 1 8 % $ 2 3 3 $ 2 8 5 1 8 % allowance loan loss credit card $ 8 0 4 2 $ 1 4 5 2 4 4 5 $ 8 0 4 2 $ 1 4 5 2 4 4 5 auto student 8 7 9 1 0 4 6 1 6 8 7 9 1 0 4 6 1 6 total allowance loan losses 8 9 2 1 1 5 5 7 0 4 3 8 9 2 1 1 5 5 7 0 4 3 allowance loan loss periodend loan credit card 6 . 4 1 % 1 0 . 1 6 % 6 . 4 1 % 1 0 . 1 6 % auto studentg 1 . 4 5 1 . 6 8 1 . 4 5 1 . 6 8 total allowance loan loss periodend loans 4 . 7 9 7 . 5 8 4 . 7 9 7 . 5 8 business metric credit card exclude commercial card sale volume billions $ 8 5 . 5 $ 7 8 . 1 9 $ 1 6 3 . 0 $ 1 4 7 . 5 1 1 new account opened 2 . 0 2 . 7 2 6 4 . 6 5 . 2 1 2 open accountsj 6 5 . 4 8 8 . 9 2 6 6 5 . 4 8 8 . 9 2 6 merchant service bank card volume billions $ 1 3 7 . 3 $ 1 1 7 . 1 1 7 $ 2 6 3 . 0 $ 2 2 5 . 1 1 7 total transaction billions 5 . 9 5 . 0 1 8 1 1 . 5 9 . 7 1 9 auto student origination volume billion auto $ 5 . 4 $ 5 . 8 7 $ 1 0 . 2 $ 1 2 . 1 1 6 student 0 . 1 nm 0 . 1 1 . 7 9 4 supplemental information akl card service exclude washington mutual portfolio loan periodend $ 1 1 3 7 6 6 $ 1 2 7 3 7 9 1 1 $ 1 1 3 7 6 6 $ 1 2 7 3 7 9 1 1 average loans 1 1 2 9 8 4 1 2 9 8 4 7 1 3 1 1 6 1 7 9 1 3 3 4 9 5 1 3 net interest income m 8 . 6 0 % 8 . 4 7 % 8 . 8 5 % 8 . 6 7 % net revenue m 1 2 . 0 1 1 0 . 9 1 1 1 . 7 9 1 0 . 9 1 risk adjust margin mn 8 . 7 1 4 . 2 1 9 . 5 1 3 . 3 0 net chargeoffs $ 1 4 7 1 $ 2 9 2 0 5 0 $ 3 2 7 7 $ 6 4 8 6 4 9 net chargeoff rate o 5 . 2 2 % 9 . 0 2 % 5 . 6 9 % 9 . 8 0 % 3 0 day delinquency rate 2 . 7 1 4 . 4 8 2 . 7 1 4 . 4 8 9 0 day delinquency rate 1 . 4 1 2 . 4 7 1 . 4 1 2 . 4 7 card service exclude washington mutual commercial card portfolio loan periodend $ 1 1 2 3 6 6 $ 1 2 7 3 7 9 1 2 $ 1 1 2 3 6 6 $ 1 2 7 3 7 9 1 2 average loans 1 1 1 6 4 1 1 2 9 8 4 7 1 4 1 1 4 8 7 4 1 3 3 4 9 5 1 4 net interest income m 8 . 7 7 % 8 . 4 7 % 9 . 0 2 % 8 . 6 7 % net revenue m 1 1 . 9 5 1 0 . 9 1 1 1 . 7 3 1 0 . 9 1 risk adjust margin mn 8 . 6 1 4 . 2 1 9 . 4 3 3 . 3 0 net chargeoffs $ 1 4 7 0 $ 2 9 2 0 5 0 $ 3 2 7 6 $ 6 4 8 6 4 9 net chargeoff rate o 5 . 2 8 % 9 . 0 2 % 5 . 7 5 % 9 . 8 0 % 3 0 day delinquency rate p 2 . 7 3 4 . 4 8 2 . 7 3 4 . 4 8 9 0 day delinquency rate q 1 . 4 2 2 . 4 7 1 . 4 2 2 . 4 7 aeffective january 1 2 0 1 1 commercial card business previously tss transfer card . material impact financial data prioryear period revise . commercial card portfolio exclude business metric supplemental information noted . btotal periodend loan include loan heldforsale $ 2 4 9 million june 3 0 2 0 1 0 . loan heldforsale june 3 0 2 0 1 1 . allowance loan loss record loan . loan heldforsale exclude calculate allowance loan loss periodend loan delinquency rates . ctotal average loan include loan heldforsale $ 2 7 6 million $ 1 . 6 billion month end june 3 0 2 0 1 1 respectively $ 1 . 8 billion $ 2 . 2 billion month end june 3 0 2 0 1 0 respectively . exclude calculate net chargeoff rate . dheadcount include 1 2 7 4 employee relate transfer commercial card business tss card quarter 2 0 1 1 . eaverage loan include loan heldforsale $ 2 7 6 million $ 1 . 6 billion month end june 3 0 2 0 1 1 respectively . loan 3 5 heldforsale month end june 3 0 2 0 1 0 . exclude calculate net chargeoff rate . net chargeoff rate include loan heldforsale nongaap financial measure 5 . 8 1 % 6 . 3 2 % month end june 3 0 2 0 1 1 respectively . faverage loan include loan heldforsale $ 1 . 8 billion $ 2 . 2 billion month end june 3 0 2 0 1 0 respectively . student loan heldforsale month end june 3 0 2 0 1 1 . exclude calculate net chargeoff rate . gperiodend loan include loan heldforsale $ 2 4 9 million june 3 0 2 0 1 0 . loan heldfor sale june 3 0 2 0 1 1 . exclude calculate allowance loan loss periodend loan 3 0 day delinquency rate . hexclude student loan insure u . s . government agency federal family education loan program ffelp $ 9 6 8 million $ 9 8 8 million june 3 0 2 0 1 1 2 0 1 0 respectively 3 0 day past . exclude reimbursement insured proceed normally . iat june 3 0 2 0 1 1 2 0 1 0 nonperforme asset exclude student loan insure u . s . government agency ffelp $ 5 5 8 million $ 4 4 7 million respectively 9 0 day past . exclude reimbursement insured proceed normally . jreflect impact portfolio sale second quarter 2 0 1 1 . ksupplemental information provide card service exclude washington mutual commercial card portfolio include loan heldforsale nongaap financial measure provide meaningful measure enable comparability prior period . lfor additional information loan balance delinquency rate net chargeoff rate washington mutual portfolio consumer credit portfolio page 7 7 8 6 note 1 3 page 1 3 4 1 4 8 form 1 0 q . mas percentage average loans . nrepresent total net revenue provision credit losses . ototal average loan include loan heldforsale $ 2 7 6 million $ 1 . 6 billion month end june 3 0 2 0 1 1 respectively include calculate net chargeoff rate . loan heldforsale month end june 3 0 2 0 1 0 . pat june 3 0 2 0 1 1 2 0 1 0 3 0 day delinquent loan card service exclude washington mutual commercial card portfolio $ 3 0 7 0 million $ 5 7 0 3 million respectively . qat june 3 0 2 0 1 1 2 0 1 0 9 0 day delinquent loan card service exclude washington mutual commercial card portfolio $ 1 6 0 0 million $ 3 1 4 4 million respectively . 3 5 athis page intentionally leave blankcommercial bankingfor discussion business profile cb page 8 2 8 3 jpmorgan chase 2 0 1 0 annual report introduction page 4 form 1 0 q . select income statement datathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue lending depositrelate fees $ 2 8 1 $ 2 8 0 % $ 5 4 5 $ 5 5 7 2 % asset management administration commissions 3 4 3 6 6 6 9 7 3 5 all incomea 2 8 3 2 3 0 2 3 4 8 6 4 1 6 1 7 noninterest revenue 5 9 8 5 4 6 1 0 1 1 0 0 1 0 4 6 5 net interest income 1 0 2 9 9 4 0 9 2 0 4 3 1 8 5 6 1 0 total net revenueb 1 6 2 7 1 4 8 6 9 3 1 4 3 2 9 0 2 8 provision credit losses 5 4 2 3 5 nm 1 0 1 2 1 nm noninter expense compensation expense 2 1 9 1 9 6 1 2 4 4 2 4 0 2 1 0 noncompensation expense 3 3 6 3 3 7 6 6 8 6 6 1 1 amortization intangibles 8 9 1 1 1 6 1 8 1 1 total noninter expense 5 6 3 5 4 2 4 1 1 2 6 1 0 8 1 4 income income tax expense 1 0 1 0 1 1 7 9 1 4 1 9 1 6 1 8 4 2 4 income tax expense 4 0 3 4 8 6 1 7 7 6 3 7 5 9 1 net income $ 6 0 7 $ 6 9 3 1 2 $ 1 1 5 3 $ 1 0 8 3 6 revenue product lendingc $ 8 8 0 $ 6 4 9 3 6 $ 1 7 1 7 $ 1 3 0 7 3 1 treasury servicesc 5 5 6 6 6 5 1 6 1 0 9 8 1 3 0 3 1 6 investment banking 1 5 2 1 1 5 3 2 2 6 2 2 2 0 1 9 other 3 9 5 7 3 2 6 6 7 2 8 total commercial banking revenue $ 1 6 2 7 $ 1 4 8 6 9 $ 3 1 4 3 $ 2 9 0 2 8 ib revenue grossd 4 4 2 3 3 3 3 3 7 5 1 6 4 4 1 7 revenue client segment middle market banking $ 7 8 9 $ 7 6 7 3 $ 1 5 4 4 $ 1 5 1 3 2 commercial term lending 2 8 6 2 3 7 2 1 5 7 2 4 6 6 2 3 corporate client bankinge 3 3 9 2 8 5 1 9 6 2 9 5 4 8 1 5 real estate banking 1 0 9 1 2 5 1 3 1 9 7 2 2 5 1 2 other 1 0 4 7 2 4 4 2 0 1 1 5 0 3 4 total commercial banking revenue $ 1 6 2 7 $ 1 4 8 6 9 $ 3 1 4 3 $ 2 9 0 2 8 financial ratio return common equity 3 0 % 3 5 % 2 9 % 2 7 % overhead ratio 3 5 3 6 3 6 3 7 acb client revenue investment banking product commercial card transaction include income . btotal net revenue include taxequivalent adjustment income tax credit relate equity investment designate community development entity provide loan qualified business lowincome community taxexempt income municipal bond activity $ 6 7 million $ 4 9 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 3 2 million $ 9 4 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . ceffective january 1 2 0 1 1 product revenue commercial card standby letter credit transaction include lending . month end june 3 0 2 0 1 1 impact change $ 1 1 4 million $ 2 2 1 million respectively . prioryear period report treasury services . drepresent total revenue relate investment banking product sell cb clients . ecorporate client banking know midcorporate banking prior january 1 2 0 1 1 . 3 6 quarterly result net income $ 6 0 7 million decrease $ 8 6 million 1 2 % prior year . decrease drive increase provision credit loss partially offset high net revenue . net revenue record $ 1 . 6 billion $ 1 4 1 million 9 % prior year . net interest income $ 1 . 0 billion $ 8 9 million 9 % drive growth liability balance wide loan spread high loan balance partially offset spread compression liability product . noninterest revenue $ 5 9 8 million $ 5 2 million 1 0 % compare prior year drive high investment banking revenue . revenue middle market banking $ 7 8 9 million increase $ 2 2 million 3 % prior year . revenue commercial term lending $ 2 8 6 million increase $ 4 9 million 2 1 % . revenue corporate client banking $ 3 3 9 million increase $ 5 4 million 1 9 % . revenue real estate banking $ 1 0 9 million decrease $ 1 6 million 1 3 % . provision credit loss $ 5 4 million compare benefit $ 2 3 5 million prior year . net chargeoff $ 4 0 million 0 . 1 6 % net chargeoff rate largely relate commercial real estate compare net chargeoff $ 1 7 6 million 0 . 7 4 % net chargeoff rate prior year . allowance loan loss endofperiod loan retain 2 . 5 6 % 2 . 8 2 % prior year . nonaccrual loan $ 1 . 6 billion $ 1 . 4 billion 4 7 % prior year primarily reflect commercial real estate repayment loan sales . noninter expense $ 5 6 3 million increase $ 2 1 million 4 % prior year primarily reflect high headcountrelate expense . yeartodate result net income $ 1 . 2 billion increase $ 7 0 million 6 % prior year . increase drive high revenue largely offset increase provision credit loss . net revenue $ 3 . 1 billion $ 2 4 1 million 8 % compare prior year . net interest income $ 2 . 0 billion $ 1 8 7 million 1 0 % drive growth liability balance wide loan spread high loan balance partially offset spread compression liability product . noninterest revenue $ 1 . 1 billion increase $ 5 4 million 5 % prior year largely drive high investment banking revenue . revenue middle market banking $ 1 . 5 billion increase $ 3 1 million 2 % prior year . revenue commercial term lending $ 5 7 2 million increase $ 1 0 6 million 2 3 % . revenue corporate client banking $ 6 2 9 million increase $ 8 1 million 1 5 % . revenue real estate banking $ 1 9 7 million decrease $ 2 8 million 1 2 % . provision credit loss $ 1 0 1 million compare benefit $ 2 1 million prior year . net chargeoff $ 7 1 million 0 . 1 4 % net chargeoff rate largely relate commercial real estate compare $ 4 0 5 million 0 . 8 5 % net chargeoff rate prior year . noninter expense $ 1 . 1 billion increase $ 4 5 million 4 % prior year largely reflect higher headcountrelate expense . 3 7 selected metricsthree month end june 3 0 month end june 3 0 million headcount ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeselected balance sheet datum periodend loan loan retained $ 1 0 2 1 2 2 $ 9 5 0 9 0 7 % $ 1 0 2 1 2 2 $ 9 5 0 9 0 7 % loan heldforsale loan fair value 5 5 7 4 4 6 2 5 5 5 7 4 4 6 2 5 total loans 1 0 2 6 7 9 9 5 5 3 6 7 1 0 2 6 7 9 9 5 5 3 6 7 equity 8 0 0 0 8 0 0 0 8 0 0 0 8 0 0 0 select balance sheet datum average total assets $ 1 4 3 5 6 0 $ 1 3 3 3 0 9 8 $ 1 4 1 9 8 9 $ 1 3 3 1 6 2 7 loans loan retained 1 0 0 8 5 7 9 5 5 2 1 6 9 9 8 4 9 9 5 9 1 7 4 loan heldforsale loan fair value 1 0 1 5 3 9 1 1 6 0 8 8 6 3 4 4 1 5 8 total loans 1 0 1 8 7 2 9 5 9 1 2 6 1 0 0 7 3 5 9 6 2 6 1 5 liability balances 1 6 2 7 6 9 1 3 6 7 7 0 1 9 1 5 9 5 0 3 1 3 4 9 6 6 1 8 equity 8 0 0 0 8 0 0 0 8 0 0 0 8 0 0 0 average loan client segment middle market banking $ 4 0 0 1 2 $ 3 4 4 2 4 1 6 $ 3 9 1 1 4 $ 3 4 1 7 3 1 4 commercial term lending 3 7 7 2 9 3 5 9 5 6 5 3 7 7 6 9 3 6 0 0 6 5 corporate client bankinga 1 3 0 6 2 1 1 8 7 5 1 0 1 2 7 2 0 1 2 0 6 5 5 real estate banking 7 4 6 7 9 8 1 4 2 4 7 5 3 7 1 0 1 2 4 2 6 other 3 6 0 2 3 8 4 3 6 3 5 9 5 3 8 9 3 8 total commercial banking loans $ 1 0 1 8 7 2 $ 9 5 9 1 2 6 $ 1 0 0 7 3 5 $ 9 6 2 6 1 5 headcount 5 1 4 0 4 8 0 8 7 5 1 4 0 4 8 0 8 7 credit datum quality statistic net chargeoffs $ 4 0 $ 1 7 6 7 7 $ 7 1 $ 4 0 5 8 2 nonperforming asset nonaccrual loan nonaccrual loan retainedb 1 6 1 3 3 0 3 6 4 7 1 6 1 3 3 0 3 6 4 7 nonaccrual loan heldforsale loan hold fair value 2 1 4 1 4 9 2 1 4 1 4 9 total nonaccrual loans 1 6 3 4 3 0 7 7 4 7 1 6 3 4 3 0 7 7 4 7 assets acquire loan satisfactions 1 9 7 2 0 8 5 1 9 7 2 0 8 5 total nonperforme assets 1 8 3 1 3 2 8 5 4 4 1 8 3 1 3 2 8 5 4 4 allowance credit loss allowance loan losses 2 6 1 4 2 6 8 6 3 2 6 1 4 2 6 8 6 3 allowance lendingrelate commitments 1 8 7 2 6 7 3 0 1 8 7 2 6 7 3 0 total allowance credit losses 2 8 0 1 2 9 5 3 5 2 8 0 1 2 9 5 3 5 net chargeoff rate 0 . 1 6 % 0 . 7 4 % 0 . 1 4 % 0 . 8 5 % allowance loan loss periodend loan retained 2 . 5 6 2 . 8 2 2 . 5 6 2 . 8 2 allowance loan loss nonaccrual loan retainedb 1 6 2 8 8 1 6 2 8 8 nonaccrual loan total periodend loans 1 . 5 9 3 . 2 2 1 . 5 9 3 . 2 2 acorporate client banking know midcorporate banking prior january 1 2 0 1 1 . ballowance loan loss $ 2 8 9 million $ 5 8 6 million hold nonaccrual loan retain june 3 0 2 0 1 1 2 0 1 0 respectively . 3 8 treasury security servicesfor discussion business profile tss page 8 4 8 5 jpmorgan chase 2 0 1 0 annual report introduction page 5 form 1 0 q . selected income statement datathree month end june 3 0 month end june 3 0 million headcount ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue lending depositrelate fees $ 3 1 4 $ 3 1 3 % $ 6 1 7 $ 6 2 4 1 % asset management administration commissions 7 2 6 7 0 5 3 1 4 2 1 1 3 6 4 4 all income 1 4 3 2 0 9 3 2 2 8 2 3 8 5 2 7 noninterest revenue 1 1 8 3 1 2 2 7 4 2 3 2 0 2 3 7 3 2 net interest income 7 4 9 6 5 4 1 5 1 4 5 2 1 2 6 4 1 5 total net revenue 1 9 3 2 1 8 8 1 3 3 7 7 2 3 6 3 7 4 provision credit losses 2 1 6 8 8 2 5 5 nm credit allocation incomeexpensea 3 2 3 0 nm 5 9 6 0 nm noninter expense compensation expense 7 1 9 6 9 7 3 1 4 3 4 1 3 5 4 6 noncompensation expense 7 1 9 6 8 4 5 1 3 6 6 1 3 3 4 2 amortization intangibles 1 5 1 8 1 7 3 0 3 6 1 7 total noninterest expense 1 4 5 3 1 3 9 9 4 2 8 3 0 2 7 2 4 4 income income tax expense 5 1 3 4 6 8 1 0 9 9 9 9 0 8 1 0 income tax expense 1 8 0 1 7 6 2 3 5 0 3 3 7 4 net income $ 3 3 3 $ 2 9 2 1 4 $ 6 4 9 $ 5 7 1 1 4 revenue business treasury services $ 9 3 0 $ 9 2 6 $ 1 8 2 1 $ 1 8 0 8 1 worldwide security services 1 0 0 2 9 5 5 5 1 9 5 1 1 8 2 9 7 total net revenue $ 1 9 3 2 $ 1 8 8 1 3 $ 3 7 7 2 $ 3 6 3 7 4 revenue geographic regionb europemiddle eastafrica 6 9 1 6 1 7 1 2 1 3 2 1 1 1 8 6 1 1 asiapacific 2 9 9 2 3 3 2 8 5 7 5 4 5 2 2 7 latin americacaribbean 8 0 7 1 1 3 1 5 6 1 1 6 3 4 north america 8 6 2 9 6 0 1 0 1 7 2 0 1 8 8 3 9 total net revenue $ 1 9 3 2 $ 1 8 8 1 3 $ 3 7 7 2 $ 3 6 3 7 4 trade finance loan geographic region periodendb europemiddle eastafrica $ 6 1 8 4 $ 2 8 9 8 1 1 3 $ 6 1 8 4 $ 2 8 9 8 1 1 3 asiapacific 1 5 7 3 6 9 8 0 2 6 1 1 5 7 3 6 9 8 0 2 6 1 latin americacaribbean 4 5 5 3 3 0 0 8 5 1 4 5 5 3 3 0 0 8 5 1 north america 1 0 0 0 6 9 3 4 4 1 0 0 0 6 9 3 4 4 total finance loans $ 2 7 4 7 3 $ 1 6 4 0 1 6 8 $ 2 7 4 7 3 $ 1 6 4 0 1 6 8 financial ratio return common equity 1 9 % 1 8 % 1 9 % 1 8 % overhead ratio 7 5 7 4 7 5 7 5 pretax margin ratio 2 7 2 5 2 6 2 5 select balance sheet datum periodend loansc $ 3 4 0 3 4 $ 2 4 5 1 3 3 9 $ 3 4 0 3 4 $ 2 4 5 1 3 3 9 equity 7 0 0 0 6 5 0 0 8 7 0 0 0 6 5 0 0 8 selected balance sheet datum average total assets $ 5 2 6 8 8 $ 4 2 8 6 8 2 3 $ 5 0 2 9 4 $ 4 0 5 8 3 2 4 loansc 3 3 0 6 9 2 2 1 3 7 4 9 3 1 1 9 0 2 0 8 6 5 4 9 liability balances 3 0 2 8 5 8 2 4 6 6 9 0 2 3 2 8 4 3 9 2 2 4 7 2 9 4 1 5 equity 7 0 0 0 6 5 0 0 8 7 0 0 0 6 5 0 0 8 headcount 2 8 2 3 0 2 7 9 4 3 1 2 8 2 3 0 2 7 9 4 3 1 aib manage traditional credit exposure relate gcb behalf ib ts . effective january 1 2 0 1 1 ib tss share economic relate firm gcb client . include allocation net revenue provision credit loss expense . prioryear period reflect reimbursement ib portion total cost manage credit portfolio . ib recognize credit allocation component income . brevenue trade finance loan base tss management view domicile clients . cloan balance include trade finance loan wholesale overdraft commercial card . effective january 1 2 0 1 1 commercial card loan business approximately $ 1 . 2 billion previously tss transfer card . material impact financial datum prioryear period revised . 3 9 quarterly result net income $ 3 3 3 million increase $ 4 1 million 1 4 % prior year . net revenue $ 1 . 9 billion increase $ 5 1 million 3 % prior year . exclude impact commercial card business net revenue 6 % . worldwide security service net revenue $ 1 . 0 billion increase $ 4 7 million 5 % . increase drive high market level high net interest income net inflow asset custody . treasury service net revenue $ 9 3 0 million relatively flat compare prior year high trade loan volume high deposit balance largely offset transfer commercial card business card service auto quarter 2 0 1 1 low spread deposit . exclude impact commercial card business ts net revenue increase 7 % . tss generate firmwide net revenue $ 2 . 6 billion include $ 1 . 6 billion treasury service $ 9 3 0 million record treasury service $ 5 5 6 million commercial banking $ 6 5 million line business . remain $ 1 . 0 billion firmwide net revenue record worldwide security services . noninter expense $ 1 . 5 billion increase $ 5 4 million 4 % prior year . increase mainly drive continued investment new product platform primarily relate international expansion partially offset transfer commercial card business card service auto . exclude impact commercial card business ts noninter expense increase 9 % . results quarter include $ 3 2 million pretax benefit relate allocation ib ts associate credit extend global corporate bank gcb client . ib manage core credit exposure relate gcb behalf ib ts . effective january 1 2 0 1 1 ib tss share economic relate firm gcb client . include allocation net revenue provision credit loss expenses . yeartodate result net income $ 6 4 9 million increase $ 7 8 million 1 4 % prior year . net revenue $ 3 . 8 billion increase $ 1 3 5 million 4 % prior year . exclude impact commercial card business net revenue 7 % . worldwide security service net revenue $ 2 . 0 billion increase $ 1 2 2 million 7 % . increase drive high market level net inflow asset custody high net interest income . treasury service net revenue $ 1 . 8 billion relatively flat compare prior year high trade loan volume high deposit balance largely offset transfer commercial card business card service auto quarter 2 0 1 1 low spread deposit . exclude impact commercial card business ts net revenue increase 7 % . tss generate firmwide net revenue $ 5 . 0 billion include $ 3 . 0 billion treasury service $ 1 . 8 billion record treasury service $ 1 . 1 billion commercial banking $ 1 2 8 million line business . remain $ 2 . 0 billion firmwide net revenue record worldwide security services . noninter expense $ 2 . 8 billion increase $ 1 0 6 million 4 % prior year . increase mainly drive continued investment new product platform primarily relate international expansion partially offset transfer commercial card business card service auto . exclude impact commercial card business ts noninter expense increase 9 % . results yeartodate include $ 5 9 million pretax benefit relate allocation ib ts associate credit extend gcb client . 4 0 selected metricsthree month end june 3 0 month end june 3 0 million ratio noted 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changets firmwide disclosure treasury service revenue reported $ 9 3 0 $ 9 2 6 % $ 1 8 2 1 $ 1 8 0 8 1 % treasury service revenue report cba 5 5 6 6 6 5 1 6 1 0 9 8 1 3 0 3 1 6 treasury service revenue report line business 6 5 6 2 5 1 2 8 1 1 8 8 treasury service firmwide revenueb 1 5 5 1 1 6 5 3 6 3 0 4 7 3 2 2 9 6 worldwide security service revenue 1 0 0 2 9 5 5 5 1 9 5 1 1 8 2 9 7 treasury security service firmwide revenueb $ 2 5 5 3 $ 2 6 0 8 2 $ 4 9 9 8 $ 5 0 5 8 1 treasury service firmwide liability balance averagec 3 7 5 4 3 2 3 0 3 2 2 4 2 4 3 5 7 4 3 6 3 0 4 1 5 9 1 8 treasury security service firmwide liability balance averagec 4 6 5 6 2 7 3 8 3 4 6 0 2 1 4 4 3 8 9 4 3 8 2 2 6 0 1 6 tss firmwide financial ratio treasury service firmwide overhead ratioad 5 9 % 5 4 % 5 8 % 5 5 % treasury security service firmwide overhead ratioad 6 7 6 4 6 7 6 5 firmwide business metric asset custody billions $ 1 6 9 4 5 $ 1 4 8 5 7 1 4 $ 1 6 9 4 5 $ 1 4 8 5 7 1 4 number u . s . $ ach transaction originated 9 5 9 9 7 0 1 1 9 5 1 1 9 1 9 2 total u . s . $ clearing volume thousands 3 2 2 7 4 3 0 5 3 1 6 6 3 2 4 5 5 9 2 0 0 7 international electronic fund transfer volume thousandse 6 3 2 0 8 5 8 4 8 4 8 1 2 4 1 5 0 1 1 4 2 3 8 9 wholesale check volume 6 0 8 5 2 6 1 6 1 1 4 0 1 0 0 4 1 4 wholesale card issue thousandsf 2 3 7 4 6 2 8 0 6 6 1 5 2 3 7 4 6 2 8 0 6 6 1 5 credit datum quality statistic net chargeoffs $ $ $ $ nonaccrual loans 3 1 4 7 9 3 1 4 7 9 allowance credit loss allowance loan losses 7 4 4 8 5 4 7 4 4 8 5 4 allowance lendingrelate commitments 4 1 6 8 4 0 4 1 6 8 4 0 total allowance credit losses 1 1 5 1 1 6 1 1 1 5 1 1 6 1 net chargeoff rate % % % % allowance loan loss periodend loans 0 . 2 2 0 . 2 0 0 . 2 2 0 . 2 0 allowance loan loss nonaccrual loan nm 3 4 3 nm 3 4 3 nonaccrual loan periodend loans 0 . 0 1 0 . 0 6 0 . 0 1 0 . 0 6 aeffective january 1 2 0 1 1 certain cb revenue exclude ts firmwide metric instead directly capture cbs lending revenue product . impact change $ 1 1 4 million month end june 3 0 2 0 1 1 $ 2 2 1 million month end june 3 0 2 0 1 1 . previous period revenue include cbs treasury service revenue product . btss firmwide revenue include foreign exchange fx revenue record tss fx revenue associate tss customer fx customer ib . fx revenue associate tss customer fx customer ib include ts ts firmwide revenue . total fx revenue generate $ 1 6 5 million $ 1 7 5 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 3 2 5 million $ 3 1 2 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . cfirmwide liability balance include liability balance record cb . doverhead ratio calculate base firmwide revenue tss ts expense respectively include allocate certain line business . fx revenue expense record ib tssrelate fx activity include ratio . einternational electronic fund transfer include nonu . s . dollar automate clearing house ach clearing volume . fwholesale card issue outstanding include u . s . domestic commercial store value prepay government electronic benefit card product . effective january 1 2 0 1 1 commercial card portfolio transfer ts card . 4 1 asset managementfor discussion business profile page 8 6 8 8 jpmorgan chase 2 0 1 0 annual report introduction page 5 form 1 0 q . selected income statement datathree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue asset management administration commissions $ 1 8 1 8 $ 1 5 2 2 1 9 % $ 3 5 2 5 $ 3 0 3 0 1 6 % income 3 2 1 1 7 7 8 1 6 3 4 4 4 3 4 3 noninterest revenue 2 1 3 9 1 6 9 9 2 6 4 1 5 9 3 4 7 3 2 0 net interest income 3 9 8 3 6 9 8 7 8 4 7 2 6 8 total net revenue 2 5 3 7 2 0 6 8 2 3 4 9 4 3 4 1 9 9 1 8 provision credit losses 1 2 5 1 4 0 1 7 4 0 5 8 noninter expense compensation expense 1 0 6 8 8 6 1 2 4 2 1 0 7 1 7 7 1 1 9 noncompensation expense 7 0 4 5 2 7 3 4 1 3 0 3 1 0 4 1 2 5 amortization intangibles 2 2 1 7 2 9 4 4 3 5 2 6 total noninter expense 1 7 9 4 1 4 0 5 2 8 3 4 5 4 2 8 4 7 2 1 income income tax expense 7 3 1 6 5 8 1 1 1 4 7 2 1 3 1 2 1 2 income tax expense 2 9 2 2 6 7 9 5 6 7 5 2 9 7 net income $ 4 3 9 $ 3 9 1 1 2 $ 9 0 5 $ 7 8 3 1 6 revenue client segment private banking $ 1 2 8 9 $ 1 1 5 3 1 2 $ 2 6 0 6 $ 2 3 0 3 1 3 institutional 7 0 4 4 5 5 5 5 1 2 5 3 9 9 9 2 5 retail 5 4 4 4 6 0 1 8 1 0 8 4 8 9 7 2 1 total net revenue $ 2 5 3 7 $ 2 0 6 8 2 3 $ 4 9 4 3 $ 4 1 9 9 1 8 financial ratio return common equity 2 7 % 2 4 % 2 8 % 2 4 % overhead ratio 7 1 6 8 7 0 6 8 pretax margin ratio 2 9 3 2 3 0 3 1 quarterly resultsnet income $ 4 3 9 million increase $ 4 8 million 1 2 % prior year . result reflect high net revenue predominantly offset high noninterest expense . net revenue $ 2 . 5 billion increase $ 4 6 9 million 2 3 % prior year . noninterest revenue $ 2 . 1 billion $ 4 4 0 million 2 6 % effect high market level net inflow product high margin high valuation seed capital investment high performance fee . net interest income $ 3 9 8 million $ 2 9 million 8 % high deposit loan balance partially offset narrow deposit spread . revenue private banking $ 1 . 3 billion 1 2 % prior year . revenue institutional $ 7 0 4 million 5 5 % . revenue retail $ 5 4 4 million 1 8 % . provision credit loss $ 1 2 million compare $ 5 million prior year . noninterest expense $ 1 . 8 billion increase $ 3 8 9 million 2 8 % prior year largely result increase headcount high performancebased compensation . yeartodate resultsnet income $ 9 0 5 million increase $ 1 2 2 million 1 6 % prior year . result reflect high net revenue low provision credit loss predominantly offset high noninter expense . net revenue $ 4 . 9 billion increase $ 7 4 4 million 1 8 % prior year . noninterest revenue $ 4 . 2 billion $ 6 8 6 million 2 0 % effect high market level net inflow product high margin high loan origination high valuation seed capital investment . net interest income $ 7 8 4 million $ 5 8 million 8 % high deposit loan balance partially offset narrow deposit spreads . revenue private banking $ 2 . 6 billion 1 3 % prior year . revenue institutional $ 1 . 3 billion 2 5 % . revenue retail $ 1 . 1 billion 2 1 % . 4 2 the provision credit loss $ 1 7 million compare $ 4 0 million prior year . noninterest expense $ 3 . 5 billion increase $ 6 0 7 million 2 1 % prior year largely result increase headcount high performancebased compensation . business metricsthree month end june 3 0 month end june 3 0 million headcount rank datum noted 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changenumber client advisorsa 2 2 8 2 2 0 8 3 1 0 % 2 2 8 2 2 0 8 3 1 0 % retirement planning service participant thousands 1 6 1 3 1 6 5 3 2 1 6 1 3 1 6 5 3 2 jpmorgan security brokers 4 3 7 4 0 3 8 4 3 7 4 0 3 8 % customer asset 4 5 star fundsb 5 0 % 4 3 % 1 6 5 0 % 4 3 % 1 6 % aum 1 st 2 nd quartilesc 1 year 5 6 % 5 8 % 3 5 6 % 5 8 % 3 3 years 7 1 % 6 7 % 6 7 1 % 6 7 % 6 5 years 7 6 % 7 8 % 3 7 6 % 7 8 % 3 selected balance sheet datum periodend loans $ 5 1 7 4 7 $ 3 8 7 4 4 3 4 $ 5 1 7 4 7 $ 3 8 7 4 4 3 4 equity 6 5 0 0 6 5 0 0 6 5 0 0 6 5 0 0 select balance sheet datum average total assets $ 7 4 2 0 6 $ 6 3 4 2 6 1 7 $ 7 1 5 7 7 $ 6 2 9 7 8 1 4 loans 4 8 8 3 7 3 7 4 0 7 3 1 4 6 9 0 3 3 7 0 0 7 2 7 deposits 9 7 5 0 9 8 6 4 5 3 1 3 9 6 3 8 6 8 3 5 7 3 1 5 equity 6 5 0 0 6 5 0 0 6 5 0 0 6 5 0 0 headcount 1 7 9 6 3 1 6 0 1 9 1 2 1 7 9 6 3 1 6 0 1 9 1 2 credit datum quality statistic net chargeoffs $ 3 3 $ 2 7 2 2 $ 4 4 $ 5 5 2 0 nonaccrual loans 2 5 2 3 0 9 1 8 2 5 2 3 0 9 1 8 allowance credit loss allowance loan losses 2 2 2 2 5 0 1 1 2 2 2 2 5 0 1 1 allowance lendingrelate commitments 9 3 2 0 0 9 3 2 0 0 total allowance credit losses 2 3 1 2 5 3 9 2 3 1 2 5 3 9 net chargeoff rate 0 . 2 7 % 0 . 2 9 % 0 . 1 9 % 0 . 3 0 % allowance loan loss periodend loans 0 . 4 3 0 . 6 5 0 . 4 3 0 . 6 5 allowance loan loss nonaccrual loans 8 8 8 1 8 8 8 1 nonaccrual loan periodend loans 0 . 4 9 0 . 8 0 0 . 4 9 0 . 8 0 aeffective january 1 2 0 1 1 methodology use determine client advisor revise . prior period revised . bderive morningstar u . s . u . k . luxembourg france hong kong taiwan nomura japan . cquartile rank source lipper u . s . taiwan morningstar u . k . luxembourg france hong kong nomura japan . 4 3 assets supervisionasset supervision $ 1 . 9 trillion increase $ 2 8 4 billion 1 7 % prior year . asset management $ 1 . 3 trillion increase $ 1 8 1 billion 1 6 % . increase effect high market level net inflow longterm product partially offset net outflow liquidity product . custody brokerage administration deposit balance $ 5 8 2 billion $ 1 0 3 billion 2 2 % effect high market level custody brokerage inflow . asset supervisiona billion quarter end june 3 0 2 0 1 1 2 0 1 0 asset asset class liquidity $ 4 7 6 $ 4 8 9 fixed income 3 1 9 2 5 9 equities multiasset 4 3 0 3 2 2 alternatives 1 1 7 9 1 total asset management 1 3 4 2 1 1 6 1 custodybrokerageadministrationdeposits 5 8 2 4 7 9 total asset supervision $ 1 9 2 4 $ 1 6 4 0 assets client segment private banking $ 2 9 1 $ 2 5 8 institutionalb 7 0 8 6 5 1 retailb 3 4 3 2 5 2 total asset management $ 1 3 4 2 $ 1 1 6 1 private bank $ 7 7 6 $ 6 5 3 institutionalb 7 0 9 6 5 2 retailb 4 3 9 3 3 5 total asset supervision $ 1 9 2 4 $ 1 6 4 0 mutual fund asset asset class liquidity $ 4 2 1 $ 4 4 0 fixed income 1 0 5 7 9 equities multiasset 1 7 6 1 3 3 alternatives 9 8 total mutual fund asset $ 7 1 1 $ 6 6 0 aexcludes asset management american century company inc . firm 4 0 % 4 2 % ownership june 3 0 2 0 1 1 2 0 1 0 respectively . bin second quarter 2 0 1 1 client hierarchy use determine asset classification revise prioryear period revise . month end june 3 0 month end june 3 0 billion 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 asset management rollforward begin balance $ 1 3 3 0 $ 1 2 1 9 $ 1 2 9 8 $ 1 2 4 9 net asset flow liquidity 1 6 2 9 2 5 9 1 fixed income 1 2 1 2 2 8 2 8 equities multiasset alternative 7 1 1 8 7 marketperformanceother impact 9 4 2 2 3 3 2 ending balance june 3 0 $ 1 3 4 2 $ 1 1 6 1 $ 1 3 4 2 $ 1 1 6 1 asset supervision rollforward begin balance $ 1 9 0 8 $ 1 7 0 7 $ 1 8 4 0 $ 1 7 0 1 net asset flow 1 2 4 4 3 1 4 marketperformanceother impact 4 6 3 4 1 4 7 ending balance june 3 0 $ 1 9 2 4 $ 1 6 4 0 $ 1 9 2 4 $ 1 6 4 0 4 4 international metric month end june 3 0 month end june 3 0 billion note 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changetotal net revenue millionsa europemiddle eastafrica $ 4 7 8 $ 3 8 1 2 5 % $ 9 1 7 $ 7 6 6 2 0 % asiapacific 2 5 7 2 1 4 2 0 5 0 3 4 3 6 1 5 latin americacaribbean 2 5 1 1 2 4 1 0 2 4 1 6 2 4 8 6 8 north america 1 5 5 1 1 3 4 9 1 5 3 1 0 7 2 7 4 9 1 3 total net revenue $ 2 5 3 7 $ 2 0 6 8 2 3 $ 4 9 4 3 $ 4 1 9 9 1 8 assets management europemiddle eastafrica $ 2 9 8 $ 2 3 9 2 5 $ 2 9 8 $ 2 3 9 2 5 asiapacific 1 1 9 9 5 2 5 1 1 9 9 5 2 5 latin americacaribbean 3 7 2 4 5 4 3 7 2 4 5 4 north america 8 8 8 8 0 3 1 1 8 8 8 8 0 3 1 1 total asset management $ 1 3 4 2 $ 1 1 6 1 1 6 $ 1 3 4 2 $ 1 1 6 1 1 6 assets supervision europemiddle eastafrica $ 3 5 3 $ 2 8 2 2 5 $ 3 5 3 $ 2 8 2 2 5 asiapacific 1 6 1 1 2 7 2 7 1 6 1 1 2 7 2 7 latin americacaribbean 9 4 6 8 3 8 9 4 6 8 3 8 north america 1 3 1 6 1 1 6 3 1 3 1 3 1 6 1 1 6 3 1 3 total asset supervision $ 1 9 2 4 $ 1 6 4 0 1 7 $ 1 9 2 4 $ 1 6 4 0 1 7 aregional revenue base domicile clients . 4 5 corporate private equityfor discussion business profile corporateprivate equity page 8 9 9 0 jpmorgan chase 2 0 1 0 annual report . select income statement datathree month end june 3 0 month end june 3 0 million headcount 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changerevenue principal transactions $ 7 4 5 $ 6 9 nm $ 2 0 4 3 $ 4 7 8 3 2 7 % security gains 8 3 7 9 9 0 1 5 % 9 3 9 1 6 0 0 4 1 all income 2 6 5 1 8 2 4 6 3 4 3 3 0 6 1 2 noninterest revenue 1 8 4 7 1 1 0 3 6 7 3 3 2 5 2 3 8 4 3 9 net interest income a 2 1 8 7 4 7 7 1 2 5 2 1 8 2 3 8 6 total net revenueb 2 0 6 5 1 8 5 0 1 2 3 5 7 7 4 2 0 7 1 5 provision credit losses 9 2 3 5 0 1 9 1 5 nm noninter expense compensation expense 6 1 4 7 7 0 2 0 1 2 7 1 1 2 4 5 2 noncompensation expensec 2 0 9 7 1 4 6 8 4 3 3 2 4 0 4 5 0 9 2 8 subtotal 2 7 1 1 2 2 3 8 2 1 4 5 1 1 5 7 5 4 2 2 net expense allocate businesses 1 2 7 0 1 1 9 2 7 2 5 0 8 2 3 7 2 6 total noninter expense 1 4 4 1 1 0 4 6 3 8 2 0 0 3 3 3 8 2 4 1 income income tax expensebenefit 6 3 3 8 0 6 2 1 1 5 9 3 8 1 0 9 7 income tax expensebenefit 1 3 1 1 5 3 1 4 3 6 9 7 1 nmnet income $ 5 0 2 $ 6 5 3 2 3 $ 1 2 2 4 $ 8 8 1 3 9 total net revenue private equity $ 7 9 6 $ 4 8 nm $ 1 4 9 5 $ 1 6 3 nmcorporate 1 2 6 9 1 8 0 2 3 0 2 0 8 2 4 0 4 4 4 9 total net revenue $ 2 0 6 5 $ 1 8 5 0 1 2 $ 3 5 7 7 $ 4 2 0 7 1 5 net income private equity $ 4 4 4 $ 1 1 nm $ 8 2 7 $ 6 6 nmcorporate 5 8 6 4 2 9 1 3 9 7 8 1 5 5 1 total net income $ 5 0 2 $ 6 5 3 2 3 $ 1 2 2 4 $ 8 8 1 3 9 headcount 2 1 4 4 4 1 9 4 8 2 1 0 2 1 4 4 4 1 9 4 8 2 1 0 anet interest income 2 0 1 1 low compare 2 0 1 0 primarily drive low funding benefit security portfolio . btotal net revenue include taxequivalent adjustment predominantly taxexempt income municipal bond investment $ 6 9 million $ 5 7 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 3 3 million $ 1 0 5 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . cincluded litigation expense $ 1 . 3 billion $ 1 . 6 billion month end june 3 0 2 0 1 1 respectively compare $ 6 9 4 million $ 3 . 0 billion month end june 3 0 2 0 1 0 respectively . quarterly result net income $ 5 0 2 million compare net income $ 6 5 3 million prior year . private equity net income $ 4 4 4 million compare $ 1 1 million prior year . net revenue $ 7 9 6 million increase $ 7 4 8 million drive primarily gain sale net increase investment valuation . noninterest expense $ 1 0 2 million increase $ 7 0 million prior year . corporate report net income $ 5 8 million compare $ 6 4 2 million prior year . net revenue $ 1 . 3 billion include $ 8 3 7 million security gain . noninterest expense include $ 1 . 3 billion additional litigation reserve predominantly mortgagerelated matter . noninter expense prior year include $ 6 9 4 million additional litigation reserves . yeartodate resultsnet income $ 1 . 2 billion compare net income $ 8 8 1 million prior year . private equity net income $ 8 2 7 million compare $ 6 6 million prior year . net revenue $ 1 . 5 billion increase $ 1 . 3 billion drive primarily gain sale net increase investment valuation . noninterest expense $ 2 1 5 million increase $ 1 5 3 million prior year . corporate report net income $ 3 9 7 million compare $ 8 1 5 million prior year . net revenue $ 2 . 1 billion include $ 9 3 9 million security gain . noninterest expense $ 1 . 8 billion include $ 1 . 6 billion additional litigation reserve predominantly mortgage related matter . noninter expense prior year $ 3 . 3 billion include $ 3 . 0 billion additional litigation reserves . 4 6 treasury chief investment office cio select income statement balance sheet datathree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changesecuritie gainsa $ 8 3 7 $ 9 8 9 1 5 % $ 9 3 9 $ 1 5 9 9 4 1 % investment security portfolio average 3 3 5 5 4 3 3 2 0 5 7 8 5 3 2 4 4 9 2 3 2 5 5 5 3 investment security portfolio ending 3 1 8 2 3 7 3 0 5 2 8 8 4 3 1 8 2 3 7 3 0 5 2 8 8 4 mortgage loan average 1 2 7 3 1 8 5 3 9 4 9 1 2 0 7 8 8 3 5 2 4 5 mortgage loan ending 1 3 2 4 3 8 9 0 0 4 9 1 3 2 4 3 8 9 0 0 4 9 areflects reposition corporate investment security portfolio . for information investment security portfolio note 3 note 1 1 page 1 0 2 1 1 4 1 2 8 1 3 2 respectively form 1 0 q . information cio var firm nontrade interest ratesensitive revenue risk market risk management section page 8 8 9 2 form 1 0 q . private equity portfolio select income statement balance sheet datathree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 change 2 0 1 1 2 0 1 0 changeprivate equity gainslosse realize gains $ 1 2 1 9 $ 7 8 nm $ 1 3 9 0 $ 1 9 1 nmunrealize gainslossesa 7 2 6 7 nm 3 5 6 8 2 3 3 4 % total direct investments 4 9 3 7 1 nm 1 0 3 4 1 0 9 nmthirdparty fund investments 3 2 3 4 nm 5 0 9 1 0 2 3 9 9 total private equity gainslossesb $ 8 1 6 $ 7 5 nm $ 1 5 4 3 $ 2 1 1 nmprivate equity portfolio informationc direct investment millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 changepublicly hold security carry value $ 6 7 0 $ 8 7 5 2 3 % cost 5 9 5 7 3 2 1 9 quoted public value 7 2 1 9 3 5 2 3 privately hold direct security carry value 5 6 8 0 5 8 8 2 3 cost 6 8 9 1 6 8 8 7 thirdparty fund investmentsd carry value 2 4 8 1 1 9 8 0 2 5 cost 2 4 6 4 2 4 0 4 2 total private equity portfolio carry value $ 8 8 3 1 $ 8 7 3 7 1 cost $ 9 9 5 0 $ 1 0 0 2 3 1 aunrealized gainslosse contain reversal unrealized gain loss recognize prior period realized . binclude principal transaction revenue consolidated statement income . cfor information firm policy regard valuation private equity portfolio note 3 page 1 7 0 1 8 7 jpmorgan chase 2 0 1 0 annual report . dunfunded commitment thirdparty private equity fund $ 8 7 6 million $ 1 . 0 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . the carry value private equity portfolio june 3 0 2 0 1 1 december 3 1 2 0 1 0 $ 8 . 8 billion $ 8 . 7 billion respectively . increase portfolio month end june 3 0 2 0 1 1 primarily net increase investment valuation portfolio incremental new investment partially offset sale . portfolio represent 6 . 6 % 6 . 9 % firm stockholder ' equity goodwill june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . 4 7 international operationsdure month end june 3 0 2 0 1 1 firm report approximately $ 6 . 8 billion $ 1 3 . 6 billion respectively revenue derive client customer counterpartie domicile outside north america . approximately 6 9 % 6 8 % respectively derive europemiddle eastafrica emea approximately 2 1 % 2 3 % respectively asiapacific approximately 1 0 % 9 % respectively latin americacaribbean . month end june 3 0 2 0 1 0 firm report approximately $ 4 . 9 billion $ 1 1 . 7 billion respectively revenue derive client customer counterpartie domicile outside north america . approximately 6 3 % 6 7 % respectively derive emea approximately 2 8 % 2 5 % respectively asiapacific approximately 9 % 8 % respectively latin americacaribbean . firm commit expand wholesale business activity outside united state intend add additional clientserve banker product sale support personnel address need firm client locate region . comprehensive coordinated international business strategy growth plan effort investment growth outside united state accelerate prioritized . set forth certain key metric relate firm wholesale international operation include emea asia pacific latin americacaribbean number country region operate frontoffice headcount number client revenue select balance sheet datum . additional information regard international operation international operation page 9 1 note 3 3 page 2 9 0 jpmorgan chase 2 0 1 0 annual report . emeaasiapacificlatin americacaribbeanin million notedthree monthsende june 3 0 six monthsende june 3 0 three month end june 3 0 six monthsende june 3 0 three month end june 3 0 six month end june 3 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 revenue $ 4 6 2 8 $ 3 0 8 3 $ 9 1 1 8 $ 7 8 4 3 $ 1 4 1 4 $ 1 3 9 9 $ 3 1 5 1 $ 2 9 0 7 $ 6 6 8 $ 4 4 3 $ 1 2 3 7 $ 9 2 3 country operation 3 4 3 3 3 4 3 3 1 6 1 6 1 6 1 6 8 8 8 8 totalheadcounta 1 6 5 4 7 1 5 6 6 1 1 6 5 4 7 1 5 6 6 1 2 0 2 5 9 1 8 0 6 5 2 0 2 5 9 1 8 0 6 5 1 2 6 0 9 6 4 1 2 6 0 9 6 4 frontoffice headcount 6 1 4 0 5 5 8 0 6 1 4 0 5 5 8 0 4 4 7 0 4 0 2 7 4 4 7 0 4 0 2 7 5 2 8 4 0 1 5 2 8 4 0 1 significantclientsb 9 5 1 9 1 5 9 5 1 9 1 5 4 7 5 4 0 8 4 7 5 4 0 8 1 6 3 1 4 6 1 6 3 1 4 6 depositsaveragec $ 1 6 3 1 5 0 $ 1 3 3 4 6 4 $ 1 5 4 9 0 1 $ 1 3 6 8 2 1 $ 5 1 6 0 4 $ 4 9 7 0 8 $ 4 9 5 1 0 $ 5 1 8 4 4 $ 2 3 5 6 $ 1 3 7 2 $ 2 2 2 8 $ 1 3 5 2 loansperiodendd 3 3 4 9 6 2 6 1 1 1 3 3 4 9 6 2 6 1 1 1 2 5 4 0 0 1 7 8 3 1 2 5 4 0 0 1 7 8 3 1 2 1 1 7 2 1 3 5 7 7 2 1 1 7 2 1 3 5 7 7 asset management billions 2 9 8 2 3 9 2 9 8 2 3 9 1 1 9 9 5 1 1 9 9 5 3 7 2 4 3 7 2 4 asset supervision billions 3 5 3 2 8 2 3 5 3 2 8 2 1 6 1 1 2 7 1 6 1 1 2 7 9 4 6 8 9 4 6 8 note wholesale international operation comprise ib ts cb ciotreasury . atotal headcount include employee include service center locate region . bsignificant client define company $ 1 million revenue trail month period region exclude private banking clients . cdeposit base booking location . dloan outstanding base predominantly domicile borrower exclude loan heldforsale loan carry fair value . 4 8 balance sheet analysisselecte consolidated balance sheet datum millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 assets cash banks $ 3 0 4 6 6 $ 2 7 5 6 7 deposits banks 1 6 9 8 8 0 2 1 6 7 3 federal fund sell security purchase resale agreements 2 1 3 3 6 2 2 2 2 5 5 4 securitie borrowed 1 2 1 4 9 3 1 2 3 5 8 7 trading asset debt equity instruments 3 8 1 3 3 9 4 0 9 4 1 1 derivative receivables 7 7 3 8 3 8 0 4 8 1 securities 3 2 4 7 4 1 3 1 6 3 3 6 loans 6 8 9 7 3 6 6 9 2 9 2 7 allowance loan losses 2 8 5 2 0 3 2 2 6 6 loans net allowance loan losses 6 6 1 2 1 6 6 6 0 6 6 1 accrue interest account receivable 8 0 2 9 2 7 0 1 4 7 premise equipment 1 3 6 7 9 1 3 3 5 5 goodwill 4 8 8 8 2 4 8 8 5 4 mortgage servicing rights 1 2 2 4 3 1 3 6 4 9 other intangible assets 3 6 7 9 4 0 3 9 other assets 1 0 8 1 0 9 1 0 5 2 9 1 total assets $ 2 2 4 6 7 6 4 $ 2 1 1 7 6 0 5 liabilitie deposits $ 1 0 4 8 6 8 5 $ 9 3 0 3 6 9 federal fund purchase security loan sell repurchase agreements 2 5 4 1 2 4 2 7 6 6 4 4 commercial paper 5 1 1 6 0 3 5 3 6 3 other borrow fundsa 3 0 2 0 8 3 4 3 2 5 trading liability debt equity instruments 8 4 8 6 5 7 6 9 4 7 derivative payables 6 3 6 6 8 6 9 2 1 9 account payable liabilities 1 8 4 4 9 0 1 7 0 3 3 0 beneficial interest issue consolidated vies 6 7 4 5 7 7 7 6 4 9 longterm debta 2 7 9 2 2 8 2 7 0 6 5 3 total liabilities 2 0 6 3 8 8 5 1 9 4 1 4 9 9 stockholder equity 1 8 2 8 7 9 1 7 6 1 0 6 total liability stockholder equity $ 2 2 4 6 7 6 4 $ 2 1 1 7 6 0 5 aeffective january 1 2 0 1 1 $ 2 3 . 0 billion longterm advance fhlb reclassify borrow fund longterm debt . prioryear period revise conform current presentation . additional information note 3 note 1 8 page 1 0 2 1 1 4 1 6 4 respectively form 1 0 q . consolidated balance sheet overview jpmorgan chase asset liability increase december 3 1 2 0 1 0 predominantly overall growth wholesale client cash management activity month 2 0 1 1 increase deposit inflow end second quarter 2 0 1 1 . inflow contribute high deposit bank particular balance federal reserve bank . addition deposit bank factor affect increase total asset include higher accrue interest account receivable offset partially low trading asset debt equity instrument . addition deposit factor affect increase total liability high commercial paper account payable liability offset low federal fund purchase security loan sell repurchase agreement low beneficial interest issue consolidated vie . increase stockholder equity primarily reflect net income month end june 3 0 2 0 1 1 net repurchase common stock declaration dividend . 4 9 the following discussion significant change specific line caption consolidated balance sheet december 3 1 2 0 1 0 . description specific line caption discuss page 9 2 9 4 jpmorgan chase 2 0 1 0 annual report . deposit bank federal fund sell security purchase resale agreement security borrow deposit bank increase significantly reflect high level balance federal reserve bank increase predominantly result overall growth wholesale client cash management activity month 2 0 1 1 increase inflow shortterm wholesale deposit tss client end june 2 0 1 1 . additional information deposit discussion . security purchase resale agreement security borrow decrease predominantly ib reflect low client financing activity . trade asset liability debt equity instrumentstrade asset debt equity instrument decrease base client marketmaking activity ib . decrease primarily decline u . s . government agency mortgagebacke security equity security partially offset increase nonu . s . government debt security . additional information refer note 3 page 1 0 2 1 1 4 form 1 0 q . trading asset liability derivative receivables payablesderivative receivable payable decrease largely reduction foreign exchange derivative offset partially increase equity derivative ibs marketmaking activity . additional information refer derivative contract page 7 3 7 5 note 3 note 5 page 1 0 2 1 1 4 1 1 7 1 2 4 respectively form 1 0 q . securitiessecurities increase largely repositioning portfolio corporate response change interest rate environment . repositioning increase level nonu . s . government debt mortgagebacke security reduce level corporate debt u . s . government agency security . additional information relate security refer discussion corporateprivate equity segment page 4 6 4 7 note 3 note 1 1 page 1 0 2 1 1 4 1 2 8 1 3 2 respectively form 1 0 q . loans allowance loan lossesloan decrease modestly reflect continue portfolio runoff rfs low seasonal balance high repayment rate continue runoff washington mutual portfolio sale kohls portfolio card . decrease offset partially increase wholesale loan reflect growth client activity firm wholesale business . allowance loan loss decrease predominantly result low estimate loss credit card loan portfolio loan sale net repayment wholesale portfolio . detailed discussion loan portfolio allowance loan loss refer credit risk management page 6 7 8 8 note 3 4 1 3 1 4 page 1 0 2 1 1 4 1 1 4 1 1 6 1 3 4 1 4 8 1 4 9 1 5 0 respectively form 1 0 q . accrue interest account receivableaccrue interest account receivable increase largely high receivable security transaction pende settlement . mortgage servicing rightsmsrs decrease primarily change input assumption msr valuation model . quarter 2 0 1 1 firm revise cost service assumption reflect estimate impact high servicing cost enhance servicing process particularly loan modification foreclosure procedure include cost comply consent order enter banking regulator result $ 1 . 1 billion decrease fair value msr asset . decline interest rate contribute decrease fair value msr asset . increase cost service assumption decrease interest rate predominately change fair value msr asset result largely offset impact new capitalization amortization . additional information msrs note 3 note 1 6 page 1 0 2 1 1 4 1 5 9 1 6 3 respectively form 1 0 q . other intangible assetsthe decrease intangible asset predominantly amortization . additional information intangible asset note 1 6 page 1 5 9 1 6 3 form 1 0 q . depositsdeposit increase significantly predominantly result overall growth wholesale client cash management activity month 2 0 1 1 increase inflow end june 2 0 1 1 shortterm wholesale deposit tss client . contribute increase deposit growth number client high balance cb rfs rfs deposit net attrition relate inactive lowbalance washington mutual account . information deposit refer rfs segment discussion page 2 3 3 2 4 2 4 5 respectively liquidity risk management discussion page 6 2 6 6 note 3 1 7 page 1 0 2 1 1 4 1 6 4 respectively form 1 0 q . information wholesale liability balance include deposit refer cb ts segment discussion page 3 6 3 8 3 9 4 1 respectively form 1 0 q . 5 0 federal fund purchase security loan sell repurchase agreementssecuritie sell repurchase agreement decrease predominantly ib low financing firm trade asset low client financing balance . additional information firm liquidity risk management page 6 2 6 6 form 1 0 q . commercial paper borrow fundscommercial paper borrow fund increase growth volume liability balance sweep account relate tsss cash management product modest incremental increase commercial paper issue wholesale funding market . additional information firm liquidity risk management borrow fund page 6 2 6 6 note 1 8 page 1 6 4 form 1 0 q . accounts payable liabilitiesaccount payable liability increase largely high ib prime service customer balance additional litigation reserve predominantly mortgagerelate matters . beneficial interest issue consolidated viesbeneficial interest decrease predominantly maturity firmsponsore credit card securitization transaction . additional information firmsponsore vie loan securitization trust offbalance sheet arrangement note 1 5 page 1 5 1 1 5 9 form 1 0 q . longterm debt longterm debt increase net issuance longterm borrowing . additional information firm longterm debt activity liquidity risk management discussion page 6 2 6 6 form 1 0 q . stockholder equitytotal stockholder equity increase predominantly net income half 2 0 1 1 net increase accumulate comprehensive income reflect net unrealized gain afs security associate increase market value agency mb municipal security partially offset widening spread nonu . s . corporate debt realization gain portfolio repositioning net change fair value derivative use cash flowhedge purpose net issuance commitment issue firm employee stockbase compensation plan . increase partially offset repurchase common stock declaration cash dividend common preferred stock . 5 1 offbalance sheet arrangementsjpmorgan chase involve type offbalance sheet arrangement include specialpurpose entity spe type vie lendingrelate financial instrument e . g . commitment guarantee . discussion offbalance sheet arrangement contractual cash obligation page 9 5 1 0 1 jpmorgan chase 2 0 1 0 annual report . specialpurpose entitiesspe common type vie use securitization transaction order isolate certain asset distribute related cash flow investor . spe continue important financial market include mortgage assetbacked security commercial paper market provide market liquidity facilitate investor access specific portfolio asset risk . firm hold capital deem appropriate sperelate transaction related exposure derivative transaction lendingrelated commitment guarantee . information firm involvement spe note 1 5 page 1 5 1 1 5 9 form 1 0 q note 1 page 1 6 4 1 6 5 note 1 5 page 2 4 4 2 5 9 jpmorgan chase 2 0 1 0 annual report . implication credit rating downgrade jpmorgan chase bank n . a . certain liquidity commitment spe firm require provide funding shortterm credit rating jpmorgan chase bank n . a . downgrade specific level primarily p 1 a 1 f 1 moodys standard poor fitch respectively . aggregate liquidity commitment consolidated nonconsolidated spe $ 3 5 . 7 billion $ 3 4 . 2 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . alternatively jpmorgan chase bank n . a . downgrade firm replace liquidity provider lieu provide funding liquidity commitment certain circumstance firm facilitate sale refinancing asset spe order provide liquidity . specialpurpose entity revenue follow table summarize certain revenue information relate consolidated nonconsolidated vie firm significant involvement . revenue report table primarily represent contractual servicing credit fee income i . e . income act administrator structurer liquidity provider . include gain loss change fair value trading position derivative transaction enter vie . gain loss record principal transaction revenue . revenue vie securitization entitiesathree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 multiseller conduits $ 4 4 $ 6 0 $ 9 2 $ 1 2 7 investor intermediation 1 0 1 2 2 5 2 5 other securitization entitiesb 3 6 1 5 4 4 7 7 3 1 0 8 8 total $ 4 1 5 $ 6 1 6 $ 8 9 0 $ 1 2 4 0 aincludes revenue associate consolidated vie significant nonconsolidated vies . bexclude service revenue loan sell securitize parties . offbalance sheet lendingrelate financial instrument guarantee commitmentsjpmorgan chase provide lendingrelate financial instrument e . g . commitment guarantee meet financing need customer . contractual financial instrument represent maximum possible credit risk firm counterparty draw commitment firm require fulfill obligation guarantee counterparty subsequently fail perform accord term contract . commitment guarantee expire draw default occur . result total contractual instrument firm view representative actual future credit exposure funding requirement . discussion lendingrelate commitment guarantee firm account lendingrelated commitment page 7 5 note 2 1 page 1 6 7 1 7 1 form 1 0 q lendingrelate commitment page 1 2 8 note 3 0 page 2 7 5 2 8 0 jpmorgan chase 2 0 1 0 annual report . the follow table present june 3 0 2 0 1 1 contractual maturity offbalance sheet lendingrelate financial instrument guarantee commitment . table credit card home equity lendingrelate commitment represent total available credit borrower product . firm experience anticipate available line credit product use borrower time . firm reduce cancel credit card line credit provide borrower notice case notice permit law . firm reduce close home equity line credit significant decrease value underlying property demonstrable decline creditworthiness borrower . accompanying table exclude certain guarantee contractual maturity date e . g . loan sale securitizationrelated indemnification obligation . information discussion mortgage repurchase liability loan sale securitizationrelated indemnification 5 2 pages 5 3 5 6 note 2 1 page 1 6 7 1 7 1 respectively form 1 0 q repurchase liability loan sale securitizationrelated indemnification page 9 8 1 0 1 note 3 0 page 2 7 5 2 8 0 respectively jpmorgan chase 2 0 1 0 annual report . offbalance sheet lendingrelate financial instrument guarantee commitment june 3 0 2 0 1 1 dec 3 1 2 0 1 0 expire 1 year 3 year expire 3 year 5 year remain maturity millionsexpire 1 year expire 5 year total totallendingrelate consumer exclude credit card home equity senior lien $ 7 7 8 $ 4 1 8 2 $ 5 3 4 2 $ 6 9 6 3 $ 1 7 2 6 5 $ 1 7 6 6 2 home equity junior lien 1 6 1 5 8 3 8 4 9 3 6 4 9 2 2 3 2 8 5 8 6 3 0 9 4 8 prime mortgage 1 1 1 7 1 1 1 7 1 2 6 6 subprime mortgage auto 6 5 3 2 2 5 9 4 6 7 9 5 5 2 4 6 business banking 9 2 7 9 3 7 8 7 3 3 1 6 1 0 0 4 6 9 7 0 2 student other 2 5 1 5 1 1 6 5 4 9 9 8 4 0 5 7 9 total consumer exclude credit card 1 9 3 4 6 1 3 3 5 4 1 4 9 4 8 1 7 0 0 1 6 4 6 4 9 6 5 4 0 3 credit card 5 3 5 6 2 5 5 3 5 6 2 5 5 4 7 2 2 7 total consumer 5 5 4 9 7 1 1 3 3 5 4 1 4 9 4 8 1 7 0 0 1 6 0 0 2 7 4 6 1 2 6 3 0 wholesale unfunded commitment extend creditab 6 2 7 6 0 8 0 9 0 5 5 9 1 3 8 7 2 2 0 2 1 0 0 2 3 1 9 9 8 5 9 standby letter credit financial guaranteesabcd 2 7 3 6 9 3 9 0 8 3 2 6 5 4 6 4 0 5 2 9 7 0 5 0 9 4 8 3 7 unuse advise line credit 3 9 8 4 1 1 2 2 5 2 1 8 6 5 6 9 5 2 8 4 8 4 4 7 2 0 other letter creditad 3 9 7 3 1 6 6 9 1 2 6 5 7 6 8 6 6 6 3 total wholesale 1 3 3 9 4 3 1 3 3 9 0 9 8 5 9 9 6 1 1 8 4 1 3 6 5 6 8 9 3 4 6 0 7 9 total lendingrelated $ 6 8 8 9 1 4 $ 1 4 7 2 6 3 $ 1 0 0 9 4 4 $ 2 8 8 4 2 $ 9 6 5 9 6 3 $ 9 5 8 7 0 9 other guarantee commitment security lending guaranteese $ 2 0 5 4 1 1 $ $ $ $ 2 0 5 4 1 1 $ 1 8 1 7 1 7 derivative qualify guaranteesf 3 4 1 0 7 2 3 4 3 7 6 3 3 6 1 9 3 8 4 0 8 9 8 7 7 6 8 unsettle reverse repurchase security borrow agreements 5 9 5 7 0 5 9 5 7 0 3 9 9 2 7 other guarantee commitmentsg 1 1 1 3 2 3 2 3 0 8 4 5 2 4 6 1 7 7 6 4 9 2 aat june 3 0 2 0 1 1 december 3 1 2 0 1 0 represent contractual net risk participation total $ 6 0 8 million $ 5 4 2 million respectively unfunded commitment extend credit $ 2 2 . 3 billion $ 2 2 . 4 billion respectively standby letter credit financial guarantee $ 1 . 4 billion $ 1 . 1 billion respectively letter credit . regulatory filing federal reserve commitment gross risk participations . bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include credit enhancement bond commercial paper liquidity commitment u . s . state municipality hospital notforprofit entity $ 4 6 . 4 billion $ 4 3 . 4 billion respectively . commitment include liquidity facility nonconsolidate municipal bond vie information note 1 5 page 1 5 1 1 5 9 form 1 0 q . cat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include unissued standby letter credit commitment $ 4 1 . 9 billion $ 4 1 . 6 billion respectively . dat june 3 0 2 0 1 1 december 3 1 2 0 1 0 jpmorgan chase hold collateral relate $ 3 9 . 3 billion $ 3 7 . 8 billion respectively standby letter credit $ 1 . 7 billion $ 2 . 1 billion respectively collateral relate letter credit . eat june 3 0 2 0 1 1 december 3 1 2 0 1 0 collateral hold firm support security lending indemnification agreement total $ 2 0 7 . 9 billion $ 1 8 5 . 0 billion respectively . security lend collateral comprise primarily cash security issue government member organisation economic cooperation development oecd u . s . government agencies . frepresent notional derivative contract qualify guarantee . discussion guarantee note 5 page 1 1 7 1 2 4 note 2 1 page 1 6 7 1 7 1 form 1 0 q . gat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include unfunded commitment $ 8 7 6 million $ 1 . 0 billion respectively thirdparty private equity fund $ 1 . 5 billion $ 1 . 4 billion respectively equity investment . commitment include $ 8 1 5 million $ 1 . 0 billion respectively relate investment generally fair value net asset value discuss note 3 page 1 0 2 1 1 4 form 1 0 q . addition june 3 0 2 0 1 1 december 3 1 2 0 1 0 include letter credit hedge derivative transaction manage market risk basis $ 3 . 8 billion $ 3 . 8 billion respectively . mortgage repurchase liabilityin connection firm mortgage loan sale securitization activity fannie mae freddie mac gse mortgage loan sale privatelabel securitization transaction firm representation warranty loan sell meet certain requirement . firm require repurchase loan andor indemnify gse investor loss material breach representation warranty predominantly 5 3 repurchase demand receive firm firm loss realize date relate loan sell gse . primary reason repurchase demand gse relate allege misrepresentation primarily arise credit quality andor undisclosed debt borrower ii income level andor employment status borrower iii appraise value collateral . substantially instance mortgage insurance rescind result violation representation warranty gse cause repurchase demand gses . from 2 0 0 5 2 0 0 8 exclude washington mutual loan sell gse subject certain representation warranty firm liable approximately $ 3 8 0 billion represent principal sell adjust subsequent activity borrower repayment principal repurchase complete date . addition 2 0 0 5 2 0 0 8 washington mutual sell approximately $ 1 5 0 billion loan gse subject certain representation warranty . subsequent firm acquisition certain asset liability washington mutual fdic september 2 0 0 8 firm resolve andor limit certain current future repurchase demand loan sell gse washington mutual remain firm position obligation remain fdic receivership . additional information regard loan sell gse repurchase liability page 9 8 1 0 1 jpmorgan chase 2 0 1 0 annual report . the firm sell loan securitization transaction ginnie mae loan typically insure guarantee government agency . firm role servicer elect require repurchase delinquent loan securitize ginnie mae include sell ginnie mae subsequent modification . term repurchase loan continue insure reimbursement insured proceed normally . accordingly firm record repurchase liability relate loans . from 2 0 0 5 2 0 0 8 firm certain acquire entity certain loan level representation warranty connection approximately $ 4 5 0 billion residential mortgage loan sell deposit privatelabel securitization . $ 4 5 0 billion originally sell deposit include $ 1 6 5 billion washington mutual firm maintain certain repurchase obligation remain fdic receivership approximately $ 1 8 5 billion principal repay include $ 6 8 billion relate washington mutual . approximately $ 9 0 billion principal liquidate include $ 3 2 billion relate washington mutual average loss severity 5 8 % . remain outstanding principal balance loan include washington mutual june 3 0 2 0 1 1 approximately $ 1 7 5 billion $ 6 2 billion 6 0 day past . remain outstanding principal balance loan relate washington mutual approximately $ 6 5 billion $ 2 3 billion 6 0 day past . additional information regard loan sell private investor repurchase liability page 9 8 1 0 1 jpmorgan chase 2 0 1 0 annual report . date loanlevel repurchase demand privatelabel securitization limit . result firm repurchase reserve primarily relate loan sale gse predominantly calculate base firm repurchase activity experience gse . possible volume repurchase demand investor privatelabel securitization increase future firm offer reasonable estimate future demand base historical experience date . extent repurchase demand receive related loan firm purchase party remain viable firm typically right seek recovery related repurchase loss related party . claim relate privatelabel securitization include claim insurer guarantee certain obligation securitization trust far generally manifest securitiesrelated litigation . firm consider claim estimate repurchase liability firm separately evaluate exposure litigation establish litigation reserve . additional information regard litigation note 2 3 page 1 7 2 1 7 9 form 1 0 q . estimate mortgage repurchase liabilityto estimate firm repurchase liability arise breach representation warranty firm consider ithe level outstanding unresolved repurchase demandsiiestimate probable future repurchase demand consider information file request delinquent liquidated loan resolve unresolved mortgage insurance rescission notice firm historical experience iiithe potential ability firm cure defect identify repurchase demand cure rate ivthe estimate severity loss repurchase loan collateral makewhole settlement indemnification vthe firm potential ability recover loss thirdparty originator andvithe term agreement certain mortgage insurer parties . base factor firm recognize repurchase liability $ 3 . 6 billion $ 3 . 3 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . discussion repurchase demand process approach use firm estimate repurchase liability repurchase liability page 9 8 1 0 1 jpmorgan chase 2 0 1 0 annual report . 5 4 the follow table provide information outstanding repurchase demand unresolved mortgage insurance rescission notice exclude relate washington mutual past quarterend date . outstanding repurchase demand unresolved mortgage insurance rescission notice counterparty typea millionsjune 3 0 2 0 1 1 march 3 1 2 0 1 1 december 3 1 2 0 1 0 september 3 0 2 0 1 0 june 3 0 2 0 1 0 gse other $ 1 8 2 6 $ 1 3 2 1 $ 1 2 5 1 $ 1 3 3 3 $ 1 5 6 2 mortgage insurers 1 0 9 3 1 2 4 0 1 1 2 1 1 0 0 7 1 3 1 9 overlapping populationb 1 4 5 1 2 7 1 0 4 1 0 9 2 3 9 total $ 2 7 7 4 $ 2 4 3 4 $ 2 2 6 8 $ 2 2 3 1 $ 2 6 4 2 aprior period revise include repurchase demand mortgage insurance rescission notice relate certain loan sell deposit privatelabel securitization . firm outstanding repurchase demand predominantly gses . bbecause gse repurchase demand base mortgage insurance rescission notice remain unresolved certain loan subject unresolved mortgage insurance rescission notice unresolved repurchase demand . the follow table trend repurchase demand mortgage insurance rescission notice receive loan origination vintage exclude relate washington mutual past quarter . firm expect repurchase demand remain elevated level . quarterly mortgage repurchase demand receive loan origination vintagea millionsjune 3 0 2 0 1 1 march 3 1 2 0 1 1 december 3 1 2 0 1 0 september 3 0 2 0 1 0 june 3 0 2 0 1 0 pre 2 0 0 5 $ 3 2 $ 1 5 $ 3 9 $ 3 1 $ 3 7 2 0 0 5 5 7 4 5 7 3 6 7 9 9 2 0 0 6 3 6 3 1 5 8 1 9 8 2 1 3 3 0 0 2 0 0 7 5 1 0 3 8 1 5 3 9 5 3 7 5 3 9 2 0 0 8 3 0 1 2 4 9 2 5 4 1 9 1 1 8 6 post 2 0 0 8 8 9 9 4 6 5 4 6 5 3 total repurchase demand received $ 1 3 5 2 $ 9 4 2 $ 1 1 6 8 $ 1 0 8 5 $ 1 2 1 4 a prior period revise include repurchase demand relate certain loan sell deposit privatelabel securitizations . quarterly mortgage insurance rescission notice receive loan origination vintage millionsjune 3 0 2 0 1 1 march 3 1 2 0 1 1 december 3 1 2 0 1 0 september 3 0 2 0 1 0 june 3 0 2 0 1 0 pre 2 0 0 5 $ 3 $ 5 $ 3 $ 5 $ 4 2 0 0 5 2 4 3 2 9 7 9 2 0 0 6 3 9 6 5 5 3 6 9 4 8 2 0 0 7 7 2 1 4 4 1 4 2 1 3 4 1 8 2 2 0 0 8 3 1 4 9 5 0 4 3 5 2 post 2 0 0 8 1 1 1 total mortgage insurance rescission receivedb $ 1 7 0 $ 2 9 6 $ 2 5 8 $ 2 5 8 $ 2 9 5 aprior period revise include mortgage insurance rescission notice relate certain loan sell deposit privatelabel securitizations . bmortgage insurance rescission ultimately result repurchase demand gse lagged basis . table include mortgage insurance rescission notice gse issue repurchase demand . because firm demonstrate ability cure certain type defect frequently e . g . miss document trend type defect identify firm historical datum consider estimate future cure rate . beginning 2 0 1 0 firm overall cure rate exclude washington mutual approximately 5 0 % . repurchase result mortgage insurance rescission reflect firm overall cure rate . actual cure rate vary quarter quarter firm expect overall cure rate remain 4 0 5 0 % range foreseeable future . firm observe direct relationship type defect cause breach representation warranty severity realize loss . loss severity assumption estimate use firm historical experience projection regard home price appreciation . actual loss severity finalize repurchase makewhole settlement date exclude relate washington mutual currently average approximately 5 0 % vary quarter quarter base characteristic underlie loan change home price . loan originate thirdparty correspondent firm typically right seek recovery related repurchase loss correspondent originator . correspondentoriginate loan comprise approximately 5 9 % loan underlie outstanding repurchase demand exclude relate washington mutual . actual thirdparty recovery rate vary quarter quarter base underlie mix correspondent e . g . active inactive outofbusiness originator recovery sought . 5 5 the firm enter agreement mortgage insurer resolve claim certain portfolio firm servicer . agreement cover resolve approximately onethird firm total mortgage insurance rescission risk exposure term unpaid principal balance serviced loan cover mortgage insurance mortgage insurance coverage . impact agreement reflect repurchase liability disclose outstanding mortgage insurance rescission notice june 3 0 2 0 1 1 . firm consider remain unresolved mortgage insurance rescission risk exposure estimate repurchase liability june 3 0 2 0 1 1 . substantially estimate assumption underlie firm establish methodology compute record repurchase liability include probable future demand purchaser base historical experience ability firm cure identify defect severity loss repurchase foreclosure recovery party require application significant level management judgment . estimate repurchase liability complicate limited rapidly change historical datum uncertainty surround numerous external factor include economic factor example decline home price change borrower behavior lead increase number default severity loss ii level future demand dependent action party gse mortgage insurer . firm use good information available estimate repurchase liability estimation process inherently uncertain imprecise potentially volatile additional information obtain external factor continue evolve . the follow table summarize change repurchase liability period presented . summary change mortgage repurchase liability month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 repurchase liability beginning period $ 3 4 7 4 $ 1 9 8 2 $ 3 2 8 5 $ 1 7 0 5 realized lossesa 2 4 1 3 1 7 4 7 2 5 6 3 provision repurchase losses 3 9 8 6 6 7 8 1 8 1 1 9 0 repurchase liability end period $ 3 6 3 1 $ 2 3 3 2 $ 3 6 3 1 $ 2 3 3 2 aincludes principal loss accrue interest repurchase loan makewhole settlement settlement claimant certain related expense . makewhole settlement $ 1 2 6 million $ 1 5 0 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 2 4 1 million $ 2 5 5 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . the follow table summarize total unpaid principal balance repurchase period indicated . unpaid principal balance mortgage loan repurchasesa month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 ginnie maeb $ 1 2 2 8 $ 3 2 3 0 $ 2 7 1 3 $ 5 2 4 0 gses othercd 2 4 7 4 9 4 4 6 3 8 1 5 total $ 1 4 7 5 $ 3 7 2 4 $ 3 1 7 6 $ 6 0 5 5 aexcludes mortgage insurer . rescission mortgage insurance ultimately trigger repurchase demand mortgage insurer present repurchase demand firm . bin substantially case repurchase represent firm voluntary repurchase certain delinquent loan loan pool package permit ginnie mae guideline i . e . result repurchase demand breach representation warranty . firm typically elect repurchase delinquent loan continue service andor manage foreclosure process accordance applicable requirement ginnie mae federal housing administration fha rural housing administration rha andor u . s . department veteran affair va . cpredominantly repurchase relate gse . dnonaccrual loan heldforinvestment include $ 3 7 8 million $ 3 5 4 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively loan repurchase result breach representation warranties . 5 6 capital managementthe follow discussion jpmorgan chase capital management highlight development december 3 1 2 0 1 0 read conjunction capital management page 1 0 2 1 0 6 jpmorgan chase 2 0 1 0 annual report . firm capital management objective hold capital sufficient tocover material risk underlie firm business activitiesmaintain wellcapitalize status regulatory requirementsachieve debt rating targetsretain flexibility advantage future investment opportunity andbuild invest business highly stress environment . regulatory capital federal reserve establish capital requirement include wellcapitalize standard consolidated financial hold company . office comptroller currency occ establish similar capital requirement standard firm national bank include jpmorgan chase bank n . a . chase bank usa n . a . june 3 0 2 0 1 1 december 3 1 2 0 1 0 jpmorgan chase banking subsidiary wellcapitalize meet capital requirement subject . the follow table present regulatory capital asset riskbase capital ratio jpmorgan chase significant banking subsidiary june 3 0 2 0 1 1 december 3 1 2 0 1 0 . determine accordance regulation issue federal reserve andor occ . jpmorgan chase co . i jpmorgan chase bank n . a . j chase bank usa n . a . j wellcapitalize ratiosjminimum capital ratiosjin million ratiosjune 3 0 2 0 1 1 dec . 3 1 2 0 1 0 june 3 0 2 0 1 1 dec . 3 1 2 0 1 0 june 3 0 2 0 1 1 dec . 3 1 2 0 1 0 regulatory capital tier 1 a $ 1 4 8 8 8 0 $ 1 4 2 4 5 0 $ 9 3 4 9 8 $ 9 1 7 6 4 $ 1 3 2 9 9 $ 1 2 9 6 6 total 1 8 7 8 9 9 1 8 2 2 1 6 1 3 1 5 3 7 1 3 0 4 4 4 1 6 7 8 9 1 6 6 5 9 tier 1 commonb 1 2 1 2 0 9 1 1 4 7 6 3 9 2 7 1 5 9 0 9 8 1 1 3 2 9 9 1 2 9 6 6 asset riskweightedcd 1 1 9 8 7 1 1 1 1 7 4 9 7 8 1 0 0 3 5 6 8 9 6 5 8 9 7 1 0 2 4 6 0 1 1 6 9 9 2 adjust averagee 2 1 2 9 5 1 0 2 0 2 4 5 1 5 1 7 0 1 7 9 4 1 6 1 1 4 8 6 1 0 4 0 7 3 1 1 7 3 6 8 capital ratio tier 1 af 1 2 . 4 % 1 2 . 1 % 9 . 3 % 9 . 5 % 1 3 . 0 % 1 1 . 1 % 6 . 0 % 4 . 0 % totalg 1 5 . 7 1 5 . 5 1 3 . 1 1 3 . 5 1 6 . 4 1 4 . 2 1 0 . 0 8 . 0 tier 1 leverageh 7 . 0 7 . 0 5 . 5 5 . 7 1 2 . 8 1 1 . 0 5 . 0 k 3 . 0 l tier 1 commonb 1 0 . 1 9 . 8 9 . 2 9 . 4 1 3 . 0 1 1 . 1 na na aat june 3 0 2 0 1 1 jpmorgan chase jpmorgan chase bank n . a . trust prefer capital debt security $ 1 9 . 7 billion $ 6 0 0 million respectively . security exclude calculation june 3 0 2 0 1 1 tier 1 capital $ 1 2 9 . 1 billion $ 9 2 . 9 billion respectively correspond tier 1 capital ratio 1 0 . 8 % 9 . 3 % respectively . june 3 0 2 0 1 1 chase bank usa n . a . trust prefer capital debt securities . bthe tier 1 common ratio tier 1 common divide rwa . tier 1 common capital define tier 1 capital element capital form common equity perpetual preferred stock noncontrolling interest subsidiary trust prefer capital debt security . tier 1 common capital nongaap financial measure use bank regulator investor analyst assess compare quality composition firm capital capital financial service company . firm use tier 1 common capital measure assess monitor capital position . criskweighte asset rwa consist offbalance sheet asset assign broad risk category weight factor represent risk potential default . onbalance sheet asset riskweighte base perceive credit risk associate obligor counterparty nature collateral guarantor . offbalance sheet asset lendingrelate commitment guarantee derivative offbalance sheet position riskweighte multiply contractual appropriate credit conversion factor determine onbalance sheet creditequivalent riskweighte base factor use onbalance sheet asset . rwa incorporate measure market risk relate applicable trading asset debt equity instrument foreign exchange commodity derivative . result riskweighte value risk category aggregate determine total rwa . dinclude offbalance sheet rwa june 3 0 2 0 1 1 $ 3 0 0 . 8 billion $ 2 8 7 . 5 billion $ 3 0 million december 3 1 2 0 1 0 $ 2 8 2 . 9 billion $ 2 7 4 . 2 billion $ 3 1 million jpmorgan chase jpmorgan chase bank n . a . chase bank usa n . a . respectively . eadjuste average asset purpose calculate leverage ratio include total quarterly average asset adjust unrealized gainslosse security deduction disallowed goodwill intangible asset investment certain subsidiary total adjust carry value nonfinancial equity investment subject deduction tier 1 capital . fti 1 capital ratio tier 1 capital divide rwa . tier 1 capital consist common stockholder equity perpetual preferred stock noncontrolling interest subsidiary trust prefer capital debt security goodwill certain adjustments . gtotal capital ratio total capital divide rwa . total capital ti 1 capital plus tier 2 capital . tier 2 capital consist preferred stock qualify tier 1 subordinate longterm debt instrument qualify tier 2 aggregate allowance credit loss certain percentage rwa . htier 1 leverage ratio tier 1 capital divide adjust quarterly average assets . iasset capital jpmorgan chase banking subsidiary reflect intercompany transaction respective jpmorgan chase reflect elimination intercompany transactions . 5 7 jas define regulation issue federal reserve occ fdic . krepresent requirement banking subsidiary pursuant regulation issue fdic improvement act . tier 1 leverage component definition wellcapitalize bank hold company . lthe minimum tier 1 leverage ratio bank hold company bank 3 % 4 % depend factor specify regulation issue federal reserve occ . note rating agency allow measure capital adjust upward deferred tax liability result nontaxable business combination taxdeductible goodwill . june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm defer tax liability result nontaxable business combination total $ 5 7 6 million $ 6 4 7 million respectively defer tax liability result taxdeductible goodwill $ 2 . 1 billion $ 1 . 9 billion respectively . a reconciliation total stockholder equity tier 1 common capital tier 1 capital total qualifying capital present table below . riskbase capital component asset million june 3 0 2 0 1 1 december 3 1 2 0 1 0 total stockholder equity $ 1 8 2 8 7 9 $ 1 7 6 1 0 6 preferred stock 7 8 0 0 7 8 0 0 common stockholder equity 1 7 5 0 7 9 1 6 8 3 0 6 effect certain item accumulate comprehensive incomeloss exclude tier 1 common equity 1 3 5 9 7 4 8 goodwilla 4 6 8 2 6 4 6 9 1 5 fair value dva derivative structured note liability relate firm credit quality 1 3 3 9 1 2 6 1 investment certain subsidiary 9 9 5 1 0 3 2 intangible assetsa 3 3 5 1 3 5 8 7 tier 1 common 1 2 1 2 0 9 1 1 4 7 6 3 preferred stock 7 8 0 0 7 8 0 0 qualify hybrid security noncontrolle interestsb 1 9 8 7 1 1 9 8 8 7 total tier 1 capital 1 4 8 8 8 0 1 4 2 4 5 0 longterm debt instrument qualify tier 2 2 3 8 8 4 2 5 0 1 8 qualifying allowance credit loss 1 5 2 2 1 1 4 9 5 9 adjustment investment certain subsidiary 8 6 2 1 1 total tier 2 capital 3 9 0 1 9 3 9 7 6 6 total qualify capital $ 1 8 7 8 9 9 $ 1 8 2 2 1 6 riskweighte asset 1 1 9 8 7 1 1 1 1 7 4 9 7 8 total adjust average asset $ 2 1 2 9 5 1 0 $ 2 0 2 4 5 1 5 agoodwill intangible asset net associate deferred tax liability . bprimarily include trust prefer capital debt security certain business trusts . the firm tier 1 common capital $ 1 2 1 . 2 billion june 3 0 2 0 1 1 compare $ 1 1 4 . 8 billion december 3 1 2 0 1 0 increase $ 6 . 4 billion . increase predominantly net income adjust dva $ 1 0 . 9 billion net issuance commitment issue common stock firm employee stockbase compensation plan $ 1 . 1 billion . increase partially offset $ 3 . 6 billion repurchase common stock $ 2 . 4 billion dividend common preferred stock . firm tier 1 capital $ 1 4 8 . 9 billion june 3 0 2 0 1 1 compare $ 1 4 2 . 5 billion december 3 1 2 0 1 0 increase $ 6 . 4 billion . increase tier 1 capital reflect increase tier 1 common . additional information regard firm capital ratio federal regulatory capital standard subject present regulatory development page 9 1 0 ii item 1 a risk factor page 1 9 2 1 9 3 form 1 0 q note 2 9 page 2 7 3 2 7 4 jpmorgan chase 2 0 1 0 annual report . basel iithe minimum riskbase capital requirement adopt u . s . federal banking agency follow capital accord basel committee banking supervision basel i . 2 0 0 4 basel committee publish revision accord basel ii . goal basel ii framework provide risksensitive regulatory capital calculation promote enhance risk management practice large internationally active banking organization . u . s . banking regulator publish final basel ii rule december 2 0 0 7 require jpmorgan chase implement basel ii hold company level certain key u . s . bank subsidiary . prior implementation new basel ii framework jpmorgan chase require complete qualification period consecutive quarter need demonstrate meet requirement rule satisfaction primary u . s . banking regulator . jpmorgan chase currently qualification period expect compliance relevant basel ii rule establish timeline . addition firm adopt continue adopt base establish timeline basel ii rule certain nonu . s . jurisdiction required . 5 8 basel iiiin addition basel ii framework december 1 6 2 0 1 0 basel committee issue final version capital accord commonly refer basel iii revise basel ii thing narrow definition capital increase capital requirement specific exposure introduce shortterm liquidity coverage term funding standard establish international leverage ratio . basel committee announce high capital ratio requirement basel iii provide common equity requirement increase 7 % comprise minimum 4 . 5 % plus 2 . 5 % capital conservation buffer . june 2 5 2 0 1 1 basel committee announce agreement require gsibs maintain high tier 1 common requirement range 1 % 2 . 5 % . addition basel committee state intend require certain gsibs maintain additional tier 1 common requirement 1 % certain circumstance act disincentive applicable gsib action increase systemic importance . july 1 9 2 0 1 1 basel committee publish proposal gsib assessment methodology reflect approach base broad category size interconnectedness lack substitutability crossjurisdictional activity complexity . in addition u . s . federal banking agency publish public comment propose riskbase capital floor pursuant requirement doddfrank act establish permanent basel floor basel ii basel iii capital calculation . firm fully expect compliance high basel iii capital standard effective january 1 2 0 1 9 additional doddfrank act capital requirement implement . firm estimate tier 1 common ratio basel iii rule 7 . 6 % june 3 0 2 0 1 1 . management consider estimate nongaap financial measure key measure assess firm capital position conjunction capital ratio basel requirement order enable management investor analyst compare firm capital basel iii capital standard similar estimate provide financial service companies . estimate tier 1 common basel iii rulesthe follow table present comparison tier 1 common basel rule estimate tier 1 common nongaap financial measure basel iii rule . tier 1 common basel iii include additional adjustment deduction include basel tier 1 common inclusion accumulate comprehensive income aoci relate availableforsale afs security define benefit pension postretirement employee benefit plan deduction firm define benefit pension fund assets . in million ratio june 3 0 2 0 1 1 ti 1 common basel rule $ 1 2 1 2 0 9 adjustment relate afs security define benefit pension postretirement employee benefit plansrelate component aoci 1 3 6 2 deduction net define benefit pension asset 2 5 9 5 all adjustment 2 6 estimated tier 1 common basel iii rule $ 1 1 9 9 5 0 estimated riskweighte asset basel iii rulesa $ 1 5 6 9 4 1 0 estimated tier 1 common ratio basel iii rulesb 7 . 6 % akey difference calculation riskweighte asset basel basel iii include basel iii credit risk rwa base risksensitive approach largely rely use internal credit model parameter basel rwa base fix supervisory risk weight vary counterparty type asset class b basel iii market risk rwa reflect new capital requirement relate trading asset securitization release basel committee july 2 0 0 9 include incremental capital requirement stress var correlation trading resecuritization position c basel iii include rwa operational risk basel not . bthe tier 1 common ratio tier 1 common divide rwa . the firm estimate tier 1 common ratio basel iii reflect current understanding basel iii rule application rule business currently conduct exclude impact change firm future business result implement basel iii rule . firm understanding basel iii rule base information currently publish basel committee u . s . federal banking agency . firm intend maintain strong liquidity position future shortterm liquidity coverage term funding standard basel iii rule implement 2 0 1 5 2 0 1 8 respectively . order firm believe need modify liquidity profile certain asset liability . implementation basel iii rule cause firm increase price alter type product offer customer clients . the basel iii revision govern liquidity capital requirement subject prolong observation transition period . observation period liquidity coverage ratio term funding standard begin 2 0 1 1 implementation 2 0 1 5 2 0 1 8 respectively . transition period bank meet revise tier 1 common equity requirement begin 2 0 1 3 implementation january 1 2 0 1 9 . additional capital requirement gsibs phasedin start january 1 2 0 1 6 implementation january 1 2 0 1 9 . firm continue monitor ongoing rulemaking process assess timing impact basel iii business financial condition . 5 9 brokerdealer regulatory capitaljpmorgan chase principal u . s . brokerdealer subsidiary j . p . morgan security llc jpmorgan security j . p . morgan clearing corp . jpmorgan clear . jpmorgan clearing subsidiary jpmorgan security provide clearing settlement service . jpmorgan security jpmorgan clearing subject rule 1 5 c 3 1 security exchange act 1 9 3 4 net capital rule . jpmorgan security jpmorgan clearing register future commission merchant subject rule 1 . 1 7 commodity future trade commission cftc . effective june 1 2 0 1 1 j . p . morgan future inc . register future commission merchant wholly subsidiary jpmorgan chase merge jpmorgan security . merger create combine brokerdealer future commission merchant entity provide capital operational efficiencies . jpmorgan security jpmorgan clearing elect compute minimum net capital requirement accordance alternative net capital requirement net capital rule . june 3 0 2 0 1 1 jpmorgan security net capital define net capital rule $ 1 1 . 3 billion exceed minimum requirement $ 9 . 8 billion jpmorgan clearing net capital $ 7 . 0 billion exceed minimum requirement $ 5 . 0 billion . in addition minimum net capital requirement jpmorgan security require hold tentative net capital excess $ 1 . 0 billion require notify u . s . security exchange commission sec event tentative net capital $ 5 . 0 billion accordance market credit risk standard appendix e net capital rule . june 3 0 2 0 1 1 jpmorgan security tentative net capital excess minimum notification requirements . economic risk capital jpmorgan chase assess capital adequacy relative risk underlie business activity use internal riskassessment methodology . firm measure economic capital primarily base risk factor credit market operational private equity risk . economic risk capital quarterly average billion 2 q 1 1 4 q 1 0 2 q 1 0 credit risk $ 4 7 . 6 $ 5 0 . 9 $ 4 8 . 1 market risk 1 5 . 4 1 4 . 9 1 5 . 6 operational risk 8 . 5 7 . 3 7 . 5 private equity risk 7 . 3 6 . 9 6 . 0 economic risk capital 7 8 . 8 8 0 . 0 7 7 . 2 goodwill 4 8 . 8 4 8 . 8 4 8 . 3 othera 4 6 . 5 3 8 . 0 3 3 . 6 total common stockholder equity $ 1 7 4 . 1 $ 1 6 6 . 8 $ 1 5 9 . 1 areflect additional capital require firm view meet regulatory debt rating objectives . line business equity equity line business represent firm believe business require operate independently incorporate sufficient capital address regulatory capital requirement include basel iii tier 1 common capital requirement economic risk measure capital level similarly rate peer . capital allocate line business thing goodwill intangible associate acquisition effect line business . roe measure internal target expect return establish key measure business segment performance . effective january 1 2 0 1 1 capital allocate card reduce $ 2 . 4 billion $ 1 6 . 0 billion largely reflect portfolio runoff improve risk profile business capital allocate tss increase $ 5 0 0 million $ 7 . 0 billion reflect growth underlying business . firm continue assess level capital require line business assumption methodology use allocate capital business segment refinement implement future periods . line business equity billionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 investment bank $ 4 0 . 0 $ 4 0 . 0 retail financial service 2 5 . 0 2 4 . 6 card service auto 1 6 . 0 1 8 . 4 commercial banking 8 . 0 8 . 0 treasury security service 7 . 0 6 . 5 asset management 6 . 5 6 . 5 corporateprivate equity 7 2 . 6 6 4 . 3 total common stockholder equity $ 1 7 5 . 1 $ 1 6 8 . 3 6 0 line business equity quarterly average billion 2 q 1 1 4 q 1 0 2 q 1 0 investment bank $ 4 0 . 0 $ 4 0 . 0 $ 4 0 . 0 retail financial service 2 5 . 0 2 4 . 6 2 4 . 6 card service auto 1 6 . 0 1 8 . 4 1 8 . 4 commercial banking 8 . 0 8 . 0 8 . 0 treasury security service 7 . 0 6 . 5 6 . 5 asset management 6 . 5 6 . 5 6 . 5 corporateprivate equity 7 1 . 6 6 2 . 8 5 5 . 1 total common stockholder equity $ 1 7 4 . 1 $ 1 6 6 . 8 $ 1 5 9 . 1 capital actionsdividendson march 1 8 2 0 1 1 board director increase firm quarterly common stock dividend $ 0 . 0 5 $ 0 . 2 5 share effective dividend pay april 3 0 2 0 1 1 shareholder record april 6 2 0 1 1 . firm common stock dividend policy reflect jpmorgan chase earning outlook desire dividend payout ratio capital objective alternative investment opportunity . firm current expectation return payout ratio approximately 3 0 % normalize earning time . management board determine appropriate consider increase common stock dividend firm expect review plan regulator action . discussion firm dividend payment dividend page 1 0 6 jpmorgan chase 2 0 1 0 annual report . stock repurchaseson march 1 8 2 0 1 1 board director approve $ 1 5 . 0 billion common equity repurchase program $ 8 . 0 billion authorize repurchase 2 0 1 1 . $ 1 5 . 0 billion repurchase program supersede $ 1 0 . 0 billion repurchase program approve 2 0 0 7 . month end june 3 0 2 0 1 1 firm repurchase aggregate 8 0 million 8 2 million share $ 3 . 5 billion $ 3 . 6 billion average price share $ 4 3 . 3 3 $ 4 3 . 3 9 respectively . june 3 0 2 0 1 1 $ 1 1 . 4 billion authorize repurchase capacity remain $ 4 . 4 billion approve capacity remain use 2 0 1 1 . seven month end july 3 1 2 0 1 1 firm repurchase aggregate 9 9 million share $ 4 . 3 billion average price share $ 4 2 . 9 1 . management board continue assess decision regard alternative deploy capital appropriate course year . plan use repurchase program repurchase approve 2 0 1 1 review firm banking regulator action . discussion firm stock repurchase program stock repurchase page 1 0 6 jpmorgan chase 2 0 1 0 annual report . the firm time time enter write trading plan rule 1 0 b 5 1 security exchange act 1 9 3 4 facilitate repurchase accordance repurchase program . rule 1 0 b 5 1 repurchase plan allow firm repurchase equity period repurchase common stock example internal trading blackout period . purchase rule 1 0 b 5 1 plan accord predefined plan establish firm aware material nonpublic information . additional information regard repurchase firm equity security ii item 2 unregistered sale equity security use proceed page 1 9 3 1 9 4 form 1 0 q . risk managementrisk inherent jpmorgan chase business activity . firm risk management framework governance structure intend provide comprehensive control ongoing management major risk inherent business activity . firm employ holistic approach risk management ensure broad spectrum risk type consider manage business activity . firm risk management framework intend create culture risk awareness personal responsibility firm collaboration discussion escalation sharing information encourage . firm overall risk appetite establish context firm capital earning power diversify business model . firm employ formalize risk appetite framework clearly link risk appetite return target control capital management . major type risk identify business activity firm liquidity credit market interest rate operational legal reputation fiduciary private equity risk . for discussion risk manage firm risk management page 1 0 7 1 0 9 jpmorgan chase 2 0 1 0 annual report information below . 6 1 liquidity risk managementthe follow discussion jpmorgan chase liquidity risk management framework highlight development december 3 1 2 0 1 0 read conjunction page 1 1 0 1 1 5 jpmorgan chase 2 0 1 0 annual report . the ability maintain surplus level liquidity economic cycle crucial financial service company particularly period adverse condition . firm funding strategy intend ensure liquidity diversity funding source meet actual contingent liability normal stress periods . jpmorgan chase primary source liquidity include diversified deposit base $ 1 0 4 8 . 7 billion june 3 0 2 0 1 1 access equity capital market longterm unsecured secure funding source include asset securitization borrowing federal home loan bank fhlb . additionally jpmorgan chase maintain significant highlyliquid unencumbered asset . firm actively monitor availability funding wholesale market geographic region currency . firm ability generate funding broad range source variety geographic location range tenor intend enhance financial flexibility limit funding concentration risk . management consider firm liquidity position strong base liquidity metric june 3 0 2 0 1 1 believe firm unsecured secure funding capacity sufficient meet offbalance sheet obligation . firm able access funding market need month end june 3 0 2 0 1 1 . governancethe firm governance process design ensure liquidity position remain strong . assetliability committee review approve firm liquidity policy contingency funding plan . corporate treasury formulate responsible execute firm liquidity policy contingency funding plan measure monitoring report manage firm liquidity risk profile . jpmorgan chase centralize management global funding liquidity risk corporate treasury maximize liquidity access minimize funding cost enhance global identification coordination liquidity risk . centralize approach involve frequent communication business segment discipline management liquidity parent hold company comprehensive marketbase pricing asset liability continuous balance sheet monitor frequent stress testing liquidity source frequent reporting communication senior management board director regard firm liquidity position . liquidity monitoringthe firm employ variety metric monitor manage liquidity . set analysis use firm relate timing liquidity source versus liquidity use e . g . funding gap analysis parent hold company funding discuss . second set analyse focus measurement firm reliance shortterm unsecured funding percentage total liability relationship shortterm unsecured funding highlyliquid asset depositstoloan ratio balance sheet measure . firm perform regular liquidity stress test liquidity monitoring activity . purpose liquidity stress test intend ensure sufficient liquidity firm idiosyncratic systemic market stress condition . scenario measure firm liquidity position fullyear horizon analyze net funding gap result contractual contingent cash collateral outflow versus firm ability generate additional liquidity pledge sell excess collateral issue unsecured debt . scenario produce parent hold company major bank subsidiary firm major u . s . brokerdealer subsidiary . firm currently liquidity excess project fullyear liquidity need idiosyncratic stress scenario evaluate firm net funding gap shortterm rating downgrade a 2 p 2 systemic market stress scenario evaluate firm net funding gap period severe market stress similar market condition 2 0 0 8 assume firm uniquely stress versus peers . parent hold companyliquidity monitoring parent hold company consideration regulatory restriction limit extent bank subsidiary extend credit parent hold company nonbank subsidiary . excess cash generate parent hold company issuance activity use purchase liquid collateral reverse repurchase agreement place bank nonbank subsidiary form deposit advance satisfy portion subsidiary funding requirement . firm liquidity management intend ensure subsidiary ability generate replacement funding event parent hold company require repayment aforementioned deposit advance . firm closely monitor ability parent hold company meet obligation liquid source cash cash equivalent extended period time access unsecured funding market . firm target prefunde parent hold company obligation 1 2 month conservative liquidity management action firm current environment current prefunding obligation significantly great target . 6 2 global liquidity reservein addition parent hold company firm maintain significant liquidity primarily bank subsidiary nonbank subsidiary . global liquidity reserve represent consolidated source available liquidity firm include cash deposit central bank cash proceed reasonably expect receive secured financing highly liquid unencumbered security governmentissue debt government fdicguaranteed corporate debt u . s . government agency debt agency mortgagebacke security mb . liquidity estimate realize secured financing base management current judgment assessment firm ability quickly raise secured financing . global liquidity reserve include firm borrowing capacity fhlb federal reserve bank discount window central bank collateral pledge firm bank . consider source available liquidity firm view borrowing capacity federal reserve bank discount window central bank primary source funding . june 3 0 2 0 1 1 global liquidity reserve estimate approximately $ 4 0 4 billion compare approximately $ 2 6 2 billion december 3 1 2 0 1 0 . increase global liquidity reserve reflect high level balance federal reserve bank predominantly drive overall growth wholesale client cash management activity month 2 0 1 1 increase inflow shortterm wholesale deposit tss client end june 2 0 1 1 . addition global liquidity reserve firm significant highquality marketable security available raise liquidity corporate debt equity securities . fundingsource fundsa key strength firm diversified deposit franchise rfs cb tss line business provide stable source funding decrease reliance wholesale market . june 3 0 2 0 1 1 total deposit firm $ 1 0 4 8 . 7 billion compare $ 9 3 0 . 4 billion december 3 1 2 0 1 0 . average total deposit firm $ 9 7 9 . 9 billion $ 8 7 8 . 6 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 9 5 5 . 3 billion $ 8 7 8 . 0 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively . firm typically experience high customer deposit inflow periodend . significant portion firm deposit retail deposit 3 6 % 4 0 % june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively consider particularly stable sensitive interest rate change market volatility . significant portion firm wholesale deposit consider stable source funding nature relationship generate particularly customer operate service relationship firm . june 3 0 2 0 1 1 firm depositstoloan ratio 1 5 2 % compare 1 3 4 % december 3 1 2 0 1 0 . discussion deposit liability balance trend discussion result firm business segment balance sheet analysis page 1 7 4 8 4 9 5 1 respectively form 1 0 q . additional source funding include variety unsecured secure shortterm longterm instrument . shortterm unsecured funding source include federal fund eurodollar purchase certificate deposit time deposit commercial paper borrow fund . longterm unsecured funding source include longterm debt prefer stock common stock . the firm shortterm secure source funding consist security loan sell agreement repurchase borrowing chicago pittsburgh san francisco fhlb . secure longterm funding source include assetbacked securitization borrowing chicago pittsburgh san francisco fhlb . funding market evaluate ongoing basis achieve appropriate global balance unsecured secure funding favorable rates . shortterm fundingthe firm reliance shortterm unsecured funding source limited . shortterm unsecured funding source include federal fund eurodollar purchase represent overnight fund certificate deposit time deposit commercial paper generally issue $ 1 0 0 0 0 0 maturity 2 7 0 day borrow fund consist demand note term federal fund purchase borrowing generally maturity year less . total commercial paper liability $ 5 1 . 2 billion june 3 0 2 0 1 1 compare $ 3 5 . 4 billion december 3 1 2 0 1 0 . total $ 4 3 . 5 billion $ 2 9 . 2 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively originate deposit customer choose sweep commercial paper liability cash management product offer firm . commercial paper liability source wholesale funding market $ 7 . 7 billion june 3 0 2 0 1 1 compare $ 6 . 2 billion december 3 1 2 0 1 0 addition average balance commercial paper liability source wholesale funding market $ 7 . 4 billion $ 7 . 9 billion month end june 3 0 2 0 1 1 respectively . securitie loan sell agreement repurchase generally mature day month secure predominantly highquality security collateral include governmentissued debt agency debt agency mb . balance security loan sell agreement repurchase constitute significant portion federal fund purchase security loan sell repurchase agreement $ 2 5 2 . 6 billion june 3 0 2 0 1 1 compare $ 2 7 3 . 3 billion 6 3 a december 3 1 2 0 1 0 average balance $ 2 7 7 . 4 billion $ 2 7 4 . 3 billion month end june 3 0 2 0 1 1 respectively . june 3 0 2 0 1 1 decline balance compare balance december 3 1 2 0 1 0 average balance month end june 3 0 2 0 1 1 drive low financing firm trading asset low client financing balance . balance associate security loan sell agreement repurchase fluctuate time customer investment financing activity firm demand finance firm match book activity ongoing management mix firm liability include secured unsecured financing investment trading portfolio market portfolio factor . additional information balance sheet analysis page 4 9 5 1 note 1 2 page 1 3 3 note 1 8 page 1 6 4 form 1 0 q . total borrow fund $ 3 0 . 2 billion june 3 0 2 0 1 1 compare $ 3 4 . 3 billion december 3 1 2 0 1 0 average balance borrow fund $ 3 6 . 9 billion $ 3 5 . 2 billion month end june 3 0 2 0 1 1 respectively . june 3 0 2 0 1 1 decline balance compare balance december 3 1 2 0 1 0 average balance month end june 3 0 2 0 1 1 predominantly drive low financing firm trading asset maturity shortterm unsecured bank note shortterm fhlb advances . longterm funding issuance month end june 3 0 2 0 1 1 firm issue $ 1 8 . 8 billion longterm debt include $ 1 2 . 9 billion senior note issue u . s . market $ 1 . 4 billion senior note issue nonu . s . market $ 4 . 5 billion ib structured note . addition july 2 0 1 1 firm issue $ 2 . 3 billion senior note u . s . market . month end june 3 0 2 0 1 0 firm issue $ 7 . 1 billion longterm debt include $ 1 . 3 billion senior note issue u . s . market $ 1 . 5 billion trust prefer capital debt security $ 4 . 3 billion ib structured note . month end june 3 0 2 0 1 1 $ 1 1 . 4 billion longterm debt mature redeem include $ 4 . 5 billion ib structured note . month end june 3 0 2 0 1 0 $ 1 6 . 2 billion longterm debt mature redeem include $ 5 . 4 billion ib structure notes . dure month end june 3 0 2 0 1 1 firm issue $ 3 1 . 8 billion longterm debt include $ 1 9 . 9 billion senior note issue u . s . market $ 4 . 1 billion senior note issue nonu . s . market $ 7 . 8 billion ib structured note . month end june 3 0 2 0 1 0 firm issue $ 1 8 . 0 billion longterm debt include $ 6 . 9 billion senior note issue u . s . market $ 9 0 4 million senior note issue nonu . s . market $ 1 . 5 billion trust prefer capital debt security $ 8 . 7 billion ib structured note . month end june 3 0 2 0 1 1 $ 2 9 . 5 billion longterm debt mature redeem include $ 1 0 . 1 billion ib structured note . month end june 3 0 2 0 1 0 $ 3 0 . 3 billion longterm debt mature redeem include $ 1 2 . 8 billion ib structured notes . in addition unsecured longterm funding issuance discuss firm securitize consumer credit card loan residential mortgage auto loan student loan funding purpose . month end june 3 0 2 0 1 1 firm securitize $ 1 . 0 billion credit card loan $ 3 . 2 billion loan securitization mature redeem include $ 3 . 0 billion credit card loan securitization $ 3 9 million residential mortgage loan securitization $ 7 7 million student loan securitization . month end june 3 0 2 0 1 0 firm securitize loan consolidated nonconsolidated securitization trust funding purpose $ 6 . 8 billion loan securitization mature redeem include $ 6 . 6 billion credit card loan securitization $ 4 7 million residential mortgage loan securitization $ 7 2 million student loan securitization $ 3 6 million auto loan securitizations . dure month end june 3 0 2 0 1 1 firm securitize $ 1 . 0 billion credit card loan $ 9 . 8 billion loan securitization mature redeem include $ 9 . 6 billion credit card loan securitization $ 8 3 million residential mortgage loan securitization $ 1 5 3 million student loan securitization . month end june 3 0 2 0 1 0 firm securitize loan consolidated nonconsolidated securitization trust funding purpose $ 1 3 . 5 billion loan securitization mature redeem include $ 1 3 . 2 billion credit card loan securitization $ 9 0 million residential mortgage loan securitization $ 1 5 6 million student loan securitization $ 7 5 million auto loan securitization . addition firm wholesale business securitize loan clientdriven transaction clientdriven loan securitization consider source funding firm . month end june 3 0 2 0 1 1 2 0 1 0 $ 2 6 5 million $ 3 5 2 million respectively clientdriven loan securitization mature redeem . month end june 3 0 2 0 1 1 2 0 1 0 $ 2 7 7 million $ 1 . 1 billion respectively clientdriven loan securitization mature redeem . discussion loan securitization note 1 6 page 1 5 9 1 6 3 form 1 0 q . month end june 3 0 2 0 1 1 firm borrow fhlb $ 5 million maturity . month end june 3 0 2 0 1 0 firm borrow $ 1 . 0 billion fhlb offset $ 5 . 0 billion maturity . month end june 3 0 2 0 1 1 firm borrow $ 4 . 0 billion fhlb partially offset $ 2 . 5 billion maturity . month end june 3 0 2 0 1 0 firm borrow $ 2 . 5 billion fhlb offset $ 1 3 . 5 billion maturities . 6 4 cash flowscash bank $ 3 0 . 5 billion $ 3 2 . 8 billion june 3 0 2 0 1 1 2 0 1 0 respectively . balance increase $ 2 . 9 billion december 3 1 2 0 1 0 $ 6 . 6 billion december 3 1 2 0 0 9 respectively . follow discussion highlight major activity transaction affect jpmorgan chase cash flow month end june 3 0 2 0 1 1 june 3 0 2 0 1 0 respectively . cash flow operate activitiesjpmorgan chase operate asset liability support firm capital market lending activity include origination purchase loan initially designate heldforsale . operate asset liability vary significantly normal course business timing cash flow affect clientdriven risk management activity market condition . management believe cash flow operation available cash balance firm ability generate cash short longterm borrowing sufficient fund firm operate liquidity needs . for month end june 3 0 2 0 1 1 net cash provide operate activity $ 5 8 . 7 billion . result decrease trading asset debt equity instrument drive client marketmaking activity ib primarily decline u . s . government agency mortgagebacke security equity security partially offset increase nonu . s . government debt securitie decrease trading asset derivative receivables largely reduction foreign exchange derivative partially offset increase equity derivative ibs marketmaking activity increase account payable liability largely high ib prime service customer balance . partially offset cash proceed decrease trading liability derivative payable largely aforementioned reduction foreign exchange derivative partially offset increase equity derivative increase accrue interest account receivable largely reflect high receivable security transaction pende settlement . net cash generate operate activity high net income largely result adjustment noncash item provision credit loss depreciation amortization stockbase compensation . additionally cash provide proceed sale paydown loan originate purchase initial intent sell slightly high cash use acquire loan reflect high level activity prioryear period . month end june 3 0 2 0 1 0 net cash provide operate activity $ 4 5 . 7 billion primarily drive increase trading liability reflect increase business activity market outside u . s . mainly asiapacific quarter 2 0 1 0 partially offset decrease trading asset drive low client flow result unfavorable financial market second quarter 2 0 1 0 . net cash generate operate activity high net income largely result adjustment noncash item provision credit loss stockbase compensation depreciation amortization . proceed sale paydown loan originate purchase initial intent sell high cash use acquire loan . cash flow invest activitiesthe firm invest activity predominantly include loan originated hold investment afs security portfolio shortterm interestearne asset . month end june 3 0 2 0 1 1 net cash $ 1 4 5 . 8 billion use invest activity . result significant increase deposit bank reflect high level deposit balance federal reserve bank predominantly result overall growth wholesale client ' cash management activity month 2 0 1 1 increase inflow shortterm wholesale deposit tss client end june 2 0 1 1 increase wholesale loan reflect growth client activity firm wholesale business . partially offset cash outflow decline security purchase resale agreement predominantly ib reflect low client financing activity decrease credit card loan card reflect low seasonal balance high repayment rate continue runoff washington mutual portfolio sale kohls portfolio decrease loan rfs reflect paydown portfolio runoff repayment . month end june 3 0 2 0 1 0 net cash $ 7 3 . 7 billion provide invest activity . result decrease deposit bank largely decline deposit place federal reserve bank low interbank lending market stress gradually ease end 2 0 0 9 net decrease loan portfolio drive decline credit card loan runoff washington mutual portfolio decrease loweryielde promotional loan continue runoff residential real estate portfolio rfs repayment loan sale ib continue low client demand wholesale loan proceed sale maturity afs security use firm interest rate risk management activity high cash use acquire security . cash flow financing activity firm financing activity primarily reflect cash flow relate customer deposit issue longterm debt preferred common stock . month end june 3 0 2 0 1 1 net cash provide financing activity $ 8 9 . 3 billion . largely drive significant increase deposit predominantly result overall growth wholesale client ' cash management activity month 2 0 1 1 increase inflow shortterm wholesale deposit tss client end june 2 0 1 1 growth number client high balance cb rfs rfs deposit net attrition relate inactive lowbalance washington mutual account increase commercial 6 5 paper borrow fund growth volume liability balance sweep account relate tsss cash management product modest incremental increase commercial paper issue wholesale funding market . cash use reduce security sell repurchase agreement predominantly ib low financing firm trade asset low client financing balance net repayment longterm borrowing include decline longterm beneficial interest issue consolidated vie maturity firmsponsore credit card securitization transaction repurchase common stock payment cash dividend common preferred stock . in month 2 0 1 0 net cash use financing activity $ 1 1 2 . 3 billion . result decline deposit associate wholesale funding activity reflect firm low funding need decline tss deposit reflect normalization deposit level offset partially net inflow exist customer new business cb rfs net repayment longterm borrowing include decline longterm beneficial interest issue consolidated vie maturity firmsponsore credit card securitization transaction decline longterm advance fhlb maturity payment cash dividend repurchase common stock . additionally cash use result decline security loan sell repurchase agreement largely reduce funding requirement associate low afs security corporate reduce shortterm funding requirement ib . credit rating cost availability financing influence credit rating . reduction rating adverse effect firm access liquidity source increase cost fund trigger additional collateral funding requirement decrease number investor counterpartie willing lend firm . additionally firm funding requirement vie thirdparty commitment adversely affect decline credit rating . additional information impact credit rating downgrade funding requirement vie derivative collateral agreement specialpurpose entity page 5 2 note 5 page 1 1 7 1 2 4 respectively form 1 0 q . critical factor maintain high credit rating include stable diverse earning stream strong capital ratio strong credit quality risk management control diverse funding source discipline liquidity monitor procedures . the credit rating parent hold company firm significant banking subsidiary june 3 0 2 0 1 1 follow . shortterm debt senior longterm debt moodysspfitch moodysspfitchjpmorgan chase co . p 1 a 1 f 1 aa 3 aaajpmorgan chase bank n . a . p 1 a 1 f 1 aa 1 aaaachase bank usa n . a . p 1 a 1 f 1 aa 1 aaaathe senior unsecured rating moodys sp fitch jpmorgan chase principal bank subsidiary remain unchanged june 3 0 2 0 1 1 december 3 1 2 0 1 0 . june 3 0 2 0 1 1 moodys outlook negative sps fitchs outlook stable . july 1 8 2 0 1 1 moodys place longterm debt rating firm subsidiary review possible downgrade . firm current longterm debt rating moodys reflect support uplift firm standalone financial strength moodys assessment likelihood u . s . government support . moodys action directly relate moodys place u . s . government aaa rate review possible downgrade july 1 3 2 0 1 1 . moodys indicate action reflect change moodys opinion firm standalone financial strength . shortterm debt rating firm subsidiary affirm affect action . subsequently august 3 2 0 1 1 moodys confirm longterm debt rating firm subsidiary current level assign negative outlook rating . rating confirmation directly relate moodys confirmation august 2 2 0 1 1 aaa rating assign u . s . government . if firm senior longterm debt rating downgrade notch notch firm believe cost fund increase firm ability fund impact . jpmorgan chase unsecured debt contain requirement acceleration payment maturity change structure exist debt provide limitation future borrowing require additional collateral base unfavorable change firm credit rating financial ratio earning stock price . several rating agency announce evaluate effect financial regulatory reform legislation order determine extent financial institution include firm negatively impact . assurance firm credit rating downgrade future result reviews . 6 6 credit portfoliofor discussion firm credit risk management framework page 1 1 6 1 1 8 jp morgan chase 2 0 1 0 annual report . the follow table present jpmorgan chase credit portfolio june 3 0 2 0 1 1 december 3 1 2 0 1 0 . total credit exposure $ 1 . 8 trillion june 3 0 2 0 1 1 increase $ 7 1 1 million december 3 1 2 0 1 0 reflect increase wholesale portfolio $ 3 7 . 4 billion offset decrease consumer portfolio $ 3 6 . 7 billion . month 2 0 1 1 increase lendingrelate commitment $ 7 . 3 billion offset decrease loan derivative receivable $ 3 . 2 billion $ 3 . 1 billion respectively . firm provide credit raise capital $ 9 9 0 billion client month 2 0 1 1 . firm originate mortgage 3 6 0 0 0 0 people provide credit card approximately 4 . 6 million people lend increase credit 1 6 8 0 0 small business lend 8 0 0 notforprofit government entity include state municipality hospital university extend increase loan limit approximately 3 0 0 0 middle market company lend raise capital 5 0 0 0 corporation . firm 1 small business administration lender u . s . loan lender . 2 0 0 9 2 0 1 0 firm lend $ 7 billion $ 1 0 billion respectively small business commit lend $ 1 2 billion 2 0 1 1 . firm remain committed help homeowner prevent foreclosure . beginning 2 0 0 9 firm offer 1 1 7 7 0 0 0 trial modification struggle homeowner . table report loan include loan retain i . e . heldforinvestment loan heldforsale carry low cost fair value change value record noninter revenue loan account fair value . additional information firm loan derivative receivable include firm accounting policy note 1 3 note 5 page 1 3 4 1 4 8 1 1 7 1 2 4 respectively form 1 0 q note 1 4 note 6 page 2 2 0 2 3 8 1 9 1 1 9 9 respectively jpmorgan chase 2 0 1 0 annual report . average retained loan balance use net chargeoff rate calculations . total credit portfolio month end june 3 0 month end june 3 0 credit exposure nonperformingdef net chargeoff averageannual net chargeoff rateg net chargeoff averageannual net chargeoff ratehin million ratiosjune 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 loan retained $ 6 8 4 9 1 6 $ 6 8 5 4 9 8 $ 1 1 7 1 4 $ 1 4 3 4 5 $ 3 1 0 3 $ 5 7 1 4 1 . 8 3 % 3 . 2 8 % $ 6 8 2 3 $ 1 3 6 2 4 2 . 0 2 % 3 . 8 8 % loans heldforsale 2 8 1 3 5 4 5 3 1 1 4 3 4 1 loan fair value 2 0 0 7 1 9 7 6 1 0 0 1 5 5 total loan reported 6 8 9 7 3 6 6 9 2 9 2 7 1 1 9 2 8 1 4 8 4 1 3 1 0 3 5 7 1 4 1 . 8 3 3 . 2 8 6 8 2 3 1 3 6 2 4 2 . 0 2 3 . 8 8 derivative receivables 7 7 3 8 3 8 0 4 8 1 2 2 3 4 nana nana nana nanareceivables customer interest purchase receivablesa 3 2 6 7 8 3 2 9 3 2 total creditrelate assets 7 9 9 7 9 7 8 0 6 3 4 0 1 1 9 5 0 1 4 8 7 5 3 1 0 3 5 7 1 4 1 . 8 3 3 . 2 8 6 8 2 3 1 3 6 2 4 2 . 0 2 3 . 8 8 lendingrelated commitmentsb 9 6 5 9 6 3 9 5 8 7 0 9 7 9 3 1 0 0 5 nana nana nana nanaasset acquire loan satisfaction real estate ownednana 1 2 3 9 1 6 1 0 nana nana nana nanaothernana 5 1 7 2 nana nana nana nanatotal asset acquire loan satisfactionsna 1 2 9 0 1 6 8 2 nana nana nana nanatotal credit portfolio $ 1 7 6 5 7 6 0 $ 1 7 6 5 0 4 9 $ 1 4 0 3 3 $ 1 7 5 6 2 $ 3 1 0 3 $ 5 7 1 4 1 . 8 3 % 3 . 2 8 % $ 6 8 2 3 $ 1 3 6 2 4 2 . 0 2 % 3 . 8 8 % net credit derivative hedge notionalc $ 2 4 0 0 6 $ 2 3 1 0 8 $ 4 5 $ 5 5 nana nana nana nanaliquid security cash collateral hold derivatives 1 6 5 0 6 1 6 4 8 6 nana nana nana nana nanaareceivable customer represent primarily margin loan prime retail brokerage customer include accrue interest account receivable consolidated balance sheet . interest purchase receivables represent ownership interest cash flow pool receivables transfer thirdparty seller bankruptcyremote entity generally trust include asset consolidated balance sheet . bthe nonperforme represent commitment risk rate nonaccrual . crepresent net notional protection purchase sell singlename portfolio credit derivative use manage perform nonperforme credit exposure derivative qualify hedge account u . s . gaap . additional information credit derivative page 7 4 7 5 note 5 page 1 1 7 1 2 4 form 1 0 q . dat june 3 0 2 0 1 1 december 3 1 2 0 1 0 nonperforme asset exclude 1 mortgage loan insure u . s . government agency $ 9 . 1 billion $ 9 . 4 billion respectively 9 0 day past 2 real estate insure u . s . government agency $ 2 . 4 billion $ 1 . 9 billion respectively 3 student loan insure u . s . government agency ffelp $ 5 5 8 million $ 6 2 5 million respectively 9 0 day past . exclude reimbursement insured proceed normally . addition firm policy generally exempt credit card loan place nonaccrual status permit regulatory guidance issue federal financial institution examination council ffiec . credit card loan chargedoff end month account 1 8 0 day past 6 0 day receive notification specify event e . g . bankruptcy borrower whichever earlier . eexclude pci loan acquire washington mutual transaction account pool basis . pool account 6 7 single asset single composite interest rate aggregate expectation cash flow past status pool individual loan pool meaningful . firm recognize interest income pool loan consider performing . fat june 3 0 2 0 1 1 december 3 1 2 0 1 0 total nonaccrual loan represent 1 . 7 3 % 2 . 1 4 % total loan . gfor month end june 3 0 2 0 1 1 2 0 1 0 net chargeoff rate calculate use average retained loan $ 6 8 0 . 1 billion $ 6 9 9 . 2 billion respectively . average retained loan include average pci loan $ 6 9 . 9 billion $ 7 8 . 1 billion respectively . exclude pci loan firm total chargeoff rate 2 . 0 4 % 3 . 6 9 % respectively . hfor month end june 3 0 2 0 1 1 2 0 1 0 net chargeoff rate calculate use average retained loan $ 6 8 0 . 1 billion $ 7 0 8 . 8 billion respectively . average retained loan include average pci loan $ 7 0 . 7 billion $ 7 9 . 2 billion respectively . exclude pci loan firm total chargeoff rate 2 . 2 6 % 4 . 3 6 % respectively . wholesale credit portfolioas june 3 0 2 0 1 1 wholesale exposure ib cb tss increase $ 3 7 . 4 billion december 3 1 2 0 1 0 . overall increase primarily drive increase $ 2 1 . 2 billion loan $ 1 9 . 6 billion lendingrelate commitment partly offset decrease $ 3 . 1 billion derivative receivables . growth wholesale credit exposure represent increase client activity business region . effective january 1 2 0 1 1 commercial card credit portfolio compose approximately $ 5 . 3 billion lendingrelate commitment $ 1 . 2 billion loan previously tss transfer card . wholesale credit portfolio credit exposure nonperformingdin millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 loan retained $ 2 4 4 2 2 4 $ 2 2 2 5 1 0 $ 3 3 6 2 $ 5 5 1 0 loans heldforsale 2 5 9 2 3 1 4 7 1 1 4 3 4 1 loan fair value 2 0 0 7 1 9 7 6 1 0 0 1 5 5 loan reported 2 4 8 8 2 3 2 2 7 6 3 3 3 5 7 6 6 0 0 6 derivative receivables 7 7 3 8 3 8 0 4 8 1 2 2 3 4 receivable customer interest purchase receivablesa 3 2 6 7 8 3 2 9 3 2 total wholesale creditrelate assets 3 5 8 8 8 4 3 4 1 0 4 6 3 5 9 8 6 0 4 0 lendingrelate commitmentsb 3 6 5 6 8 9 3 4 6 0 7 9 7 9 3 1 0 0 5 total wholesale credit exposure $ 7 2 4 5 7 3 $ 6 8 7 1 2 5 $ 4 3 9 1 $ 7 0 4 5 net credit derivative hedge notionalc $ 2 4 0 0 6 $ 2 3 1 0 8 $ 4 5 $ 5 5 liquid security cash collateral hold derivatives 1 6 5 0 6 1 6 4 8 6 nanaareceivable customer represent primarily margin loan prime retail brokerage customer include accrue interest account receivable consolidated balance sheet . interest purchase receivables represent ownership interest cash flow pool receivables transfer thirdparty seller bankruptcyremote entity generally trust include asset consolidated balance sheets . bthe nonperforme represent commitment risk rate nonaccrual . crepresent net notional protection purchase sell singlename portfolio credit derivative use manage perform nonperforme credit exposure derivative qualify hedge account u . s . gaap . additional information credit derivative page 7 4 7 5 note 5 page 1 1 7 1 2 4 form 1 0 q . dexcludes asset acquire loan satisfaction . 6 8 the follow table present summary maturity rating profile wholesale portfolio june 3 0 2 0 1 1 december 3 1 2 0 1 0 . rating scale base firm internal risk rating generally correspond rating define sp moodys . include table notional value net credit derivative hedge counterpartie hedge predominantly investmentgrade ig bank finance companies . wholesale credit exposure maturity rating profile maturity profilee rating profilejune 3 0 2 0 1 1 due 1 year lessdue 1 year 5 yearsdue 5 yearstotal investmentgrade noninvestmentgradetotaltotal % igin million ratio aaaaaa bbbbaa 3 bbba 1 belowloan retained $ 9 6 2 7 8 $ 8 9 2 3 0 $ 5 8 7 1 6 $ 2 4 4 2 2 4 $ 1 6 6 5 1 3 $ 7 7 7 1 1 $ 2 4 4 2 2 4 6 8 % derivative receivablesa 7 7 3 8 3 7 7 3 8 3 liquid security cash collateral hold derivative 1 6 5 0 6 1 6 5 0 6 total derivative receivables net collateral 9 6 2 8 2 1 9 9 1 2 9 2 5 8 6 0 8 7 7 4 8 1 4 5 1 2 7 3 2 6 0 8 7 7 7 9 lendingrelated commitments 1 3 3 9 4 2 2 1 9 9 0 6 1 1 8 4 1 3 6 5 6 8 9 2 9 4 2 5 8 7 1 4 3 1 3 6 5 6 8 9 8 0 subtotal 2 3 9 8 4 8 3 3 1 1 2 7 9 9 8 1 5 6 7 0 7 9 0 5 0 8 9 1 6 1 6 1 8 7 4 6 7 0 7 9 0 7 6 loan heldforsale loan fair valuebc 4 5 9 9 4 5 9 9 receivable customer interest purchase receivablesc 3 2 6 7 8 3 2 6 7 8 total exposure net liquid security cash collateral hold derivative $ 7 0 8 0 6 7 $ 7 0 8 0 6 7 net credit derivative hedge notionald $ 1 8 6 2 $ 1 5 5 2 5 $ 6 6 1 9 $ 2 4 0 0 6 $ 2 4 0 7 1 $ 6 5 $ 2 4 0 0 6 1 0 0 % maturity profilee rating profiledecember 3 1 2 0 1 0 due 1 year lessdue 1 year 5 yearsdue 5 yearstotal investmentgrade noninvestmentgradetotaltotal % igin million ratio aaaaaa bbbbaa 3 bbba 1 belowloan retained $ 7 8 0 1 7 $ 8 5 9 8 7 $ 5 8 5 0 6 $ 2 2 2 5 1 0 $ 1 4 6 0 4 7 $ 7 6 4 6 3 $ 2 2 2 5 1 0 6 6 % derivative receivablesa 8 0 4 8 1 8 0 4 8 1 liquid security cash collateral hold derivative 1 6 4 8 6 1 6 4 8 6 total derivative receivables net collateral 1 1 4 9 9 2 4 4 1 5 2 8 0 8 1 6 3 9 9 5 4 7 5 5 7 1 6 4 3 8 6 3 9 9 5 7 4 lendingrelated commitments 1 2 6 3 8 9 2 0 9 2 9 9 1 0 3 9 1 3 4 6 0 7 9 2 7 6 2 9 8 6 9 7 8 1 3 4 6 0 7 9 8 0 subtotal 2 1 5 9 0 5 3 1 9 7 0 1 9 6 9 7 8 6 3 2 5 8 4 4 6 9 9 0 2 1 6 2 6 8 2 6 3 2 5 8 4 7 4 loans heldforsale loan fair valuebc 5 1 2 3 5 1 2 3 receivable customer interest purchase receivablesc 3 2 9 3 2 3 2 9 3 2 total exposure net liquid security cash collateral hold derivative $ 6 7 0 6 3 9 $ 6 7 0 6 3 9 net credit derivative hedge notionald $ 1 2 2 8 $ 1 6 4 1 5 $ 5 4 6 5 $ 2 3 1 0 8 $ 2 3 1 5 9 $ 5 1 $ 2 3 1 0 8 1 0 0 % arepresent fair value derivative receivables report consolidated balance sheets . bloan heldforsale loan fair value relate primarily syndicate loan loan transfer retained portfolio . cfrom credit risk perspective maturity rating profile meaningful . drepresent net notional protection purchase sell singlename portfolio credit derivative use manage credit exposure derivative qualify hedge account u . s . gaap . ethe maturity profile retained loan lendingrelated commitment base remain contractual maturity . maturity profile derivative receivable base maturity profile average exposure . discussion average exposure derivative receivables mtm page 7 3 7 4 form 1 0 q . receivables customer $ 3 2 . 5 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 primarily represent margin loan prime retail brokerage client include previous table . margin loan collateralize pledge asset maintain client brokerage account subject daily minimum collateral requirement . event collateral value decrease maintenance margin client provide additional collateral account . additional collateral provide client client position liquidate firm meet minimum collateral requirements . 6 9 wholesale credit exposure select industry exposure firm focus management diversification industry exposure particular attention pay industry actual potential credit concern . exposure deem criticize generally represent rating profile similar rating ccccaa 1 low define sp moodys respectively . total criticize component portfolio exclude loan heldforsale loan fair value decrease $ 1 8 . 3 billion june 3 0 2 0 1 1 $ 2 2 . 4 billion december 3 1 2 0 1 0 . decrease primarily relate net repayment loan sales . below summary 2 5 industry exposure june 3 0 2 0 1 1 december 3 1 2 0 1 0 . 3 0 day past accruingloansyeartodate net chargeoffsrecoveriescredit derivative hedgeseliquid security cash collateral hold derivativereceivablesas month end noninvestment gradejune 3 0 2 0 1 1 creditexposuredinvestment gradenoncriticizedcriticize performingcriticize nonperformingin millionstop 2 5 industriesa bank finance companies $ 6 4 6 4 2 $ 5 3 8 8 8 $ 1 0 3 2 4 $ 3 7 7 $ 5 3 $ 2 2 $ 1 3 $ 2 4 8 6 $ 8 8 8 0 real estate 6 3 2 5 2 3 5 5 9 4 2 1 0 3 9 5 1 8 1 1 4 3 8 2 0 3 1 9 1 6 8 1 3 4 healthcare 3 9 8 9 9 3 3 2 7 4 6 3 3 1 2 5 4 4 0 3 5 6 5 9 1 3 5 state municipal governmentsb 3 7 3 5 6 3 6 2 8 7 8 4 8 1 9 6 2 5 3 1 9 1 8 7 asset managers 3 4 0 5 9 2 8 3 1 9 5 3 8 5 3 5 5 7 1 3 3 5 5 oil gas 2 9 4 1 3 2 0 7 7 2 8 5 7 3 6 7 1 5 4 1 0 6 1 7 8 utilities 2 7 3 1 6 2 2 6 9 0 3 8 5 4 5 0 4 2 6 8 3 3 2 9 5 2 6 7 consumer products 2 6 4 1 1 1 6 8 0 6 8 9 7 8 6 0 3 2 4 5 3 7 8 9 3 retail consumer services 2 1 5 1 7 1 3 5 2 7 7 4 4 6 4 7 6 6 8 1 3 4 1 1 2 technology 1 4 7 2 5 1 0 2 3 5 4 1 6 7 3 2 3 4 1 8 3 2 machinery equipment manufacturing 1 4 1 1 6 8 2 0 1 5 7 5 1 1 6 3 1 2 1 1 6 1 metalsmining 1 3 7 6 7 7 3 1 1 6 0 7 7 3 7 1 8 1 0 1 2 4 6 6 telecom services 1 3 0 4 9 1 0 0 5 8 2 2 2 4 7 6 5 2 3 7 7 8 1 6 central government 1 2 8 4 2 1 2 3 8 3 4 4 3 1 6 7 8 1 1 3 2 2 media 1 1 6 3 6 6 1 1 8 4 3 8 8 7 2 8 4 0 2 1 8 7 2 1 5 2 builde materialsconstruction 1 1 4 6 6 5 7 4 2 4 7 2 8 9 8 8 8 6 2 3 1 7 insurance 1 1 3 5 2 8 6 9 6 2 3 0 2 3 4 2 1 2 7 7 1 1 4 0 7 holde companies 1 1 2 5 2 8 8 2 0 2 3 8 0 5 0 2 1 6 2 4 5 6 chemicalsplastics 1 1 1 3 4 7 3 3 1 3 5 6 7 2 3 5 1 3 8 business services 1 1 1 3 2 6 0 2 6 4 9 6 7 9 7 4 2 4 2 9 transportation 1 0 6 0 6 7 2 4 7 3 1 4 7 1 7 1 4 1 9 1 1 0 1 6 securitie firm exchanges 1 0 3 0 6 8 5 1 2 1 7 4 1 5 3 8 8 2 2 4 1 automotive 9 6 5 9 4 7 7 5 4 7 0 8 1 7 5 1 1 1 8 2 9 agriculturepaper manufacturing 7 3 0 7 4 8 2 6 2 2 8 5 1 9 6 4 1 0 3 aerospace 5 9 7 3 4 9 2 9 9 8 8 5 6 1 1 6 2 all otherc 1 6 3 1 0 9 1 4 1 2 5 1 1 8 7 2 5 2 1 8 6 9 4 7 6 1 8 3 7 7 2 7 6 subtotal $ 6 8 7 2 9 6 $ 5 2 3 6 1 8 $ 1 4 5 3 6 6 $ 1 4 9 2 8 $ 3 3 8 4 $ 1 0 6 9 $ 2 4 5 $ 2 4 0 0 6 $ 1 6 5 0 6 loan heldforsale loan fair value 4 5 9 9 receivable customer interest purchase receivables 3 2 6 7 8 total $ 7 2 4 5 7 3 7 0 3 0 day past accruingloansyeartodate net chargeoffsrecoveriescredit derivative hedgeseliquid security cash collateral hold derivativereceivablesas year end noninvestment gradedecember 3 1 2 0 1 0 creditexposuredinvestment gradenoncriticizedcriticize performingcriticize nonperformingin millionstop 2 5 industriesa bank finance companies $ 6 5 8 6 7 $ 5 4 8 3 9 $ 1 0 4 2 8 $ 4 6 7 $ 1 3 3 $ 2 6 $ 6 9 $ 3 4 5 6 $ 9 2 1 6 real estate 6 4 3 5 1 3 4 4 4 0 2 0 5 6 9 6 4 0 4 2 9 3 8 3 9 9 8 6 2 7 6 5 7 healthcare 4 1 0 9 3 3 3 7 5 2 7 0 1 9 2 9 1 3 1 8 5 4 7 6 8 1 6 1 state municipal governmentsb 3 5 8 0 8 3 4 6 4 1 9 1 2 2 3 1 2 4 3 4 3 1 8 6 2 3 3 asset managers 2 9 3 6 4 2 5 5 3 3 3 4 0 1 4 2 7 3 7 2 9 4 8 oil gas 2 6 4 5 9 1 8 4 6 5 7 8 5 0 1 4 3 1 2 4 8 7 5 0 utilities 2 5 9 1 1 2 0 9 5 1 4 1 0 1 4 9 8 3 6 1 3 4 9 3 5 5 2 3 0 consumer products 2 7 5 0 8 1 6 7 4 7 1 0 3 7 9 3 7 1 1 1 2 1 7 1 7 5 2 2 retail consumer services 2 0 8 8 2 1 2 0 2 1 8 3 1 6 3 3 8 2 0 7 8 2 3 6 2 3 3 technology 1 4 3 4 8 9 3 5 5 4 5 3 4 3 9 9 6 0 4 7 5 0 1 5 8 machinery equipment manufacturing 1 3 3 1 1 7 6 9 0 5 3 7 2 2 4 4 5 8 2 7 4 2 metalsmining 1 1 4 2 6 5 2 6 0 5 7 4 8 3 6 2 5 6 7 3 5 2 9 6 telecom services 1 0 7 0 9 7 5 8 2 2 2 9 5 8 2 1 1 1 3 8 8 2 0 central government 1 1 1 7 3 1 0 6 7 7 4 9 6 6 8 9 7 4 2 media 1 0 9 6 7 5 8 0 8 3 9 4 5 6 7 2 5 4 2 2 9 2 2 1 2 3 building materialsconstruction 1 2 8 0 8 6 5 5 7 5 0 6 5 1 1 2 9 5 7 9 6 3 0 8 insurance 1 0 9 1 8 7 9 0 8 2 6 9 0 3 2 0 1 8 0 5 5 6 7 holde companies 1 0 5 0 4 8 3 7 5 2 0 9 1 3 8 3 3 5 3 6 2 chemicalsplastics 1 2 3 1 2 8 3 7 5 3 6 5 6 2 7 4 7 2 7 0 business services 1 1 2 4 7 6 3 5 1 4 7 3 5 1 1 5 4 6 1 1 1 5 5 transportation 9 6 5 2 6 6 3 0 2 7 3 9 2 4 5 3 8 1 6 1 3 2 securitie firm exchanges 9 4 1 5 7 6 7 8 1 7 0 0 3 7 5 3 8 2 3 5 8 automotive 9 0 1 1 3 9 1 5 4 8 2 2 2 6 9 5 5 2 7 5 8 agriculturepaper manufacturing 7 3 6 8 4 5 1 0 2 6 1 4 2 4 2 2 8 7 4 4 2 aerospace 5 7 3 2 4 9 0 3 7 3 2 9 7 3 2 1 all otherc 1 4 0 9 2 6 1 2 2 5 9 4 1 4 9 2 4 2 4 0 2 1 0 0 6 9 2 1 4 7 0 5 8 6 7 2 5 0 subtotal $ 6 4 9 0 7 0 $ 4 8 5 5 5 7 $ 1 4 1 1 3 3 $ 1 6 8 3 6 $ 5 5 4 4 $ 1 8 5 2 $ 1 7 2 7 $ 2 3 1 0 8 $ 1 6 4 8 6 loans heldforsale loan fair value 5 1 2 3 receivable customer interest purchase receivables 3 2 9 3 2 total $ 6 8 7 1 2 5 aall industry ranking base exposure june 3 0 2 0 1 1 . industry ranking present table december 3 1 2 0 1 0 base industry ranking correspond exposure june 3 0 2 0 1 1 actual ranking exposure december 3 1 2 0 1 0 . bin addition credit risk exposure state municipal government june 3 0 2 0 1 1 december 3 1 2 0 1 0 note firm $ 8 . 6 billion $ 1 4 . 0 billion respectively trading security $ 1 1 . 6 billion $ 1 1 . 6 billion respectively availableforsale security issue state municipal government . information note 5 note 1 1 page 1 1 7 1 2 4 1 2 8 1 3 2 respectively form 1 0 q . cfor information exposure spe include liquidity facility nonconsolidate municipal bond vie note 1 5 page 1 5 1 1 5 9 form 1 0 q . dcredit exposure net risk participation exclude benefit credit derivative hedge collateral hold derivative receivable loans . erepresent net notional protection purchase sell singlename portfolio credit derivative use manage credit exposure derivative qualify hedge account u . s . gaap . 7 1 the follow table present geographic distribution wholesale credit exposure include nonperforme asset past loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 . geographic distribution wholesale portfolio determine base predominantly domicile borrower . credit exposure nonperforme june 3 0 2 0 1 1 millionsloanslendingrelate commitmentsderivative receivablestotal credit exposure nonaccrual loansaderivativeslendingrelatedcommitmentstotal non performingasset acquire loan satisfactions 3 0 day pastdue andaccrue loanseuropemiddle eastafrica $ 3 3 4 9 6 $ 6 1 9 2 2 $ 3 5 2 1 8 $ 1 3 0 6 3 6 $ 4 4 $ $ 1 8 $ 6 2 $ $ 1 4 asia pacific 2 5 4 0 0 1 6 4 9 5 1 0 0 3 5 5 1 9 3 0 2 1 5 1 7 1 9 latin americacaribbean 2 1 1 7 2 1 7 1 9 1 5 2 4 0 4 3 6 0 3 4 1 3 1 7 4 3 0 1 1 7 8 other 2 0 0 1 7 0 1 0 1 8 2 0 1 0 8 3 1 7 7 1 total nonu . s . 8 2 0 6 9 1 0 2 6 1 8 5 2 3 1 3 2 3 7 0 0 0 4 6 6 1 5 3 5 5 1 6 1 2 1 2 total u . s . 1 6 2 1 5 5 2 6 3 0 7 1 2 5 0 7 0 4 5 0 2 9 6 2 8 9 6 7 7 5 8 3 6 6 1 2 8 7 8 5 7 loan heldforsale loan fair value 4 5 9 9 4 5 9 9 2 1 4 na 2 1 4 nareceivables customer interest purchase receivables 3 2 6 7 8 nananananatotal $ 2 4 8 8 2 3 $ 3 6 5 6 8 9 $ 7 7 3 8 3 $ 7 2 4 5 7 3 $ 3 5 7 6 $ 2 2 $ 7 9 3 $ 4 3 9 1 $ 2 8 8 $ 1 0 6 9 credit exposure nonperforme december 3 1 2 0 1 0 millionsloanslendingrelate commitmentsderivative receivablestotal credit exposure nonaccrual loansaderivativeslendingrelatedcommitmentstotal non performingasset acquire loan satisfactions 3 0 day pastdue andaccrue loanseuropemiddle eastafrica $ 2 7 9 3 4 $ 5 8 4 1 8 $ 3 5 1 9 6 $ 1 2 1 5 4 8 $ 1 5 3 $ 1 $ 2 3 $ 1 7 7 $ $ 1 2 7 asia pacific 2 0 5 5 2 1 5 0 0 2 1 0 9 9 1 4 6 5 4 5 5 7 9 2 1 6 0 0 7 4 latin americacaribbean 1 6 4 8 0 1 2 1 7 0 5 6 3 4 3 4 2 8 4 6 4 9 1 3 6 6 2 1 1 3 1 other 1 1 8 5 6 1 4 9 2 0 3 9 9 3 7 3 6 5 1 1 total nonu . s . 6 6 1 5 1 9 1 7 3 9 5 3 8 6 0 2 1 1 7 5 0 1 3 8 7 2 2 4 1 1 4 5 0 1 3 3 2 total u . s . 1 5 6 3 5 9 2 5 4 3 4 0 2 6 6 2 1 4 3 7 3 2 0 4 1 2 3 1 2 9 6 4 5 0 9 9 3 2 0 1 5 2 0 loan heldforsale loan fair value 5 1 2 3 5 1 2 3 4 9 6 na 4 9 6 nareceivables customer interest purchase receivables 3 2 9 3 2 nananananatotal $ 2 2 7 6 3 3 $ 3 4 6 0 7 9 $ 8 0 4 8 1 $ 6 8 7 1 2 5 $ 6 0 0 6 $ 3 4 $ 1 0 0 5 $ 7 0 4 5 $ 3 2 1 $ 1 8 5 2 aat june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm hold allowance loan loss $ 7 3 1 million $ 1 . 6 billion respectively relate nonaccrual retained loan result allowance coverage ratio 2 2 % 2 9 % respectively . wholesale nonaccrual loan represent 1 . 4 4 % 2 . 6 4 % total wholesale loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . loansin normal course business firm provide loan variety wholesale customer large corporate institutional client highnetworth individual . discussion loan include information credit quality indicator note 1 3 page 1 3 4 1 4 8 form 1 0 q . retained wholesale loan $ 2 4 4 . 2 billion june 3 0 2 0 1 1 compare $ 2 2 2 . 5 billion december 3 1 2 0 1 0 . $ 2 1 . 7 billion increase primarily relate increase client activity . firm actively manage wholesale credit exposure sale loan lendingrelated commitment . month 2 0 1 1 firm sell $ 2 . 8 billion loan commitment recognize net gain $ 1 6 million . month 2 0 1 0 firm sell $ 4 . 9 billion loan commitment recognize net gain $ 3 1 million . result include gain loss sale nonaccrual loan discuss . sale activity relate firm securitization activity . discussion securitization activity liquidity risk management note 1 5 page 6 2 6 6 1 5 1 1 5 9 respectively form 1 0 q . 7 2 the follow table present change nonaccrual loan portfolio month end june 3 0 2 0 1 1 2 0 1 0 . wholesale nonaccrual loan activity month end june 3 0 million 2 0 1 1 2 0 1 0 beginning balance $ 6 0 0 6 $ 6 9 0 4 additions 1 3 1 1 4 1 5 0 reduction paydown 1 9 7 4 2 8 5 7 gross chargeoff 3 7 7 1 1 6 2 returne perform status 4 8 9 1 1 3 sales 9 0 1 1 2 6 2 total reduction 3 7 4 1 5 3 9 4 net additionsreduction 2 4 3 0 1 2 4 4 ending balance $ 3 5 7 6 $ 5 6 6 0 nonaccrual wholesale loan decrease $ 2 . 4 billion december 3 1 2 0 1 0 primarily reflect net repayment loan sales . the follow table present net chargeoff define gross chargeoff recovery month end june 3 0 2 0 1 1 2 0 1 0 . table include gain loss sale nonaccrual loans . wholesale net chargeoffsthree month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 loan report average loan retained $ 2 3 7 5 1 1 $ 2 0 9 0 1 6 $ 2 3 2 0 5 8 $ 2 1 0 3 0 0 net chargeoffs 8 0 2 3 1 2 4 5 1 1 9 0 average annual net chargeoff ratio 0 . 1 4 % 0 . 4 4 % 0 . 2 1 % 1 . 1 4 % derivative contractsin normal course business firm use derivative instrument predominantly marketmaking activity . derivative enable customer firm manage exposure fluctuation interest rate currency market . firm use derivative instrument manage credit exposure . discussion derivative contract note 5 page 1 1 7 1 2 4 form 1 0 q . the follow table summarize net derivative receivables mtm period present . derivative receivables mtm millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 interest rate $ 3 2 9 1 1 $ 3 2 5 5 5 credit derivatives 6 1 9 8 7 7 2 5 foreign exchange 1 9 8 9 8 2 5 8 5 8 equity 7 0 8 4 4 2 0 4 commodity 1 1 2 9 2 1 0 1 3 9 total net cash collateral 7 7 3 8 3 8 0 4 8 1 liquid security cash collateral hold derivative receivables 1 6 5 0 6 1 6 4 8 6 total net collateral $ 6 0 8 7 7 $ 6 3 9 9 5 derivative receivables report consolidated balance sheet $ 7 7 . 4 billion $ 8 0 . 5 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . represent fair value i . e . mtm derivative contract effect legally enforceable master net agreement cash collateral hold firm cva . management view appropriate measure current credit risk reflect additional liquid security cash collateral hold firm $ 1 6 . 5 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 table . derivative receivables decrease december 3 1 2 0 1 0 largely reduction foreign exchange derivative balance partially offset increase equity derivative ibs marketmake activity . 7 3 the firm hold additional collateral deliver client initiation transaction collateral relate contract nondaily frequency collateral firm agree return settle reporting date . collateral reduce balance note table available security potential exposure arise mtm client derivative transaction firm favor . june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm hold $ 2 2 . 3 billion $ 1 8 . 0 billion respectively additional collateral . derivative receivables mtm net collateral include credit enhancement letter credit . additional information firm use collateral agreement note 5 page 1 1 7 1 2 4 form 1 0 q . the follow table summarize rating profile firm derivative receivables mtm net liquid security collateral date indicated . rating profile derivative receivables mtmrating equivalentjune 3 0 2 0 1 1 december 3 1 2 0 1 0 million ratiosexposure net collateral % exposure net collateral exposure net collateral % exposure net collateralaaaaaa aaaa 3 $ 2 5 0 6 7 4 1 % $ 2 3 3 4 2 3 6 % aa 1 aa 3 1 5 4 6 0 2 5 1 5 8 1 2 2 5 bbbbaa 1 bbbbaa 3 7 6 1 8 1 3 8 4 0 3 1 3 bbba 1 bb 3 1 0 1 5 1 1 7 1 3 7 1 6 2 2 ccccaa 1 below 2 5 8 1 4 2 7 2 2 4 total $ 6 0 8 7 7 1 0 0 % $ 6 3 9 9 5 1 0 0 % as note firm use collateral agreement mitigate counterparty credit risk . percentage firm derivative transaction subject collateral agreement exclude foreign exchange spot trade typically cover collateral agreement short maturity remain 8 8 % june 3 0 2 0 1 1 unchanged compare december 3 1 2 0 1 0 . firm post $ 5 7 . 9 billion $ 5 8 . 3 billion collateral june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . credit derivative detailed discussion credit derivative include type derivative note 5 credit derivative page 1 1 7 1 2 4 form 1 0 q credit derivative page 1 2 6 1 2 7 note 6 credit derivative page 1 9 7 1 9 9 jpmorgan chase 2 0 1 0 annual report . the follow table present firm notional credit derivative protection purchase sell june 3 0 2 0 1 1 december 3 1 2 0 1 0 distinguish dealerclient activity credit portfolio activity . credit derivative notional june 3 0 2 0 1 1 december 3 1 2 0 1 0 dealerclient credit portfolio dealerclient credit portfolio millionsprotection purchasedbprotection sell protection purchasedprotection soldtotal protection purchasedbprotection sell protection purchasedprotection sell totalcredit default swaps $ 2 9 2 7 0 3 8 $ 2 9 7 1 9 8 1 $ 2 4 2 0 5 $ 1 9 9 $ 5 9 2 3 4 2 3 $ 2 6 6 1 6 5 7 $ 2 6 5 8 8 2 5 $ 2 3 5 2 3 $ 4 1 5 $ 5 3 4 4 4 2 0 other credit derivativesa 6 1 2 8 0 1 2 0 7 3 3 1 8 2 0 1 3 3 4 2 5 0 9 3 7 7 6 1 2 8 0 2 6 total $ 2 9 8 8 3 1 8 $ 3 0 9 2 7 1 4 $ 2 4 2 0 5 $ 1 9 9 $ 6 1 0 5 4 3 6 $ 2 6 9 5 9 0 7 $ 2 7 5 2 6 0 1 $ 2 3 5 2 3 $ 4 1 5 $ 5 4 7 2 4 4 6 aprimarily consist total return swap credit default swap options . bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include $ 2 9 4 9 billion $ 2 6 6 2 billion respectively notional exposure firm sell protection identical underlying reference instruments . dealerclient businesswithin dealerclient business firm actively manage credit derivative buy sell credit protection predominantly corporate debt obligation accord client demand . information note 5 page 1 1 7 1 2 4 form 1 0 q . june 3 0 2 0 1 1 total notional protection purchase sell increase $ 6 3 3 billion december 3 1 2 0 1 0 primarily increase activity particularly emea region . 7 4 credit portfolio activity use singlename portfolio credit derivativesnotional protection purchase soldin millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 credit derivative use manage loan lendingrelate commitments $ 5 7 7 5 $ 6 6 9 8 derivative receivables 1 8 4 3 0 1 6 8 2 5 total protection purchased 2 4 2 0 5 2 3 5 2 3 total protection sold 1 9 9 4 1 5 credit derivative hedge notional net $ 2 4 0 0 6 $ 2 3 1 0 8 the credit derivative use jpmorgan chase credit portfolio management activity qualify hedge account u . s . gaap derivative report fair value gain loss recognize principal transaction revenue . contrast loan lendingrelated commitment riskmanage account accrual basis . asymmetry accounting treatment loan lendingrelated commitment credit derivative use credit portfolio management activity cause earning volatility representative firm view true change value firm overall credit exposure . mtm value relate firm credit derivative use manage credit exposure mtm value relate cva reflect credit quality derivative counterparty exposure include gain loss realize credit derivative disclose table . result vary period period market condition affect specific position portfolio . gain loss cva hedge cva lendingrelated commitmentsthree month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 hedge lendingrelate commitments $ 3 1 $ 6 0 $ 7 5 $ 6 0 cva hedge cva 9 8 2 8 9 1 3 7 2 9 0 net gainslosses $ 1 2 9 $ 2 2 9 $ 2 1 2 $ 3 5 0 lendingrelated commitmentsjpmorgan chase use lendingrelate financial instrument commitment guarantee meet financing need customer . contractual financial instrument represent maximum possible credit risk counterpartie draw commitment firm fulfill obligation guarantee counterpartie subsequently fail perform accord term contracts . wholesale lendingrelated commitment $ 3 6 5 . 7 billion june 3 0 2 0 1 1 compare $ 3 4 6 . 1 billion december 3 1 2 0 1 0 reflect increase client activity . firm view total contractual wholesale lendingrelated commitment representative firm actual credit risk exposure funding requirement . determine credit risk exposure firm wholesale lendingrelated commitment use basis allocate credit risk capital commitment firm establish loanequivalent commitment represent portion unused commitment contingent exposure expect base average portfolio historical experience draw event default obligor . loanequivalent firm lendingrelate commitment $ 1 9 4 . 7 billion $ 1 7 8 . 9 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . country exposurethe firm wholesale portfolio include country risk exposure develop emerge market . firm seek diversify country exposure include creditrelate lending derivative trading investment activity crossborder locally fund . country exposure firm internal risk management approach report base country asset obligor counterparty guarantor locate majority revenue derive include activity government privatesector entity country . exposure include fair value derivative receivable consider credit derivative protection sell buy base country referenced obligation . exposure include resale agreement adjust collateral receive firm credit enhancement e . g . guarantee letter credit provide party credit derivative protection purchase namespecific sovereignreference . exposure support guarantor locate outside country generally assign country enhancement provider . trading investment activity short credit equity trading position consideration . 7 5 several european country include greece portugal spain italy ireland subject credit deterioration weakness economic fiscal situation . firm closely monitor exposure country . june 3 0 2 0 1 1 aggregate net exposure country measure firm internal approach approximately $ 1 4 billion . sovereign exposure country represent approximately 2 6 % aggregate net exposure majority sovereign exposure spain . firm exposure corporate client country represent approximately 6 2 % aggregate net exposure . firm exposure banking sector represent approximately 1 2 % . firm currently believe exposure country modest relative firm overall risk exposure manageable size type exposure country diversification aggregate exposure . net exposure adjust liquid collateral hold approximately 9 0 % consist cash nonsovereign collateral . addition predominately credit derivative protection purchase investmentgrade counterpartie domicile outside country . firm continue conduct business support client activity country firm aggregate net exposure sector distribution vary time . addition net exposure affect change market condition include effect interest rate credit spread market valuations . as ongoing country risk management process firm monitor exposure emerge market country utilize country stress test measure manage risk extreme loss associate sovereign crisis country . common definition emerge market firm generally include definition country sovereign debt rating equivalent low . table present firm exposure 1 0 emerge market country base internal measurement approach . selection country base solely firm large total exposure country represent view actual potentially adverse credit conditions . top 1 0 emerge market country exposurejune 3 0 2 0 1 1 crossborder total exposurein billionslendingatradingbotherctotallocaldbrazil $ 4 . 3 $ 0 . 7 $ 1 . 2 $ 4 . 8 $ 8 . 8 $ 1 3 . 6 india 6 . 3 4 . 3 1 . 5 1 2 . 1 1 . 5 1 3 . 6 south korea 2 . 8 1 . 5 1 . 6 5 . 9 5 . 8 1 1 . 7 china 5 . 1 1 . 3 1 . 5 7 . 9 2 . 3 1 0 . 2 hong kong 4 . 0 1 . 5 2 . 4 7 . 9 2 . 0 9 . 9 taiwan 0 . 7 0 . 8 0 . 4 1 . 9 3 . 4 5 . 3 malaysia 0 . 5 3 . 2 0 . 4 4 . 1 1 . 0 5 . 1 mexico 1 . 8 2 . 3 0 . 5 4 . 6 0 . 1 4 . 7 united arab emirates 2 . 9 0 . 5 3 . 4 3 . 4 chile 1 . 3 1 . 5 0 . 5 3 . 3 0 . 1 3 . 4 december 3 1 2 0 1 0 crossborder total exposurein billionslendingatradingbotherctotallocaldbrazil $ 3 . 0 $ 1 . 8 $ 1 . 1 $ 5 . 9 $ 3 . 9 $ 9 . 8 south korea 3 . 0 1 . 4 1 . 5 5 . 9 3 . 1 9 . 0 india 4 . 2 2 . 1 1 . 4 7 . 7 1 . 1 8 . 8 china 3 . 6 1 . 1 1 . 0 5 . 7 1 . 2 6 . 9 hong kong 2 . 5 1 . 5 1 . 2 5 . 2 5 . 2 mexico 2 . 1 2 . 3 0 . 5 4 . 9 4 . 9 malaysia 0 . 6 2 . 0 0 . 3 2 . 9 0 . 4 3 . 3 taiwan 0 . 3 0 . 6 0 . 4 1 . 3 1 . 9 3 . 2 thailand 0 . 3 1 . 1 0 . 4 1 . 8 0 . 9 2 . 7 russia 1 . 2 1 . 0 0 . 3 2 . 5 2 . 5 alending include loan accrue interest receivable interestsearne deposit bank acceptance monetary asset issue letter credit net participation undrawn commitment extend credit . btrade include 1 issuer exposure crossborder debt equity instrument hold trading investment account adjust impact issuer hedge include credit derivative 2 counterparty exposure derivative foreign exchange contract security financing trade resale agreement security borrowed . cother represent mainly local exposure fund crossborder include capital investment local entities . dlocal exposure define exposure country denominate local currency book locally . exposure meet criterion define crossborder exposure . 7 6 consumer credit portfoliojpmorgan chase consumer portfolio consist primarily residential mortgage home equity loan line credit credit card auto loan student loan business banking loan . firm primary focus serve prime consumer credit market . information consumer loan note 1 3 page 1 3 4 1 4 8 form 1 0 q . substantial portion consumer loan acquire september 2 0 0 8 washington mutual transaction identify purchase creditimpaire base analysis highrisk characteristic include product type loantovalue ltv ratio fico score delinquency status . pci loan account pool basis pool consider perform . information pci loan note 1 3 page 1 3 4 1 4 8 form 1 0 q note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . credit performance consumer portfolio entire product spectrum improve particularly credit card high unemployment weak overall economic condition continue result elevated number residential real estate loan chargeoff weak housing price continue negatively affect severity loss recognize residential real estate loan default . earlystage residential real estate delinquency 3 0 8 9 day delinquent latestage delinquency 1 5 0 day delinquent decline 2 0 1 1 remain elevated . elevated level latestage delinquent loan lossmitigation activity currently undertake elongate foreclosure processing timeline . loss relate loan continue recognize accordance firm standard chargeoff practice delinquent loan foreclose remain mortgage home equity loan portfolio . ongoing weak economic condition combine elevated delinquency ongoing discussion regard mortgage foreclosurerelated matter federal state official continue result high level uncertainty residential real estate portfolio . firm action onset economic downturn 2 0 0 7 tighten underwriting loan qualification standard eliminate certain product loan origination channel result reduction credit risk improve credit performance recent loan vintage . 7 7 the follow table present manage consumer creditrelate information include rfs card residential real estate loan report corporateprivate equity segment date indicate . information firm nonaccrual chargeoff accounting policy note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . consumer credit portfolio month end june 3 0 month end june 3 0 credit exposure nonaccrual loanshi net chargeoff averageannual net chargeoff ratej net chargeoff averageannual net chargeoff ratejin million ratiosjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 consumer exclude credit card loan exclude pci loan loan heldforsale home equity senior liena $ 2 2 9 6 9 $ 2 4 3 7 6 $ 4 8 1 $ 4 7 9 $ 7 4 $ 7 0 1 . 2 7 % 1 . 0 6 % $ 1 3 9 $ 1 3 9 1 . 1 8 % 1 . 0 5 % home equity junior lienb 5 9 7 8 2 6 4 0 0 9 8 2 7 7 8 4 5 1 8 7 2 6 3 . 4 2 4 . 1 6 1 1 7 3 1 7 8 3 3 . 8 3 5 . 0 5 prime mortgage include option arms 7 4 2 7 6 7 4 5 3 9 4 0 2 4 4 3 2 0 1 9 9 2 9 0 1 . 0 7 1 . 5 2 3 7 0 7 7 5 1 . 0 0 2 . 0 4 subprime mortgage 1 0 4 4 1 1 1 2 8 7 2 0 5 8 2 2 1 0 1 5 6 2 8 2 5 . 8 5 8 . 6 3 3 4 2 7 3 9 6 . 3 3 1 1 . 1 2 autoc 4 6 7 9 6 4 8 3 6 7 1 1 1 1 4 1 1 9 5 8 0 . 1 6 0 . 4 9 6 6 1 6 0 0 . 2 8 0 . 6 8 business banking 1 7 1 4 1 1 6 8 1 2 7 7 0 8 3 2 1 1 7 1 6 8 2 . 7 4 4 . 0 4 2 3 6 3 5 9 2 . 8 0 4 . 3 1 student other 1 4 7 7 0 1 5 3 1 1 7 9 6 7 1 3 0 1 6 8 3 . 5 0 4 . 2 4 2 1 6 2 4 6 2 . 8 8 3 . 0 2 total loan exclude pci loan loan heldforsale 2 4 6 1 7 5 2 5 4 7 0 1 8 3 5 0 8 8 3 3 1 2 1 3 1 7 6 2 1 . 9 6 2 . 6 6 2 5 4 2 4 2 0 1 2 . 0 5 3 . 1 6 loans pcid home equity 2 3 5 3 5 2 4 4 5 9 nana nana nana nana nanaprime mortgage 1 6 2 0 0 1 7 3 2 2 nana nana nana nana nanasubprime mortgage 5 1 8 7 5 3 9 8 nana nana nana nana nanaoption arms 2 4 0 7 2 2 5 5 8 4 nana nana nana nana nanatotal loan pci 6 8 9 9 4 7 2 7 6 3 nana nana nana nana nanatotal loan retained 3 1 5 1 6 9 3 2 7 4 6 4 8 3 5 0 8 8 3 3 1 2 1 3 1 7 6 2 1 . 5 3 2 . 0 6 2 5 4 2 4 2 0 1 1 . 6 0 2 . 4 4 loans heldforsalee 2 2 1 1 5 4 total consumer exclude credit card loans 3 1 5 3 9 0 3 2 7 6 1 8 8 3 5 0 8 8 3 3 1 2 1 3 1 7 6 2 1 . 5 3 2 . 0 6 2 5 4 2 4 2 0 1 1 . 6 0 2 . 4 4 lendingrelated commitment home equity senior lienaf 1 7 2 6 5 1 7 6 6 2 home equity junior lienbf 2 8 5 8 6 3 0 9 4 8 prime mortgage 1 1 1 7 1 2 6 6 subprime mortgage auto 6 7 9 5 5 2 4 6 business banking 1 0 0 4 6 9 7 0 2 student other 8 4 0 5 7 9 total lendingrelate commitments 6 4 6 4 9 6 5 4 0 3 total consumer exposure exclude credit card 3 8 0 0 3 9 3 9 3 0 2 1 credit card loan retainedg 1 2 5 5 2 3 1 3 5 5 2 4 2 2 1 8 1 0 3 7 2 1 5 . 8 2 1 0 . 2 0 4 0 3 6 8 2 3 3 6 . 4 0 1 0 . 9 9 loans heldforsale 2 1 5 2 total credit card loans 1 2 5 5 2 3 1 3 7 6 7 6 2 2 1 8 1 0 3 7 2 1 5 . 8 2 1 0 . 2 0 4 0 3 6 8 2 3 3 6 . 4 0 1 0 . 9 9 lendingrelated commitmentsf 5 3 5 6 2 5 5 4 7 2 2 7 total credit card exposure 6 6 1 1 4 8 6 8 4 9 0 3 total consumer credit portfolio $ 1 0 4 1 1 8 7 $ 1 0 7 7 9 2 4 $ 8 3 5 2 $ 8 8 3 5 $ 3 0 2 3 $ 5 4 8 3 2 . 7 4 % 4 . 4 9 % $ 6 5 7 8 $ 1 2 4 3 4 2 . 9 6 % 5 . 0 3 % memo total consumer credit portfolio exclude pci $ 9 7 2 1 9 3 $ 1 0 0 5 1 6 1 $ 8 3 5 2 $ 8 8 3 5 $ 3 0 2 3 $ 5 4 8 3 3 . 2 5 % 5 . 3 4 % $ 6 5 7 8 $ 1 2 4 3 4 3 . 5 2 % 5 . 9 8 % arepresents loan jpmorgan chase hold security interest property . brepresent loan jpmorgan chase hold security interest subordinate rank lien . cat june 3 0 2 0 1 1 december 3 1 2 0 1 0 exclude operate leaserelated asset $ 4 . 2 billion $ 3 . 7 billion respectively . dchargeoff record pci loan actual loss exceed estimate loss record purchase accounting adjustment time acquisition . date chargeoff record loans . erepresent prime mortgage loan heldforsale . fthe credit card home equity lendingrelate commitment represent total available line credit product . firm experience anticipate available line credit use time . credit card commitment home equity commitment certain condition meet firm reduce cancel line credit provide borrower notice case notice permit law . ginclude bill finance charge fee net allowance uncollectible amounts . hat june 3 0 2 0 1 1 december 3 1 2 0 1 0 nonaccrual loan exclude 1 mortgage loan insure u . s . government agency $ 9 . 1 billion $ 9 . 4 billion 7 8 respectively 9 0 day past 2 student loan insure u . s . government agency ffelp $ 5 5 8 million $ 6 2 5 million respectively 9 0 day past . exclude reimbursement insured proceed normally . addition firm policy generally exempt credit card loan place nonaccrual status permit regulatory guidance . guidance issue ffiec credit card loan charge end month account 1 8 0 day past 6 0 day receive notification specify event e . g . bankruptcy borrower whichever earlier . iexclude pci loan acquire washington mutual transaction account pool basis . pool account single asset single composite interest rate aggregate expectation cash flow pastdue status pool individual loan pool meaningful . firm recognize interest income pool loan consider perform . javerage consumer loan heldforsale $ 3 5 2 million $ 1 . 9 billion respectively month end june 3 0 2 0 1 1 2 0 1 0 $ 1 . 7 billion $ 2 . 4 billion respectively month end june 3 0 2 0 1 1 2 0 1 0 . exclude calculate net chargeoff rates . consumer exclude credit cardloan balance decline month end june 3 0 2 0 1 1 paydown portfolio runoff chargeoff . credit performance improve portfolio remain stress . follow discussion relate specific loan lendingrelated category . pci loan generally exclude individual loan product discussion address separately below . home equity home equity loan june 3 0 2 0 1 1 $ 8 2 . 8 billion compare $ 8 8 . 4 billion december 3 1 2 0 1 0 . decrease portfolio primarily reflect loan paydown chargeoff . senior lien nonaccrual loan remain relatively flat compare december 3 1 2 0 1 0 junior lien nonaccrual loan increase slightly . earlystage delinquency modestly improve december 3 1 2 0 1 0 net chargeoff improve period prior year . approximately 2 0 % firm home equity portfolio consist home equity loan heloan remainder consist home equity line credit helocs . heloan generally fixedrate closedend amortize loan term range 3 3 0 year . approximately half heloan senior lien remainder junior lien . general helocs openende revolve loan 1 0 year period time heloc convert loan 2 0 year amortization period . firm manage risk helocs revolving period close reduce undrawn line extent permit law borrower experience financial difficulty collateral support loan . majority helocs fund 2 0 0 5 later fullyamortize payment require significant portion heloc portfolio 2 0 1 5 . firm regularly evaluate nearterm longerterm reprice risk inherent heloc portfolio ensure allowance credit loss account management practice appropriate portfolio risk profile . at june 3 0 2 0 1 1 firm estimate home equity portfolio contain approximately $ 4 billion junior lien loan borrower mortgage loan delinquent modify . loan consider pose high risk default junior lien loan senior lien delinquent modify . estimate $ 4 billion balance firm 5 % service approximately 3 0 % related senior lien loan borrower case firm know senior lien loan delinquent modify . case firm service senior lien loan firm estimate higherrisk junior lien loan . performance firm junior lien loan materially consistent regardless firm service service senior lien . increase probability default associate higherrisk junior lien loan consider estimate allowance loan losses . mortgage mortgage loan june 3 0 2 0 1 1 include prime subprime loan heldforsale $ 8 4 . 9 billion compare $ 8 6 . 0 billion december 3 1 2 0 1 0 . decrease primarily paydown portfolio runoff chargeoff delinquent loan partially offset prime mortgage origination . net chargeoff decrease period prior year remain elevated . prime mortgage include option adjustablerate mortgage arm loan heldforsale june 3 0 2 0 1 1 $ 7 4 . 5 billion compare $ 7 4 . 7 billion december 3 1 2 0 1 0 . loan relatively unchanged december 3 1 2 0 1 0 chargeoff delinquent loan paydown portfolio runoff option arm loan offset prime mortgage origination . exclude loan insure u . s . government agency earlystage latestage delinquency modest improvement half year remain elevated . nonaccrual loan improvement remain elevated result ongoing foreclosure processing delay . net chargeoff decline year year remain high . option arm loan include prime mortgage portfolio $ 7 . 9 billion $ 8 . 1 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively represent 1 1 % prime mortgage portfolio period . decrease option arm loan result portfolio runoff partially offset repurchase loan previously securitize securitization entity terminate . firm option arm loan hold pci portfolio primarily loan low ltv ratio high borrower ficos . accordingly firm expect substantially low loss portfolio compare pci option arm pool . june 3 0 2 0 1 1 approximately 6 % option arm borrower delinquent 4 % interestonly negatively amortize payment 9 0 % amortize payment . approximately 8 4 % borrower portfolio subject risk payment shock future payment recast limited number loan modify . cumulative unpaid interest add unpaid principal balance negative 7 9 amortization option arm material june 3 0 2 0 1 1 december 3 1 2 0 1 0 . firm estimate follow balance option arm loan experience recast result payment increase $ 2 9 million 2 0 1 1 $ 2 9 7 million 2 0 1 2 $ 9 8 1 million 2 0 1 3 . firm originate option arm new origination option arm discontinue washington mutual prior date jpmorgan chase acquisition banking operation . subprime mortgage june 3 0 2 0 1 1 $ 1 0 . 4 billion compare $ 1 1 . 3 billion december 3 1 2 0 1 0 . decrease portfolio runoff chargeoff delinquent loan . earlystage latestage delinquency improve december 2 0 1 0 . delinquency nonaccrual loan remain elevated level . net chargeoff improve significantly period prior year . auto auto loan june 3 0 2 0 1 1 $ 4 6 . 8 billion compare $ 4 8 . 4 billion december 3 1 2 0 1 0 . loan balance decline impact increase competition . delinquent nonaccrual loan decrease . net chargeoff decline prior year result low delinquency decline loss severity strong usedcar market nationwide . auto loan portfolio reflect high concentration primequality credits . business banking business banking loan june 3 0 2 0 1 1 $ 1 7 . 1 billion compare $ 1 6 . 8 billion december 3 1 2 0 1 0 . increase growth new loan origination volume . loan primarily include loan collateralize personal loan guarantee include small business administration guarantee . delinquent loan nonaccrual loan improvement remain elevated . net chargeoff decline prior year . student student loan june 3 0 2 0 1 1 $ 1 4 . 8 billion compare $ 1 5 . 3 billion december 3 1 2 0 1 0 . decrease paydown student loan . loan primarily include secured unsecured consumer loan . delinquency nonaccrual loan remain elevate chargeoff decrease prioryear quarter . purchase creditimpaire loan pci loan june 3 0 2 0 1 1 $ 6 9 . 0 billion compare $ 7 2 . 8 billion december 3 1 2 0 1 0 . portfolio represent loan acquire washington mutual transaction record fair value time acquisition . the firm regularly update principal interest cash flow expect collect loan . probable decrease expect loan principal cash flow trigger recognition impairment provision loan loss . probable significant increase expect cash flow e . g . decrease principal credit loss net benefit modification reverse previously record allowance loan loss remain increase expect cash flow recognize prospectively interest income remain estimate life underlie loans . at june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm allowance loan loss home equity prime mortgage subprime mortgage option arm pci pool $ 1 . 6 billion $ 1 . 8 billion $ 9 8 million $ 1 . 5 billion respectively . approximately 3 6 % option arm pci loan delinquent 4 % interestonly negatively amortize payment 6 0 % amortize payment . approximately 3 4 % current borrower subject risk payment shock future payment recast substantially remain loan modify fixedrate fully amortize loan . cumulative unpaid interest add unpaid principal balance option arm pci pool $ 1 . 2 billion $ 1 . 4 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . firm estimate follow balance option arm pci loan experience recast result payment increase $ 5 4 7 million 2 0 1 1 $ 2 . 4 billion 2 0 1 2 $ 5 0 1 million 2 0 1 3 . the follow table provide summary lifetime loss estimate include nonaccretable difference allowance loan loss . principal chargeoff record pool nonaccretable difference fully deplete . lifetime loss estimatesa ltd liquidation lossesbin billionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 home equity $ 1 4 . 7 $ 1 4 . 7 $ 9 . 7 $ 8 . 8 prime mortgage 4 . 9 4 . 9 1 . 9 1 . 5 subprime mortgage 3 . 7 3 . 7 1 . 4 1 . 2 option arms 1 1 . 6 1 1 . 6 5 . 7 4 . 9 total $ 3 4 . 9 $ 3 4 . 9 $ 1 8 . 7 $ 1 6 . 4 aincludes original nonaccretable difference establish purchase accounting $ 3 0 . 5 billion principal loss plus additional principal loss recognize subsequent acquisition provision allowance loan loss . remain nonaccretable difference principal loss $ 1 1 . 8 billion $ 1 4 . 1 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . blifetodate ltd liquidation loss represent realization loss loan resolution . 8 0 geographic composition current ltvs residential real estate loansthe consumer credit portfolio geographically diverse . california great concentration residential real estate loan 2 4 % total retain residential real estate loan portfolio exclude mortgage loan insure u . s . government agency pci loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 . total retain residential real estate loan portfolio exclude mortgage loan insure u . s . government agency pci loan $ 8 2 . 7 billion 5 4 % concentrate california new york arizona florida michigan june 3 0 2 0 1 1 compare $ 8 6 . 4 billion 5 4 % december 3 1 2 0 1 0 . current estimate average ltv ratio residential real estate loan retain exclude mortgage loan insure u . s . government agency pci loan 8 3 % june 3 0 2 0 1 1 december 3 1 2 0 1 0 . exclude mortgage loan insure u . s . government agency pci loan 2 4 % retained portfolio current estimate ltv ratio great 1 0 0 % 1 0 % retained portfolio current estimate ltv ratio great 1 2 5 % june 3 0 2 0 1 1 december 3 1 2 0 1 0 . decline home price 2 0 0 7 significant impact collateral value underlie firm residential real estate loan portfolio . general delinquency rate loan high ltv ratio great delinquency rate loan borrower equity collateral . large portion loan current estimate ltv ratio great 1 0 0 % continue pay current continue willingness ability borrower pay remain uncertain . the follow table present current estimate ltv ratio ratio carry value underlie loan current estimate collateral value pci loan . loan initially measure fair value ratio carry value current estimate collateral value low current estimate ltv ratio base unpaid principal balance . estimate collateral value use calculate ratio represent actual appraise loanlevel collateral value result ratio necessarily imprecise view estimate . ltv ratio ratio carry value current estimate collateral value pci loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 million ratiosunpaid principal balance acurrent estimate ltv ratiobnet carry valuedratio netcarrye valueto current estimate collateral value unpaid principal balanceacurrent estimate ltv ratiobnet carry valuedratio netcarrye valueto current estimate collateral value home equity $ 2 6 6 1 1 1 1 7 % c $ 2 1 9 5 2 9 7 % $ 2 8 3 1 2 1 1 7 % c $ 2 2 8 7 6 9 5 % prime mortgage 1 7 4 7 3 1 1 0 1 4 4 3 4 9 1 1 8 9 2 8 1 0 9 1 5 5 5 6 9 0 subprime mortgage 7 6 7 7 1 1 5 5 0 8 9 7 6 8 0 4 2 1 1 3 5 3 0 0 7 4 option arms 2 8 4 4 5 1 1 0 2 2 5 7 8 8 7 3 0 7 9 1 1 1 1 2 4 0 9 0 8 7 arepresent contractual principal owe june 3 0 2 0 1 1 december 3 1 2 0 1 0 . brepresents aggregate unpaid principal balance loan divide estimate current property value . current property value estimate quarterly base home valuation model utilize nationally recognize home price index valuation estimate model incorporate actual datum extent available forecast datum actual datum available . crepresent current estimate combined ltv junior home equity lien consider available lien position relate property . product present consideration subordinate lien property . dnet carry value include effect fair value adjustment apply consumer pci portfolio date acquisition net allowance loan loss $ 1 . 6 billion home equity $ 1 . 8 billion prime mortgage $ 9 8 million subprime mortgage $ 1 . 5 billion option arm june 3 0 2 0 1 1 december 3 1 2 0 1 0 . priorperiod revise conform currentperiod presentation . pci loan state california florida represent 5 3 % 1 0 % respectively total pci loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 . current estimate average ltv ratio 1 1 8 % 1 4 0 % california florida loan respectively june 3 0 2 0 1 1 compare 1 1 8 % 1 3 5 % respectively december 3 1 2 0 1 0 . continue pressure housing price california florida contribute negatively current estimate average ltv ratio ratio net carry value current estimate collateral value loan pci portfolio . pci portfolio june 3 0 2 0 1 1 december 3 1 2 0 1 0 6 3 % current estimate ltv ratio great 1 0 0 % 3 1 % current estimate ltv ratio great 1 2 5 % . while current estimate collateral value great net carry value pci loan ultimate performance portfolio highly dependent borrower behavior ongoing ability willingness continue payment home negative equity cost alternative housing . information geographic composition current estimate ltvs residential real estate nonpci pci loan note 1 3 page 1 3 4 1 4 8 form 1 0 q . 8 1 loan modification activitiesfor additional information consumer loan modification activity include consumer loan modification account troubled debt restructuring tdrs note 1 3 page 1 3 4 1 4 8 form 1 0 q note 1 4 page 1 3 9 1 4 0 jpmorgan chase 2 0 1 0 annual report . residential real estate loan firm onbalance sheet loan loan service 1 1 7 7 0 0 0 mortgage modification offer borrower approximately 3 7 5 0 0 0 approve beginning 2 0 0 9 . approximately 3 5 5 0 0 0 achieve permanent modification june 3 0 2 0 1 1 . remain 8 0 2 0 0 0 offer modification 2 7 % trial period review modification 7 3 % drop modification program eligible final modification . the firm participate u . s . treasury home affordable mha program continue expand lossmitigation effort financially distressed borrower qualify u . s . treasury program . mha program include home affordable modification program hamp second lien modification program 2 mp . firm lossmitigation program troubled borrower qualify hamp include traditional modification program offer gse ginnie mae firm proprietary modification program include concession similar offer hamp expand eligibility criterion . addition firm offer modification program target specifically borrower higherrisk mortgage product . mha firm lossmitigation program generally provide concession financially troubled borrower include limit interest rate reduction term payment extension deferral forgiveness principal payment require term original agreement . 8 1 3 0 0 onbalance sheet loan modify hamp firm lossmitigation program july 1 2 0 0 9 5 3 % permanent loan modification include interest rate reduction 5 7 % include term payment extension 1 2 % include principal deferment 2 2 % include principal forgiveness . principal forgiveness limit specific modification program higherrisk borrower . sum percentage type loan modification exceed 1 0 0 % case modification individual loan include type concession . generally borrower payment new term trial modification period successfully reunderwritten income verification mortgage home equity loan permanently modify . firm modify home equity line credit future lending commitment relate modify loan cancel term modification . the ultimate success modification program impact reduce credit loss remain uncertain short period time modification . primary indicator use management monitor success program rate modify loan redefault . modification redefault rate affect number factor include type loan modify borrower overall ability willingness repay modify loan macroeconomic factor . reduction payment size borrower significant driver improve redefault rate . modification complete july 1 2 0 0 9 hamp firm modification program differ modification complete prior program generally fully underwritten successful trial payment period month . performance metric date modification season month weight average redefault rate 2 0 % 2 8 % hamp firm modification program respectively . redefault rate exclude certain recent modification offer borrower current loan prior modification subject future payment recast risk . weighted average default rate modification season month 5 % . redefault rate hamp firm modification program compare favorably equivalent metric modification complete program effect prior july 1 2 0 0 9 ultimate redefault rate remain uncertain modify loan season . follow table present information june 3 0 2 0 1 1 december 3 1 2 0 1 0 relate restructure onbalance sheet residential real estate loan concession grant borrower experience financial difficulty . modification pci loan continue account report pci loan impact modification incorporate firm quarterly assessment estimate future cash flow . modification consumer loan pci loan generally account report tdrs . 8 2 restructured residential real estate loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 millionsonbalance sheet loansnonaccrual onbalance sheet loansd onbalance sheet loansnonaccrual onbalance sheet loansdrestructure residential real estate loan exclude pci loansab home equity senior lien $ 2 6 1 $ 5 3 $ 2 2 6 $ 3 8 home equity junior lien 5 1 7 2 3 2 2 8 3 6 3 prime mortgage include option arms 3 3 9 0 6 9 8 2 0 8 4 5 3 4 subprime mortgage 2 8 4 3 6 9 5 2 7 5 1 6 3 2 total restructure residential real estate loan exclude pci loans $ 7 0 1 1 $ 1 6 7 8 $ 5 3 4 4 $ 1 2 6 7 restructured pci loansc home equity $ 7 4 9 na $ 4 9 2 naprime mortgage 3 6 6 3 na 3 0 1 8 nasubprime mortgage 3 5 6 0 na 3 3 2 9 naoption arms 1 2 5 7 4 na 9 3 9 6 natotal restructure pci loans $ 2 0 5 4 6 na $ 1 6 2 3 5 naaamount represent carry value restructure residential real estate loans . bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 $ 3 . 5 billion $ 3 . 0 billion respectively loan modify subsequent repurchase ginnie mae accordance standard appropriate government agency i . e . fha va rha exclude loan account tdrs . loan perform subsequent modification accordance ginnie mae guideline generally sell ginnie mae loan pool . modify loan reperform subject foreclosure . additional information sale loan securitization transaction ginnie mae note 1 5 page 1 5 1 1 5 9 form 1 0 q . camounts represent unpaid principal balance restructure pci loans . dnonaccrual loan modify tdr return accrual status repayment reasonably assure borrower minimum payment new term payment subsequent permanent modification trial modification payment . june 3 0 2 0 1 1 december 3 1 2 0 1 0 nonaccrual loan include $ 9 3 8 million $ 5 8 0 million respectively tdrs borrower payment modify terms . foreclosure prevention foreclosure resort firm significant effort help borrower stay home . second quarter 2 0 0 9 firm prevent foreclosure loan modification short sale foreclosure prevention mean foreclosure completed . the firm welldefine foreclosure prevention process borrower fail pay loan . customer contact attempt multiple time way pursue option foreclosure . addition firm unable contact customer review complete borrower fact circumstance foreclosure sale complete . time foreclosure sale borrower payment average 1 4 month . foreclosure process govern law regulation establish statebystate basis . state foreclosure process involve judicial process require file document court . state process nonjudicial involve process require file document governmental agency . quarter 2 0 1 0 firm aware certain document execute firm personnel connection foreclosure process comply applicable procedural requirement . result firm instruct outside foreclosure counsel temporarily suspend foreclosure foreclosure sale eviction 4 3 state review process . matter subject investigation federal state official . discussion mortgage foreclosure investigation litigation note 2 3 page 1 7 2 1 7 9 form 1 0 q . june 3 0 2 0 1 1 firm resume initiation new foreclosure proceeding nearly state previously suspend proceedings . 8 3 nonperforme assetsthe follow table present information june 3 0 2 0 1 1 december 3 1 2 0 1 0 consumer exclude credit card nonperforme assets . nonperforme assetsa millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 nonaccrual loansbc home equity senior lien $ 4 8 1 $ 4 7 9 home equity junior lien 8 2 7 7 8 4 prime mortgage include option arms 4 0 2 4 4 3 2 0 subprime mortgage 2 0 5 8 2 2 1 0 auto 1 1 1 1 4 1 business banking 7 7 0 8 3 2 student other 7 9 6 7 total nonaccrual loans 8 3 5 0 8 8 3 3 asset acquire loan satisfaction real estate owned 9 5 6 1 2 9 4 other 4 6 6 7 total asset acquire loan satisfactions 1 0 0 2 1 3 6 1 total nonperforme assets $ 9 3 5 2 $ 1 0 1 9 4 aat june 3 0 2 0 1 1 december 3 1 2 0 1 0 nonperforme asset exclude 1 mortgage loan insure u . s . government agency $ 9 . 1 billion $ 9 . 4 billion respectively 9 0 day past 2 real estate insure u . s . government agency $ 2 . 4 billion $ 1 . 9 billion respectively 3 student loan insure u . s . government agency ffelp $ 5 5 8 million $ 6 2 5 million respectively 9 0 day past . exclude reimbursement insured proceed normally . bexclude pci loan acquire washington mutual transaction account pool basis . pool account single asset single composite interest rate aggregate expectation cash flow pastdue status pool individual loan pool meaningful . firm recognize interest income pool loan consider performing . cat june 3 0 2 0 1 1 december 3 1 2 0 1 0 consumer exclude credit card nonaccrual loan represent 2 . 6 5 % 2 . 7 0 % respectively total consumer exclude credit card loan . nonaccrual loan total consumer exclude credit card nonaccrual loan $ 8 . 4 billion june 3 0 2 0 1 1 compare $ 8 . 8 billion december 3 1 2 0 1 0 . nonaccrual loan stabilize remain elevated level . increase loan modification activity expect continue result elevated level nonaccrual loan residential real estate portfolio result redefault modify loan firm policy modify loan remain nonaccrual status repayment reasonably assure borrower minimum payment new term payment subsequent permanent modification trial modification payment . nonaccrual loan residential real estate portfolio total $ 7 . 4 billion june 3 0 2 0 1 1 7 1 % great 1 5 0 day past compare nonaccrual residential real estate loan $ 7 . 8 billion december 3 1 2 0 1 0 7 1 % great 1 5 0 day past . modify residential real estate loan $ 1 . 7 billion $ 1 . 3 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively classify nonaccrual loan . modify residential real estate loan $ 9 3 8 million $ 5 8 0 million payment modify term june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively remain nonaccrual modify loan redefaulte . aggregate unpaid principal balance residential real estate loan great 1 5 0 day past charge approximately 4 8 % 4 6 % estimate collateral value june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . real estate reo reo asset exclude insure u . s . government agency decrease $ 3 3 8 million december 3 1 2 0 1 0 $ 9 5 6 million june 3 0 2 0 1 1 . enhancements mortgage servicingdure second quarter 2 0 1 1 firm enter consent order banking regulator relate residential mortgage servicing foreclosure lossmitigation activity . order regulator mandate significant change firm service default business outline requirement implement change . accordance requirement consent order firm submit comprehensive action plan set forth step necessary ensure firm residential mortgage servicing foreclosure lossmitigation activity conduct accordance requirement order . addition firm undertake remedial action ensure satisfy requirement relate mortgage servicing foreclosure lossmitigation activity outline consent order . corrective action firm intend implement course year include strengthen compliance program ensure mortgageservicing foreclosure operation include lossmitigation loan modification comply applicable legal requirements . establishing single point contact borrower ensure effective coordination communication relate foreclosure 8 4 lossmitigation loan modification . ensure appropriate oversight thirdparty vendor foreclosure related functions . ensuring appropriate control oversight firm activity respect mortgage electronic registration system mer compliance merscorps membership rule term conditions . enhance management information system loan modification lossmitigation foreclosure activities . develope comprehensive assessment risk service operation include limit operational transaction legal reputational risks . in addition pursuant consent order firm require enhance oversight mortgage servicing activity include compliance management audit accordingly change organization structure control oversight customer service practice includeestablishe independent compliance committee meet regularly monitor progress consent orders . submission mer plan ensure firm appropriate control place compliance merscorps membership rule term condition . completion draft comprehensive risk assessment submit senior management review risk management plan development intend complete 1 2 0 day consent order . adde upgrade compliance resource support expand role regard ongoing activity expand testing plan . define single point contact role include role supervisor manager subsequent initiation pilot rollout single point contact schedule later year . additionally pursuant consent order firm retain independent consultant conduct review residential foreclosure action period january 1 2 0 0 9 december 3 1 2 0 1 0 include foreclosure action bring respect loan service remediate error deficiency identify independent consultant include require reimburse borrower identify financial injury incur . identification residential mortgage loan service firm foreclosure action initiate process provide independent consultant . borrower outreach process develop . additional information note 2 3 page 1 7 2 1 7 9 form 1 0 q . credit cardtotal credit card loan $ 1 2 5 . 5 billion june 3 0 2 0 1 1 decrease $ 1 2 . 2 billion december 3 1 2 0 1 0 seasonality high repayment rate runoff washington mutual portfolio firm sale $ 3 . 7 billion kohl portfolio april 1 2 0 1 1 . for retained credit card portfolio 3 0 plus day delinquency rate decrease 2 . 9 8 % june 3 0 2 0 1 1 4 . 1 4 % december 3 1 2 0 1 0 net chargeoff rate decrease 5 . 8 2 % month end june 3 0 2 0 1 1 1 0 . 2 0 % month end june 3 0 2 0 1 0 . month end june 3 0 2 0 1 1 2 0 1 0 respective net chargeoff rate 6 . 4 0 % 1 0 . 9 9 % . delinquency trend improvement especially earlystage delinquency . chargeoff improve result low delinquent loan . credit card portfolio continue reflect wellseasone largely rewardsbase portfolio good u . s . geographic diversification . great geographic concentration credit card retain loan california represent 1 3 % total retain loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 . loan concentration state california new york texas florida illinoi consist $ 5 0 . 5 billion receivables 4 0 % retained loan portfolio june 3 0 2 0 1 1 compare $ 5 4 . 4 billion 4 0 % december 3 1 2 0 1 0 . total retain credit card loan exclude washington mutual portfolio $ 1 1 3 . 8 billion june 3 0 2 0 1 1 compare $ 1 2 1 . 8 billion december 3 1 2 0 1 0 . 3 0 plus day delinquency rate 2 . 7 1 % june 3 0 2 0 1 1 3 . 7 3 % december 3 1 2 0 1 0 net chargeoff rate decrease 5 . 2 3 % month end june 3 0 2 0 1 1 9 . 0 2 % month end june 3 0 2 0 1 0 . month end june 3 0 2 0 1 1 2 0 1 0 respective net chargeoff rate 5 . 7 7 % 9 . 8 0 % . 8 5 retained credit card loan washington mutual portfolio $ 1 1 . 8 billion june 3 0 2 0 1 1 compare $ 1 3 . 7 billion december 3 1 2 0 1 0 . washington mutual portfolio 3 0 plus day delinquency rate 5 . 5 3 % june 3 0 2 0 1 1 7 . 7 4 % december 3 1 2 0 1 0 . respective net chargeoff rate month end june 3 0 2 0 1 1 2 0 1 0 1 1 . 2 8 % 1 9 . 5 3 % month end june 3 0 2 0 1 1 2 0 1 0 respectively net chargeoff rate 1 2 . 1 6 % 2 0 . 1 0 % . modifications credit card loan additional information loan modification program borrower modification credit card loan page 1 3 7 1 3 8 jpmorgan chase 2 0 1 0 annual report . at june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm $ 8 . 5 billion $ 1 0 . 0 billion respectively onbalance sheet credit card loan outstanding modify tdrs . balance include credit card loan modified payment term credit card loan revert premodification payment term . decrease modify credit card loan outstanding december 3 1 2 0 1 0 june 3 0 2 0 1 1 primarily attributable reduction new modification ongoing payment chargeoff previously modify credit card loan contribute decrease . firm expect significant portion borrower loan modify ultimately comply modify payment term . base historical experience estimate weightedaverage ultimate default rate modify credit card loan 3 7 . 4 0 % june 3 0 2 0 1 1 3 6 . 4 5 % december 3 1 2 0 1 0 . consistent firm policy credit card loan typically remain accrual status . firm establish allowance estimate uncollectible portion bill accrue interest fee income credit card loan reflect charge interest income . community reinvestment act exposurethe community reinvestment act cra encourage bank meet credit need borrower segment community include neighborhood low moderate income . jpmorgan chase national leader community development provide loan investment community development service community united states . at june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm cra loan portfolio approximately $ 1 5 billion $ 1 6 billion respectively . june 3 0 2 0 1 1 december 3 1 2 0 1 0 6 5 % respectively cra portfolio residential mortgage loan period 1 6 % 1 5 % respectively business banking loan 1 3 % 1 4 % respectively commercial real estate loan 6 % respectively loan period . cra nonaccrual loan 6 % firm nonaccrual loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . net chargeoff cra portfolio 3 % 2 % respectively firm net chargeoff month end june 3 0 2 0 1 1 2 0 1 0 . month end june 3 0 2 0 1 1 2 0 1 0 net chargeoff cra portfolio 3 % 2 % respectively firm net chargeoff . allowance credit lossesjpmorgan chase allowance loan loss cover wholesale riskrate consumer primarily score portfolio . allowance represent management estimate probable credit loss inherent firm loan portfolio . management determine allowance wholesale consumer exclude credit card lendingrelate commitment use methodology similar use wholesale loans . for discussion component allowance credit loss critical accounting estimate use firm page 9 2 9 5 note 1 4 page 1 4 9 1 5 0 form 1 0 q . at quarterly allowance credit loss review chief risk officer chief financial officer controller firm discuss risk policy audit committee board director firm . june 3 0 2 0 1 1 jpmorgan chase deem allowance credit loss appropriate i . e . sufficient absorb loss inherent portfolio . allowance credit loss $ 2 9 . 1 billion june 3 0 2 0 1 1 decrease $ 3 . 8 billion $ 3 3 . 0 billion december 3 1 2 0 1 0 . credit card allowance loan loss decrease $ 3 . 0 billion december 3 1 2 0 1 0 primarily result low estimate loss . wholesale allowance loan loss decrease $ 6 7 0 million december 3 1 2 0 1 0 primarily relate impact loan sale net repayments . the allowance lendingrelated commitment wholesale consumer exclude credit card portfolio report liability total $ 6 2 6 million $ 7 1 7 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . 8 6 the credit ratio table base retained loan balance exclude loan heldforsale loan account fair value . summary change allowance credit loss 2 0 1 1 2 0 1 0 six month end june 3 0 wholesaleconsumer exclude credit cardcredit cardtotal wholesaleconsumer exclude credit cardcredit card totalin million ratio allowance loan loss beginning balance january 1 $ 4 7 6 1 $ 1 6 4 7 1 $ 1 1 0 3 4 $ 3 2 2 6 6 $ 7 1 4 5 $ 1 4 7 8 5 $ 9 6 7 2 $ 3 1 6 0 2 cumulative effect change accounting principlesa 1 4 1 2 7 7 3 5 3 7 4 9 4 gross chargeoffs 3 8 7 2 8 1 7 4 7 6 2 7 9 6 6 1 2 7 8 4 4 2 9 8 9 4 5 1 4 6 5 2 gross recoveries 1 4 2 2 7 5 7 2 6 1 1 4 3 8 8 2 2 8 7 1 2 1 0 2 8 net chargeoffs 2 4 5 2 5 4 2 4 0 3 6 6 8 2 3 1 1 9 0 4 2 0 1 8 2 3 3 1 3 6 2 4 provision loan losses 4 1 4 2 4 4 6 1 0 3 6 3 0 6 8 8 1 2 5 4 5 0 5 7 3 3 1 0 3 7 1 other 1 1 1 2 8 9 9 3 1 7 ending balance $ 4 0 9 1 $ 1 6 3 8 7 $ 8 0 4 2 $ 2 8 5 2 0 $ 5 1 4 8 $ 1 6 1 6 4 $ 1 4 5 2 4 $ 3 5 8 3 6 impairment methodology assetspecificbcd $ 7 4 9 $ 1 0 4 9 $ 3 4 5 1 $ 5 2 4 9 $ 1 3 2 4 $ 1 0 9 1 $ 4 8 4 6 $ 7 2 6 1 formulabasedc 3 3 4 2 1 0 3 9 7 4 5 9 1 1 8 3 3 0 3 8 2 4 1 2 2 6 2 9 6 7 8 2 5 7 6 4 pci 4 9 4 1 4 9 4 1 2 8 1 1 2 8 1 1 total allowance loan losses $ 4 0 9 1 $ 1 6 3 8 7 $ 8 0 4 2 $ 2 8 5 2 0 $ 5 1 4 8 $ 1 6 1 6 4 $ 1 4 5 2 4 $ 3 5 8 3 6 allowance lendingrelated commitment beginning balance january 1 $ 7 1 1 $ 6 $ $ 7 1 7 $ 9 2 7 $ 1 2 $ $ 9 3 9 cumulative effect change accounting principlesa 1 8 1 8 provision lendingrelated commitments 8 9 8 9 4 2 2 other 2 2 1 1 1 1 ending balance $ 6 2 0 $ 6 $ $ 6 2 6 $ 9 0 2 $ 1 0 $ $ 9 1 2 impairment methodology assetspecific $ 1 4 4 $ $ $ 1 4 4 $ 2 4 8 $ $ $ 2 4 8 formulabased 4 7 6 6 4 8 2 6 5 4 1 0 6 6 4 total allowance lendingrelate commitments $ 6 2 0 $ 6 $ $ 6 2 6 $ 9 0 2 $ 1 0 $ $ 9 1 2 total allowance credit losses $ 4 7 1 1 $ 1 6 3 9 3 $ 8 0 4 2 $ 2 9 1 4 6 $ 6 0 5 0 $ 1 6 1 7 4 $ 1 4 5 2 4 $ 3 6 7 4 8 memo retain loan end period $ 2 4 4 2 2 4 $ 3 1 5 1 6 9 $ 1 2 5 5 2 3 $ 6 8 4 9 1 6 $ 2 1 2 9 8 7 $ 3 3 9 2 2 9 $ 1 4 2 9 9 4 $ 6 9 5 2 1 0 retained loan average 2 3 2 0 5 8 3 2 0 8 9 4 1 2 7 1 3 6 6 8 0 0 8 8 2 1 0 3 0 0 3 4 7 4 8 3 1 5 1 0 2 0 7 0 8 8 0 3 pci loan end period 5 4 6 8 9 9 4 6 9 0 4 8 9 4 7 6 9 0 1 7 6 9 9 5 credit ratio allowance loan loss retain loans 1 . 6 8 % 5 . 2 0 % 6 . 4 1 % 4 . 1 6 % 2 . 4 2 % 4 . 7 6 % 1 0 . 1 6 % 5 . 1 5 % allowance loan loss retain nonaccrual loansd 1 2 2 1 9 6 nm 2 4 3 9 7 1 5 4 nm 2 2 7 allowance loan loss retain nonaccrual loan exclude credit card 1 2 2 1 9 6 nm 1 7 5 9 7 1 5 4 nm 1 3 5 net chargeoff ratese 0 . 2 1 1 . 6 0 6 . 4 0 2 . 0 2 1 . 1 4 2 . 4 4 1 0 . 9 9 3 . 8 8 credit ratio exclude home lending pci loan allowance loan loss retain loansf 1 . 6 8 4 . 6 5 6 . 4 1 3 . 8 3 2 . 4 2 5 . 0 9 1 0 . 1 6 5 . 3 4 allowance loan loss retain nonaccrual loansdf 1 2 2 1 3 7 nm 2 0 1 9 7 1 2 7 nm 2 0 9 allowance loan loss retain nonaccrual loan exclude credit carddf 1 2 2 1 3 7 nm 1 3 3 9 7 1 2 7 nm 1 1 7 aeffective january 1 2 0 1 0 firm adopt accounting guidance relate vie . adoption guidance firm consolidate sponsor credit card securitization trust administer multiseller conduit certain consumer loan securitization entity primarily mortgagerelate . result $ 7 . 4 billion $ 1 4 million $ 1 2 7 million respectively allowance loan loss record onbalance sheet consolidation entity . discussion note 1 6 page 2 4 4 2 5 9 jpmorgan chase 2 0 1 0 annual report . binclude riskrate loan place nonaccrual status loan modify tdr . cthe assetspecific consumer exclude credit card allowance loan loss include tdr reserve $ 9 6 2 million $ 9 4 6 million june 3 0 2 0 1 1 2 0 1 0 respectively . dthe firm policy generally exempt credit card loan place nonaccrual status permit regulatory guidance . guidance issue ffiec credit card loan charge end month account 1 8 0 day past 6 0 day receive notification specify event e . g . bankruptcy borrower whichever early . 8 7 echargeoffs record pci loan actual loss exceed estimate loss record purchase accounting adjustment time acquisition . fexclude impact pci loan acquire washington mutual transaction . provision credit lossesfor month end june 3 0 2 0 1 1 provision credit loss $ 1 . 8 billion $ 3 . 0 billion respectively 4 6 % 7 1 % respectively prior year period . consumer exclude credit card provision credit loss $ 1 . 1 billion $ 2 . 4 billion 3 5 % 5 5 % respectively prior year period reflect improve delinquency chargeoff trend 2 0 1 1 portfolio . credit card provision credit loss $ 8 1 0 million $ 1 . 0 billion 6 4 % 8 2 % respectively prior year period drive primarily improve delinquency net credit loss trend . credit card month provision benefit reduction allowance loan loss prior current year period . wholesale provision credit loss low benefit $ 1 1 7 million $ 5 0 3 million compare benefit $ 5 7 2 million $ 8 0 8 million prioryear period primarily reflect continue improvement credit environment yearago period . currentquarter benefit reflect reduction allowance loan loss primarily net repayments . three month end june 3 0 provision loan loss provision lendingrelated commitment total provision credit lossesin millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 wholesale $ 5 5 $ 5 5 5 $ 6 2 $ 1 7 $ 1 1 7 $ 5 7 2 consumer exclude credit card 1 1 1 7 1 7 1 4 1 1 1 7 1 7 1 4 credit card 8 1 0 2 2 2 1 8 1 0 2 2 2 1 total provision credit losses $ 1 8 7 2 $ 3 3 8 0 $ 6 2 $ 1 7 $ 1 8 1 0 $ 3 3 6 3 six month end june 3 0 provision loan loss provision lendingrelated commitment total provision credit lossesin millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 wholesale $ 4 1 4 $ 8 1 2 $ 8 9 $ 4 $ 5 0 3 $ 8 0 8 consumer exclude credit card 2 4 4 6 5 4 5 0 2 2 4 4 6 5 4 4 8 credit card 1 0 3 6 5 7 3 3 1 0 3 6 5 7 3 3 total provision credit losses $ 3 0 6 8 $ 1 0 3 7 1 $ 8 9 $ 2 $ 2 9 7 9 $ 1 0 3 7 3 market risk managementfor discussion firm market risk management organization major market risk driver classification risk page 1 4 2 1 4 6 jpmorgan chase 2 0 1 0 annual report . valueatrisk jpmorgan chase utilize var statistical risk measure estimate potential loss adverse market . business day risk management activitie firm undertake comprehensive var calculation include majority material market risk . var provide consistent crossbusiness measure risk profile level diversification use compare risk business monitoring limit . var result report senior management regulator utilize regulatory capital calculations . the firm calculate var estimate possible economic outcome current position use historical simulation measure risk instrument portfolio consistent comparable way . simulation base datum previous 1 2 month . approach assume historical change market value representative distribution potential outcome immediate future . var calculate use day time horizon expect tailloss methodology approximate 9 5 % confidence level . mean firm expect incur loss great predict var estimate time 1 0 0 trading day 1 2 1 3 time year . firm var calculation highly granular incorporate numerous risk factor select base risk profile portfolio . 8 8 the table result firm var measure use 9 5 % confidence level . total ib trading var risk type credit portfolio var var month end june 3 0 month end june 3 0 2 0 1 1 2 0 1 0 june 3 0 average million avg . minmax avg . minmax 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 ib var risk type fix income $ 4 5 $ 3 6 $ 5 7 $ 6 4 $ 3 3 $ 9 5 $ 3 7 $ 8 7 $ 4 7 $ 6 6 foreign exchange 9 6 1 3 1 0 7 1 8 1 0 1 1 1 0 1 2 equities 2 5 1 7 3 6 2 0 1 2 3 2 1 8 2 3 2 7 2 2 commodity other 1 6 1 1 2 4 2 0 1 2 3 2 1 3 1 2 1 5 1 8 diversification benefit ib trading var 3 7 a nmb nmb 4 2 a nmb nmb 3 9 a 4 2 a 3 8 a 4 6 a ib trade var $ 5 8 $ 3 8 $ 7 5 $ 7 2 $ 4 0 $ 1 0 7 $ 3 9 $ 9 1 $ 6 1 $ 7 2 credit portfolio var 2 7 2 2 3 3 2 7 1 8 4 0 2 2 2 9 2 7 2 3 diversification benefit ib trading credit portfolio var 8 a nmb nmb 9 a nmb nmb 1 0 a 9 a 8 a 9 a total ib trading credit portfolio var $ 7 7 $ 5 1 $ 9 8 $ 9 0 $ 5 0 $ 1 2 8 $ 5 1 $ 1 1 1 $ 8 0 $ 8 6 var risk type mortgage production service var 2 0 6 3 0 2 4 1 2 4 2 1 9 1 9 1 8 2 5 chief investment office cio var 5 1 4 3 5 7 7 2 5 5 7 9 4 6 5 5 5 6 7 1 diversification benefit total var 1 0 a nmb nmb 1 4 a nmb nmb 5 a 1 2 a 1 2 a 1 4 a total var $ 6 1 $ 5 5 $ 6 8 $ 8 2 $ 5 5 $ 9 7 $ 6 0 $ 6 2 $ 6 2 $ 8 2 diversification benefit total ib var 4 4 a nmb nmb 7 9 a nmb nmb 2 9 a 5 9 a 5 1 a 7 3 a total ib var $ 9 4 $ 8 2 $ 1 0 7 $ 9 3 $ 6 6 $ 1 3 3 $ 8 2 $ 1 1 4 $ 9 1 $ 9 5 aaverage var periodend var sum var component describe portfolio diversification . diversification effect reflect fact risk perfectly correlate . risk portfolio position usually sum risk position themselves . bdesignate meaningful nm minimum maximum occur different day different risk component meaningful compute portfoliodiversification effect . var measurementib trading var include substantially trading activity ib include credit spread sensitivity certain mortgage product syndicate lending facility firm intend distribute . firm use proxy estimate var product daily time series largely available . likely use actual pricebase time series product available affect var result present . addition certain product include ib trading credit portfolio var particular risk parameter fully capture example correlation risk . credit portfolio var include derivative cva hedge cva marktomarket mtm hedge retained loan portfolio report principal transaction revenue . credit portfolio var include retained portfolio mtm . oth var include certain position employ firm risk management function chief investment office cio mortgage production service business . cio var include position primarily debt security credit product use manage structural risk include interest rate credit mortgage risk arise firm ongoing business activity . mortgage production servicing var include firm mortgage pipeline warehouse loan msrs related hedges . as note ib credit portfolio var include retained credit portfolio mark market include hedge position . include debit valuation adjustment dva derivative structured liability reflect credit quality firm principal investment mezzanine financing taxoriente investment etc . certain security investment hold corporateprivate equity line business include private equity investment capital management position longerterm investment manage cio . longerterm position manage firm earning risk cash flow monitoring process use var measure . principal investing activity private equity position manage use stress scenario analysis . dva sensitivity table page 9 1 form 1 0 q detail . discussion corporateprivate equity page 4 6 4 7 form 1 0 q . 8 9 secondquarter yeartodate 2 0 1 1 var resultsa present table average total ib var increase slightly month end june 3 0 2 0 1 1 compare respective 2 0 1 0 period . increase drive reduction firm average ib var diversification benefit . month end june 3 0 2 0 1 1 average total ib var decrease comparable 2 0 1 0 period . decrease drive reduced market volatility position changes . average total ib trading credit portfolio var month end june 3 0 2 0 1 1 decrease compare respective 2 0 1 0 period . decrease drive primarily reduced market volatility position changes . cio var mortgage production servicing var month month end june 3 0 2 0 1 1 decrease comparable 2 0 1 0 period . decrease cio mortgage production servicing var drive reduced market volatility position changes . the firm average ib var diversification benefit $ 4 4 million 3 2 % sum month end june 3 0 2 0 1 1 compare $ 7 9 million 4 6 % sum month end june 3 0 2 0 1 0 . firm average ib var diversification benefit $ 5 1 million 3 6 % sum month end june 3 0 2 0 1 1 compare $ 7 3 million 4 3 % sum month end june 3 0 2 0 1 0 . general course year var exposure vary significantly position change market volatility fluctuate diversification benefit change . var backteste firm conduct daily backtesting var market riskrelate revenue define change value principal transaction revenue ib cio private equity gainslosse revenue longerterm cio investment tradingrelate net interest income ib cio mortgage production service ib brokerage commission underwriting fee revenue revenue syndicate lending facility firm intend distribute mortgage fee related income firm mortgage pipeline warehouse loan msrs related hedge . daily firmwide market riskrelate revenue exclude gain loss dva . the follow histogram illustrate daily market riskrelate gain loss ib cio mortgage production service position month 2 0 1 1 . chart firm post market riskrelate gain 1 2 7 1 2 9 day period day exceed $ 2 0 0 million . inset graph look day firm experience loss depict var exceed actual loss day . loss sustain day month end june 3 0 2 0 1 1 exceed var measure . 9 0 the follow table provide information gross sensitivity dva onebasispoint increase jpmorgan chase credit spread . sensitivity represent impact onebasispoint parallel shift jpmorgan chase entire credit curve . credit curve typically parallel fashion sensitivity multiply change spread single maturity point representative actual revenue recognized . debit valuation adjustment sensitivity millionsone basispoint increase jpmorgan chase credit spreadjune 3 0 2 0 1 1 $ 3 6 december 3 1 2 0 1 0 3 5 economicvalue stress testingwhile var reflect risk loss adverse change market use recent historical market behavior indicator loss stress testing capture firm exposure unlikely plausible event abnormal market use multiple scenario assume significant change credit spread equity price interest rate currency rate commodity price . scenario update dynamically redefine ongoing basis reflect current market condition . var stress testing important measure control risk enhance understanding firm risk profile loss potential stress loss monitor limit . stress testing employ crossbusiness risk management . stresst result trend explanation base current market risk position report firm senior management line business allow better understand event risksensitive position manage risk transparency . nontrading interest ratesensitive revenueatrisk i . e . earningsatriskinterest rate risk represent firm significant market risk exposure . risk arise trading activity firm traditional banking activity include extension loan credit facility deposit issue debt . firm manage interest rate risk generally investment security portfolio related derivative . firm evaluate nontrade interest rate risk exposure stress testing earningsatrisk measure extent change interest rate affect firm net interest income interest ratesensitive fee nontrade interest ratesensitive revenue . earningsatrisk exclude impact trading activity msrs sensitivity capture var . discussion interest rate exposure earningsatrisk stress testing page 1 4 5 1 4 6 jpmorgan chase 2 0 1 0 annual report . firm conduct simulation change nontrade interest ratesensitive revenue variety interest rate scenario . earningsatrisk test measure potential change revenue corresponding impact firm pretax earning following 1 2 month . test highlight exposure interest ratesensitive factor rate e . g . prime lending rate pricing strategy deposit optionality change product mix . test include forecast balance sheet change asset sale securitization prepayment reinvestment behavior . mortgage prepayment assumption base current interest rate compare underlie contractual rate time origination factor update periodically base historical experience forward market expectation . balance pricing assumption deposit state maturity base historical performance competitive environment customer behavior product mix . immediate change interest rate present limited view risk number alternative scenario review . scenario include imply forward curve nonparallel rate shift severe interest rate shock select key rate . scenario intend provide comprehensive view jpmorgan chase earning risk wide range outcomes . jpmorgan chase 1 2 month pretax earning sensitivity profiles . exclude impact trading activity msrs immediate change rate millions 2 0 0 bp 1 0 0 bp 1 0 0 bp 2 0 0 bpjune 3 0 2 0 1 1 $ 3 5 9 5 $ 2 0 6 2 nma nma december 3 1 2 0 1 0 2 4 6 5 1 4 8 3 nma nma adownward 1 0 0 2 0 0 basispoint parallel shock result fed fund target rate zero negative sixmonth treasury rate . earningsatrisk result lowprobability scenario meaningful . 9 1 the change earning risk december 3 1 2 0 1 0 result investment portfolio repositioning assumed high level deposit balance . firm risk rise rate largely result widen deposit margin currently compress low shortterm interest rates . additionally interest rate scenario use firm involve steep yield curve longterm rate rise 1 0 0 basis point shortterm rate stay current level result 1 2 month pretax earning benefit $ 9 8 0 million . increase earning scenario reinvestment mature asset high longterm rate funding cost remain unchanged . private equity risk managementfor discussion private equity risk management page 1 4 7 jpmorgan chase 2 0 1 0 annual report . june 3 0 2 0 1 1 december 3 1 2 0 1 0 carry value private equity portfolio $ 8 . 8 billion $ 8 . 7 billion respectively $ 6 7 0 million $ 8 7 5 million respectively represent security publicly available market quotations . operational risk managementfor discussion jpmorgan chase operational risk management page 1 4 7 1 4 8 jpmorgan chase 2 0 1 0 annual report . reputation fiduciary risk managementfor discussion firm reputation fiduciary risk management page 1 4 8 jpmorgan chase 2 0 1 0 annual report . supervision regulationthe follow discussion read conjunction regulatory development page 9 1 0 form 1 0 q supervision regulation section page 1 5 jpmorgan chase 2 0 1 0 form 1 0 k . dividendsat june 3 0 2 0 1 1 jpmorgan chase banking subsidiary pay aggregate $ 4 . 1 billion dividend respective bank hold company prior approval relevant banking regulators . critical accounting estimate use firmjpmorgan chase account policy use estimate integral understand report result . firm complex accounting estimate require management judgment ascertain value asset liability . firm establish detailed policy control procedure intend ensure valuation method include judgment method wellcontrolle independently review apply consistently period period . addition policy procedure intend ensure process change methodology occur appropriate manner . firm believe estimate determine value asset liability appropriate . following brief description firm critical accounting estimate involve significant valuation judgment . allowance credit lossesjpmorgan chase allowance credit loss cover retain wholesale consumer loan portfolio firm wholesale consumer lendingrelated commitment . allowance loan loss intend adjust value firm loan asset reflect probable credit loss inherent portfolio balance sheet date . allowance lendingrelated commitment establish cover probable loss lendingrelated commitment portfolio . discussion methodology use establish firm allowance credit loss allowance credit loss page 1 4 9 1 5 0 note 1 5 page 2 3 9 2 4 3 jpmorgan chase 2 0 1 0 annual report record june 3 0 2 0 1 1 2 0 1 0 allowance credit loss page 8 6 8 8 note 1 4 page 1 4 9 1 5 0 form 1 0 q . as note discussion page 1 4 9 jpmorgan chase 2 0 1 0 annual report firm allowance credit loss sensitive factor depend portfolio . firm consumer loan portfolio sensitive change economic environment delinquency status realizable value collateral fico score borrower behavior risk factor firm wholesale loan portfolio sensitive estimate credit quality individual loan express assign risk rating . significant judgment require estimate allowance credit loss portfolio segment consider relevant factor . example credit performance consumer portfolio entire consumer credit product spectrum improve particularly credit card high unemployment weak overall economic condition continue result elevated number residential real estate loan chargeoff weak housing price continue negatively affect severity loss recognize residential real estate loan default . significant judgment require estimate duration 9 2 severity recent economic downturn potential impact housing price labor market . ongoing weak economic condition combine elevated delinquency ongoing discussion regard mortgage foreclosurerelated matter federal state official continue result high level uncertainty residential real estate portfolio . change economic condition firm assumption affect firm estimate probable loss inherent portfolio balance sheet date . example deterioration follow input following effect firm loss estimate june 3 0 2 0 1 1 consideration offsetting correlate effect input firm allowance loan lossesa onenotch downgrade firm internal risk rating entire wholesale loan portfolio imply increase loss estimate approximately $ 1 . 9 billion . a 5 % decline home price current assumption derive nationally recognize home price index imply increase model annual loss estimate residential real estate portfolio exclude pci loan approximately $ 0 . 5 billion . a 5 0 basis point deterioration forecast credit card loss rate imply increase model annualize credit card loan loss estimate approximately $ 0 . 6 billion . the purpose sensitivity analyse provide indication isolated impact hypothetical alternative assumption credit loss estimate . change input present intend imply management expectation future deterioration risk factor . difficult estimate potential change specific factor affect allowance credit loss management consider variety factor input estimate allowance credit loss . change factor input occur rate consistent geography product type change factor directionally inconsistent improvement factor offset deterioration factor . addition difficult predict change specific economic condition assumption affect borrower behavior factor consider management estimate allowance credit loss . process firm follow evaluate risk factor relate loan include risk rating home price assumption credit card loss estimate management believe current estimate allowance credit loss appropriate . fair value financial instrument msrs commodity inventory jpmorgan chase carry portion asset liability fair value . majority asset liability measure fair value recur basis . certain asset liability measure fair value nonrecurring basis include loan account low cost fair value subject fair value adjustment certain circumstance . asset measure fair valuethe follow table include firm asset measure fair value portion asset classify level 3 valuation hierarchy . june 3 0 2 0 1 1 december 3 1 2 0 1 0 billionstotal asset fair valuetotal level 3 asset total asset fair valuetotal level 3 assetstrade debt equity instrumentsa $ 3 8 1 . 3 $ 3 2 . 8 $ 4 0 9 . 4 $ 3 4 . 6 derivative receivables gross 1 3 9 2 . 4 3 4 . 2 1 5 2 9 . 4 3 4 . 6 netting adjustment 1 3 1 5 . 0 1 4 4 8 . 9 derivative receivables net 7 7 . 4 3 4 . 2 d 8 0 . 5 3 4 . 6 d afs securities 3 2 4 . 7 1 5 . 9 3 1 6 . 3 1 4 . 3 loans 2 . 0 1 . 5 2 . 0 1 . 5 msrs 1 2 . 2 1 2 . 2 1 3 . 6 1 3 . 6 private equity investments 8 . 7 8 . 0 8 . 7 7 . 9 otherb 4 6 . 0 4 . 5 4 3 . 8 4 . 1 total asset measure fair value recur basis 8 5 2 . 3 1 0 9 . 1 8 7 4 . 3 1 1 0 . 6 total asset measure fair value nonrecurring basisc 3 . 9 0 . 7 9 . 9 4 . 0 total asset measure fair value $ 8 5 6 . 2 $ 1 0 9 . 8 e $ 8 8 4 . 2 $ 1 1 4 . 6 e total firm assets $ 2 2 4 6 . 8 $ 2 1 1 7 . 6 level 3 asset percentage total firm asset 5 % 5 % level 3 asset percentage total firm asset fair value 1 3 % 1 3 % ainclude physical commodity generally carry low cost fair value . binclude certain security purchase resale agreement security borrow accrue interest receivable investments . cpredominantly include mortgage home equity loan carry value base fair value underlie collateral carry consolidated balance sheet low cost fair value june 3 0 2 0 1 1 december 3 1 2 0 1 0 include credit card loan carry consolidated balance sheet low cost fair value december 3 1 2 0 1 0 . 9 3 dderivative receivable derivative payable balance related cash collateral receive pay present net consolidated balance sheet legally enforceable master netting agreement place counterpartie . purpose table firm reduce level 3 derivative receivable balance net adjustment adjustment relevant presentation base transparency input valuation . derivative balance report fair value hierarchy level gross counterparty netting adjustment . firm net balance level 3 reduction level 3 derivative receivable payable balance $ 1 3 . 5 billion $ 1 2 . 7 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively exclusive netting benefit associate cash collateral reduce level 3 balances . eat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include $ 6 3 . 1 billion $ 6 6 . 0 billion respectively level 3 asset consist recur nonrecurre asset carry ib . valuationfor instrument classify level 3 hierarchy judgment use estimate fair value significant . arrive estimate fair value instrument level 3 management determine appropriate model use . second lack observability significant input management assess relevant empirical datum derive valuation input include limit yield curve interest rate volatility equity debt price foreign exchange rate credit curve . addition market information model incorporate transaction detail maturity . finally management judgment apply assess appropriate level valuation adjustment reflect counterparty credit quality firm creditworthiness constraint liquidity unobservable parameter relevant . judgment typically affect type product specific contractual term level liquidity product market . discussion change level 3 asset note 3 page 1 0 2 1 1 4 form 1 0 q . imprecision estimate unobservable market input affect revenue loss record particular position . furthermore firm believe valuation method appropriate consistent market participant use different methodology assumption determine fair value certain financial instrument result different estimate fair value reporting date . detailed discussion determination fair value individual financial instrument note 3 page 1 7 0 1 8 7 jpmorgan chase 2 0 1 0 annual report . purchase creditimpaire loansin connection washington mutual transaction jpmorgan chase acquire certain loan evidence deterioration credit quality origination probable acquisition firm unable collect contractually require payment receivable . loan consider pci loan account describe note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . application accounting guidance pci loan require number significant estimate judgment determine loan scope pci accounting guidance ii fair value pci loan acquisition iii loan aggregate apply guidance account pool loan iv estimate cash flow collect term loan . additional information pci loan include significant assumption estimate judgment involve pci loan page 1 5 2 1 5 3 jpmorgan chase 2 0 1 0 annual report note 1 4 page 1 4 9 1 5 0 form 1 0 q . as june 3 0 2 0 1 1 carry value aggregate portfolio pci loan incorporate assumption home price derive nationally recognize home price index index reflect 5 % decline housing price base geographic distribution pci portfolio . adverse home price scenario reflect additional 5 % decline housing price assume imply increase credit loss estimate loan approximately $ 1 . 5 billion . goodwill impairmentmanagement apply significant judgment testing goodwill impairment . description significant valuation judgment associate goodwill impairment goodwill impairment page 1 5 3 jpmorgan chase 2 0 1 0 annual report . month end june 3 0 2 0 1 1 firm update discounted cash flow valuation certain consumer lending business rfs card continue elevate risk goodwill impairment exposure u . s . consumer credit risk effect regulatory legislative change . assumption use valuation business include estimate future cash flow business dependent portfolio outstanding balance net interest margin operate expense credit loss capital necessary risk business activity meet regulatory capital requirement b cost equity use discount cash flow present value . factor require significant judgment assumption use base management good estimate current projection include anticipate effect regulatory legislative change derive firm business forecasting process review senior management . projection consistent shortterm assumption discuss business outlook page 8 9 form 1 0 q long term incorporate set macroeconomic assumption firm good estimate longterm growth return business . possible firm use thirdparty peer datum benchmark assumption estimates . 9 4 addition business firm review current condition include estimate effect regulatory legislative change prior projection business performance . base update valuation consumer lending business review business firm conclude goodwill allocate reporting unit impair june 3 0 2 0 1 1 . fair value firm consumer lending business rfs card exceed carry value 1 5 % associate goodwill line business remain elevated risk impairment business ' exposure u . s . consumer credit risk effect economic regulatory legislative change . deterioration economic market condition increase estimate effect recent regulatory legislative change additional regulatory legislative change result decline project business performance management current expectation . example rfs decline result increase cost resolve foreclosurerelated matter deterioration economic condition result increase credit loss include decrease home price management current expectation . card decline business performance result deterioration economic condition increase unemployment claim bankruptcy filing result increase credit loss change customer behavior cause decrease account activity receivable balance . decline business performance increase equity capital requirement increase estimate cost equity cause estimate fair value firm report unit associated goodwill decline result material impairment charge earning future period relate portion associate goodwill . for additional information goodwill note 1 6 page 1 5 9 1 6 3 form 1 0 q . income taxis description significant assumption judgment interpretation associate accounting income taxis income taxis page 1 5 4 jpmorgan chase 2 0 1 0 annual report . litigation reserve description significant estimate judgment associate establish litigation reserve note 2 3 page 1 7 2 1 7 9 form 1 0 q note 3 2 page 2 8 2 2 8 9 jpmorgan chase 2 0 1 0 annual report . 9 5 accounte report developmentsfair value measurement disclosuresin january 2 0 1 0 fasb issue guidance require new disclosure clarifie exist disclosure requirement fair value measurement . clarification requirement separately disclose transfer instrument level 1 level 2 fair value hierarchy effective interim report period begin december 1 5 2 0 0 9 firm adopt guidance quarter 2 0 1 0 . additional information impact adoption new fair value measurement guidance note 3 page 1 0 2 1 1 4 form 1 0 q . addition new requirement provide purchase sale issuance settlement level 3 rollforward gross basis effective fiscal year begin december 1 5 2 0 1 0 . firm adopt new guidance effective january 1 2 0 1 1 . in 2 0 1 1 fasb issue guidance amend requirement fair value measurement disclosure . guidance change clarifie certain exist requirement relate portfolio financial instrument valuation adjustment require additional disclosure fair value measurement categorize level 3 fair value hierarchy include disclosure range input use certain valuation financial instrument carry fair value fair value require disclose . guidance effective quarter 2 0 1 2 . firm currently assess impact guidance . disclosure credit quality financing receivable allowance credit lossesin july 2 0 1 0 fasb issue guidance require enhance disclosure surround credit characteristic firm loan portfolio . new guidance firm require disclose accounting policy method use determine component allowance credit loss qualitative quantitative information credit risk inherent loan portfolio include additional information certain type loan modification . firm new disclosure relate loan modification effective 2 0 1 0 annual report . additional information note 1 3 1 4 page 1 3 4 1 4 8 1 4 9 1 5 0 form 1 0 q . adoption guidance affected jpmorgan chase disclosure financing receivable consolidated balance sheet result operation . new disclosure regard tdrs effective 2 0 1 1 quarter . determine restructuring troubled debt restructuringin april 2 0 1 1 fasb issue guidance clarify exist standard determine restructuring represent tdr perspective creditor . guidance effective quarter 2 0 1 1 apply retrospectively january 1 2 0 1 1 . firm expect implementation new guidance significant impact firm consolidate balance sheet result operations . accounte repurchase similar agreement april 2 0 1 1 fasb issue guidance amend criterion use assess repurchase similar agreement account financing sale purchase forward agreement repurchase resell . specifically guidance eliminate circumstance lack adequate collateral maintenance requirement result repurchase agreement account sale . guidance effective new transaction exist transaction modify begin january 1 2 0 1 2 . firm account repurchase similar agreement secure financing firm expect application guidance impact firm consolidate balance sheet result operations . presentation comprehensive incomein june 2 0 1 1 fasb issue guidance modify presentation comprehensive income consolidated financial statement . guidance require item net income item comprehensive income total comprehensive income present continuous statement separate consecutive statement . public company guidance effective interim annual reporting period begin december 1 5 2 0 1 1 . application guidance affect presentation consolidated financial statement impact firm consolidate balance sheet result operations . 9 6 forwardlooking statementsfrom time time firm forwardlooking statement . statement identify fact relate strictly historical current fact . forwardlooke statement use word anticipate target expect estimate intend plan goal believe word similar meaning . forwardlooke statement provide jpmorgan chase current expectation forecast future event circumstance result aspiration . jpmorgan chase disclosure form 1 0 q contain forwardlooke statement meaning private security litigation reform act 1 9 9 5 . firm forwardlooke statement document file furnish security exchange commission . addition firm senior management forwardlooking statement orally analyst investor representative medium others . all forwardlooke statement nature subject risk uncertaintie firm control . jpmorgan chase actual future result differ materially set forth forwardlooking statement . assurance list risk uncertainty risk factor complete certain factor cause actual result differ forwardlooke statement local regional international business economic political condition geopolitical eventschange law regulatory requirement include result newlyenacted financial service legislationchange trade monetary fiscal policy lawssecuritie capital market behavior include change market liquidity volatilitychange investor sentiment consumer spending saving behaviorability firm manage effectively liquiditychange credit rating assign firm subsidiariesdamage firm reputationability firm deal effectively economic slowdown economic market disruptiontechnology change institute firm counterpartie competitorsmerger acquisition include firm ability integrate acquisitionsability firm develop new product service extent product service previously sell firm including limit mortgage assetbacked security require firm incur liability absorb loss contemplate initiation originationability firm address enhance regulatory requirement affect mortgage businessacceptance firm new exist product service marketplace ability firm increase market share ability firm attract retain employeesability firm control expensecompetitive pressureschange credit quality firm customer counterpartiesadequacy firm risk management frameworkadverse judicial regulatory proceedingschange applicable accounting policiesability firm determine accurate value certain asset liabilitiesoccurrence natural manmade disaster calamity conflict include effect disaster calamity conflict firm power generation facility firm commodityrelate activitiesthe risk uncertainty detail ii item 1 a risk factor page 1 9 2 1 9 3 form 1 0 q item 1 a risk factor page 5 1 2 2 0 1 0 form 1 0 k . any forwardlooke statement behalf firm speak date jpmorgan chase undertake update forwardlooke statement reflect impact circumstance event arise date forwardlooke statement . reader consult disclosure forwardlooke nature firm subsequent annual report form 1 0 k quarterly report form 1 0 q current report form 8 k . 9 7 jpmorgan chase co . consolidate statement income unaudited month end june 3 0 month end june 3 0 million share data 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 revenue investment bank fees $ 1 9 3 3 $ 1 4 2 1 $ 3 7 2 6 $ 2 8 8 2 principal transactions 3 1 4 0 2 0 9 0 7 8 8 5 6 6 3 8 lending depositrelate fees 1 6 4 9 1 5 8 6 3 1 9 5 3 2 3 2 asset management administration commissions 3 7 0 3 3 3 4 9 7 3 0 9 6 6 1 4 securities gainsa 8 3 7 1 0 0 0 9 3 9 1 6 1 0 mortgage fee related income 1 1 0 3 8 8 8 6 1 6 1 5 4 6 credit card income 1 6 9 6 1 4 9 5 3 1 3 3 2 8 5 6 other income 8 8 2 5 8 5 1 4 5 6 9 9 7 noninterest revenue 1 4 9 4 3 1 2 4 1 4 2 8 2 5 9 2 6 3 7 5 interest income 1 5 6 3 2 1 5 7 1 9 3 1 0 7 9 3 2 5 6 4 interest expense 3 7 9 6 3 0 3 2 7 3 3 8 6 1 6 7 net interest income 1 1 8 3 6 1 2 6 8 7 2 3 7 4 1 2 6 3 9 7 total net revenue 2 6 7 7 9 2 5 1 0 1 5 2 0 0 0 5 2 7 7 2 provision credit losses 1 8 1 0 3 3 6 3 2 9 7 9 1 0 3 7 3 noninterest expense compensation expense 7 5 6 9 7 6 1 6 1 5 8 3 2 1 4 8 9 2 occupancy expense 9 3 5 8 8 3 1 9 1 3 1 7 5 2 technology communication equipment expense 1 2 1 7 1 1 6 5 2 4 1 7 2 3 0 2 professional outside services 1 8 6 6 1 6 8 5 3 6 0 1 3 2 6 0 marketing 7 4 4 6 2 8 1 4 0 3 1 2 1 1 other expense 4 2 9 9 2 4 1 9 7 2 4 2 6 8 6 0 amortization intangibles 2 1 2 2 3 5 4 2 9 4 7 8 total noninterest expense 1 6 8 4 2 1 4 6 3 1 3 2 8 3 7 3 0 7 5 5 income income tax expense 8 1 2 7 7 1 0 7 1 6 1 8 4 1 1 6 4 4 income tax expense 2 6 9 6 2 3 1 2 5 1 9 8 3 5 2 3 net income $ 5 4 3 1 $ 4 7 9 5 $ 1 0 9 8 6 $ 8 1 2 1 net income applicable common stockholders $ 5 0 6 7 $ 4 3 6 3 $ 1 0 2 0 3 $ 7 3 3 5 net income common share datum basic earning share $ 1 . 2 8 $ 1 . 1 0 $ 2 . 5 7 $ 1 . 8 4 diluted earning share 1 . 2 7 1 . 0 9 2 . 5 5 1 . 8 3 weightedaverage basic shares 3 9 5 8 . 4 3 9 8 3 . 5 3 9 7 0 . 0 3 9 7 7 . 0 weightedaverage dilute shares 3 9 8 3 . 2 4 0 0 5 . 6 3 9 9 8 . 6 4 0 0 0 . 2 cash dividend declare common share $ 0 . 2 5 $ 0 . 0 5 $ 0 . 5 0 $ 0 . 1 0 athe follow otherthantemporary impairment loss include security gain period present . month end june 3 0 month end june 3 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 total otherthantemporary impairment losses $ $ $ 2 7 $ 9 4 losses record inreclassifie comprehensive income 1 3 1 6 6 total credit loss recognize income $ 1 3 $ $ 4 3 $ 1 0 0 the note consolidated financial statement unaudited integral statements . 9 8 jpmorgan chase co . consolidate balance sheet unauditedin million share datajune 3 0 2 0 1 1 december 3 1 2 0 1 0 assets cash banks $ 3 0 4 6 6 $ 2 7 5 6 7 deposits banks 1 6 9 8 8 0 2 1 6 7 3 federal fund sell security purchase resale agreement include $ 2 1 2 9 7 $ 2 0 2 9 9 fair value 2 1 3 3 6 2 2 2 2 5 5 4 securitie borrow include $ 1 4 8 3 3 $ 1 3 9 6 1 fair value 1 2 1 4 9 3 1 2 3 5 8 7 trading asset include asset pledge $ 9 9 1 4 0 $ 7 3 0 5 6 4 5 8 7 2 2 4 8 9 8 9 2 securitie include $ 3 2 4 7 2 6 $ 3 1 6 3 1 8 fair value asset pledge $ 9 6 1 6 7 $ 8 6 8 9 1 3 2 4 7 4 1 3 1 6 3 3 6 loan include $ 2 0 0 7 $ 1 9 7 6 fair value 6 8 9 7 3 6 6 9 2 9 2 7 allowance loan losses 2 8 5 2 0 3 2 2 6 6 loans net allowance loan losses 6 6 1 2 1 6 6 6 0 6 6 1 accrue interest account receivable 8 0 2 9 2 7 0 1 4 7 premise equipment 1 3 6 7 9 1 3 3 5 5 goodwill 4 8 8 8 2 4 8 8 5 4 mortgage servicing rights 1 2 2 4 3 1 3 6 4 9 other intangible assets 3 6 7 9 4 0 3 9 other asset include $ 1 8 4 2 3 $ 1 8 2 0 1 fair value asset pledge $ 1 5 9 7 $ 1 4 8 5 1 0 8 1 0 9 1 0 5 2 9 1 total assetsa $ 2 2 4 6 7 6 4 $ 2 1 1 7 6 0 5 liabilitie deposit include $ 4 7 8 8 $ 4 3 6 9 fair value $ 1 0 4 8 6 8 5 $ 9 3 0 3 6 9 federal fund purchase security loan sell repurchase agreement include $ 6 5 8 8 $ 4 0 6 0 fair value 2 5 4 1 2 4 2 7 6 6 4 4 commercial paper 5 1 1 6 0 3 5 3 6 3 other borrow fund include $ 1 1 7 0 1 $ 9 9 3 1 fair value 3 0 2 0 8 3 4 3 2 5 trading liabilities 1 4 8 5 3 3 1 4 6 1 6 6 account payable liability include allowance lendingrelated commitment $ 6 2 6 $ 7 1 7 $ 7 3 $ 2 3 6 fair value 1 8 4 4 9 0 1 7 0 3 3 0 beneficial interest issue consolidated variable interest entity include $ 9 1 1 $ 1 4 9 5 fair value 6 7 4 5 7 7 7 6 4 9 longterm debt include $ 3 8 5 1 6 $ 3 8 8 3 9 fair value 2 7 9 2 2 8 2 7 0 6 5 3 total liabilitiesa 2 0 6 3 8 8 5 1 9 4 1 4 9 9 commitment contingency note 2 1 2 3 form 1 0 q stockholder equity preferred stock $ 1 par value authorize 2 0 0 0 0 0 0 0 0 share issue 7 8 0 0 0 0 shares 7 8 0 0 7 8 0 0 common stock $ 1 par value authorize 9 0 0 0 0 0 0 0 0 0 share issue 4 1 0 4 9 3 3 8 9 5 shares 4 1 0 5 4 1 0 5 capital surplus 9 5 0 6 1 9 7 4 1 5 retaine earnings 8 2 6 1 2 7 3 9 9 8 accumulate comprehensive incomeloss 1 6 3 8 1 0 0 1 share hold rsu trust cost 1 1 9 1 3 8 4 1 1 9 2 7 1 2 shares 5 3 5 3 treasury stock cost 1 9 4 7 3 7 5 1 7 1 9 4 6 3 9 7 8 5 shares 8 2 8 4 8 1 6 0 total stockholder equity 1 8 2 8 7 9 1 7 6 1 0 6 total liability stockholder equity $ 2 2 4 6 7 6 4 $ 2 1 1 7 6 0 5 athe follow table present information asset liability relate vie consolidate firm june 3 0 2 0 1 1 december 3 1 2 0 1 0 . difference total vie asset liability represent firm interest entity eliminate consolidation . june 3 0 2 0 1 1 december 3 1 2 0 1 0 asset trading assets $ 7 1 2 4 $ 9 8 3 7 loans 8 0 3 8 7 9 5 5 8 7 all assets 2 6 7 5 3 4 9 4 total assets $ 9 0 1 8 6 $ 1 0 8 9 1 8 liabilities beneficial interest issue consolidated variable interest entities $ 6 7 4 5 7 $ 7 7 6 4 9 all liabilities 1 5 8 7 1 9 2 2 total liabilities $ 6 9 0 4 4 $ 7 9 5 7 1 the asset consolidated vie use settle liability entity . holder beneficial interest recourse general credit jpmorgan chase . june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm provide limited programwide credit enhancement $ 2 . 0 billion relate firmadministered multiseller conduit . discussion note 1 5 page 1 5 1 1 5 9 form 1 0 q . the note consolidated financial statement unaudited integral statements . 9 9 jpmorgan chase co . consolidate statement change stockholder equity comprehensive income unaudited month end june 3 0 million share datum 2 0 1 1 2 0 1 0 preferre stock balance january 1 june 3 0 $ 7 8 0 0 $ 8 1 5 2 common stock balance january 1 june 3 0 4 1 0 5 4 1 0 5 capital surplus balance january 1 9 7 4 1 5 9 7 9 8 2 share issue commitment issue common stock employee stockbase compensation award related tax effect 2 3 5 1 3 6 other 3 1 2 7 3 balance june 3 0 9 5 0 6 1 9 6 7 4 5 retained earning balance january 1 7 3 9 9 8 6 2 4 8 1 cumulative effect change accounting principle 4 3 9 1 net income 1 0 9 8 6 8 1 2 1 dividend declare preferred stock 3 1 5 3 2 5 common stock $ 0 . 5 0 $ 0 . 1 0 share 2 0 5 7 4 2 1 balance june 3 0 8 2 6 1 2 6 5 4 6 5 accumulated comprehensive incomeloss balance january 1 1 0 0 1 9 1 cumulative effect change accounting principle 1 2 9 other comprehensive income 6 3 7 2 6 2 4 balance june 3 0 1 6 3 8 2 4 0 4 share hold rsu trust cost balance january 1 june 3 0 5 3 6 8 treasury stock cost balance january 1 8 1 6 0 7 1 9 6 purchase treasury stock 3 5 7 5 1 3 5 reissuance treasury stock 3 4 5 1 1 6 4 8 balance june 3 0 8 2 8 4 5 6 8 3 total stockholder equity $ 1 8 2 8 7 9 $ 1 7 1 1 2 0 comprehensive income net income $ 1 0 9 8 6 $ 8 1 2 1 other comprehensive income 6 3 7 2 6 2 4 comprehensive income $ 1 1 6 2 3 $ 1 0 7 4 5 the note consolidated financial statement unaudited integral statements . 1 0 0 jpmorgan chase co . consolidate statement cash flow unaudited month end june 3 0 millions 2 0 1 1 2 0 1 0 operating activity net income $ 1 0 9 8 6 $ 8 1 2 1 adjustment reconcile net income net cash provide operate activity provision credit losses 2 9 7 9 1 0 3 7 3 depreciation amortization 2 1 2 3 1 9 3 4 amortization intangibles 4 2 9 4 7 8 deferred tax expensebenefit 6 7 9 5 6 7 investment security gains 9 3 9 1 6 1 0 stockbased compensation 1 5 5 7 1 7 7 4 origination purchase loan heldforsale 4 1 6 3 7 1 4 2 5 9 proceed sale securitization paydown loan heldforsale 4 2 4 4 4 1 8 3 7 4 net change trading assets 3 4 9 3 4 1 7 9 5 3 securitie borrowed 2 0 9 5 2 6 2 0 accrue interest account receivable 1 0 1 5 1 9 2 7 0 other assets 1 1 7 2 1 8 6 7 5 trading liabilities 7 6 2 7 1 9 3 9 6 account payable liabilities 1 2 9 9 3 1 0 6 6 other operate adjustments 6 6 8 8 3 1 4 9 net cash provide operate activities 5 8 7 2 5 4 5 7 2 7 investing activity net change deposit banks 1 4 8 1 9 3 2 3 8 6 6 federal fund sell security purchase resale agreements 9 1 9 5 3 3 4 3 heldtomaturity security proceeds 3 4 availableforsale security proceed maturities 3 9 9 0 2 5 7 0 1 2 proceed sales 4 2 9 9 4 7 7 7 5 4 purchases 8 3 3 2 2 1 0 2 2 9 1 proceed sale securitization loan heldforinvestment 7 7 5 5 5 8 5 0 other change loan net 1 4 1 3 3 1 3 1 3 8 net cash use business acquisition dispositions 1 4 6 all investing activity net 6 1 6 9 0 net cash use inprovide invest activities 1 4 5 8 0 7 7 3 6 7 4 financing activity net change deposits 1 1 0 8 9 6 4 6 1 7 9 federal fund purchase security loan sell repurchase agreements 2 2 4 9 9 2 4 0 2 3 commercial paper borrow funds 1 2 6 6 9 9 6 3 beneficial interest issue consolidated variable interest entities 5 6 6 2 2 7 3 proceed longterm borrowing trust prefer capital debt securities 3 6 8 5 5 2 0 8 9 4 payment longterm borrowing trust prefer capital debt securities 4 2 1 3 2 5 8 4 2 4 excess tax benefit relate stockbase compensation 7 7 6 2 1 treasury stock purchased 3 5 7 5 1 3 5 dividends paid 1 5 6 5 7 4 5 all financing activity net 1 5 3 4 4 9 7 net cash provide byuse finance activities 8 9 3 2 5 1 1 2 3 2 4 effect exchange rate change cash banks 6 5 6 4 7 7 net increase cash banks 2 8 9 9 6 6 0 0 cash bank beginning period 2 7 5 6 7 2 6 2 0 6 cash bank end period $ 3 0 4 6 6 $ 3 2 8 0 6 cash interest paid $ 7 5 4 4 $ 6 3 6 3 cash income taxis pay net 4 7 5 3 5 3 6 1 noteeffective january 1 2 0 1 0 firm adopt accounting guidance relate vie . adoption guidance firm consolidated noncash asset liability $ 8 7 . 7 billion $ 9 2 . 2 billion respectively . the note consolidated financial statement unaudited integral statements . 1 0 1 see glossary term page 1 8 6 1 8 9 form 1 0 q definition term use note consolidated financial statements . note consolidated financial statement unauditednote 1 basis presentationjpmorgan chase co . jpmorgan chase firm financial hold company incorporate delaware law 1 9 6 8 lead global financial service firm large banking institution united state america u . s . operation 6 0 country . firm leader investment bank financial service consumer small business commercial banking financial transaction processing asset management private equity . discussion firm businesssegment information note 2 4 page 1 8 0 1 8 2 form 1 0 q . accounting financial reporting policy jpmorgan chase subsidiary conform accounting principle generally accept u . s . u . s . gaap . additionally applicable policy conform accounting report guideline prescribe bank regulatory authority . unaudited consolidated financial statement prepare conformity u . s . gaap require management estimate assumption affect reported asset liability revenue expense disclosure contingent asset liability . actual result different estimate . opinion management normal recur adjustment include fair statement interim financial information . unaudited consolidated financial statement read conjunction audit consolidated financial statement related note thereto include jpmorgan chase annual report form 1 0 k year end december 3 1 2 0 1 0 file u . s . security exchange commission sec retrospectively revise current report form 8 k file sec november 4 2 0 1 1 . references 2 0 1 0 annual report 2 0 1 0 form 1 0 k form 8 k firm 2 0 1 0 form 1 0 k retrospectively revise form 8 k file november 4 2 0 1 1 . certain report prior period reclassify conform current presentation . note 2 business change developmentsincrease common stock dividendon march 1 8 2 0 1 1 board director raise firm quarterly common stock dividend $ 0 . 0 5 $ 0 . 2 5 share effective dividend pay april 3 0 2 0 1 1 shareholder record april 6 2 0 1 1 . stock repurchaseson march 1 8 2 0 1 1 board director approve $ 1 5 . 0 billion common equity repurchase program $ 8 . 0 billion authorize repurchase 2 0 1 1 . $ 1 5 . 0 billion repurchase program supersede $ 1 0 . 0 billion repurchase program approve 2 0 0 7 . $ 1 5 . 0 billion authorization include share repurchase offset issuance firm employee stockbase incentive plans . the authorization repurchase common equity utilize management discretion timing purchase exact common equity repurchase subject factor include market condition legal consideration affect timing repurchase activity firm capital position account goodwill intangible internal capital generation alternative investment opportunity . repurchase program include specific price target timetable execute open market purchase privately negotiate transaction utilize rule 1 0 b 5 1 program suspend time . for additional information repurchase item 2 unregistered sale equity security use proceed page 1 9 3 1 9 4 form 1 0 q . note 3 fair value measurementfor discussion firm valuation methodology asset liability lendingrelated commitment measure fair value fair value hierarchy note 3 page 1 7 0 1 8 7 jpmorgan chase 2 0 1 0 annual report . dure month 2 0 1 1 change firm valuation model expect material impact firm consolidate balance sheet result operations . the follow table present asset liability measure fair value june 3 0 2 0 1 1 december 3 1 2 0 1 0 major product category fair value hierarchy . 1 0 2 assets liability measure fair value recur basis fair value hierarchy june 3 0 2 0 1 1 millionslevel 1 hlevel 2 h level 3 hnetting adjustmentstotal fair valuefederal fund sell security purchase resale agreements $ $ 2 1 2 9 7 $ $ $ 2 1 2 9 7 securitie borrowed 1 4 8 3 3 1 4 8 3 3 trade asset debt instrument mortgagebacke security u . s . government agenciesa 2 2 9 9 0 7 7 4 7 1 6 5 3 0 9 0 2 residential nonagency 2 6 0 9 8 6 3 3 4 7 2 commercial nonagency 8 8 1 1 8 4 3 2 7 2 4 total mortgagebacke securities 2 2 9 9 0 1 1 2 3 7 2 8 7 1 3 7 0 9 8 u . s . treasury government agenciesa 1 4 2 1 2 9 4 7 7 2 3 6 8 9 obligation u . s . state municipalities 1 6 7 6 4 1 8 5 5 8 6 2 0 certificate deposit banker acceptance commercial paper 2 9 8 3 2 9 8 3 nonu . s . government debt securities 2 3 7 8 6 5 1 6 5 2 8 2 7 5 5 2 0 corporate debt securities 4 1 4 0 5 5 6 0 6 4 7 0 1 1 loansb 2 4 6 1 3 1 1 7 4 2 3 6 3 5 5 assetbacked securities 3 5 4 7 8 3 1 9 1 1 8 6 6 total debt instruments 6 0 9 8 9 1 5 1 6 7 8 3 0 4 7 5 2 4 3 1 4 2 equity securities 1 0 9 3 8 9 3 1 2 4 1 4 0 8 1 1 3 9 2 1 physical commoditiesc 1 8 5 5 9 2 4 9 6 2 1 0 5 5 other 2 3 1 3 9 0 8 3 2 2 1 total debt equity instrumentsd 1 8 8 9 3 7 1 5 9 6 1 1 3 2 7 9 1 3 8 1 3 3 9 derivative receivables interest rate 1 0 2 1 9 9 2 9 8 2 5 9 0 1 9 6 6 9 9 3 3 2 9 1 1 credit 1 1 3 8 9 1 1 5 1 3 1 1 2 2 8 2 4 6 1 9 8 foreign exchange 1 5 8 1 1 5 2 1 5 5 4 6 2 4 1 3 8 4 6 2 1 9 8 9 8 equity 4 5 4 1 8 5 8 5 1 5 1 3 9 9 7 0 7 0 8 4 commodity 2 4 0 3 5 2 2 6 0 3 3 6 9 4 6 7 4 0 1 1 2 9 2 total derivative receivablese 5 0 5 0 1 3 5 3 1 4 6 3 4 1 7 6 1 3 1 4 9 8 9 7 7 3 8 3 total trading assets 1 9 3 9 8 7 1 5 1 2 7 5 7 6 6 9 6 7 1 3 1 4 9 8 9 4 5 8 7 2 2 availableforsale security mortgagebacke security u . s . government agenciesa 1 0 1 7 8 7 1 7 1 1 4 1 1 8 9 0 1 residential nonagency 1 5 8 9 2 8 4 5 8 9 3 3 commercial nonagency 4 9 3 2 2 4 0 5 1 7 2 total mortgagebacke securities 1 0 1 7 8 8 8 0 9 7 4 2 4 4 1 8 3 0 0 6 u . s . treasury government agenciesa 5 7 0 4 7 1 7 5 2 8 7 obligation u . s . state municipalities 2 7 1 1 2 9 4 2 5 7 1 1 5 7 8 certificate deposit 4 8 6 1 4 8 6 1 nonu . s . government debt securities 1 9 0 6 2 1 1 7 5 4 3 0 8 1 6 corporate debt securities 5 5 8 0 6 5 5 8 0 6 assetbacke security credit card receivables 5 4 0 1 5 4 0 1 collateralized loan obligations 1 1 8 1 5 1 3 3 1 5 2 5 1 other 9 2 1 6 2 6 9 9 4 8 5 equity securities 3 1 9 7 3 8 3 2 3 5 total availableforsale securities 1 2 4 6 4 4 1 8 4 1 7 9 1 5 9 0 3 3 2 4 7 2 6 loans 5 3 5 1 4 7 2 2 0 0 7 mortgage service rights 1 2 2 4 3 1 2 2 4 3 other asset private equity investmentsf 8 1 5 8 9 8 0 2 2 8 6 9 2 all other 5 1 0 0 1 8 2 4 4 4 9 9 7 3 1 total assets 5 1 8 1 7 7 1 1 2 4 7 1 1 8 4 2 3 total asset measure fair value recur basisg $ 3 2 3 8 1 2 $ 1 7 3 4 3 7 2 $ 1 0 9 0 5 6 $ 1 3 1 4 9 8 9 $ 8 5 2 2 5 1 deposits $ $ 3 9 2 5 $ 8 6 3 $ $ 4 7 8 8 federal fund purchase security loan sell repurchase agreements 6 5 8 8 6 5 8 8 other borrow funds 9 6 2 3 2 0 7 8 1 1 7 0 1 trade liability debt equity instrumentsd 6 6 3 7 4 1 8 2 9 4 1 9 7 8 4 8 6 5 derivative payable interest rate 9 8 3 9 5 9 8 0 4 2 7 8 4 9 4 6 2 6 5 1 7 3 0 6 credit 1 1 5 0 7 6 1 0 3 9 8 1 2 0 5 9 6 4 8 7 8 foreign exchange 1 5 3 7 1 4 6 5 7 8 5 1 6 0 1 3 4 2 6 0 1 9 0 1 5 equity 5 1 3 8 2 3 7 8 3 5 4 3 5 2 1 2 1 1 4 3 0 commodity 2 3 1 8 5 1 3 5 3 4 6 4 3 4 7 2 7 5 1 1 0 3 9 total derivative payablese 4 8 8 9 1 3 1 1 0 4 8 3 1 3 3 9 1 2 8 3 6 0 8 6 3 6 6 8 total trading liabilities 7 1 2 6 3 1 3 2 9 3 4 2 3 1 5 3 6 1 2 8 3 6 0 8 1 4 8 5 3 3 account payable liabilities 7 3 7 3 beneficial interest issue consolidated vies 4 8 1 4 3 0 9 1 1 longterm debt 2 4 9 8 2 1 3 5 3 4 3 8 5 1 6 total liability measure fair value recur basis $ 7 1 2 6 3 $ 1 3 7 4 9 4 1 $ 4 8 5 1 4 $ 1 2 8 3 6 0 8 $ 2 1 1 1 1 0 1 0 3 fair value hierarchy december 3 1 2 0 1 0 millionslevel 1 hlevel 2 h level 3 hnetting adjustmentstotal fair valuefederal fund sell security purchase resale agreements $ $ 2 0 2 9 9 $ $ $ 2 0 2 9 9 securitie borrowed 1 3 9 6 1 1 3 9 6 1 trade asset debt instrument mortgagebacke security u . s . government agenciesa 3 6 8 1 3 1 0 7 3 8 1 7 4 4 7 7 2 5 residential nonagency 2 8 0 7 6 8 7 3 4 9 4 commercial nonagency 1 0 9 3 2 0 6 9 3 1 6 2 total mortgagebacke securities 3 6 8 1 3 1 4 6 3 8 2 9 3 0 5 4 3 8 1 u . s . treasury government agenciesa 1 2 8 6 3 9 0 2 6 2 1 8 8 9 obligation u . s . state municipalities 1 1 7 1 5 2 2 5 7 1 3 9 7 2 certificate deposit banker acceptance commercial paper 3 2 4 8 3 2 4 8 nonu . s . government debt securities 3 1 1 2 7 3 8 4 8 2 2 0 2 6 9 8 1 1 corporate debt securities 4 2 2 8 0 4 9 4 6 4 7 2 2 6 loansb 2 1 7 3 6 1 3 1 4 4 3 4 8 8 0 assetbacke securities 2 7 4 3 8 4 6 0 1 1 2 0 3 total debt instruments 8 0 8 0 3 1 4 3 8 6 8 3 1 9 3 9 2 5 6 6 1 0 equity securities 1 2 4 4 0 0 3 1 5 3 1 6 8 5 1 2 9 2 3 8 physical commoditiesc 1 8 3 2 7 2 7 0 8 2 1 0 3 5 other 1 5 9 8 9 3 0 2 5 2 8 total debt equity instrumentsd 2 2 3 5 3 0 1 5 1 3 2 7 3 4 5 5 4 4 0 9 4 1 1 derivative receivables interest rate 2 2 7 8 1 1 2 0 2 8 2 5 4 2 2 1 0 9 5 4 2 7 3 2 5 5 5 credit 1 1 1 8 2 7 1 7 9 0 2 1 2 2 0 0 4 7 7 2 5 foreign exchange 1 1 2 1 1 6 3 1 1 4 4 2 3 6 1 4 2 6 1 3 2 5 8 5 8 equity 3 0 3 8 7 1 8 4 8 8 5 3 9 4 2 9 4 2 0 4 commodity 1 3 2 4 5 6 0 7 6 2 1 9 7 4 9 4 5 8 1 0 1 3 9 total derivative receivablese 4 7 5 3 1 4 9 0 0 1 7 3 4 6 4 2 1 4 4 8 9 3 1 8 0 4 8 1 total trading assets 2 2 8 2 8 3 1 6 4 1 3 4 4 6 9 1 9 6 1 4 4 8 9 3 1 4 8 9 8 9 2 availableforsale security mortgagebacke security u . s . government agenciesa 1 0 4 7 3 6 1 5 4 9 0 1 2 0 2 2 6 residential nonagency 1 4 8 9 6 9 5 4 8 9 7 5 commercial nonagency 5 4 0 3 2 5 1 5 6 5 4 total mortgagebacke securities 1 0 4 7 3 7 6 9 8 6 2 2 5 6 1 7 4 8 5 5 u . s . treasury government agenciesa 5 2 2 1 0 8 2 6 1 1 3 4 8 obligation u . s . state municipalities 3 1 1 1 2 7 2 2 5 6 1 1 5 5 9 certificate deposit 6 3 6 4 1 3 6 4 7 nonu . s . government debt securities 1 3 1 0 7 7 6 7 0 2 0 7 7 7 corporate debt securities 6 1 7 9 3 6 1 7 9 3 assetbacke security credit card receivables 7 6 0 8 7 6 0 8 collateralized loan obligations 1 2 8 1 3 4 7 0 1 3 5 9 8 other 8 7 7 7 3 0 5 9 0 8 2 equity securities 1 9 9 8 5 3 2 0 5 1 total availableforsale securities 1 2 0 4 0 1 1 8 1 6 3 0 1 4 2 8 7 3 1 6 3 1 8 loans 5 1 0 1 4 6 6 1 9 7 6 mortgage service rights 1 3 6 4 9 1 3 6 4 9 other asset private equity investmentsf 4 9 8 2 6 7 8 6 2 8 7 3 7 all other 5 0 9 3 1 9 2 4 1 7 9 9 4 6 4 total assets 5 1 4 2 1 0 1 8 1 2 0 4 1 1 8 2 0 1 total asset measure fair value recur basisg $ 3 5 3 8 2 6 $ 1 8 5 8 7 6 2 $ 1 1 0 6 3 9 $ 1 4 4 8 9 3 1 $ 8 7 4 2 9 6 deposits $ $ 3 5 9 6 $ 7 7 3 $ $ 4 3 6 9 federal fund purchase security loan sell repurchase agreements 4 0 6 0 4 0 6 0 other borrow funds 8 5 4 7 1 3 8 4 9 9 3 1 trade liability debt equity instrumentsd 5 8 4 6 8 1 8 4 2 5 5 4 7 6 9 4 7 derivative payable interest rate 2 6 2 5 1 0 8 5 2 3 3 2 5 8 6 1 0 7 0 0 5 7 2 0 3 8 7 credit 1 1 2 5 4 5 1 2 5 1 6 1 1 9 9 2 3 5 1 3 8 foreign exchange 9 7 2 1 5 8 9 0 8 4 8 5 0 1 3 9 7 1 5 2 5 0 1 5 equity 2 2 3 9 0 4 6 7 3 3 1 3 5 9 4 9 1 0 4 5 0 commodity 8 6 2 5 4 6 1 1 3 0 0 2 5 0 2 4 6 8 2 2 9 total derivative payablese 4 4 8 1 1 4 5 0 3 4 3 3 0 2 8 5 1 4 1 5 8 9 0 6 9 2 1 9 total trading liabilities 6 2 9 4 9 1 4 6 8 7 6 8 3 0 3 3 9 1 4 1 5 8 9 0 1 4 6 1 6 6 account payable liabilities 2 3 6 2 3 6 beneficial interest issue consolidated vies 6 2 2 8 7 3 1 4 9 5 longterm debt 2 5 7 9 5 1 3 0 4 4 3 8 8 3 9 total liability measure fair value recur basis $ 6 2 9 4 9 $ 1 5 1 1 3 8 8 $ 4 6 6 4 9 $ 1 4 1 5 8 9 0 $ 2 0 5 0 9 6 aat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include total u . s . governmentsponsore enterprise obligation $ 1 2 4 . 0 billion $ 1 3 7 . 3 billion respectively predominantly mortgagerelate . 1 0 4 bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include trading loan $ 2 0 . 1 billion $ 2 2 . 7 billion respectively residential firstlien mortgage $ 2 . 4 billion $ 2 . 6 billion respectively commercial firstlien mortgage . residential mortgage loan include conform mortgage loan originate intent sell u . s . government agency $ 1 1 . 9 billion $ 1 3 . 1 billion respectively reverse mortgage $ 3 . 9 billion $ 4 . 0 billion respectively . cphysical commodity inventory generally account low cost fair value . dbalance reflect reduction security long position security sell purchase short position long short position identical committee uniform security identification procedure number cusips . eas permit u . s . gaap firm elect net derivative receivables derivative payable related cash collateral receive pay legally enforceable master netting agreement exist . purpose table firm reduce derivative receivables derivative payable balance net adjustment level fair value hierarchy netting relevant presentation base transparency input valuation asset liability . balance report fair value hierarchy table gross counterparty netting adjustment . firm net balance level 3 reduction level 3 derivative receivable payable balance $ 1 3 . 5 billion $ 1 2 . 7 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively exclusive netting benefit associate cash collateral reduce level 3 balances . fprivate equity instrument represent investment corporateprivate equity line business . cost basis private equity investment portfolio total $ 9 . 6 billion $ 1 0 . 0 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . gat june 3 0 2 0 1 1 december 3 1 2 0 1 0 balance include investment value net asset value $ 1 2 . 2 billion $ 1 2 . 1 billion respectively $ 6 . 0 billion $ 5 . 9 billion respectively classify level 1 $ 1 . 7 billion $ 2 . 0 billion respectively level 2 $ 4 . 5 billion $ 4 . 2 billion respectively level 3 . hfor month end june 3 0 2 0 1 1 2 0 1 0 transfer level 1 2 3 significant . change level 3 recur fair value measurement following table include rollforward balance sheet include change fair value financial instrument classify firm level 3 fair value hierarchy month end june 3 0 2 0 1 1 and 2 0 1 0 . determination classify financial instrument level 3 determination base significance unobservable parameter overall fair value measurement . level 3 financial instrument typically include addition unobservable level 3 component observable component component actively quote validate external source accordingly gain loss table include change fair value observable factor valuation methodology . firm riskmanage observable component level 3 financial instrument use security derivative position classify level 1 2 fair value hierarchy level 1 level 2 risk management instrument include gain loss following table reflect effect firm risk management activity relate level 3 instruments . 1 0 5 fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 1 fair value april 1 2 0 1 1 total realizedunrealizedgainslosse transfer andorout level 3 gfair value atjune 3 0 2 0 1 1 change unrealizedgainslosse relate financial instrument heldat june 3 0 2 0 1 1 millionspurchasesfsalesissuancessettlementsasset trading asset debt instrument mortgagebacke security u . s . government agencies $ 1 9 1 $ 1 2 $ 7 $ 1 8 $ $ 2 7 $ $ 1 6 5 $ 1 1 residential nonagency 7 8 2 5 6 2 4 6 1 0 3 5 7 6 1 8 6 3 1 0 commercial nonagency 1 8 8 5 3 1 2 1 9 2 6 2 3 0 1 8 4 3 2 1 total mortgagebacke securities 2 8 5 8 9 9 4 7 2 3 8 3 1 1 4 6 1 2 8 7 1 2 0 obligation u . s . state municipalities 1 9 7 1 1 4 2 7 2 4 1 4 1 2 1 8 5 5 1 8 nonu . s . government debt securities 1 1 3 1 1 1 3 1 1 1 3 4 8 2 1 corporate debt securities 5 6 2 3 2 3 1 8 0 0 1 8 2 0 1 1 1 9 1 5 6 0 6 3 9 loans 1 2 4 9 0 1 9 0 1 7 2 6 1 7 5 3 4 2 4 4 8 7 1 1 7 4 2 1 4 5 assetbacke securities 8 8 8 3 2 2 8 8 5 5 1 4 0 4 2 4 3 8 3 1 9 6 7 total debt instruments 3 1 9 3 8 5 5 5 5 2 3 8 5 8 8 5 9 2 6 4 4 5 3 0 4 7 5 2 9 0 equity securities 1 3 6 7 1 7 0 6 1 1 2 5 4 6 1 9 1 4 0 8 1 5 8 other 9 4 3 4 1 4 1 1 3 4 9 0 8 5 total debt equity instruments 3 4 2 4 8 7 2 1 b 5 3 1 3 6 0 2 1 1 0 0 6 4 6 4 3 2 7 9 1 4 4 3 b net derivative receivables interest rate 2 4 7 0 1 4 0 7 2 1 7 3 6 9 8 8 4 7 3 1 1 7 7 2 0 credit 4 3 7 3 3 0 1 1 3 6 5 4 4 7 3 3 6 2 2 foreign exchange 2 5 4 3 9 1 3 2 0 6 3 5 3 6 5 6 3 equity 2 8 4 3 1 5 7 1 4 0 2 4 2 1 1 0 9 3 2 0 3 1 3 commodity 8 6 5 3 0 6 4 9 3 0 1 1 7 5 1 2 7 4 3 5 3 total net derivative receivables 3 1 3 7 7 0 2 b 4 9 8 3 1 4 1 1 7 0 1 6 2 8 3 7 4 1 3 b availableforsale security assetbacke securities 1 5 0 1 6 1 0 3 8 5 1 2 2 5 4 6 1 5 4 0 2 1 0 3 other 5 0 9 8 5 0 1 2 total availableforsale securities 1 5 5 2 5 9 5 c 8 5 1 2 2 5 4 6 1 5 9 0 3 1 0 5 c loans 1 3 7 1 1 4 0 b 4 1 8 0 1 4 7 2 1 2 6 b mortgage servicing rights 1 3 0 9 3 9 6 0 d 5 9 1 4 8 1 1 2 2 4 3 9 6 0 d asset private equity investments 8 8 5 3 7 7 7 b 4 6 9 1 9 0 6 1 7 1 8 0 2 2 3 8 0 b other 4 5 6 0 2 9 e 3 0 0 3 5 2 3 0 4 4 4 9 2 9 e fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 1 fair value april 1 2 0 1 1 total realizedunrealizedgainslosse transfer andorout level 3 gfair value atjune 3 0 2 0 1 1 change unrealizedgainslosse relate financial instrument heldat june 3 0 2 0 1 1 millionspurchasesfsalesissuancessettlementsliabilitiesa deposits $ 7 5 4 $ 3 b $ $ $ 1 5 7 $ 5 1 $ $ 8 6 3 $ 4 b borrow funds 1 8 4 4 5 b 3 2 6 9 7 2 0 7 8 5 b trading liability debt equity instruments 1 7 3 5 b 1 3 3 1 5 8 4 1 9 7 1 b account payable liabilities 1 4 6 2 6 e 4 7 7 3 1 e beneficial interest issue consolidated vies 5 8 8 3 1 b 1 0 3 2 9 2 4 3 0 6 b longterm debt 1 3 0 2 7 3 9 5 b 6 0 3 4 9 1 1 3 5 3 4 3 3 2 b 1 0 6 fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 0 fair value april 1 2 0 1 0 total realize unrealized gainslossespurchase issuance settlement nettransfer andorout level 3 gfair value june 3 0 2 0 1 0 change unrealized gainslosse relate financial instrument hold june 3 0 2 0 1 0 millionsasset trading asset debt instrument mortgagebacke security u . s . government agencies $ 2 1 5 $ 1 9 $ 5 5 $ 3 $ 1 7 6 $ residential nonagency 8 4 1 6 1 3 6 6 2 8 0 4 5 6 commercial nonagency 1 6 7 3 8 0 1 1 3 1 7 3 9 6 6 total mortgagebacke securities 2 7 2 9 1 6 0 1 0 2 6 8 2 7 1 9 1 2 2 obligation u . s . state municipalities 1 9 7 5 1 5 1 8 2 0 0 8 1 nonu . s . government debt securities 1 1 8 1 8 1 4 1 1 4 1 8 corporate debt securities 4 9 4 7 5 3 1 7 7 1 6 6 4 5 5 1 3 4 loans 1 5 7 7 6 4 1 9 4 3 1 5 1 4 8 8 9 4 9 assetbacke securities 8 6 7 3 2 1 0 2 3 4 6 0 8 6 3 7 2 0 2 total debt instruments 3 4 2 1 8 6 5 9 5 6 2 7 9 3 2 9 1 8 8 2 equity securities 1 7 1 6 1 0 1 1 4 1 8 2 2 1 5 4 other 1 0 0 1 3 0 5 1 9 2 0 2 0 total debt equity instruments 3 6 9 3 5 6 b 1 0 0 6 2 7 5 3 5 6 6 0 5 2 b net derivative receivables interest rate 2 4 6 4 1 0 2 1 5 3 4 9 6 3 0 4 7 9 1 1 credit 9 1 8 6 2 0 0 3 1 4 1 0 7 9 7 8 6 2 3 4 9 foreign exchange 3 2 9 5 1 3 2 3 6 1 5 1 4 5 2 equity 1 8 6 7 2 8 4 6 4 7 2 2 1 5 9 1 2 3 commodity 2 8 1 2 4 1 7 0 3 5 4 1 7 2 8 8 total net derivative receivables 9 8 3 1 1 9 8 6 b 1 5 7 4 6 5 1 0 3 0 8 2 3 9 7 b availableforsale security assetbacke securities 1 2 5 7 1 3 9 1 9 8 1 2 3 3 4 5 1 other 3 6 3 1 0 6 7 1 0 4 4 1 0 2 total availableforsale securities 1 2 9 3 4 2 9 c 2 6 5 1 0 4 1 2 7 4 4 5 3 c loans 1 1 4 0 1 2 b 7 9 1 6 1 0 6 5 3 2 b mortgage servicing rights 1 5 5 3 1 3 5 8 4 d 9 4 1 1 8 5 3 3 5 8 4 d asset private equity investments 6 3 8 5 1 2 b 9 9 2 1 1 9 7 2 4 6 1 9 b other 4 3 5 2 4 0 e 8 0 8 4 4 3 0 8 2 0 e fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 0 fair value april 1 2 0 1 0 total realize unrealized gainslossespurchase issuance settlement nettransfer andorout level 3 gfair value june 3 0 2 0 1 0 change unrealized gainslosse relate financial instrument hold june 3 0 2 0 1 0 millionsliabilitiesa deposits $ 4 4 0 $ 1 5 b $ 9 5 $ 3 3 4 $ 8 8 4 $ 1 0 b borrow funds 4 5 2 4 8 b 1 0 3 1 0 2 9 1 3 7 b trading liability debt equity instruments 3 2 2 b 3 0 4 b account payable liabilities 3 2 8 1 7 b 1 3 8 4 4 9 5 b beneficial interest issue consolidated vies 1 8 1 7 2 6 b 3 9 9 1 3 9 2 6 8 b longterm debt 1 7 5 1 8 6 3 2 b 1 2 1 9 9 5 1 5 7 6 2 3 6 5 b 1 0 7 fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 1 fair value january 1 2 0 1 1 total realizedunrealizedgainslosse transfer andorout level 3 gfair value atjune 3 0 2 0 1 1 change unrealizedgainslosse relate financial instrument hold june 3 0 2 0 1 1 millionspurchasesfsalesissuancessettlementsasset trading asset debt instrument mortgagebacke security u . s . government agencies $ 1 7 4 $ 2 9 $ 2 8 $ 3 9 $ $ 2 7 $ $ 1 6 5 $ 1 2 residential nonagency 6 8 7 1 2 7 5 0 5 2 7 1 1 2 4 6 1 8 6 3 3 9 commercial nonagency 2 0 6 9 4 7 5 6 5 7 4 4 9 4 1 8 4 3 6 total mortgagebacke securities 2 9 3 0 2 0 3 1 0 9 8 1 0 5 4 2 4 5 6 1 2 8 7 1 3 3 obligation u . s . state municipalities 2 2 5 7 5 5 6 9 6 9 1 1 2 1 8 5 5 8 nonu . s . government debt securities 2 0 2 4 2 4 3 2 5 4 3 9 7 4 8 2 6 corporate debt securities 4 9 4 6 5 5 3 4 2 9 2 8 9 5 1 1 7 1 8 8 5 6 0 6 5 8 loans 1 3 1 4 4 3 2 1 2 6 1 4 2 7 7 7 1 1 5 3 4 0 7 1 1 7 4 2 7 9 assetbacked securities 8 4 6 0 6 2 8 1 9 7 3 2 4 6 1 3 0 0 1 9 8 3 1 9 3 4 7 total debt instruments 3 1 9 3 9 1 2 1 1 9 9 1 3 1 0 4 1 0 1 8 5 5 3 2 3 3 0 4 7 5 5 1 5 equity securities 1 6 8 5 2 4 0 9 8 1 9 9 3 7 6 4 0 1 4 0 8 3 8 0 other 9 3 0 3 1 1 9 1 2 6 0 9 0 8 3 6 total debt equity instruments 3 4 5 5 4 1 4 8 2 b 1 0 0 3 0 1 0 6 2 1 2 2 9 1 3 6 3 3 2 7 9 1 9 3 1 b net derivative receivables interest rate 2 8 3 6 1 9 2 6 3 4 5 1 1 9 1 9 0 3 3 2 3 1 1 7 7 2 9 credit 5 3 8 6 5 5 2 2 3 8 1 1 9 4 7 3 3 3 6 7 foreign exchange 6 1 4 4 8 2 1 1 6 3 4 6 2 1 5 5 3 6 5 3 0 equity 2 4 4 6 2 2 2 3 5 5 7 2 5 3 9 9 7 3 2 0 3 4 9 commodity 8 0 5 2 8 9 1 3 5 9 7 5 4 1 2 5 5 1 2 7 4 8 0 total net derivative receivables 4 3 5 7 1 2 0 3 b 8 3 3 7 9 4 2 6 0 2 1 6 0 2 8 3 7 1 9 9 b availableforsale security assetbacke securities 1 3 7 7 5 5 8 1 1 9 6 0 2 6 8 8 8 1 5 4 0 2 5 7 9 other 5 1 2 1 3 9 5 0 1 9 total availableforsale securities 1 4 2 8 7 5 8 2 c 1 9 6 0 2 9 8 9 7 1 5 9 0 3 5 8 8 c loans 1 4 6 6 2 6 0 b 1 2 5 3 6 3 1 6 1 4 7 2 2 3 4 b mortgage servicing rights 1 3 6 4 9 1 7 1 1 d 1 3 4 9 1 0 4 4 1 2 2 4 3 1 7 1 1 d asset private equity investments 7 8 6 2 1 6 8 2 b 7 9 7 2 0 4 5 2 7 4 8 0 2 2 7 2 2 b other 4 1 7 9 3 1 e 7 0 9 3 4 3 8 2 9 4 4 4 9 3 1 e fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 1 fair value january 1 2 0 1 1 total realizedunrealizedgainslosse transfer andorout level 3 gfair value atjune 3 0 2 0 1 1 change unrealizedgainslosse relate financial instrument hold june 3 0 2 0 1 1 millionspurchasesfsalesissuancessettlementsliabilitiesa deposits $ 7 7 3 $ 8 b $ $ $ 2 1 6 $ 1 1 7 $ 1 $ 8 6 3 $ b borrow funds 1 3 8 4 2 6 b 9 0 3 1 8 5 2 2 0 7 8 4 b trading liability debt equity instruments 5 4 5 b 1 3 3 2 7 7 4 1 9 7 1 b account payable liabilities 2 3 6 6 3 e 1 0 0 7 3 3 e beneficial interest issue consolidated vies 8 7 3 2 5 b 1 1 4 5 8 2 4 3 0 3 4 b longterm debt 1 3 0 4 4 4 5 7 b 1 2 5 6 1 4 6 2 2 3 9 1 3 5 3 4 2 3 8 b 1 0 8 fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 0 fair value january 1 2 0 1 0 total realize unrealized gainslossespurchase issuance settlement nettransfer andorout level 3 gfair value june 3 0 2 0 1 0 change unrealizedgainslosse relate financial instrument hold june 3 0 2 0 1 0 millionsasset trading asset debt instrument mortgagebacke security u . s . government agencies $ 2 6 0 $ 2 4 $ 1 0 5 $ 3 $ 1 7 6 $ 1 0 residential nonagency 1 1 1 5 7 7 3 4 0 4 8 8 0 4 4 4 commercial nonagency 1 7 7 0 1 1 6 1 4 4 3 1 7 3 9 3 0 total mortgagebacke securities 3 1 4 5 2 1 7 5 8 9 5 4 2 7 1 9 6 4 obligation u . s . state municipalities 1 9 7 1 2 7 7 8 1 4 2 2 0 0 8 4 2 nonu . s . government debt securities 8 9 2 2 4 7 1 1 4 5 1 corporate debt securities 5 2 4 1 3 3 1 4 6 7 1 0 8 4 5 5 1 5 loans 1 3 2 1 8 2 9 0 2 0 4 3 8 2 1 4 8 8 9 3 5 8 assetbacke securities 8 6 2 0 1 5 7 1 5 8 1 6 8 6 3 7 3 0 2 total debt instruments 3 2 2 8 4 6 1 0 1 1 1 4 1 3 0 3 2 9 1 8 5 9 2 equity securities 1 9 5 6 8 1 2 3 1 1 6 1 8 2 2 2 1 3 other 1 4 4 1 5 6 6 5 5 7 8 9 2 0 5 1 total debt equity instruments 3 5 6 8 1 4 7 3 b 2 2 8 2 2 4 3 5 6 6 0 3 2 8 b net derivative receivables interest rate 2 0 4 0 1 4 4 1 5 7 5 1 4 1 3 0 4 7 6 7 1 credit 1 0 3 5 0 1 3 9 9 1 9 6 1 2 9 7 8 6 1 6 6 9 foreign exchange 1 0 8 2 8 9 3 1 5 6 2 9 4 5 1 8 6 1 equity 2 3 0 6 8 6 4 2 2 9 2 1 5 9 6 0 commodity 3 2 9 6 5 2 4 7 2 9 2 4 1 7 2 6 7 total net derivative receivables 1 0 8 3 7 1 2 0 9 b 1 9 0 4 1 6 6 1 0 3 0 8 1 2 7 2 b availableforsale security assetbacke securities 1 2 7 3 2 1 0 5 2 9 3 1 2 3 3 4 9 6 other 4 6 1 6 7 8 9 1 0 5 4 1 0 9 5 total availableforsale securities 1 3 1 9 3 1 7 2 c 3 8 2 1 0 5 1 2 7 4 4 1 9 1 c loans 9 9 0 1 1 b 7 8 8 1 0 6 5 4 8 b mortgage servicing rights 1 5 5 3 1 3 6 8 0 d 2 1 1 8 5 3 3 6 8 0 d asset private equity investments 6 5 6 3 1 3 6 b 9 3 1 3 8 4 7 2 4 6 1 1 b other 9 5 2 1 5 8 e 5 0 6 0 9 5 4 3 0 8 1 1 1 e fair value measurement use significant unobservable input month endedjune 3 0 2 0 1 0 fair value january 1 2 0 1 0 total realize unrealized gainslossespurchase issuance settlement nettransfer andorout level 3 gfair value june 3 0 2 0 1 0 change unrealized gainslosse relate financial instrument hold june 3 0 2 0 1 0 millionsliabilitiesa deposits $ 4 7 6 $ 5 b $ 9 4 $ 3 0 9 $ 8 8 4 $ 3 2 b borrow funds 5 4 2 1 0 0 b 9 2 2 4 3 2 9 1 1 1 0 b trading liability debt equity instruments 1 0 4 b 3 3 2 3 4 1 b account payable liabilities 3 5 5 4 0 b 1 3 4 4 4 9 1 3 b beneficial interest issue consolidated vies 6 2 5 3 3 b 8 0 0 1 3 9 2 1 0 5 b longterm debt 1 8 2 8 7 1 0 3 5 b 1 8 8 7 3 9 7 1 5 7 6 2 5 1 3 b alevel 3 liability percentage total firm liability account fair value include liability measure fair value nonrecurring basis 2 3 % 2 3 % june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . bpredominantly report principal transaction revenue change fair value retail financial service rfs mortgage loan originate intent sell report mortgage fee relate income . crealized gainslosse availableforsale afs security otherthantemporary impairment loss record earning report security gain . unrealized gain loss report comprehensive income oci . realize gain loss foreign exchange remeasurement adjustment record income afs security $ 1 0 3 million $ 1 3 million month end june 3 0 2 0 1 1 1 0 9 and 2 0 1 0 $ 4 3 4 million $ 6 5 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . unrealized gain loss report afs security oci $ 8 million $ 4 2 million month end june 3 0 2 0 1 1 2 0 1 0 $ 1 4 8 million $ 1 0 7 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . dchange fair value rfs mortgage servicing right report mortgage fee relate income . elargely report income . floan origination include purchases . gall transfer andor level 3 assume occur beginning report period . asset liability measure fair value nonrecurring basiscertain asset liability unfunde lendingrelated commitment measure fair value nonrecurring basis measure fair value ongoing basis subject fair value adjustment certain circumstance example evidence impairment . follow table present asset liability carry consolidated balance sheet caption level valuation hierarchy june 3 0 2 0 1 1 december 3 1 2 0 1 0 nonrecurre change fair value record reporting period . fair value hierarchy june 3 0 2 0 1 1 million level 1 d level 2 d level 3 d total fair valueloan retaineda $ $ 2 6 3 4 $ 2 3 1 $ 2 8 6 5 loans heldforsale 4 8 0 2 0 3 6 8 3 total loans 3 1 1 4 4 3 4 3 5 4 8 other real estate owned 6 1 2 8 1 3 4 2 other assets 7 7 total assets 6 1 2 8 8 3 4 9 total asset fair value nonrecurring basis $ $ 3 1 7 5 $ 7 2 2 $ 3 8 9 7 account payable liabilitiesb $ $ 1 1 $ 1 4 $ 2 5 total liability fair value nonrecurring basis $ $ 1 1 $ 1 4 $ 2 5 fair value hierarchy december 3 1 2 0 1 0 million level 1 d level 2 d level 3 d total fair valueloan retaineda $ $ 5 4 8 4 $ 5 1 3 e $ 5 9 9 7 loans heldforsalec 3 1 2 3 2 0 0 3 5 1 2 total loans 5 7 9 6 3 7 1 3 9 5 0 9 other real estate owned 7 8 3 1 1 3 8 9 other assets 2 2 total assets 7 8 3 1 3 3 9 1 total asset fair value nonrecurring basis $ $ 5 8 7 4 $ 4 0 2 6 $ 9 9 0 0 account payable liabilitiesb $ $ 5 3 $ 1 8 $ 7 1 total liability fair value nonrecurring basis $ $ 5 3 $ 1 8 $ 7 1 areflects mortgage home equity loan carry value base fair value underlie collateral . brepresent june 3 0 2 0 1 1 december 3 1 2 0 1 0 fair value adjustment associate $ 5 2 9 million $ 5 1 7 million respectively unfunded heldforsale lendingrelated commitment leveraged lending portfolio . cpredominantly include credit card loan december 3 1 2 0 1 0 . loan heldforsale carry consolidated balance sheet low cost fair value . dfor month end june 3 0 2 0 1 1 2 0 1 0 transfer level 1 2 3 significant . ethe prior period revise conform current presentation . the method use estimate fair value impair collateraldependent loan loan carry value base fair value underlie collateral e . g . residential mortgage loan charge accordance regulatory guidance depend type collateral e . g . security real estate nonfinancial asset underlie loan . fair value collateral typically estimate base quote market price broker quote independent appraisal . information note 1 4 page 1 4 9 1 5 0 form 1 0 q . nonrecurring fair value change follow table present total change value asset liability fair value adjustment include consolidated statement income sixmonth period end june 3 0 2 0 1 1 2 0 1 0 relate financial instrument hold date . 1 1 0 month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 loan retained $ 7 0 9 $ 1 1 0 9 a $ 1 2 7 2 $ 2 1 4 2 a loan heldforsale 1 3 3 3 8 6 5 total loans 6 9 6 1 1 1 2 1 2 3 4 2 0 7 7 assets 4 8 1 1 4 7 2 9 account payable liabilities 4 1 5 total nonrecurre fair value gainslosses $ 7 4 8 $ 1 1 0 1 $ 1 2 8 0 $ 2 0 4 3 prior period revise conform current presentation . level 3 analysislevel 3 asset june 3 0 2 0 1 1 predominantly include derivative receivables mortgage servicing right msrs collateralized loan obligation clos hold afs security portfolio loan assetbacke security trading portfolio private equity investment . derivative receivable include $ 3 4 . 2 billion interest rate credit foreign exchange equity commodity contract classify level 3 june 3 0 2 0 1 1 . credit derivative receivable $ 1 5 . 1 billion include $ 9 . 9 billion structured credit derivative corporate debt underlie $ 3 . 3 billion credit default swap commercial mortgage risk partially mitigate similar offset derivative payable . interest rate derivative receivables $ 5 . 9 billion include longdate structured interest rate derivative dependent correlation . equity derivative receivable $ 5 . 2 billion principally include longdate contract volatility level unobservable . foreign exchange derivative receivable $ 4 . 6 billion include longdate foreign exchange derivative dependent correlation foreign exchange interest rates . mortgage servicing right represent fair value future cash flow perform specified mortgage servicing activity predominantly respect residential mortgage loan . description msr asset interest rate risk management valuation methodology use msrs include valuation assumption sensitivity note 1 7 page 2 6 0 2 6 3 jpmorgan chase 2 0 1 0 annual report note 1 6 page 1 5 9 1 6 3 form 1 0 q . clos total $ 1 5 . 1 billion security corporate loan hold afs security portfolio . substantially security rate aaa aa average credit enhancement 3 0 % . credit enhancement clos primarily form subordination form structural credit enhancement realize loss associate asset hold issuing vehicle allocate tranche security issue vehicle consider relative seniority . discussion note 1 1 page 1 2 8 1 3 2 form 1 0 q . trading loan total $ 1 1 . 7 billion include $ 5 . 7 billion residential mortgage loan commercial mortgage loan limited price transparency $ 3 . 9 billion reverse mortgage principal risk sensitivity mortality risk home price . fair value commercial residential mortgage loan estimate project expect cash flow consider relevant borrowerspecific market factor discount cash flow rate reflect current market liquidity . loan partially hedge level 2 instrument include credit default swap interest rate derivative valuation input observable liquid . consolidated balance sheet changeslevel 3 asset include asset measure fair value nonrecurring basis 5 % total firm asset june 3 0 2 0 1 1 . follow describe significant change level 3 asset december 3 1 2 0 1 0 . for month end june 3 0 2 0 1 1 level 3 asset $ 1 0 9 . 8 billion june 3 0 2 0 1 1 reflect decrease $ 6 . 3 billion quarter largely relate a $ 4 . 4 billion decrease nonrecurre loan heldforsale drive sale loan portfoliosfor month end june 3 0 2 0 1 1 level 3 asset decrease $ 4 . 9 billion month 2 0 1 1 following $ 3 . 0 billion net decrease nonrecurre loan heldforsale drive sale loan portfolio $ 1 . 4 billion decrease trading loan primarily asset sales $ 1 . 4 billion decrease msrs . discussion change refer note 1 6 page 1 5 9 1 6 3 form 1 0 q . $ 1 . 6 billion increase assetbacked afs security predominantly drive purchase new issuance clos 1 1 1 gain lossesinclude table month end june 3 0 2 0 1 1 $ 9 6 0 million loss msrs . discussion change refer note 1 6 page 1 5 9 1 6 3 form 1 0 q . include table month end june 3 0 2 0 1 0 $ 2 . 0 billion net gain derivative largely drive widening credit spread $ 6 3 2 million gain relate longterm structured note liability largely drive volatility equity market $ 3 . 6 billion loss msrs predominantly decline interest ratesinclude table month end june 3 0 2 0 1 1 $ 1 . 7 billion gain private equity predominately drive net increase investment valuation sale portfolio . $ 1 . 2 billion net gain derivative largely drive increase interest rate derivatives $ 1 . 7 billion loss msrs . discussion change refer note 1 6 page 1 5 9 1 6 3 form 1 0 qincluded table month end june 3 0 2 0 1 0 $ 3 . 7 billion loss msrs predominantly decline interest rates $ 1 . 2 billion gain net derivative receivables $ 1 . 0 billion gain relate longterm structured note liability primarily volatility equity markets . credit adjustment determine fair value instrument necessary record valuation adjustment arrive exit price u . s . gaap . valuation adjustment include limit reflect counterparty credit quality firm creditworthiness . market view firm credit quality reflect credit spread observe credit default swap market . detailed discussion valuation adjustment firm consider note 3 page 1 7 0 1 8 7 jpmorgan chase 2 0 1 0 annual report . the follow table provide credit adjustment exclude effect hedging activity reflect consolidated balance sheet date indicate . millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 derivative receivables balance net derivative cva $ 7 7 3 8 3 $ 8 0 4 8 1 derivative cvaa 4 0 7 5 4 3 6 2 derivative payable balance net derivative dva 6 3 6 6 8 6 9 2 1 9 derivative dva 8 3 6 8 8 2 structure note balance net structured note dvabc 5 5 0 0 5 5 3 1 3 9 structure note dva 1 3 1 8 1 1 5 3 aderivative credit valuation adjustment cva gross hedge include result manage credit portfolio line business investment bank ib . bstructure note record longterm debt borrow fund deposit consolidated balance sheet base tenor legal form note . cstructure note measure fair value base firm election fair value option . information election note 4 page 1 1 4 1 1 6 form 1 0 q . the follow table provide impact credit adjustment earning respective period exclude effect hedging activity . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 credit adjustment derivative cvaa $ 2 4 8 $ 1 0 7 0 $ 2 8 7 $ 9 1 4 derivative dva 2 3 3 9 7 4 6 2 9 1 structured note dvab 1 4 2 5 8 8 1 6 5 6 9 6 aderivatives cva gross hedge include result manage credit portfolio line business ib . bstructure note measure fair value base firm election fair value option . information election note 4 page 1 1 4 1 1 6 form 1 0 q . 1 1 2 additional disclosure fair value financial instrument include financial instrument carry fair valuethe follow table present carry value estimate fair value financial asset liability . additional information regard financial instrument scope disclosure method significant assumption use estimate fair value note 3 page 1 7 0 1 8 7 jpmorgan chase 2 0 1 0 annual report . the follow table present carry value estimate fair value financial asset liability . june 3 0 2 0 1 1 december 3 1 2 0 1 0 billionscarryingvalueestimatedfair valueappreciationdepreciation carryingvalueestimatedfair valueappreciationdepreciationfinancial asset asset fair value approximate carry value $ 2 0 0 . 3 $ 2 0 0 . 3 $ $ 4 9 . 2 $ 4 9 . 2 $ accrued interest account receivable 8 0 . 3 8 0 . 3 7 0 . 1 7 0 . 1 federal fund sell security purchase resale agreement include $ 2 1 . 3 $ 2 0 . 3 fair value 2 1 3 . 4 2 1 3 . 4 2 2 2 . 6 2 2 2 . 6 securitie borrow include $ 1 4 . 8 $ 1 4 . 0 fair value 1 2 1 . 5 1 2 1 . 5 1 2 3 . 6 1 2 3 . 6 trading assets 4 5 8 . 7 4 5 8 . 7 4 8 9 . 9 4 8 9 . 9 securitie include $ 3 2 4 . 7 $ 3 1 6 . 3 fair value 3 2 4 . 7 3 2 4 . 7 3 1 6 . 3 3 1 6 . 3 loan include $ 2 . 0 $ 2 . 0 fair valuea 6 6 1 . 2 6 6 1 . 3 0 . 1 6 6 0 . 7 6 6 3 . 5 2 . 8 mortgage servicing right fair value 1 2 . 2 1 2 . 2 1 3 . 6 1 3 . 6 other include $ 1 8 . 4 $ 1 8 . 2 fair value 6 9 . 1 6 9 . 4 0 . 3 6 4 . 9 6 5 . 0 0 . 1 total financial assets $ 2 1 4 1 . 4 $ 2 1 4 1 . 8 $ 0 . 4 $ 2 0 1 0 . 9 $ 2 0 1 3 . 8 $ 2 . 9 financial liability deposit include $ 4 . 8 $ 4 . 4 fair value $ 1 0 4 8 . 7 $ 1 0 4 9 . 5 $ 0 . 8 $ 9 3 0 . 4 $ 9 3 1 . 5 $ 1 . 1 federal fund purchase security loan sell repurchase agreement include $ 6 . 6 $ 4 . 1 fair value 2 5 4 . 1 2 5 4 . 1 2 7 6 . 6 2 7 6 . 6 commercial paper 5 1 . 2 5 1 . 2 3 5 . 4 3 5 . 4 other borrow fund include $ 1 1 . 7 $ 9 . 9 fair valueb 3 0 . 2 3 0 . 2 3 4 . 3 3 4 . 3 trading liabilities 1 4 8 . 5 1 4 8 . 5 1 4 6 . 2 1 4 6 . 2 accounts payable liability include $ 0 . 1 $ 0 . 2 fair value 1 5 1 . 6 1 5 1 . 5 0 . 1 1 3 8 . 2 1 3 8 . 2 beneficial interest issue consolidated vie include $ 0 . 9 $ 1 . 5 fair value 6 7 . 5 6 7 . 9 0 . 4 7 7 . 6 7 7 . 9 0 . 3 longterm debt junior subordinate deferrable interest debenture include $ 3 8 . 5 $ 3 8 . 8 fair valueb 2 7 9 . 2 2 8 0 . 7 1 . 5 2 7 0 . 7 2 7 1 . 9 1 . 2 total financial liabilities $ 2 0 3 1 . 0 $ 2 0 3 3 . 6 $ 2 . 6 $ 1 9 0 9 . 4 $ 1 9 1 2 . 0 $ 2 . 6 net depreciationappreciation $ 2 . 2 $ 0 . 3 afair value typically estimate use discount cash flow model incorporate characteristic underlie loan include principal contractual interest rate contractual fee key input include expect lifetime credit loss interest rate prepayment rate primary origination secondary market spread . certain loan fair value measure base value underlying collateral . difference estimate fair value carry value financial asset liability result different methodology use determine fair value compare carry value . example credit loss estimate financial asset remain life fair value calculation estimate loss emergence period loan loss reserve calculation future loan income interest fee incorporate fair value calculation generally consider loan loss reserve calculation . discussion firm methodology estimate fair value loan lendingrelated commitment note 3 page 1 7 1 1 7 3 jpmorgan chase 2 0 1 0 annual report . beffective january 1 2 0 1 1 $ 2 3 . 0 billion longterm advance federal home loan bank fhlb reclassify borrow fund longterm debt . prioryear period revise conform current presentation . 1 1 3 the majority firm lendingrelate commitment carry fair value recur basis consolidated balance sheet actively trade . carry value estimate fair value firm wholesale lendingrelated commitment follow period indicate . june 3 0 2 0 1 1 december 3 1 2 0 1 0 billionscarryingvalueaestimatedfair value carryingvalueaestimatedfair valuewholesale lendingrelate commitments $ 0 . 6 $ 1 . 5 $ 0 . 7 $ 0 . 9 arepresent allowance wholesale lendingrelate commitment . exclude current carry value guarantee liability offset asset recognize fair value inception guarantees . the firm estimate fair value consumer lendingrelate commitment . case firm reduce cancel commitment provide borrower notice case notice permit law . discussion valuation lendingrelate commitment note 3 page 1 7 1 1 7 3 jpmorgan chase 2 0 1 0 annual report . trade asset liability average balance average trading asset liability follow period indicate . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 trading asset debt equity instrumentsa $ 4 2 2 7 1 5 $ 3 4 0 6 1 2 $ 4 2 0 1 0 3 $ 3 3 6 2 1 2 trading asset derivative receivables 8 2 8 6 0 7 9 4 0 9 8 4 1 4 1 7 9 0 4 8 trade liability debt equity instrumentsab 8 4 2 5 0 7 7 4 9 2 8 3 5 8 8 7 4 2 0 5 trading liability derivative payables 6 6 0 0 9 6 2 5 4 7 6 8 6 3 4 6 0 8 0 9 abalance reflect reduction security long position security sell purchase short position long short position identical cusip number . bprimarily represent security sell purchased . note 4 fair value optionfor discussion primary financial instrument fair value option previously elect include basis election determination instrumentspecific credit risk relevant note 4 page 1 8 7 1 8 9 jpmorgan chase 2 0 1 0 annual report . change fair value fair value option electionthe follow table present change fair value include consolidated statement income month end june 3 0 2 0 1 1 2 0 1 0 item fair value option elect . profit loss information present include financial instrument elect measure fair value relate risk management instrument require measure fair value include table . 1 1 4 month end june 3 0 2 0 1 1 2 0 1 0 millionsprincipaltransactionsotherincometotal changesin fair value record principaltransactionsotherincometotal change fair value recordedfederal fund sell security purchase resale agreements $ 1 2 1 $ $ 1 2 1 $ 2 6 1 $ $ 2 6 1 securities borrowed 8 8 2 7 2 7 trading asset debt equity instrument exclude loans 1 0 7 4 c 1 0 3 4 0 1 2 c 2 8 loans report trading asset change instrumentspecific credit risk 4 2 9 4 c 4 3 3 3 8 9 2 8 c 4 1 7 other change fair value 1 3 1 3 7 1 c 1 3 8 4 2 9 9 1 2 1 7 c 9 1 8 loans change instrumentspecific credit risk 7 7 3 2 3 2 other change fair value 1 3 9 1 3 9 4 4 4 4 other assets 4 2 d 4 2 4 9 d 4 9 depositsa 9 3 9 3 1 0 3 1 0 3 federal fund purchase security loan sell repurchase agreements 1 4 1 4 5 6 5 6 other borrow fundsa 7 3 9 7 3 9 8 3 8 8 3 8 trading liabilities 3 3 beneficial interest issue consolidated vies 5 5 5 5 1 4 1 4 other liabilities 1 1 d 2 1 9 1 4 d 5 longterm debt change instrumentspecific credit riska 1 4 5 1 4 5 5 3 4 5 3 4 other change fair valueb 9 3 9 3 1 3 3 2 1 3 3 2 month end june 3 0 2 0 1 1 2 0 1 0 millionsprincipaltransactionsotherincometotal changesin fair value record principaltransactionsotherincometotal change fair value recordedfederal fund sell security purchase resale agreements $ 3 $ $ 3 $ 2 8 0 $ $ 2 8 0 securities borrowed 1 1 3 9 3 9 trading asset debt equity instrument exclude loans 2 7 1 1 c 2 7 0 1 9 6 1 1 c 1 8 5 loans report trading asset change instrumentspecific credit risk 9 0 9 4 c 9 1 3 7 9 8 2 2 c 8 2 0 other change fair value 1 3 8 2 0 9 4 c 2 2 3 2 6 8 3 1 9 7 2 c 1 2 8 9 loans change instrumentspecific credit risk 1 3 1 3 7 9 7 9 other change fair value 2 8 2 2 8 2 7 1 7 1 other assets 4 2 d 4 2 1 0 2 d 1 0 2 depositsa 1 1 0 1 1 0 2 9 2 2 9 2 federal fund purchase security loan sell repurchase agreements 2 1 2 1 6 5 6 5 other borrow fundsa 9 5 6 9 5 6 9 1 2 9 1 2 trading liabilities 6 6 3 3 beneficial interest issue consolidated vies 8 9 8 9 3 2 3 2 other liabilities 4 3 d 7 4 1 4 d 1 8 longterm debt change instrumentspecific credit riska 1 9 9 1 9 9 5 8 5 5 8 5 other change fair valueb 1 1 7 1 1 7 1 5 5 8 1 5 5 8 atotal change instrumentspecific credit risk relate structured note $ 1 4 2 million $ 5 8 8 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 1 6 5 million $ 6 9 6 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . total include adjustment structured note classify deposit borrow fund longterm debt . 1 1 5 bstructured note debt instrument embed derivative tailor meet client need . embed derivative primary driver risk . risk associate structured note actively manage gain report table include income statement impact risk management instruments . creporte mortgage fee relate income . dreporte income . difference aggregate fair value aggregate remain contractual principal balance outstanding follow table reflect difference aggregate fair value aggregate remain contractual principal balance outstanding june 3 0 2 0 1 1 december 3 1 2 0 1 0 loan longterm debt longterm beneficial interest fair value option elect . june 3 0 2 0 1 1 december 3 1 2 0 1 0 millionscontractualprincipaloutstande fair valuefair valueoverundercontractualprincipal outstanding contractualprincipaloutstande fair valuefair valueoverundercontractualprincipal outstandingloan perform loan 9 0 day past loan report trading assets $ $ $ $ $ $ loan nonaccrual loan loan report trading assets 5 3 4 2 1 4 1 0 3 9 3 2 5 2 4 6 1 2 3 9 4 0 0 7 loans 8 8 9 7 2 8 1 7 9 2 7 1 3 2 7 9 5 subtotal 6 2 3 1 1 4 8 2 4 7 4 9 6 1 7 3 1 3 7 1 4 8 0 2 all perform loan loan report trading assets 4 0 2 5 5 3 4 9 4 5 5 3 1 0 3 9 4 9 0 3 3 6 4 1 5 8 4 9 loans 2 2 3 9 1 4 8 8 7 5 1 2 4 9 6 1 4 3 4 1 0 6 2 total loans $ 4 8 7 2 5 $ 3 7 9 1 5 $ 1 0 8 1 0 $ 4 8 1 5 9 $ 3 6 4 4 6 $ 1 1 7 1 3 longterm debt principalprotecte debt $ 2 0 6 2 0 b $ 2 1 1 5 7 $ 5 3 7 $ 2 0 7 6 1 b $ 2 1 3 1 5 $ 5 5 4 nonprincipalprotected debtana 1 7 3 5 9 na na 1 7 5 2 4 natotal longterm debtna $ 3 8 5 1 6 na na $ 3 8 8 3 9 nalongterm beneficial interest principalprotecte debt $ $ $ $ 4 9 $ 4 9 $ nonprincipalprotected debtana 9 1 1 na na 1 4 4 6 natotal longterm beneficial interestsna $ 9 1 1 na na $ 1 4 9 5 naaremaining contractual principal applicable nonprincipalprotected note . unlike principalprotected note firm obligate return state principal maturity note nonprincipalprotecte note obligate firm return state principal maturity return base performance underlying variable derivative feature embed note . bwhere firm issue principalprotecte zerocoupon discount note balance reflect remain contractual principal final principal payment maturity . at june 3 0 2 0 1 1 december 3 1 2 0 1 0 contractual letter credit fair value option elect $ 3 . 8 billion corresponding fair value $ 6 million . information regard offbalance sheet lendingrelate financial instrument note 3 0 page 2 7 5 2 8 0 jpmorgan chase 2 0 1 0 annual report . 1 1 6 note 5 derivative instrumentsfor discussion firm use accounting policy regard derivative instrument note 6 page 1 9 1 1 9 9 jpmorgan chase 2 0 1 0 annual report . notional derivative contractsthe follow table summarize notional derivative contract outstanding june 3 0 2 0 1 1 december 3 1 2 0 1 0 . notional amountsbin billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 interest rate contract swap $ 4 4 1 9 1 $ 4 6 2 9 9 futures forwards 8 8 7 1 9 2 9 8 written option 4 3 6 1 4 0 7 5 purchased option 4 6 2 3 3 9 6 8 total interest rate contract 6 2 0 4 6 6 3 6 4 0 credit derivativesa 6 1 0 5 5 4 7 2 foreign exchange contract crosscurrency swap 2 8 7 5 2 5 6 8 spot future forwards 4 6 2 4 3 8 9 3 written option 7 1 8 6 7 4 purchase option 7 1 1 6 4 9 total foreign exchange contract 8 9 2 8 7 7 8 4 equity contract swap 1 3 0 1 1 6 future forwards 5 1 4 9 written option 5 1 9 4 3 0 purchased option 4 7 3 3 7 7 total equity contract 1 1 7 3 9 7 2 commodity contract swap 4 0 1 3 4 9 spot future forwards 1 8 9 1 7 0 written option 3 0 7 2 6 4 purchased option 2 9 7 2 5 4 total commodity contract 1 1 9 4 1 0 3 7 total derivative notional $ 7 9 4 4 6 $ 7 8 9 0 5 aprimarily consist credit default swap . information volume type credit derivative contract credit derivative discussion page 1 2 3 1 2 4 note . brepresent sum gross long gross short thirdparty notional derivative contracts . while notional disclose indication volume firm derivative activity notional significantly exceed firm view possible loss arise transaction . derivative transaction notional exchange use simply reference calculate payments . 1 1 7 impact derivative consolidated balance sheetsthe follow table summarize information derivative fair value reflect firm consolidate balance sheet june 3 0 2 0 1 1 december 3 1 2 0 1 0 account designation e . g . derivative designate hedge contract type . freestande derivativesa derivative receivables derivative payablesjune 3 0 2 0 1 1 millionsnot designate hedgesdesignated hedgestotal derivative receivables designate hedgesdesignated hedgestotal derivative payablestrade asset liability interest rate $ 9 9 4 1 5 7 $ 5 7 4 7 $ 9 9 9 9 0 4 $ 9 6 2 2 1 9 $ 1 3 5 2 $ 9 6 3 5 7 1 credit 1 2 9 0 2 2 1 2 9 0 2 2 1 2 5 4 7 4 1 2 5 4 7 4 foreign exchangeb 1 5 4 6 9 7 3 6 6 3 1 5 8 3 6 0 1 5 1 4 9 8 1 7 7 7 1 5 3 2 7 5 equity 4 7 0 5 4 4 7 0 5 4 4 6 6 4 2 4 6 6 4 2 commodity 5 7 7 1 7 3 1 5 5 8 0 3 2 5 6 5 8 2 1 7 3 2 5 8 3 1 4 gross fair value trading asset liabilities $ 1 3 8 2 6 4 7 $ 9 7 2 5 $ 1 3 9 2 3 7 2 $ 1 3 4 2 4 1 5 $ 4 8 6 1 $ 1 3 4 7 2 7 6 netting adjustmentc 1 3 1 4 9 8 9 1 2 8 3 6 0 8 carrying value derivative trading asset trading liability consolidated balance sheet $ 7 7 3 8 3 $ 6 3 6 6 8 derivative receivables derivative payablesdecember 3 1 2 0 1 0 not designate hedgesdesignated hedgestotal derivative receivables designate hedgesdesignated hedgestotal derivative payablestrade asset liability interest rate $ 1 1 2 1 7 0 3 $ 6 2 7 9 $ 1 1 2 7 9 8 2 $ 1 0 8 9 6 0 4 $ 8 4 0 $ 1 0 9 0 4 4 4 credit 1 2 9 7 2 9 1 2 9 7 2 9 1 2 5 0 6 1 1 2 5 0 6 1 foreign exchangeb 1 6 5 2 4 0 3 2 3 1 1 6 8 4 7 1 1 6 3 6 7 1 1 0 5 9 1 6 4 7 3 0 equity 4 3 6 3 3 4 3 6 3 3 4 6 3 9 9 4 6 3 9 9 commodity 5 9 5 7 3 2 4 5 9 5 9 7 5 6 3 9 7 2 0 7 8 d 5 8 4 7 5 gross fair value trading asset liabilities $ 1 5 1 9 8 7 8 $ 9 5 3 4 $ 1 5 2 9 4 1 2 $ 1 4 8 1 1 3 2 $ 3 9 7 7 $ 1 4 8 5 1 0 9 netting adjustmentc 1 4 4 8 9 3 1 1 4 1 5 8 9 0 carrying value derivative trading asset trading liability consolidated balance sheet $ 8 0 4 8 1 $ 6 9 2 1 9 aexcludes structure note fair value option elect . note 4 page 1 1 4 1 1 6 form 1 0 q note 4 page 1 8 7 1 8 9 jpmorgan chase 2 0 1 0 annual report information . bexclude $ 1 5 million $ 2 1 million foreign currencydenominate debt designate net investment hedge june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . cu . s . gaap permit netting derivative receivable payable related cash collateral receive pay legally enforceable master netting agreement exist firm derivative counterparty . d exclude $ 1 . 0 billion relate commodity derivative embed debt instrument use fair value hedge instrument record line item host contract borrow fund december 3 1 2 0 1 0 . derivative receivable payable fair valuethe follow table summarize fair value derivative receivable payable include designate hedge contract type net adjustment june 3 0 2 0 1 1 december 3 1 2 0 1 0 . trading asset derivative receivables trading liability derivative payablesin millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 contract type interest rate $ 3 2 9 1 1 $ 3 2 5 5 5 $ 1 7 3 0 6 $ 2 0 3 8 7 credit 6 1 9 8 7 7 2 5 4 8 7 8 5 1 3 8 foreign exchange 1 9 8 9 8 2 5 8 5 8 1 9 0 1 5 2 5 0 1 5 equity 7 0 8 4 4 2 0 4 1 1 4 3 0 1 0 4 5 0 commodity 1 1 2 9 2 1 0 1 3 9 1 1 0 3 9 8 2 2 9 total $ 7 7 3 8 3 $ 8 0 4 8 1 $ 6 3 6 6 8 $ 6 9 2 1 9 1 1 8 impact derivative consolidated statement incomefair value hedge gain loss follow table present derivative instrument contract type use fair value hedge accounting relationship pretax gainslosse record derivative related hedge item month end june 3 0 2 0 1 1 2 0 1 0 respectively . firm include gainslosse hedging derivative related hedge item line item consolidated statement income . gainslosse record income income statement impact tothree month endedjune 3 0 2 0 1 1 millionsderivativeshedge itemstotal income statement impact hedgeineffectivenessd exclude componentsecontract type interest ratea $ 1 6 6 $ 1 0 2 $ 6 4 $ 1 7 $ 8 1 foreign exchangeb 1 2 3 9 f 1 4 0 1 1 6 2 1 6 2 commodityc 4 0 1 9 7 4 9 8 3 5 0 1 total $ 1 4 7 4 $ 1 2 0 2 $ 2 7 2 $ 1 4 $ 2 5 8 gainslosse record income income statement impact tothree month endedjune 3 0 2 0 1 0 millionsderivativeshedge itemstotal income statement impact hedgeineffectivenessd exclude componentsecontract type interest ratea $ 1 3 4 5 $ 1 1 0 0 $ 2 4 5 $ 9 6 $ 1 4 9 foreign exchangeb 3 8 4 1 f 3 8 6 5 2 4 2 4 commodityc 1 3 9 3 3 2 1 9 3 1 9 3 total $ 5 3 2 5 $ 5 2 9 7 $ 2 8 $ 9 6 $ 6 8 gainslosse record income income statement impact tosix month end june 3 0 2 0 1 1 millionsderivativeshedge itemstotal income statement impact hedgeineffectivenessd exclude componentsecontract type interest ratea $ 5 5 2 $ 6 9 8 $ 1 4 6 $ 2 6 $ 1 7 2 foreign exchangeb 4 4 4 5 f 4 5 2 5 8 0 8 0 commodityc 4 7 4 3 3 6 1 3 8 2 1 4 0 total $ 5 4 7 1 $ 5 5 5 9 $ 8 8 $ 2 4 $ 1 1 2 gainslosse record income income statement impact tosix month endedjune 3 0 2 0 1 0 millionsderivativeshedge itemstotal income statement impact hedgeineffectivenessd exclude componentsecontract type interest ratea $ 1 9 7 7 $ 1 5 9 8 $ 3 7 9 $ 1 2 4 $ 2 5 5 foreign exchangeb 5 4 8 8 f 5 5 2 2 3 4 3 4 commodityc 3 1 6 6 4 2 5 2 2 5 2 total $ 7 1 4 9 $ 7 0 5 6 $ 9 3 $ 1 2 4 $ 3 1 aprimarily consist hedge benchmark e . g . london interbank offer rate libor interest rate risk fixedrate longterm debt afs security . gain loss record net interest income . bprimarily consist hedge foreign currency risk longterm debt afs security change spot foreign currency rate . gain loss relate derivative hedge item change spot foreign currency rate record principal transaction revenue . cconsist overall fair value hedge certain commodity inventory . gain loss record principal transaction revenue . dhedge ineffectiveness gain loss designate derivative instrument exactly offset gain loss hedged item attributable hedge risk . ecertain component hedge derivative permit exclude assessment hedge effectiveness forward point foreign exchange forward contract . relate exclude component record currentperiod income . finclude $ 1 . 8 billion $ 3 . 8 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 5 . 0 billion $ 5 . 6 billion month end june 3 0 2 0 1 1 2 0 1 0 respectively revenue relate certain foreign exchange trading derivative designate fair value hedge instruments . 1 1 9 cash flow hedge gain loss follow table present derivative instrument contract type use cash flow hedge accounting relationship pretax gainslosse record derivative month end june 3 0 2 0 1 1 2 0 1 0 respectively . firm include gainloss hedging derivative line item offset change cash flow hedged item consolidated statement income . gainslosse record income comprehensive income ocilosscthree month endedjune 3 0 2 0 1 1 millionsderivative effective portion reclassify aoci incomehedge ineffectiveness record directly incomedtotal income statement impactderivative effective portion record ocitotal change oci periodcontract type interest ratea $ 7 5 $ 6 $ 8 1 $ 1 0 3 $ 1 7 8 foreign exchangeb 7 7 4 0 3 3 total $ 6 8 $ 6 $ 7 4 $ 1 4 3 $ 2 1 1 gainslosse record income comprehensive incomelosscthree month endedjune 3 0 2 0 1 0 millionsderivative effective portion reclassify aoci incomehedge ineffectiveness record directly incomedtotal income statement impactderivative effective portion record ocitotal change oci periodcontract type interest ratea $ 3 3 $ 8 $ 4 1 $ 9 8 $ 6 5 foreign exchangeb 2 3 3 2 6 4 7 7 0 total $ 1 0 $ 5 $ 1 5 $ 1 4 5 $ 1 3 5 gainslosse record income comprehensive incomelosscsix month end june 3 0 2 0 1 1 millionsderivative effective portion reclassify aoci incomehedge ineffectiveness record directly incomedtotal income statement impactderivative effective portion record ocitotal change oci periodcontract type interest ratea $ 1 6 9 $ 9 $ 1 7 8 $ 1 3 4 $ 3 0 3 foreign exchangeb 1 5 1 5 2 2 3 7 total $ 1 8 4 $ 9 $ 1 9 3 $ 1 5 6 $ 3 4 0 gainslosse record income comprehensive incomelosscsix month end june 3 0 2 0 1 0 millionsderivative effective portion reclassify aoci incomehedge ineffectiveness record directly incomedtotal income statement impactderivative effective portion record ocitotal change oci periodcontract type interest ratea $ 8 2 $ 1 1 $ 9 3 $ 3 4 9 $ 2 6 7 foreign exchangeb 7 5 3 7 8 6 5 1 0 total $ 7 $ 8 $ 1 5 $ 2 8 4 $ 2 7 7 aprimarily consist benchmark interest rate hedge liborindexed floatingrate asset floatingrate liability . gain loss record net interest income . bprimarily consist hedge foreign currency risk nonu . s . dollardenominate revenue expense . income statement classification gain loss follow hedged item primarily net interest income compensation expense expense . cthe firm experience forecasted transaction fail occur month end june 3 0 2 0 1 1 respectively . month end june 3 0 2 0 1 0 firm reclassify $ 2 5 million loss accumulate comprehensive income aoci earning firm determine probable forecast interest payment cash flow relate certain wholesale deposit occur . dhedge ineffectiveness cumulative gain loss designate derivative instrument exceed present value cumulative expect change cash flow hedged item attributable hedge risk . 1 2 0 over 1 2 month firm expect $ 9 6 million aftertax net gain record aoci june 3 0 2 0 1 1 relate cash flow hedge recognize income . maximum length time forecast transaction hedge 1 0 year transaction primarily relate core lending borrowing activity . net investment hedge gain loss follow table present hedging instrument contract type use net investment hedge accounting relationship pretax gainslosse record instrument month end june 3 0 2 0 1 1 2 0 1 0 . gainslosse record income comprehensive incomeloss 2 0 1 1 2 0 1 0 three month end june 3 0 millionsexcluded component record directly incomeaeffective portionrecorde oci exclude component record directly incomeaeffective portionrecorde ocicontract type foreign exchange derivatives $ 7 4 $ 3 8 3 $ 3 2 $ 4 2 9 foreign currency denominate debt 2 total $ 7 4 $ 3 8 3 $ 3 2 $ 4 3 1 gainslosse record income comprehensive incomeloss 2 0 1 1 2 0 1 0 six month end june 3 0 millionsexcluded component record directly incomeaeffective portionrecorde oci exclude component record directly incomeaeffective portionrecorde ocicontract type foreign exchange derivatives $ 1 4 5 $ 7 7 3 $ 7 3 $ 7 1 4 foreign currency denominate debt 4 3 total $ 1 4 5 $ 7 7 3 $ 7 3 $ 7 5 7 acertain component hedge derivative permit exclude assessment hedge effectiveness forward point foreign exchange forward contract . relate exclude component record currentperiod income . ineffectiveness net investment hedge accounting relationship month end june 3 0 2 0 1 1 2 0 1 0 . risk management derivative gain loss designate hedge instrumentsthe follow table present nontrade derivative contract type designate hedge relationship pretax gainslosse record derivative month end june 3 0 2 0 1 1 2 0 1 0 . derivative risk management instrument use mitigate transform market risk exposure arise banking activity trading activity discuss separately . derivative gainslosse record income month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 contract type interest ratea $ 1 4 8 6 $ 3 6 6 2 $ 1 5 6 2 $ 3 8 0 2 creditb 5 6 0 6 3 5 9 foreign exchangec 7 8 1 9 8 2 0 commodityb 1 1 2 4 4 7 total $ 1 4 1 4 $ 3 6 9 9 $ 1 4 0 1 $ 3 6 7 6 agains loss record principal transaction revenue mortgage fee related income net interest income . bgain loss record principal transaction revenue . cgain loss record principal transaction revenue net interest income . 1 2 1 trade derivative gain lossesthe follow table present trading derivative gain loss contract type record principal transaction revenue consolidated statement income month end june 3 0 2 0 1 1 2 0 1 0 . firm elect present derivative gain loss relate trading activity cash instrument risk manage . gainslosse record principal transaction revenue month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 type instrument interest rate $ 3 5 3 $ 3 7 $ 1 3 $ 7 0 credit 7 4 5 1 2 8 7 1 9 5 4 3 4 1 2 foreign exchangea 2 2 9 4 2 4 8 3 1 1 0 5 1 equity 7 4 3 8 5 1 5 7 1 9 0 7 commodity 1 2 1 9 2 0 1 3 9 3 4 3 3 total $ 2 5 8 3 $ 1 7 7 9 $ 5 7 6 2 $ 5 8 7 3 ain 2 0 1 0 reporting trading gain loss enhance include trading gain loss relate certain trading derivative designate fair value hedge instrument . priorperiod revise conform current presentation . credit risk liquidity risk creditrelate contingent featuresthe aggregate fair value net derivative payable contain contingent collateral termination feature trigger downgrade $ 1 5 . 4 billion june 3 0 2 0 1 1 firm post collateral $ 1 1 . 2 billion normal course business . june 3 0 2 0 1 1 impact singlenotch twonotch rating downgrade jpmorgan chase co . subsidiary primarily jpmorgan chase bank national association jpmorgan chase bank n . a . require $ 1 . 4 billion $ 2 . 8 billion respectively additional collateral post firm . addition june 3 0 2 0 1 1 impact singlenotch twonotch rating downgrade jpmorgan chase co . subsidiary primarily jpmorgan chase bank n . a . relate contract termination trigger require firm settle trade fair value $ 4 3 0 million $ 9 3 0 million respectively . the follow table carry value derivative receivable payable net adjustment adjustment collateral hold transfer june 3 0 2 0 1 1 december 3 1 2 0 1 0 . derivative receivables derivative payablesin millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 gross derivative fair value $ 1 3 9 2 3 7 2 $ 1 5 2 9 4 1 2 $ 1 3 4 7 2 7 6 $ 1 4 8 5 1 0 9 netting adjustment offset receivablespayablesa 1 2 4 8 2 4 3 1 3 7 6 9 6 9 1 2 4 8 2 4 3 1 3 7 6 9 6 9 netting adjustment cash collateral receivedpaida 6 6 7 4 6 7 1 9 6 2 3 5 3 6 5 3 8 9 2 1 carrye value consolidated balance sheets $ 7 7 3 8 3 $ 8 0 4 8 1 $ 6 3 6 6 8 $ 6 9 2 1 9 collateral hold collateral transferredin billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 netting adjustment cash collaterala $ 6 6 . 7 $ 7 2 . 0 $ 3 5 . 4 $ 3 8 . 9 liquid security cash collateralb 1 6 . 5 1 6 . 5 1 2 . 5 1 0 . 9 additional liquid security cash collateralc 2 2 . 3 1 8 . 0 1 0 . 0 8 . 5 total collateral derivative transaction $ 1 0 5 . 5 $ 1 0 6 . 5 $ 5 7 . 9 $ 5 8 . 3 aas permit u . s . gaap firm elect net cash collateral receive pay related derivative receivables derivative payable legally enforceable master netting agreement exist . brepresent cash collateral receive pay subject legally enforceable master netting agreement liquid security collateral hold transfer . crepresent liquid security cash collateral hold transfer initiation derivative transaction available security potential exposure arise fair value transaction collateral hold transfer relate contract nondaily frequency collateral post collateral firm counterparty agree return settle reporting date . net derivative receivables payable table individual counterparty level collateral exceed fair value exposure june 3 0 2 0 1 1 december 3 1 2 0 1 0 . 1 2 2 credit derivative detailed discussion credit derivative include description different type use firm note 6 page 1 9 1 1 9 9 jpmorgan chase 2 0 1 0 annual report . the follow table present summary notional credit derivative creditrelate note firm sell purchase june 3 0 2 0 1 1 december 3 1 2 0 1 0 . credit event firm seller protection typically pay percentage notional net protection sell actually require pay contract account recovery value reference obligation time settlement . firm manage credit risk contract sell protection purchase protection identical similar underlying reference entity . purchase protection reference follow table include credit derivative buy relate identical reference position include index portfolio coverage reference point protection purchase creditrelated note . firm use notional credit derivative primary measure risk management derivative notional account probability occurrence credit event recovery value reference obligation related cash instrument economic hedge reduce firm view risk associate derivatives . total credit derivative creditrelated note maximum payoutnotional amountjune 3 0 2 0 1 1 protection soldprotection purchase identical underlyingsbnet protection soldpurchasedcother protection purchaseddin millionscredit derivative credit default swaps $ 2 9 7 2 1 8 0 $ 2 9 1 2 4 4 6 $ 5 9 7 3 4 $ 3 8 7 9 7 other credit derivativesa 1 2 0 7 3 3 3 6 2 7 8 8 4 4 5 5 2 5 0 0 2 total credit derivatives 3 0 9 2 9 1 3 2 9 4 8 7 2 4 1 4 4 1 8 9 6 3 7 9 9 creditrelate notes 1 5 4 4 1 5 4 4 4 0 0 9 total $ 3 0 9 4 4 5 7 $ 2 9 4 8 7 2 4 $ 1 4 5 7 3 3 $ 6 7 8 0 8 maximum payoutnotional amountdecember 3 1 2 0 1 0 protection soldprotection purchase identical underlyingsbnet protection soldpurchasedcother protection purchaseddin millionscredit derivative credit default swaps $ 2 6 5 9 2 4 0 $ 2 6 5 2 3 1 3 $ 6 9 2 7 $ 3 2 8 6 7 oth credit derivativesa 9 3 7 7 6 1 0 0 1 6 8 3 7 6 0 2 4 2 3 4 total credit derivatives 2 7 5 3 0 1 6 2 6 6 2 3 2 9 9 0 6 8 7 5 7 1 0 1 creditrelate notes 2 0 0 8 2 0 0 8 3 3 2 7 total $ 2 7 5 5 0 2 4 $ 2 6 6 2 3 2 9 $ 9 2 6 9 5 $ 6 0 4 2 8 aprimarily consist total return swap credit default swap option . brepresent total notional protection purchase underlying reference instrument identical reference instrument protection sell notional protection purchase individual identical underlying reference instrument great low notional protection sold . cdoe account fair value reference obligation time settlement generally reduce seller protection pay buyer protection determine settlement value . drepresent protection purchase firm singlename index credit default swap creditrelate notes . the follow table summarize notional fair value credit derivative creditrelated note june 3 0 2 0 1 1 december 3 1 2 0 1 0 jpmorgan chase seller protection . maturity profile base remain contractual maturity credit derivative contract . rating profile base rating reference entity credit derivative contract base . rating maturity profile credit derivative creditrelated note jpmorgan chase purchaser protection comparable profile reflect below . 1 2 3 protection sell credit derivative creditrelated note ratingsamaturity profilejune 3 0 2 0 1 1 millions 1 year 1 5 years 5 yearstotal notional amountfair valuebrisk rating reference entity investmentgrade $ 2 1 8 6 6 9 $ 1 4 5 0 3 5 4 $ 4 1 8 8 2 0 $ 2 0 8 7 8 4 3 $ 2 5 2 8 4 noninvestmentgrade 1 9 0 7 2 8 6 5 8 3 6 4 1 5 7 5 2 2 1 0 0 6 6 1 4 5 2 2 3 8 total $ 4 0 9 3 9 7 $ 2 1 0 8 7 1 8 $ 5 7 6 3 4 2 $ 3 0 9 4 4 5 7 $ 7 7 5 2 2 december 3 1 2 0 1 0 millions 1 year 1 5 years 5 yearstotal notional amountfair valuebrisk rating reference entity investmentgrade $ 1 7 5 6 1 8 $ 1 1 9 4 6 9 5 $ 3 3 6 3 0 9 $ 1 7 0 6 6 2 2 $ 1 7 2 6 1 noninvestmentgrade 1 4 8 4 3 4 7 0 2 6 3 8 1 9 7 3 3 0 1 0 4 8 4 0 2 5 9 9 3 9 total $ 3 2 4 0 5 2 $ 1 8 9 7 3 3 3 $ 5 3 3 6 3 9 $ 2 7 5 5 0 2 4 $ 7 7 2 0 0 athe rating scale base firm internal rating generally correspond rating define sp moodys . bamount gross basis benefit legally enforceable master net agreement cash collateral receive firm . note 6 noninterest revenuefor discussion component accounting policy firm noninter revenue note 7 page 1 9 9 2 0 0 jpmorgan chase 2 0 1 0 annual report . the follow table present component investment banking fee . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 underwrite equity $ 4 5 5 $ 3 5 4 $ 8 3 4 $ 7 6 7 debt 8 7 6 7 1 1 1 8 5 8 1 4 6 2 total underwriting 1 3 3 1 1 0 6 5 2 6 9 2 2 2 2 9 advisory 6 0 2 3 5 6 1 0 3 4 6 5 3 total investment bank fees $ 1 9 3 3 $ 1 4 2 1 $ 3 7 2 6 $ 2 8 8 2 principal transaction revenue consist trading revenue realize unrealized gain loss private equity investment . trading revenue drive firm client marketmaking client drive activity certain risk management activities . the spread price firm buy price firm sell financial instrument client market maker recognize trading revenue . trading revenue include unrealized gain loss financial instrument firm hold inventory market maker meet client need risk management purposes . the follow table present principal transaction revenue major underlying type risk exposure . table include type revenue net interest income trading asset integral overall performance firm clientdriven trading activity . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 trade revenue risk exposure interest rate $ 3 2 5 $ 2 8 8 $ 1 9 0 $ 5 7 2 credit 9 1 9 1 3 7 1 2 1 9 8 3 4 1 8 foreign exchange 2 2 5 4 7 4 7 8 5 1 1 7 2 equity 7 5 4 3 7 1 7 7 8 1 0 2 9 commoditya 7 2 9 1 6 0 1 2 9 1 2 0 5 total trading revenue $ 2 3 0 2 $ 2 0 1 0 $ 6 2 4 2 $ 6 3 9 6 private equity gainslossesb 8 3 8 8 0 1 6 4 3 2 4 2 principal transactions $ 3 1 4 0 $ 2 0 9 0 $ 7 8 8 5 $ 6 6 3 8 aincludes realize gain realize unrealized loss physical commodity inventory carry low cost market gain loss commodity derivative financial instrument carry fair value income . commodity derivative frequently use manage firm risk exposure physical commodity inventory . binclude revenue private equity investment hold private equity business corporateprivate equity hold business segments . 1 2 4 the follow table present component asset management administration commission . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 asset management investment management fees $ 1 6 5 5 $ 1 3 1 7 $ 3 1 4 9 $ 2 6 4 4 all asset management fees 1 4 8 1 1 6 2 9 2 2 2 5 total asset management fees 1 8 0 3 1 4 3 3 3 4 4 1 2 8 6 9 total administration feesa 5 7 9 5 3 1 1 1 3 0 1 0 2 2 commission fee brokerage commissions 6 9 9 7 5 3 1 4 6 2 1 4 5 6 all commission fees 6 2 2 6 3 2 1 2 7 6 1 2 6 7 total commission fees 1 3 2 1 1 3 8 5 2 7 3 8 2 7 2 3 total asset management administration commissions $ 3 7 0 3 $ 3 3 4 9 $ 7 3 0 9 $ 6 6 1 4 aincludes fee custody security lending fund service security clearance . note 7 interest income interest expensefor description jpmorgan chase accounting policy regard interest income interest expense note 8 page 2 0 0 jpmorgan chase 2 0 1 0 annual report . detail interest income interest expense follow . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 interest income loans $ 9 1 4 0 $ 9 9 6 9 $ 1 8 6 4 7 $ 2 0 5 2 6 securities 2 5 9 0 2 5 1 7 4 8 0 6 5 4 2 1 trading assets 2 9 6 6 2 5 7 4 5 8 5 1 5 3 3 4 federal fund sell security purchase resale agreements 6 0 4 3 9 8 1 1 4 7 8 0 5 securitie borrowed 3 0 3 2 7 7 6 1 deposit banks 1 4 4 9 2 2 4 5 1 8 7 other assetsa 1 5 8 1 3 7 3 0 6 2 3 0 total interest income 1 5 6 3 2 1 5 7 1 9 3 1 0 7 9 3 2 5 6 4 interest expense interestbeare deposits 1 1 2 3 8 8 3 2 0 4 5 1 7 2 7 shortterm liabilitiesbc 8 9 0 4 9 6 1 7 0 8 1 0 5 8 longterm debtc 1 5 8 1 1 3 4 7 3 1 6 9 2 7 4 6 beneficial interest issue consolidated vies 2 0 2 3 0 6 4 1 6 6 3 6 total interest expense 3 7 9 6 3 0 3 2 7 3 3 8 6 1 6 7 net interest income 1 1 8 3 6 1 2 6 8 7 2 3 7 4 1 2 6 3 9 7 provision credit losses 1 8 1 0 3 3 6 3 2 9 7 9 1 0 3 7 3 net interest income provision credit losses $ 1 0 0 2 6 $ 9 3 2 4 $ 2 0 7 6 2 $ 1 6 0 2 4 apredominantly margin loans . binclude brokerage customer payables . ceffective january 1 2 0 1 1 longterm portion advance fhlb reclassify borrow fund longterm debt . related interest expense prioryear period reclassify conform current presentation . 1 2 5 note 8 pension postretirement employee benefit plansfor discussion jpmorgan chase pension postretirement employee benefit opeb plan note 9 page 2 0 1 2 1 0 jpmorgan chase 2 0 1 0 annual report . follow table present component net periodic benefit cost report consolidated statement income firm u . s . nonu . s . define benefit pension define contribution opeb plan . pension plan u . s . nonu . s . opeb plansthree month end june 3 0 million 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 component net periodic benefit cost benefit earn period $ 6 2 $ 5 8 $ 9 $ 6 $ $ 1 interest cost benefit obligation 1 1 3 1 1 7 3 5 7 7 1 3 1 3 expect return plan asset 1 9 7 1 8 5 3 6 7 5 2 2 2 4 amortization net loss 4 1 5 6 1 2 1 3 prior service costcredit 1 1 1 1 1 2 4 net periodic define benefit cost 8 3 5 1 9 2 1 1 1 1 4 define benefit pension plansa 4 3 5 1 nana total define benefit plan 1 2 3 8 2 4 2 2 1 1 1 4 total define contribution plan 8 9 8 4 6 5 6 7 nana total pension opeb cost include compensation expense $ 1 0 1 $ 1 2 2 $ 8 9 $ 8 9 $ 1 1 $ 1 4 pension plan u . s . nonu . s . opeb planssix month end june 3 0 million 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 component net periodic benefit cost benefit earn period $ 1 2 4 $ 1 1 6 $ 1 8 $ 1 3 $ $ 1 interest cost benefit obligation 2 2 6 2 3 4 6 8 6 3 2 6 2 8 expect return plan asset 3 9 5 3 7 1 7 2 6 2 4 4 4 8 amortization net loss 8 2 1 1 2 2 4 2 7 prior service costcredit 2 1 2 2 1 4 7 net periodic define benefit cost 1 6 6 9 3 7 4 1 2 2 2 6 define benefit pension plansa 1 1 7 9 5 nana total define benefit plan 2 7 7 6 4 6 4 6 2 2 2 6 total define contribution plan 1 6 7 1 4 7 1 4 3 1 3 2 nana total pension opeb cost include compensation expense $ 1 9 4 $ 2 2 3 $ 1 8 9 $ 1 7 8 $ 2 2 $ 2 6 ainclude define benefit pension plan individually immaterial . the fair value plan asset u . s . define benefit pension opeb plan material nonu . s . define benefit pension plan $ 1 2 . 5 billion $ 2 . 9 billion respectively june 3 0 2 0 1 1 $ 1 2 . 2 billion $ 2 . 6 billion respectively december 3 1 2 0 1 0 . note 2 0 page 1 6 6 form 1 0 q information unrecognized i . e . net loss prior service costscredit reflect aoci sixmonth period end june 3 0 2 0 1 1 2 0 1 0 . the potential 2 0 1 1 contribution u . s . qualified define benefit pension plan determinable time . year 2 0 1 1 cost funding benefit firm u . s . nonqualifie define benefit pension plan expect total $ 4 2 million . 2 0 1 1 contribution nonu . s . define benefit pension opeb plan expect $ 1 6 6 million $ 2 million respectively . 1 2 6 note 9 employee stockbase incentivesfor discussion accounting policy information relate employee stockbase incentive note 1 0 page 2 1 0 2 1 2 jpmorgan chase 2 0 1 0 annual report . the firm recognize follow noncash compensation expense relate employee stockbase incentive plan consolidated statement income . month end june 3 0 month end june 3 0 million 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 cost prior grant restricted stock unit rsus stock appreciation right sar amortize applicable vesting period $ 5 2 0 $ 6 4 6 $ 1 0 8 1 $ 1 3 3 4 accrual estimate cost rsus sar grant future period include fullcareer eligible employee 2 0 7 1 8 7 4 7 6 4 4 0 total noncash compensation expense relate employee stockbase incentive plan $ 7 2 7 $ 8 3 3 $ 1 5 5 7 $ 1 7 7 4 quarter 2 0 1 1 connection annual incentive grant firm grant 5 5 million rsus 1 4 million sar weightedaverage grant date fair value $ 4 4 . 3 1 rsu $ 1 3 . 1 2 sar . note 1 0 noninter expensethe follow table present component noninter expense . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 compensation expensea $ 7 5 6 9 $ 7 6 1 6 $ 1 5 8 3 2 $ 1 4 8 9 2 noncompensation expense occupancy expense 9 3 5 8 8 3 1 9 1 3 1 7 5 2 technology communication equipment expense 1 2 1 7 1 1 6 5 2 4 1 7 2 3 0 2 professional outside services 1 8 6 6 1 6 8 5 3 6 0 1 3 2 6 0 marketing 7 4 4 6 2 8 1 4 0 3 1 2 1 1 other expensebc 4 2 9 9 2 4 1 9 7 2 4 2 6 8 6 0 amortization intangibles 2 1 2 2 3 5 4 2 9 4 7 8 total noncompensation expense 9 2 7 3 7 0 1 5 1 7 0 0 5 1 5 8 6 3 total noninter expense $ 1 6 8 4 2 $ 1 4 6 3 1 $ 3 2 8 3 7 $ 3 0 7 5 5 athe month end june 3 0 2 0 1 0 include payroll tax expense relate united kingdom u . k . bank payroll tax certain compensation award december 9 2 0 0 9 april 5 2 0 1 0 relevant banking employees . bincluded litigation expense $ 1 . 9 billion $ 3 . 0 billion month end june 3 0 2 0 1 1 respectively compare $ 7 9 2 million $ 3 . 7 billion month end june 3 0 2 0 1 0 respectively . cinclude foreclosed property expense $ 1 7 4 million $ 3 8 4 million month end june 3 0 2 0 1 1 respectively compare $ 2 4 4 million $ 5 4 7 million month end june 3 0 2 0 1 0 respectively . 1 2 7 note 1 1 securitiessecuritie classify afs heldtomaturity htm trading . additional information regard afs htm security note 1 2 page 2 1 4 2 1 8 jpmorgan chase 2 0 1 0 annual report . trading security discuss note 3 page 1 0 2 1 1 4 form 1 0 q . securities gain lossesthe follow table present realize gain loss credit loss recognize income afs security . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 realized gains $ 8 8 1 $ 1 1 3 0 $ 1 0 3 3 $ 1 8 8 2 realized losses 3 1 1 3 0 5 1 1 7 2 net realize gainsa 8 5 0 1 0 0 0 9 8 2 1 7 1 0 credit loss include security gainsb 1 3 4 3 1 0 0 net security gains $ 8 3 7 $ 1 0 0 0 $ 9 3 9 $ 1 6 1 0 aproceeds security sell approximately 4 % amortize cost . binclude otherthantemporary impairment loss recognize income certain prime mortgagebacke security month end june 3 0 2 0 1 1 certain prime mortgagebacke security obligation u . s . state municipality month end june 3 0 2 0 1 0 . the amortize cost estimate fair value afs htm security follow date indicate . june 3 0 2 0 1 1 december 3 1 2 0 1 0 millionsamortize costgross unrealized gainsgross unrealized lossesfair value amortize costgross unrealized gainsgross unrealized lossesfair valueavailableforsale debt security mortgagebacke security u . s . government agenciesa $ 1 1 5 2 7 1 $ 3 8 3 8 $ 2 0 8 $ 1 1 8 9 0 1 $ 1 1 7 3 6 4 $ 3 1 5 9 $ 2 9 7 $ 1 2 0 2 2 6 residential prime alta 2 2 0 1 7 2 1 8 0 d 2 0 9 3 2 1 7 3 8 1 2 5 0 d 2 0 0 4 subprime 1 1 1 1 nonu . s . 5 6 8 2 4 3 3 2 3 1 7 5 6 8 3 9 4 7 0 8 9 2 9 0 4 0 9 4 6 9 7 0 commercial 4 7 5 5 4 3 0 1 3 5 1 7 2 5 1 6 9 5 0 2 1 7 5 6 5 4 total mortgagebacke securities 1 7 9 0 5 2 4 6 7 2 7 1 8 1 8 3 0 0 6 1 7 1 7 9 6 4 0 3 2 9 7 3 1 7 4 8 5 5 u . s . treasury government agenciesa 5 1 9 7 1 1 2 2 2 5 2 8 7 1 1 2 5 8 1 1 8 2 8 1 1 3 4 8 obligation u . s . state municipalities 1 1 3 5 3 3 4 0 1 1 5 1 1 5 7 8 1 1 7 3 2 1 6 5 3 3 8 1 1 5 5 9 certificate deposit 4 8 5 9 2 4 8 6 1 3 6 4 8 1 2 3 6 4 7 nonu . s . government debt securities 3 0 6 6 2 2 1 7 6 3 3 0 8 1 6 2 0 6 1 4 1 9 1 2 8 2 0 7 7 7 corporate debt securitiesb 5 5 9 2 7 3 9 3 5 1 4 5 5 8 0 6 6 1 7 1 7 4 9 5 4 1 9 6 1 7 9 3 assetbacked security credit card receivables 5 1 2 4 2 7 7 5 4 0 1 7 2 7 8 3 3 5 5 7 6 0 8 collateralized loan obligations 1 4 8 5 9 5 0 9 1 1 7 1 5 2 5 1 1 3 3 3 6 4 7 2 2 1 0 1 3 5 9 8 other 9 3 1 8 1 7 7 1 0 9 4 8 5 8 9 6 8 1 3 0 1 6 9 0 8 2 total availableforsale debt securities 3 1 6 3 5 1 6 6 9 9 1 5 5 9 d 3 2 1 4 9 1 3 1 0 3 4 7 5 9 3 9 2 0 1 9 d 3 1 4 2 6 7 availableforsale equity securities 3 0 3 2 2 0 6 3 3 2 3 5 1 8 9 4 1 6 3 6 2 0 5 1 total availableforsale securities $ 3 1 9 3 8 3 $ 6 9 0 5 $ 1 5 6 2 d $ 3 2 4 7 2 6 $ 3 1 2 2 4 1 $ 6 1 0 2 $ 2 0 2 5 d $ 3 1 6 3 1 8 total heldtomaturity securitiesc $ 1 5 $ 1 $ $ 1 6 $ 1 8 $ 2 $ $ 2 0 aincludes total u . s . governmentsponsore enterprise obligation fair value $ 9 5 . 2 billion $ 9 4 . 2 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively predominantly mortgagerelated . bconsist primarily bank debt include sovereign governmentguaranteed bank debt . cconsist primarily mortgagebacke security issue u . s . governmentsponsore enterprises . dinclude total $ 1 0 2 million $ 1 3 3 million pretax unrealized loss relate prime mortgagebacke security credit loss recognize income june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . unrealized loss creditrelate remain report aoci . 1 2 8 securitie impairment follow table present fair value gross unrealized loss afs security age category june 3 0 2 0 1 1 december 3 1 2 0 1 0 . security gross unrealized loss 1 2 month 1 2 month june 3 0 2 0 1 1 millionsfair valuegross unrealized loss fair valuegross unrealized lossestotal fair valuetotal gross unrealized lossesavailableforsale debt security mortgagebacke security u . s . government agencies $ 1 3 7 7 4 $ 2 0 7 $ 1 1 $ 1 $ 1 3 7 8 5 $ 2 0 8 residential prime alta 3 2 5 1 1 1 1 9 1 7 9 1 4 4 4 1 8 0 subprime nonu . s . 1 8 1 6 3 8 7 1 9 3 8 5 2 3 0 3 7 5 4 8 3 1 7 commercial 7 9 0 1 3 7 9 0 1 3 total mortgagebacke securities 3 3 0 5 2 3 0 8 2 0 5 1 5 4 1 0 5 3 5 6 7 7 1 8 u . s . treasury government agencies 4 7 9 2 2 4 7 9 2 2 obligation u . s . state municipalities 3 9 0 5 1 0 7 2 7 8 3 9 3 2 1 1 5 certificate deposit nonu . s . government debt securities 1 0 7 1 3 6 3 1 0 7 1 3 6 3 corporate debt securities 1 8 8 6 4 5 1 4 1 8 8 6 4 5 1 4 assetbacked security credit card receivables collateralized loan obligations 9 8 8 4 5 7 5 0 1 1 3 6 7 3 8 1 1 7 other 2 5 7 7 8 9 6 2 2 6 7 3 1 0 total availableforsale debt securities 7 0 5 7 8 1 0 2 6 2 6 3 8 8 5 3 3 9 6 9 6 6 1 5 5 9 availableforsale equity securities 4 3 4 3 total security gross unrealized losses $ 7 0 5 8 2 $ 1 0 2 9 $ 2 6 3 8 8 $ 5 3 3 $ 9 6 9 7 0 $ 1 5 6 2 security gross unrealized loss 1 2 month 1 2 month december 3 1 2 0 1 0 millionsfair valuegross unrealized loss fair valuegross unrealized lossestotal fair valuetotal gross unrealized lossesavailableforsale debt security mortgagebacke security u . s . government agencies $ 1 4 0 3 9 $ 2 9 7 $ $ $ 1 4 0 3 9 $ 2 9 7 residential prime alta 1 1 9 3 2 5 0 1 1 9 3 2 5 0 subprime nonu . s . 3 5 1 6 6 3 7 9 1 0 8 0 3 0 3 6 2 4 6 4 0 9 commercial 5 4 8 1 4 1 1 3 5 5 9 1 7 total mortgagebacke securities 4 9 7 5 3 6 9 0 2 2 8 4 2 8 3 5 2 0 3 7 9 7 3 u . s . treasury government agencies 9 2 1 2 8 9 2 1 2 8 obligation u . s . state municipalities 6 8 9 0 3 3 0 2 0 8 6 9 1 0 3 3 8 certificate deposit 1 7 7 1 2 1 7 7 1 2 nonu . s . government debt securities 6 9 6 0 2 8 6 9 6 0 2 8 corporate debt securities 1 8 7 8 3 4 1 8 9 0 1 1 8 8 7 3 4 1 9 assetbacked security credit card receivables 3 4 5 5 3 4 5 5 collateralized loan obligations 4 6 0 1 0 6 3 2 1 2 0 0 6 7 8 1 2 1 0 other 2 6 1 5 9 3 2 7 2 6 4 7 1 6 total availableforsale debt securities 8 8 1 5 3 1 5 1 5 9 0 9 2 5 0 4 9 7 2 4 5 2 0 1 9 availableforsale equity security 2 6 2 6 total security gross unrealized losses $ 8 8 1 5 3 $ 1 5 1 5 $ 9 0 9 4 $ 5 1 0 $ 9 7 2 4 7 $ 2 0 2 5 1 2 9 otherthantemporary impairment ottithe follow table present credit loss include security gain loss table . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 debt securitie firm intend sell credit loss total otherthantemporary impairment lossesa $ $ $ 2 7 $ 9 4 losses record inreclassifie comprehensive income 1 3 1 6 6 total credit loss recognize incomeb $ 1 3 $ $ 4 3 $ 1 0 0 afor initial otti represent excess amortize cost fair value afs debt security . subsequent impairment security represent additional decline fair value subsequent previously record otti applicable . brepresent credit loss component certain prime mortgagebacke security month end june 3 0 2 0 1 1 certain prime mortgagebacke security obligation u . s . state municipality month end june 3 0 2 0 1 0 firm intend sell . subsequent credit loss record security correspond decline fair value decline expect cash flow . change credit loss component creditimpaire debt securitiesthe follow table present rollforward month end june 3 0 2 0 1 1 2 0 1 0 credit loss component otti loss recognize income relate debt security firm intend sell . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 balance beginning period $ 6 6 2 $ 6 6 0 $ 6 3 2 $ 5 7 8 additions newly creditimpaire security 4 increase loss previously creditimpaire security 9 4 losses reclassify comprehensive income previously creditimpaire securities 1 3 3 9 6 reduction sale creditimpaire securities 2 0 2 3 impact new accounting guidance relate vie 1 5 balance end period $ 6 7 5 $ 6 4 0 $ 6 7 5 $ 6 4 0 gross unrealized lossesgross unrealized loss generally decrease december 3 1 2 0 1 0 unrealized loss position 1 2 month increase slightly . june 3 0 2 0 1 1 firm intend sell security loss position aoci likely firm require sell security recovery amortize cost basis . security report table credit loss recognize income firm believe security unrealized loss aoci otherthantemporarily impair june 3 0 2 0 1 1 . following description firm principal investment security significant unrealized loss exist 1 2 month june 3 0 2 0 1 1 key assumption use firm estimate present value cash flow likely collect investments . mortgagebacked security prime alta nonagencyas june 3 0 2 0 1 1 gross unrealized loss relate prime alta residential mortgagebacke security issue private issuer $ 1 8 0 million $ 1 7 9 million relate security unrealized loss position 1 2 month . approximately 5 8 % total portfolio amortized cost currently rate investmentgrade firm record otti loss 6 6 % investmentgrade position . majority otti attribute security primarily mortgage high credit risk characteristic base collateral type vintage geographic concentration . remain security investmentgrade experience otti generally possess characteristic sufficient credit enhancement protect investment . average credit enhancement associate investmentgrade investmentgrade position 8 % 4 4 % respectively . analyze prime alta residential mortgagebacke security potential credit loss firm use methodology focus loanlevel detail estimate future cash flow allocate tranche security . loanlevel analysis primarily consider current home value loantovalue ltv ratio loan type geographical location underlying property forecast prepayment home price default rate loss severity . forecast weight average underlie default rate position 2 4 % related weighted average loss severity 4 7 % . base analysis otti loss $ 1 3 million $ 4 3 million recognize month month end june 3 0 2 0 1 1 respectively certain security relate high loss assumption . overall unrealized loss decrease december 3 1 2 0 1 0 recovery security price result increase demand higheryielde asset class deceleration pace home price decline u . s . government program facilitate financing spur home purchase . unrealized loss $ 1 8 0 million consider temporary base management assessment estimate future cash flow credit enhancement level security remain sufficient support firm investment . 1 3 0 mortgagebacked security nonu . s . as june 3 0 2 0 1 1 gross unrealized loss relate nonu . s . residential mortgagebacke security $ 3 1 7 million $ 2 3 0 million relate security unrealized loss position 1 2 month . substantially security rate aaa aa represent mortgage exposure united kingdom netherland . key assumption use analyze nonu . s . residential mortgagebacke security potential credit loss include credit enhancement recovery rate default rate constant prepayment rate . credit enhancement primarily form subordination form structural credit enhancement realize loss associate asset hold issuing vehicle allocate tranche security issue vehicle consider relative seniority . credit enhancement form subordination approximately 1 0 % outstanding principal balance securitize mortgage loan compare expect lifetime loss 1 . 5 % outstanding principal . determine potential credit loss assumption include recovery rate 6 0 % default rate 0 . 2 5 % 0 . 5 % constant prepayment rate 1 5 % 2 0 % . unrealized loss consider temporary base management assessment estimate future cash flow credit enhancement level security remain sufficient support firm investment . assetbacke security collateralized loan obligationsas june 3 0 2 0 1 1 gross unrealized loss relate clos $ 1 1 7 million $ 1 1 3 million relate security unrealized loss position 1 2 month . overall loss decrease december 3 1 2 0 1 0 mainly result low default forecast spread tighten asset class . substantially security rate aaa aa average credit enhancement 3 0 % . key assumption consider analyze potential credit loss underlie loan debt security default loss severity . base current default trend collateral underlie security firm assume collateral default rate 2 % second quarter 2 0 1 1 4 % . loss severity assume 4 8 % loan 8 2 % debt security . loss collateral estimate occur approximately 1 8 month default . unrealized loss consider temporary base management assessment estimate future cash flow credit enhancement level security remain sufficient support firm investment . 1 3 1 contractual maturity yieldsthe follow table present amortize cost estimate fair value june 3 0 2 0 1 1 jpmorgan chase afs htm security contractual maturity . june 3 0 2 0 1 1 by remain maturityin millionsdue year lessdue year yearsdue year 1 0 yearsdue 1 0 yearsctotalavailableforsale debt security mortgagebacke securitiesa amortize cost $ 9 $ 6 9 2 $ 3 1 6 5 $ 1 7 5 1 8 6 $ 1 7 9 0 5 2 fair value 9 7 2 6 3 1 9 4 1 7 9 0 7 7 1 8 3 0 0 6 average yieldb 5 . 0 2 % 4 . 2 2 % 2 . 2 0 % 3 . 7 2 % 3 . 6 9 % u . s . treasury government agenciesa amortize cost $ 1 6 5 5 $ 3 2 8 9 $ 1 $ 2 5 2 $ 5 1 9 7 fair value 1 6 6 7 3 3 9 0 1 2 2 9 5 2 8 7 average yieldb 1 . 6 4 % 2 . 2 0 % 4 . 8 7 % 3 . 8 5 % 2 . 1 0 % obligation u . s . state municipality amortize cost $ 2 2 $ 2 6 1 $ 2 4 2 $ 1 0 8 2 8 $ 1 1 3 5 3 fair value 2 2 2 7 8 2 6 3 1 1 0 1 5 1 1 5 7 8 average yieldb 1 . 0 6 % 4 . 0 5 % 4 . 3 5 % 4 . 9 2 % 4 . 8 8 % certificates deposit amortize cost $ 4 7 9 5 $ 6 4 $ $ $ 4 8 5 9 fair value 4 7 9 7 6 4 4 8 6 1 average yieldb 4 . 5 4 % 0 . 9 6 % % % 4 . 5 0 % nonu . s . government debt security amortize cost $ 1 0 4 1 0 $ 1 7 6 0 1 $ 2 6 4 7 $ 4 $ 3 0 6 6 2 fair value 1 0 4 3 5 1 7 7 2 5 2 6 5 2 4 3 0 8 1 6 average yieldb 1 . 8 5 % 1 . 9 7 % 3 . 2 7 % 4 . 7 3 % 2 . 0 4 % corporate debt security amortize cost $ 2 3 7 0 5 $ 2 5 9 2 0 $ 6 3 0 2 $ $ 5 5 9 2 7 fair value 2 3 9 3 5 2 5 6 4 6 6 2 2 5 5 5 8 0 6 average yieldb 2 . 0 7 % 2 . 7 3 % 4 . 8 0 % % 2 . 6 8 % assetbacke security amortize cost $ 1 9 $ 5 4 3 0 $ 1 0 7 8 1 $ 1 3 0 7 1 $ 2 9 3 0 1 fair value 2 1 5 6 8 1 1 1 1 3 0 1 3 3 0 5 3 0 1 3 7 average yieldb 0 . 0 3 % 2 . 8 7 % 2 . 2 8 % 2 . 2 3 % 2 . 3 6 % total availableforsale debt security amortize cost $ 4 0 6 1 5 $ 5 3 2 5 7 $ 2 3 1 3 8 $ 1 9 9 3 4 1 $ 3 1 6 3 5 1 fair value 4 0 8 8 6 5 3 5 1 0 2 3 4 6 5 2 0 3 6 3 0 3 2 1 4 9 1 average yieldb 2 . 2 8 % 2 . 4 9 % 3 . 0 9 % 3 . 6 8 % 3 . 2 6 % availableforsale equity security amortize cost $ $ $ $ 3 0 3 2 $ 3 0 3 2 fair value 3 2 3 5 3 2 3 5 average yieldb % % % 0 . 3 2 % 0 . 3 2 % total availableforsale security amortize cost $ 4 0 6 1 5 $ 5 3 2 5 7 $ 2 3 1 3 8 $ 2 0 2 3 7 3 $ 3 1 9 3 8 3 fair value 4 0 8 8 6 5 3 5 1 0 2 3 4 6 5 2 0 6 8 6 5 3 2 4 7 2 6 average yieldb 2 . 2 8 % 2 . 4 9 % 3 . 0 9 % 3 . 6 3 % 3 . 2 3 % total heldtomaturity security amortize cost $ $ 7 $ 7 $ 1 $ 1 5 fair value 7 8 1 1 6 average yieldb % 6 . 9 6 % 6 . 8 2 % 6 . 4 8 % 6 . 8 6 % au . s . government agency u . s . governmentsponsore enterprise issuer security exceed 1 0 % jpmorgan chase total stockholder equity june 3 0 2 0 1 1 . b average yield compute use effective yield security end period weight base amortize cost security . effective yield consider contractual coupon amortization premium accretion discount effect related hedging derivative . taxableequivalent use applicable . cinclude security stated maturity . substantially firm residential mortgagebacke security collateralized mortgage obligation 1 0 year base contractual maturity . estimate duration reflect anticipate future prepayment base consensus dealer market approximately year agency residential mortgagebacke security year agency residential collateralized mortgage obligation year nonagency residential collateralized mortgage obligation . 1 3 2 note 1 2 security financing activity discussion accounting policy relate security financing activity note 1 3 page 2 1 9 jpmorgan chase 2 0 1 0 annual report . information regard security borrow security lend agreement fair value option elect note 4 page 1 1 4 1 1 6 form 1 0 q . follow table detail firm security financing agreement account collateralized financing period presented . in millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 securitie purchase resale agreementsa $ 2 1 3 0 7 4 $ 2 2 2 3 0 2 security borrowedb 1 2 1 4 9 3 1 2 3 5 8 7 security sell repurchase agreementsc $ 2 2 9 6 6 6 $ 2 6 2 7 2 2 security loan 2 2 9 3 9 1 0 5 9 2 aat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include resale agreement $ 2 1 . 3 billion $ 2 0 . 3 billion respectively account fair value . bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include security borrow $ 1 4 . 8 billion $ 1 4 . 0 billion respectively account fair value . cat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include repurchase agreement $ 6 . 6 billion $ 4 . 1 billion respectively account fair value . the report table reduce $ 1 0 9 . 4 billion $ 1 1 2 . 7 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively result agreement effect meet specify condition net presentation applicable accounting guidance . for information regard asset pledge collateral receive security financing agreement note 2 2 page 1 7 1 form 1 0 q . 1 3 3 note 1 3 loansloan account frameworkthe accounting loan depend management strategy loan loan creditimpaire date acquisition . firm account loan base follow categoriesoriginate purchase loan heldforinvestment i . e . retain purchase creditimpaire pci loansloan heldforsaleloan fair valuepci loan heldforinvestmentfor detailed discussion loan include accounting policy note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . note 4 page 1 1 4 1 1 6 form 1 0 q information firm election fair value account fair value option . note 3 page 1 0 2 1 1 4 form 1 0 q information loan carry fair value classify trading asset . loan portfoliothe firm loan portfolio divide portfolio segment segment use firm determine allowance loan loss wholesale consumer exclude credit card credit card . portfolio segment firm monitor assess credit risk following class loan base risk characteristic loan class wholesalea consumer exclude credit cardb credit card commercial industrial real estate financial institution government agency residential real estate exclude pci home equity senior lien home equity junior lien prime mortgage include option adjustablerate mortgage arm subprime mortgageother consumer loan autoc business bankingc student residential real estate pci home equity prime mortgage subprime mortgage option arm chase exclude account originate washington mutual account originate washington mutualainclude loan report ib commercial banking cb treasury security service tss asset management corporateprivate equity segments . binclude loan report rfs auto student loan report card service auto card residential real estate loan report corporateprivate equity segment . cinclude auto business banking riskrate loan apply wholesale methodology determine allowance loan loss loan manage card rfs respectively consistency presentation include consumer loan classes . 1 3 4 the follow table summarize firm loan balance portfolio segmentjune 3 0 2 0 1 1 millionswholesaleconsumer excludingcredit cardcredit cardtotal retained $ 2 4 4 2 2 4 $ 3 1 5 1 6 9 $ 1 2 5 5 2 3 $ 6 8 4 9 1 6 a heldforsale 2 5 9 2 2 2 1 2 8 1 3 fair value 2 0 0 7 2 0 0 7 total $ 2 4 8 8 2 3 $ 3 1 5 3 9 0 $ 1 2 5 5 2 3 $ 6 8 9 7 3 6 december 3 1 2 0 1 0 millionswholesaleconsumer excludingcredit cardcredit cardtotal retained $ 2 2 2 5 1 0 $ 3 2 7 4 6 4 $ 1 3 5 5 2 4 $ 6 8 5 4 9 8 a heldforsale 3 1 4 7 1 5 4 2 1 5 2 5 4 5 3 fair value 1 9 7 6 1 9 7 6 total $ 2 2 7 6 3 3 $ 3 2 7 6 1 8 $ 1 3 7 6 7 6 $ 6 9 2 9 2 7 aloan pci loan fair value option select present net unearned income unamortized discount premium net deferred loan cost $ 2 . 4 billion $ 1 . 9 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . follow table provide information carry value retained loan purchase retain loan sell retain loan reclassify heldforsale period indicate . table exclude loan record fair value . ongoing basis firm manage exposure credit risk . sell loan way firm reduce credit exposures . three month end june 3 0 2 0 1 1 million wholesaleconsumer exclude credit cardcredit cardtotalpurchase $ 2 1 8 $ 1 6 6 8 $ $ 1 8 8 6 sales 8 0 5 4 0 1 1 2 0 6 retaine loan reclassify heldforsale 1 2 3 1 2 3 six month end june 3 0 2 0 1 1 million wholesaleconsumer exclude credit cardcredit cardtotalpurchase $ 3 4 1 $ 3 6 6 0 $ $ 4 0 0 1 sales 1 6 8 2 6 5 8 2 3 4 0 retained loan reclassify heldforsale 3 0 0 1 9 1 2 2 2 1 2 the follow table provide information gainslosse loan sale portfolio segment . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 net gainslosse sale loan include low cost fair value adjustmentsa wholesale $ 8 0 $ 5 1 $ 1 4 1 $ 1 3 0 consumer exclude credit card 2 8 9 8 5 3 1 2 8 credit card 4 2 4 total net gainslosse sale loan include low cost fair value adjustmentsa $ 1 0 4 $ 1 4 9 $ 1 7 0 $ 2 5 8 aexcludes sale relate loan account fair value . 1 3 5 wholesale loan portfoliowholesale loan include loan variety customer large corporate institutional client certain highnet worth individual . primary credit quality indicator wholesale loan risk rating assign loan . information risk rating note 1 4 1 5 page 2 2 0 2 4 3 jpmorgan chase 2 0 1 0 annual report . table provide information class receivable retained loan wholesale portfolio segment . commercial industrial real estatein million ratiosjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 loan risk rating investment grade $ 3 6 7 5 2 $ 3 1 6 9 7 $ 2 9 4 2 5 $ 2 8 5 0 4 noninvestment grade noncriticized 3 3 2 0 5 3 0 8 7 4 1 6 7 2 5 1 6 4 2 5 criticized performing 2 3 8 9 2 3 7 1 4 8 0 5 5 7 6 9 criticized nonaccrual 1 2 0 7 1 6 3 4 1 4 3 7 2 9 3 7 total noninvestment grade 3 6 8 0 1 3 4 8 7 9 2 2 9 6 7 2 5 1 3 1 total retain loans $ 7 3 5 5 3 $ 6 6 5 7 6 $ 5 2 3 9 2 $ 5 3 6 3 5 % total criticize total retain loans 4 . 8 9 % 6 . 0 2 % 1 1 . 9 1 % 1 6 . 2 3 % % nonaccrual loan total retain loans 1 . 6 4 2 . 4 5 2 . 7 4 5 . 4 8 loans geographic distributiona total nonu . s . $ 2 2 0 2 5 $ 1 7 7 3 1 $ 1 6 2 5 $ 1 9 6 3 total u . s . 5 1 5 2 8 4 8 8 4 5 5 0 7 6 7 5 1 6 7 2 total retained loans $ 7 3 5 5 3 $ 6 6 5 7 6 $ 5 2 3 9 2 $ 5 3 6 3 5 loan delinquencyb current 3 0 day past accruing $ 7 2 2 0 3 $ 6 4 5 0 1 $ 5 0 7 5 2 $ 5 0 2 9 9 3 0 8 9 day past accruing 1 4 0 4 3 4 1 5 5 2 9 0 9 0 day past accruingc 3 7 4 8 1 0 9 criticized nonaccrual 1 2 0 7 1 6 3 4 1 4 3 7 2 9 3 7 total retained loans $ 7 3 5 5 3 $ 6 6 5 7 6 $ 5 2 3 9 2 $ 5 3 6 3 5 au . s . nonu . s . distribution determine base predominantly domicile borrower . bfor wholesale loan past status loan generally significant indicator credit quality ongoing review monitoring obligor ability meet contractual obligation . discussion significant factor note 1 4 page 2 2 3 jpmorgan chase 2 0 1 0 annual report . crepresent loan 9 0 day past principal andor interest accrue interest loan consider wellcollateralize . dother primarily include loan special purpose entity loan private banking client . note 1 page 1 6 4 1 6 5 firm 2 0 1 0 annual report additional information spes . the follow table present additional information real estate class loan wholesale portfolio segment period indicate . information real estate loan note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . multifamily commercial lessorsin million ratiosjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 real estate retain loans $ 3 1 2 2 6 $ 3 0 6 0 4 $ 1 4 1 6 1 $ 1 5 7 9 6 criticized exposure 3 2 3 6 3 7 9 8 1 9 0 2 3 5 9 3 % criticize exposure total real estate retain loans 1 0 . 3 6 % 1 2 . 4 1 % 1 3 . 4 3 % 2 2 . 7 5 % criticized nonaccrual $ 7 6 4 $ 1 0 1 6 $ 3 4 8 $ 1 5 4 9 % criticize nonaccrual total real estate retain loans 2 . 4 5 % 3 . 3 2 % 2 . 4 6 % 9 . 8 1 % 1 3 6 table continue previous pagefinancial institution government agency otherd totalretaine loansjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 $ 2 6 8 4 8 $ 2 2 5 2 5 $ 6 7 9 7 $ 6 8 7 1 $ 6 6 6 9 1 $ 5 6 4 5 0 $ 1 6 6 5 1 3 $ 1 4 6 0 4 7 9 3 1 7 8 4 8 0 3 6 0 3 8 2 6 6 9 4 6 0 1 2 6 6 3 0 1 6 2 1 7 3 1 9 8 3 1 7 4 3 6 5 2 3 2 0 8 0 4 8 8 7 8 0 6 5 1 3 6 2 3 2 2 6 3 0 7 8 1 3 3 6 2 5 5 1 0 9 5 8 0 8 9 3 3 3 8 7 4 0 7 7 9 7 6 7 1 1 3 7 7 7 1 1 7 6 4 6 3 $ 3 6 4 2 8 $ 3 1 4 5 8 $ 7 1 8 4 $ 7 2 7 8 $ 7 4 6 6 7 $ 6 3 5 6 3 $ 2 4 4 2 2 4 $ 2 2 2 5 1 0 0 . 7 2 % 1 . 4 4 % 0 . 3 8 % 0 . 3 4 % 1 . 7 2 % 1 . 7 3 % 4 . 6 7 % 6 . 4 2 % 0 . 1 8 0 . 4 3 0 . 3 2 0 . 3 0 0 . 8 4 1 . 2 3 1 . 3 8 2 . 4 8 $ 2 5 8 9 3 $ 1 9 7 5 6 $ 1 1 7 5 $ 8 7 0 $ 3 1 3 5 1 $ 2 5 8 3 1 $ 8 2 0 6 9 $ 6 6 1 5 1 1 0 5 3 5 1 1 7 0 2 6 0 0 9 6 4 0 8 4 3 3 1 6 3 7 7 3 2 1 6 2 1 5 5 1 5 6 3 5 9 $ 3 6 4 2 8 $ 3 1 4 5 8 $ 7 1 8 4 $ 7 2 7 8 $ 7 4 6 6 7 $ 6 3 5 6 3 $ 2 4 4 2 2 4 $ 2 2 2 5 1 0 $ 3 6 2 6 1 $ 3 1 2 8 9 $ 7 1 5 8 $ 7 2 2 2 $ 7 3 4 1 9 $ 6 1 8 3 7 $ 2 3 9 7 9 3 $ 2 1 5 1 4 8 1 0 0 3 1 3 3 4 5 9 9 7 0 4 9 9 7 1 4 9 3 2 2 1 9 2 4 1 7 2 3 5 9 6 5 1 3 6 2 3 2 2 6 3 0 7 8 1 3 3 6 2 5 5 1 0 $ 3 6 4 2 8 $ 3 1 4 5 8 $ 7 1 8 4 $ 7 2 7 8 $ 7 4 6 6 7 $ 6 3 5 6 3 $ 2 4 4 2 2 4 $ 2 2 2 5 1 0 table continue previous pagecommercial construction development total real estate loansjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 $ 3 0 7 8 $ 3 3 9 5 $ 3 9 2 7 $ 3 8 4 0 $ 5 2 3 9 2 $ 5 3 6 3 5 4 4 5 6 1 9 6 5 9 6 9 6 6 2 4 2 8 7 0 6 1 4 . 4 6 % 1 8 . 2 3 % 1 6 . 7 8 % 1 8 . 1 3 % 1 1 . 9 1 % 1 6 . 2 3 % $ 1 2 7 $ 1 7 4 $ 1 9 8 $ 1 9 8 $ 1 4 3 7 $ 2 9 3 7 4 . 1 3 % 5 . 1 3 % 5 . 0 4 % 5 . 1 6 % 2 . 7 4 % 5 . 4 8 % 1 3 7 wholesale impaired loan loan modification wholesale impaired loan include loan place nonaccrual status andor modify tdr . impaired loan evaluate assetspecific allowance describe note 1 4 page 1 4 9 1 5 0 form 1 0 q . table set forth information firm wholesale impaired loan . commercialand industrial real estate financialinstitution government agency total retain loansin millionsjune 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 impaired loan allowance $ 1 1 4 3 $ 1 5 1 2 $ 1 0 7 7 $ 2 5 1 0 $ 4 4 $ 1 2 7 $ 2 3 $ 2 2 $ 5 6 5 $ 6 9 7 $ 2 8 5 2 $ 4 8 6 8 without allowancea 1 1 9 1 5 7 3 2 3 4 4 5 2 1 8 6 5 8 5 2 8 6 1 8 total impair loans $ 1 2 6 2 $ 1 6 6 9 $ 1 4 0 0 $ 2 9 5 5 $ 6 5 $ 1 3 5 $ 2 3 $ 2 2 $ 6 3 0 $ 7 0 5 $ 3 3 8 0 $ 5 4 8 6 allowance loan loss relate impair loansb $ 3 3 1 $ 4 3 5 $ 2 5 1 $ 8 2 5 $ 1 4 $ 6 1 $ 1 4 $ 1 4 $ 1 3 9 $ 2 3 9 $ 7 4 9 $ 1 5 7 4 unpaid principal balance impaired loansc 1 9 7 9 2 4 5 3 1 3 8 4 3 4 8 7 1 3 2 2 4 4 2 3 3 0 1 3 9 6 1 0 4 6 4 9 1 4 7 2 6 0 awhen discount cash flow collateral value market price equal exceed record investment loan loan require allowance . typically occur impaired loan partially chargedoff andor interest payment receive apply loan balance . bthe allowance impaired loan include jpmorgan chase assetspecific allowance loan losses . crepresent contractual principal owe june 3 0 2 0 1 1 december 3 1 2 0 1 0 unpaid principal balance differ impaired loan balance factor include chargeoff interest payment receive apply carry value net defer loan fee cost unamortized discount premium purchase loans . the follow table present firm average impaired loan period indicate . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 commercial industrial $ 1 4 2 6 $ 1 5 7 4 $ 1 4 8 6 $ 1 7 3 9 real estate 2 1 0 1 3 3 9 9 2 4 2 1 3 2 2 0 financial institutions 6 7 2 7 0 8 1 3 9 1 government agencies 2 3 4 2 2 4 other 6 3 5 8 7 2 6 3 5 9 3 4 totala $ 4 2 5 2 $ 6 1 1 9 $ 4 6 4 5 $ 6 2 8 8 athe related interest income accrue impaired loan interest income recognize cash basis material month end june 3 0 2 0 1 1 2 0 1 0 . the follow table provide information firm wholesale loan modify troubled debt restructuring tdrs . tdr loan include impaired loan table . commercialand industrial real estate financialinstitution government agency total retain loansin millionsjune 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 loan modify troubled debt restructuringsa $ 6 8 3 $ 2 1 2 $ 2 8 9 $ 9 0 7 $ $ 1 $ 2 2 $ 2 2 $ 6 $ 1 $ 1 0 0 0 $ 1 1 4 3 tdrs nonaccrual status 6 2 8 1 6 3 2 7 3 8 3 1 1 2 2 2 2 6 1 9 2 9 1 0 1 8 additional commitment lend borrower loan modify tdrs 1 8 6 1 1 8 6 1 athese modification generally provide interest rate concession borrower deferral principal repayments . 1 3 8 consumer exclude credit card loan portfolioconsumer loan exclude credit card loan consist primarily residential mortgage home equity loan line credit auto loan business banking loan student loan primary focus serve prime consumer credit market . portfolio include home equity loan secure junior lien mortgage loan interestonly payment option predominantly prime borrower certain paymentoption loan originate washington mutual result negative amortization . consumer loan pci loan riskrated loan business banking auto portfolio generally charge allowance loan loss reach specify stage delinquency accordance federal financial institution examination council ffiec policy . table provide information consumer retain loan class exclude credit card loan portfolio segment . in millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 residential real estate exclude pci home equity senior liena $ 2 2 9 6 9 $ 2 4 3 7 6 junior lienb 5 9 7 8 2 6 4 0 0 9 mortgage prime include option arms 7 4 2 7 6 7 4 5 3 9 subprime 1 0 4 4 1 1 1 2 8 7 other consumer loan auto 4 6 7 9 6 4 8 3 6 7 business banking 1 7 1 4 1 1 6 8 1 2 student other 1 4 7 7 0 1 5 3 1 1 residential real estate pci home equity 2 3 5 3 5 2 4 4 5 9 prime mortgage 1 6 2 0 0 1 7 3 2 2 subprime mortgage 5 1 8 7 5 3 9 8 option arms 2 4 0 7 2 2 5 5 8 4 total retain loans $ 3 1 5 1 6 9 $ 3 2 7 4 6 4 arepresent loan jpmorgan chase hold security interest property . brepresent loan jpmorgan chase hold security interest subordinate rank lien . delinquency rate primary credit quality indicator consumer loan exclude credit card . indicator consideration consumer loan exclude credit card includefor residential real estate loan include nonpci pci portfolio current estimate loantovalue ltv ratio combined ltv ratio case loan junior lien geographic distribution loan collateral borrower current refresh fico score . scored auto business banking loan student loan geographic distribution loan . riskrated business banking auto loan risk rating loan geographic consideration relevant loan loan consider criticize andor nonaccrual . for information consumer credit quality indicator note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . residential real estate exclude pci loan follow table provide information class residential real estate exclude pci retain loan consumer exclude credit card portfolio segment . follow factor consider analyze certain credit statistic applicable firm residential real estate exclude pci loan portfolio junior lien home equity loan fully charge loan 1 8 0 day past borrower unable unwilling repay loan value collateral support repayment loan result relatively high chargeoff rate product class ii lengthening lossmitigation timeline result high delinquency rate loan carry estimate collateral value remain firm consolidate balance sheet . 1 3 9 residential real estate exclude pci loan home equity senior lien junior lienin million ratiosjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 loan delinquencya current 3 0 day past due $ 2 2 2 5 2 $ 2 3 6 1 5 $ 5 8 3 4 5 $ 6 2 3 1 5 3 0 1 4 9 day past due 3 6 1 4 1 4 1 2 1 5 1 5 0 8 1 5 0 day past due 3 5 6 3 4 7 2 2 2 1 8 6 total retain loans $ 2 2 9 6 9 $ 2 4 3 7 6 $ 5 9 7 8 2 $ 6 4 0 0 9 % 3 0 day past total retain loans 3 . 1 2 % 3 . 1 2 % 2 . 4 0 % 2 . 6 5 % 9 0 day past accruing $ $ $ $ 9 0 day past government guaranteedb nonaccrual loans 4 8 1 4 7 9 8 2 7 7 8 4 current estimate ltv ratioscdef great 1 2 5 % refresh fico score equal great 6 6 0 $ 3 5 0 $ 3 6 3 $ 6 6 9 9 $ 6 9 2 8 less 6 6 0 1 7 6 1 9 6 2 2 5 1 2 4 9 5 1 0 1 % 1 2 5 % refresh fico score equal great 6 6 0 6 9 0 6 1 9 9 3 8 9 9 4 0 3 less 6 6 0 2 6 8 2 4 9 2 7 4 5 2 8 7 3 8 0 % 1 0 0 % refresh fico score equal great 6 6 0 1 9 5 5 1 9 0 0 1 2 4 2 3 1 3 3 3 3 less 6 6 0 6 5 3 6 5 7 2 8 3 2 3 1 5 5 less 8 0 % refresh fico score equal great 6 6 0 1 6 1 9 9 1 7 4 7 4 2 0 4 5 9 2 2 5 2 7 less 6 6 0 2 6 7 8 2 9 1 8 2 9 8 4 3 2 9 5 u . s . governmentguaranteed total retain loans $ 2 2 9 6 9 $ 2 4 3 7 6 $ 5 9 7 8 2 $ 6 4 0 0 9 geographic region california $ 3 2 0 1 $ 3 3 4 8 $ 1 3 6 9 9 $ 1 4 6 5 6 new york 3 1 6 2 3 2 7 2 1 1 6 5 8 1 2 2 7 8 texas 3 2 9 0 3 5 9 4 2 0 3 6 2 2 3 9 florida 1 0 3 3 1 0 8 8 3 2 1 5 3 4 7 0 illinois 1 5 5 3 1 6 3 5 3 9 8 7 4 2 4 8 ohio 1 8 7 1 2 0 1 0 1 4 3 8 1 5 6 8 new jersey 7 0 8 7 3 2 3 3 9 7 3 6 1 7 michigan 1 1 0 1 1 1 7 6 1 5 0 1 1 6 1 8 arizona 1 3 9 3 1 4 8 1 2 7 3 8 2 9 7 9 washington 7 3 7 7 7 6 2 0 1 7 2 1 4 2 all otherg 4 9 2 0 5 2 6 4 1 4 0 9 6 1 5 1 9 4 total retain loans $ 2 2 9 6 9 $ 2 4 3 7 6 $ 5 9 7 8 2 $ 6 4 0 0 9 a individual delinquency classification include mortgage loan insure u . s . government agency follow current 3 0 day past include $ 3 . 0 billion $ 2 . 5 billion 3 0 1 4 9 day past include $ 1 . 9 billion $ 2 . 5 billion 1 5 0 day past include $ 8 . 2 billion $ 7 . 9 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . bthese balance 9 0 day past insure u . s . government agency exclude nonaccrual loan . predominately case 1 0 0 % principal balance loan insure interest guarantee specify reimbursement rate subject meeting agree service guideline . exclude nonaccrual loan reimbursement insured guarantee proceed normally expect occur . june 3 0 2 0 1 1 december 3 1 2 0 1 0 balance include $ 5 . 7 billion $ 2 . 8 billion respectively loan longer accrue interest interest curtail u . s . government agency predominantly case 1 0 0 % principal insure . remain balance interest accrue guarantee reimbursement rate . crepresent aggregate unpaid principal balance loan divide estimate current property value . current property value estimate minimum quarterly base home valuation model utilize nationally recognize home price index valuation estimate incorporate actual datum extent available forecast datum actual datum available . property value represent actual appraise loan level collateral value result ratio necessarily imprecise view estimates . djunior lien represent combine ltv consider available lien position relate property . product present consideration subordinate lien property . erefreshed fico score represent borrower recent credit score obtain firm quarterly basis . ffor senior lien home equity loan priorperiod restate currentperiod presentation . gat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include mortgage loan insure u . s . government agency $ 1 3 . 1 billion $ 1 2 . 9 billion respectively . hat june 3 0 2 0 1 1 december 3 1 2 0 1 0 exclude mortgage loan insure u . s . government agency $ 1 0 . 1 billion $ 1 0 . 3 billion respectively . exclude reimbursement insured proceed normally . 1 4 0 table continue previous pagemortgage prime include option arm subprime total residential real estate exclude pci june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 $ 5 9 8 4 1 $ 5 9 2 2 3 $ 8 0 1 5 $ 8 4 7 7 $ 1 4 8 4 5 3 $ 1 5 3 6 3 0 3 1 3 0 4 0 5 2 8 9 6 1 1 8 4 5 6 0 2 7 1 5 8 1 1 3 0 5 1 1 2 6 4 1 5 3 0 1 6 2 6 1 3 4 1 3 1 3 4 2 3 $ 7 4 2 7 6 $ 7 4 5 3 9 $ 1 0 4 4 1 $ 1 1 2 8 7 $ 1 6 7 4 6 8 $ 1 7 4 2 1 1 5 . 9 0 % h 6 . 6 8 % h 2 3 . 2 4 % 2 4 . 9 0 % 5 . 3 5 % h 5 . 8 8 % h $ $ $ $ $ $ 9 1 2 9 9 4 1 7 9 1 2 9 9 4 1 7 4 0 2 4 4 3 2 0 2 0 5 8 2 2 1 0 7 3 9 0 7 7 9 3 $ 3 0 0 5 $ 3 0 3 9 $ 3 6 0 $ 3 3 8 $ 1 0 4 1 4 $ 1 0 6 6 8 1 4 7 7 1 5 9 5 1 1 2 0 1 1 5 3 5 0 2 4 5 4 3 9 4 6 8 3 4 7 3 3 5 2 8 5 0 6 1 5 2 9 0 1 5 2 6 1 1 7 9 3 1 7 7 5 1 4 4 6 1 4 8 6 6 2 5 2 6 3 8 3 1 0 2 5 1 1 0 7 2 0 8 8 1 9 2 5 2 5 5 1 0 2 6 8 7 8 2 6 7 4 2 7 8 6 1 7 6 1 1 9 5 5 7 9 2 0 8 5 5 3 3 2 6 6 9 3 2 3 8 5 1 9 8 9 2 2 5 2 7 1 3 1 6 7 4 6 3 8 4 6 2 5 4 5 5 7 2 3 5 6 2 6 7 2 1 2 6 4 3 1 3 4 4 2 1 3 0 9 9 1 2 9 4 9 1 3 0 9 9 1 2 9 4 9 $ 7 4 2 7 6 $ 7 4 5 3 9 $ 1 0 4 4 1 $ 1 1 2 8 7 $ 1 6 7 4 6 8 $ 1 7 4 2 1 1 $ 1 8 5 8 0 $ 1 9 2 7 8 $ 1 6 0 1 $ 1 7 3 0 $ 3 7 0 8 1 $ 3 9 0 1 2 9 8 1 7 9 5 8 7 1 2 8 8 1 3 8 1 2 5 9 2 5 2 6 5 1 8 2 7 3 1 2 5 6 9 3 2 3 3 4 5 8 3 8 0 8 7 4 7 4 6 8 8 4 8 4 0 1 3 0 9 1 4 2 2 1 0 2 4 5 1 0 8 2 0 3 8 9 2 3 7 6 5 4 2 4 4 6 8 9 8 5 6 1 0 1 1 6 4 5 2 4 6 2 2 5 4 2 7 5 4 0 1 5 4 3 1 5 2 0 1 6 2 0 2 6 4 9 1 5 3 4 6 6 1 2 6 9 0 9 9 4 3 9 6 3 2 6 6 2 9 4 3 8 1 1 4 0 5 1 1 2 4 8 1 3 2 0 2 2 1 2 4 4 5 6 0 0 6 0 2 4 1 9 7 9 2 0 5 6 2 3 0 2 4 7 4 9 6 3 5 2 2 1 2 7 9 3 0 2 7 6 7 3 4 0 3 4 4 3 4 7 5 0 9 8 0 5 2 4 7 8 $ 7 4 2 7 6 $ 7 4 5 3 9 $ 1 0 4 4 1 $ 1 1 2 8 7 $ 1 6 7 4 6 8 $ 1 7 4 2 1 1 residential real estate impair loan loan modification exclude pci loansthe firm participate u . s . treasury home affordable mha program continue expand lossmitigation effort financially distressed borrower qualify mha program . information note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . 1 4 1 the table set forth information firm residential real estate impair loan exclude pci . loan consider impair modify tdr . impaired loan evaluate assetspecific allowance describe note 1 4 page 1 4 9 1 5 0 form 1 0 q . home equity mortgage senior lien junior lien prime include option arm subprime total residential real estate exclude pciin millionsjune 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 impaired loansab allowance $ 2 4 4 $ 2 1 1 $ 4 8 9 $ 2 5 8 $ 2 8 1 2 $ 1 5 2 5 $ 2 6 6 6 $ 2 5 6 3 $ 6 2 1 1 $ 4 5 5 7 without allowancec 1 7 1 5 2 8 2 5 5 7 8 5 5 9 1 7 7 1 8 8 8 0 0 7 8 7 total impair loansd $ 2 6 1 $ 2 2 6 $ 5 1 7 $ 2 8 3 $ 3 3 9 0 $ 2 0 8 4 $ 2 8 4 3 $ 2 7 5 1 $ 7 0 1 1 $ 5 3 4 4 allowance loan loss relate impair loans $ 8 2 $ 7 7 $ 1 4 8 $ 8 2 $ 7 8 $ 9 7 $ 5 1 2 $ 5 5 5 $ 8 2 0 $ 8 1 1 unpaid principal balance impaired loanse 3 2 0 2 6 5 7 1 5 4 0 2 4 3 0 8 2 7 5 1 4 0 7 9 3 7 7 7 9 4 2 2 7 1 9 5 impaired loan nonaccrual status 5 3 3 8 2 3 2 6 3 6 9 8 5 3 4 6 9 5 6 3 2 1 6 7 8 1 2 6 7 arepresent loan modify tdr . modification generally provide interest rate concession borrower deferral principal repayments . bthere additional commitment lend borrower loan modify tdrs june 3 0 2 0 1 1 december 3 1 2 0 1 0 . cwhen discount cash flow collateral value equal exceed record investment loan loan require allowance . result typically occur impaired loan partially charge off . dat june 3 0 2 0 1 1 december 3 1 2 0 1 0 $ 3 . 5 billion $ 3 . 0 billion respectively loan modify subsequent repurchase ginnie mae accordance standard appropriate government agency i . e . federal housing administration fha u . s . department veteran affair va rural housing administration rha exclude loan account tdrs . loan perform subsequent modification accordance ginnie mae guideline generally sell ginnie mae loan pool . modify loan reperform subject foreclosure . erepresent contractual principal owe june 3 0 2 0 1 1 december 3 1 2 0 1 0 . unpaid principal balance differ impaired loan balance factor include chargeoff net deferred loan fee cost unamortized discount premium purchase loans . the follow table present average impaired loan related interest income report firm . three month end june 3 0 average impaired loan interest income onimpaire loansa interest income impaired loan cash basisain millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 home equity senior lien $ 2 4 5 $ 2 2 1 $ 2 $ 3 $ 1 $ 1 junior lien 4 6 9 2 5 5 4 5 1 1 mortgages prime include option arms 3 2 1 6 1 3 6 5 3 3 1 2 3 4 subprime 2 7 8 7 2 4 7 5 3 7 2 9 3 6 total residential real estate exclude pci $ 6 7 1 7 $ 4 3 1 6 $ 7 6 $ 4 9 $ 8 $ 1 2 six month end june 3 0 average impaired loan interest income onimpaire loansa interest income impaired loan cash basisain millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 home equity senior lien $ 2 3 8 $ 1 9 3 $ 5 $ 5 $ 1 $ 1 junior lien 4 1 1 2 6 2 8 8 1 1 mortgages prime include option arms 2 8 4 8 1 1 7 1 5 9 2 9 6 5 subprime 2 7 6 9 2 3 4 0 7 1 5 6 6 1 0 total residential real estate exclude pci $ 6 2 6 6 $ 3 9 6 6 $ 1 4 3 $ 9 8 $ 1 4 $ 1 7 a generally interest income loan modify tdr recognize cash basis time borrower minimum payment new term . june 3 0 2 0 1 1 2 0 1 0 loan $ 9 3 8 million $ 1 . 0 billion respectively tdrs borrower payment modify terms . 1 4 2 other consumer loansthe table provide information consumer retain loan class include auto business banking student loan . auto business banking student total consumer million ratiosjun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 loan delinquencya current 3 0 day past due $ 4 6 3 3 9 $ 4 7 7 7 8 $ 1 6 6 5 8 $ 1 6 2 4 0 $ 1 3 5 5 4 $ 1 3 9 9 8 $ 7 6 5 5 1 $ 7 8 0 1 6 3 0 1 1 9 day past due 4 5 0 5 7 9 2 9 9 3 5 1 7 4 2 7 9 5 1 4 9 1 1 7 2 5 1 2 0 day past due 7 1 0 1 8 4 2 2 1 4 7 4 5 1 8 6 6 5 7 4 9 total retain loans $ 4 6 7 9 6 $ 4 8 3 6 7 $ 1 7 1 4 1 $ 1 6 8 1 2 $ 1 4 7 7 0 $ 1 5 3 1 1 $ 7 8 7 0 7 $ 8 0 4 9 0 % 3 0 day past total retain loans 0 . 9 8 % 1 . 2 2 % 2 . 8 2 % 3 . 4 0 % 1 . 6 8 % d 1 . 6 1 % d 1 . 5 1 % d 1 . 7 5 % d 9 0 day past accrue b $ $ $ $ $ 5 5 8 $ 6 2 5 $ 5 5 8 $ 6 2 5 nonaccrual loans 1 1 1 1 4 1 7 7 0 8 3 2 7 9 6 7 9 6 0 1 0 4 0 geographic region california $ 4 2 6 0 $ 4 3 0 7 $ 1 1 1 4 $ 8 5 1 $ 1 2 8 6 $ 1 3 3 0 $ 6 6 6 0 $ 6 4 8 8 new york 3 6 1 6 3 8 7 5 2 8 6 5 2 8 7 7 1 2 6 7 1 3 0 5 7 7 4 8 8 0 5 7 texas 4 4 2 3 4 5 0 5 2 6 1 2 2 5 5 0 1 2 1 9 1 2 7 3 8 2 5 4 8 3 2 8 florida 1 8 3 3 1 9 2 3 2 4 8 2 2 0 6 9 6 7 2 2 2 7 7 7 2 8 6 5 illinois 2 4 1 3 2 6 0 8 1 3 3 1 1 3 2 0 9 1 5 9 4 0 4 6 5 9 4 8 6 8 ohio 2 7 3 8 2 9 6 1 1 6 0 2 1 6 4 7 9 7 0 1 0 1 0 5 3 1 0 5 6 1 8 new jersey 1 8 0 4 1 8 4 2 2 3 3 4 2 2 4 8 8 5 0 2 2 5 2 5 2 7 6 6 michigan 2 3 0 8 2 4 3 4 1 3 8 7 1 4 0 1 6 9 9 7 2 9 4 3 9 4 4 5 6 4 arizona 1 5 2 6 1 4 9 9 1 1 9 0 1 2 1 8 3 6 6 3 8 7 3 0 8 2 3 1 0 4 washington 7 3 1 7 1 6 1 4 2 1 1 5 2 7 0 2 7 9 1 1 4 3 1 1 1 0 other 2 1 1 4 4 2 1 6 9 7 4 4 1 7 4 1 9 1 6 5 9 4 6 8 3 4 3 2 1 5 5 3 2 7 2 2 total retain loans $ 4 6 7 9 6 $ 4 8 3 6 7 $ 1 7 1 4 1 $ 1 6 8 1 2 $ 1 4 7 7 0 $ 1 5 3 1 1 $ 7 8 7 0 7 $ 8 0 4 9 0 loan risk ratingsc noncriticized $ 5 7 0 2 $ 5 8 0 3 $ 1 1 1 1 4 $ 1 0 3 5 1 na na $ 1 6 8 1 6 $ 1 6 1 5 4 criticize performing 1 9 1 2 6 5 8 2 7 9 8 2 na na 1 0 1 8 1 2 4 7 criticize nonaccrual 1 1 2 5 5 7 5 7 4 na na 5 5 8 5 8 6 aloan insure u . s . government agency federal family education loan program ffelp include delinquency classification present base payment status . priorperiod revise conform currentperiod presentation . bthese represent student loan insure u . s . government agency ffelp . accrue reimbursement insured proceed normally . cfor riskrate business banking auto loan primary credit quality indicator risk rating loan include loan consider criticize andor nonaccrual . djune 3 0 2 0 1 1 december 3 1 2 0 1 0 exclude loan 3 0 day past accrue insure u . s . government agency ffelp $ 9 6 8 million $ 1 . 1 billion respectively . exclude reimbursement insured proceed normally . 1 4 3 other consumer impair loansthe table set forth information firm consumer impair loan include riskrate business banking auto loan place nonaccrual status loan modify tdr . auto business banking total consumercin millionsjun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 impaired loan allowance $ 8 8 $ 1 0 2 $ 7 5 8 $ 7 7 4 $ 8 4 6 $ 8 7 6 without allowancea 1 1 total impaired loans $ 8 9 $ 1 0 2 $ 7 5 8 $ 7 7 4 $ 8 4 7 $ 8 7 6 allowance loan loss relate impair loans $ 1 2 $ 1 6 $ 2 1 7 $ 2 4 8 $ 2 2 9 $ 2 6 4 unpaid principal balance impair loansb 1 2 2 1 3 2 8 7 2 8 9 9 9 9 4 1 0 3 1 impaired loan nonaccrual status 3 9 5 0 5 9 8 6 4 7 6 3 7 6 9 7 awhen discount cash flow collateral value market price equal exceed record investment loan loan require allowance . typically occur impaired loan partially charge andor interest payment receive apply loan balance . brepresent contractual principal owe june 3 0 2 0 1 1 december 3 1 2 0 1 0 . unpaid principal balance differ impaired loan balance factor include chargeoff interest payment receive apply principal balance net defer loan fee cost unamortized discount premium purchase loans . cthere impaired student loan june 3 0 2 0 1 1 december 3 1 2 0 1 0 . the follow table present average impaired loan . average impaired loansb month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 auto $ 9 2 $ 1 3 0 $ 9 5 $ 1 2 8 business banking 7 6 4 6 4 6 7 6 8 5 7 8 total consumera $ 8 5 6 $ 7 7 6 $ 8 6 3 $ 7 0 6 a student loan modify tdrs june 3 0 2 0 1 1 2 0 1 0 . b related interest income impaired loan include cash basis material month end june 3 0 2 0 1 1 2 0 1 0 . the follow table provide information firm consumer loan modify tdrs . tdr loan include impaired loan table . auto business banking total consumercin millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 loan modify troubled debt restructuringsab $ 8 8 $ 9 1 $ 4 2 9 $ 3 9 5 $ 5 1 7 $ 4 8 6 tdrs nonaccrual status 3 8 3 9 2 6 9 2 6 8 3 0 7 3 0 7 athese modification generally provide interest rate concession borrower deferral principal repayments . badditional commitment lend borrower loan modify tdrs june 3 0 2 0 1 1 december 3 1 2 0 1 0 immaterial . cthere student loan modify tdrs june 3 0 2 0 1 1 december 3 1 2 0 1 0 . 1 4 4 purchase creditimpaire pci loansfor detailed discussion pci loan include related accounting policy note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . residential real estate pci loansthe table set forth information firm consumer exclude credit card pci loan . home equity prime mortgage subprime mortgage option arm total pciin million ratiosjun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 carrying valuea $ 2 3 5 3 5 $ 2 4 4 5 9 $ 1 6 2 0 0 $ 1 7 3 2 2 $ 5 1 8 7 $ 5 3 9 8 $ 2 4 0 7 2 $ 2 5 5 8 4 $ 6 8 9 9 4 $ 7 2 7 6 3 related allowance loan lossesb 1 5 8 3 1 5 8 3 1 7 6 6 1 7 6 6 9 8 9 8 1 4 9 4 1 4 9 4 4 9 4 1 4 9 4 1 loan delinquency base unpaid principal balance current 3 0 day past due $ 2 4 2 2 3 $ 2 5 7 8 3 $ 1 2 3 9 6 $ 1 3 0 3 5 $ 4 3 6 4 $ 4 3 1 2 $ 1 8 2 0 8 $ 1 8 6 7 2 $ 5 9 1 9 1 $ 6 1 8 0 2 3 0 1 4 9 day past due 1 1 1 4 1 3 4 8 1 1 2 9 1 4 6 8 7 9 3 1 0 2 0 1 6 3 6 2 2 1 5 4 6 7 2 6 0 5 1 1 5 0 day past due 1 2 7 4 1 1 8 1 3 9 4 8 4 4 2 5 2 5 2 0 2 7 1 0 8 6 0 1 9 9 0 4 1 6 3 4 3 1 8 2 2 0 total loans $ 2 6 6 1 1 $ 2 8 3 1 2 $ 1 7 4 7 3 $ 1 8 9 2 8 $ 7 6 7 7 $ 8 0 4 2 $ 2 8 4 4 5 $ 3 0 7 9 1 $ 8 0 2 0 6 $ 8 6 0 7 3 % 3 0 day past total loans 8 . 9 7 % 8 . 9 3 % 2 9 . 0 6 % 3 1 . 1 3 % 4 3 . 1 5 % 4 6 . 3 8 % 3 5 . 9 9 % 3 9 . 3 6 % 2 6 . 2 0 % 2 8 . 2 0 % current estimate ltv ratio base unpaid principal balancecde great 1 2 5 % refresh fico score equal great 6 6 0 $ 6 0 6 6 $ 6 2 8 9 $ 2 1 6 8 $ 2 4 0 0 $ 4 5 0 $ 4 3 2 $ 2 3 7 7 $ 2 6 8 1 $ 1 1 0 6 1 $ 1 1 8 0 2 less 6 6 0 3 6 3 5 4 0 4 3 2 6 0 4 2 7 4 4 2 0 7 2 2 1 2 9 5 5 9 5 6 3 3 0 1 3 9 0 6 1 5 2 4 6 1 0 1 % 1 2 5 % refresh fico score equal great 6 6 0 5 7 3 3 6 0 5 3 3 4 6 6 3 8 1 5 4 2 4 4 2 4 4 0 1 6 4 2 9 2 1 3 6 3 9 1 4 5 8 4 less 6 6 0 2 5 4 6 2 6 9 6 2 8 1 4 3 0 1 1 1 6 6 1 1 6 6 3 4 6 9 5 5 0 0 5 1 1 7 1 6 1 2 3 7 5 8 0 % 1 0 0 % refresh fico score equal great 6 6 0 3 7 0 4 3 9 9 5 1 8 7 0 1 9 7 0 3 4 1 3 7 4 3 8 4 9 4 1 5 2 9 7 6 4 1 0 4 9 1 less 6 6 0 1 3 8 3 1 4 8 2 1 6 9 0 1 8 5 7 1 3 6 5 1 4 7 7 3 4 1 8 3 5 5 1 7 8 5 6 8 3 6 7 lower 8 0 % refresh fico score equal great 6 6 0 2 5 0 3 2 6 4 1 1 3 0 6 1 4 4 3 1 7 8 1 8 6 2 1 6 3 2 2 8 1 6 1 5 0 6 5 5 1 less 6 6 0 1 0 4 1 1 1 1 3 1 5 5 5 1 6 8 8 1 1 8 6 1 3 5 7 2 3 3 2 2 4 9 9 6 1 1 4 6 6 5 7 total unpaid principal balance $ 2 6 6 1 1 $ 2 8 3 1 2 $ 1 7 4 7 3 $ 1 8 9 2 8 $ 7 6 7 7 $ 8 0 4 2 $ 2 8 4 4 5 $ 3 0 7 9 1 $ 8 0 2 0 6 $ 8 6 0 7 3 geographic region base unpaid principal balance california $ 1 6 0 0 2 $ 1 7 0 1 2 $ 9 9 8 1 $ 1 0 8 9 1 $ 1 8 2 4 $ 1 9 7 1 $ 1 4 8 1 1 $ 1 6 1 3 0 $ 4 2 6 1 8 $ 4 6 0 0 4 new york 1 2 4 5 1 3 1 6 1 0 6 4 1 1 1 1 7 2 1 7 3 6 1 6 2 3 1 7 0 3 4 6 5 3 4 8 6 6 texas 4 8 7 5 2 5 1 7 6 1 9 4 4 2 0 4 3 5 1 4 7 1 5 5 1 2 3 0 1 3 0 9 florida 2 4 4 9 2 5 9 5 1 4 0 7 1 5 1 9 8 8 0 9 0 6 3 5 8 1 3 9 1 6 8 3 1 7 8 9 3 6 illinois 5 9 1 6 2 7 5 3 5 5 6 2 4 2 7 4 3 8 7 4 1 7 6 0 2 2 9 4 2 3 8 7 ohio 3 4 3 8 8 6 9 1 1 1 9 1 2 2 1 1 9 1 3 1 3 5 8 3 8 2 new jersey 5 0 6 5 4 0 4 6 7 4 8 6 3 0 8 3 1 6 1 0 2 0 1 0 6 4 2 3 0 1 2 4 0 6 michigan 8 8 9 5 2 5 5 2 7 9 1 9 9 2 1 4 2 9 7 3 4 5 8 3 9 9 3 3 arizona 5 0 4 5 3 9 2 9 9 3 5 9 1 4 5 1 6 5 4 4 1 5 2 8 1 3 8 9 1 5 9 1 washington 1 4 4 5 1 5 3 5 4 2 2 4 5 1 1 7 4 1 7 8 7 0 4 7 4 5 2 7 4 5 2 9 0 9 all other 3 2 6 0 3 4 9 0 2 7 8 1 2 9 8 5 2 4 6 0 2 5 6 1 4 9 6 1 5 3 1 4 1 3 4 6 2 1 4 3 5 0 total unpaid principal balance $ 2 6 6 1 1 $ 2 8 3 1 2 $ 1 7 4 7 3 $ 1 8 9 2 8 $ 7 6 7 7 $ 8 0 4 2 $ 2 8 4 4 5 $ 3 0 7 9 1 $ 8 0 2 0 6 $ 8 6 0 7 3 acarrying value include effect fair value adjustment apply consumer pci portfolio date acquisition . bmanagement conclude firm regular assessment pci loan pool probable high expect principal credit loss result decrease expect cash flow . result allowance loan loss impairment pool recognized . crepresent aggregate unpaid principal balance loan divide estimate current property value . current property value estimate minimum quarterly base home valuation model utilize nationally recognize home price index valuation estimate incorporate actual datum extent available forecast datum actual datum available . property value represent actual appraise loan level collateral value result ratio necessarily imprecise view estimate . current estimate combined ltv junior lien home equity loan consider available lien position relate property . drefreshed fico score represent borrower recent credit score obtain firm . firm obtain refresh fico score quarterly . efor home equity loan priorperiod restate conform currentperiod presentation . 1 4 5 the table set forth accretable yield activity firm pci consumer loan month end june 3 0 2 0 1 1 2 0 1 0 represent firm estimate gross interest income expect earn remain life pci loan portfolio . table exclude cost fund pci portfolio represent net interest income expect earn portfolio . total pci month end june 3 0 month end june 3 0 million ratios 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 beginning balance $ 1 8 8 1 6 $ 2 0 5 7 1 $ 1 9 0 9 7 $ 2 5 5 4 4 accretion interest income 7 0 6 7 8 7 1 4 1 0 1 6 7 3 change interest rate variablerate loans 1 8 1 3 3 3 2 1 3 7 2 7 other change expect cash flowsa 1 5 4 1 7 0 6 0 9 3 5 2 3 balance june 3 0 $ 1 8 0 8 3 $ 1 9 6 2 1 $ 1 8 0 8 3 $ 1 9 6 2 1 accretable yield percentage 4 . 3 6 % 4 . 2 0 % 4 . 3 2 % 4 . 3 9 % aother change expect cash flow vary period period firm continue refine cash flow model periodically update model assumption . month end june 3 0 2 0 1 1 change expect cash flow principally drive change prepayment assumption . month end june 3 0 2 0 1 0 change expect cash flow principally drive change prepayment assumption reclassification nonaccretable difference . change prepayment assumption change expect remain life portfolio drive change expect future interest cash collection . change significant impact accretable yield percentage . the factor significantly affect estimate gross cash flow expect collect accordingly accretable yield balance include change benchmark interest rate index variablerate product option arm home equity loan ii change prepayment assumptions . since date acquisition decrease accretable yield percentage primarily relate decrease interest rate variablerate loan extent extend loan liquidation period . certain event extended loan liquidation period affect timing expect cash flow cash expect receive i . e . accretable yield balance . extended loan liquidation period reduce accretable yield percentage accretable yield balance recognize higherthanexpected loan balance longerthanexpected period time . 1 4 6 credit card loan portfoliothe credit card portfolio segment include credit card loan originate purchase firm include acquire washington mutual transaction . delinquency rate primary credit quality indicator credit card loan . addition delinquency rate geographic distribution loan provide insight credit quality portfolio base regional economy . the borrower credit score general indicator credit quality . credit score tend lagging indicator credit quality firm use credit score primary indicator credit quality . information credit quality indicator note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . firm generally originate new card account prime consumer borrower . certain cardholder refresh fico score change time depend performance cardholder change credit score technology . the table set forth information firm credit card loan . chase excludingwashington mutual portfolioc washington mutual portfolioc total credit cardin million ratiosjun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 loan delinquencya current 3 0 day past accruing $ 1 1 0 6 7 6 $ 1 1 7 2 4 8 $ 1 1 1 0 7 $ 1 2 6 7 0 $ 1 2 1 7 8 3 $ 1 2 9 9 1 8 3 0 8 9 day past accruing 1 4 8 7 2 0 9 2 3 0 1 4 5 9 1 7 8 8 2 5 5 1 9 0 day past accruing 1 6 0 1 2 4 4 9 3 4 9 6 0 4 1 9 5 0 3 0 5 3 nonaccrual loans 2 2 2 2 total retain loans $ 1 1 3 7 6 6 $ 1 2 1 7 9 1 $ 1 1 7 5 7 $ 1 3 7 3 3 $ 1 2 5 5 2 3 $ 1 3 5 5 2 4 loan delinquency ratio % 3 0 plus day past total retain loans 2 . 7 1 % 3 . 7 3 % 5 . 5 3 % 7 . 7 4 % 2 . 9 8 % 4 . 1 4 % % 9 0 plus day past total retain loans 1 . 4 1 2 . 0 1 2 . 9 7 4 . 4 0 1 . 5 5 2 . 2 5 credit card loan geographic region california $ 1 4 4 2 1 $ 1 5 4 5 4 $ 2 2 5 6 $ 2 6 5 0 $ 1 6 6 7 7 $ 1 8 1 0 4 new york 9 0 0 0 9 5 4 0 8 8 5 1 0 3 2 9 8 8 5 1 0 5 7 2 texas 8 8 1 2 9 2 1 7 8 6 8 1 0 0 6 9 6 8 0 1 0 2 2 3 florida 6 1 9 2 6 7 2 4 9 8 7 1 1 6 5 7 1 7 9 7 8 8 9 illinois 6 6 4 8 7 0 7 7 4 6 6 5 4 2 7 1 1 4 7 6 1 9 new jersey 4 7 4 3 5 0 7 0 4 2 2 4 9 4 5 1 6 5 5 5 6 4 ohio 4 6 2 2 5 0 3 5 3 4 3 4 0 1 4 9 6 5 5 4 3 6 pennsylvania 4 1 2 3 4 5 2 1 3 6 4 4 2 4 4 4 8 7 4 9 4 5 michigan 3 5 9 5 3 9 5 6 2 3 3 2 7 3 3 8 2 8 4 2 2 9 virginia 2 8 4 1 3 0 2 0 2 5 4 2 9 5 3 0 9 5 3 3 1 5 georgia 2 5 9 6 2 8 3 4 3 3 9 3 9 8 2 9 3 5 3 2 3 2 washington 1 9 5 9 2 0 5 3 3 8 0 4 3 8 2 3 3 9 2 4 9 1 all other 4 4 2 1 4 4 7 2 9 0 3 9 6 0 4 6 1 5 4 8 1 7 4 5 1 9 0 5 total retain loans $ 1 1 3 7 6 6 $ 1 2 1 7 9 1 $ 1 1 7 5 7 $ 1 3 7 3 3 $ 1 2 5 5 2 3 $ 1 3 5 5 2 4 percentage portfolio base carry value estimate refresh fico scoresb equal great 6 6 0 8 2 . 7 % 8 0 . 6 % 6 0 . 4 % 5 6 . 4 % 8 0 . 4 % 7 7 . 9 % less 6 6 0 1 7 . 3 1 9 . 4 3 9 . 6 4 3 . 6 1 9 . 6 2 2 . 1 athe firm policy generally exempt credit card loan place nonaccrual status permit regulatory guidance . guidance issue federal financial institution examination council ffiec credit card loan charge end month account 1 8 0 day past 6 0 day receive notification specify event e . g . bankruptcy borrower whichever earlier . brefreshe fico score estimate base statistically significant random sample credit card account credit card portfolio period . firm obtain refresh fico score quarterly . cinclude bill finance charge fee net allowance uncollectible amounts . 1 4 7 credit card impair loansfor detailed discussion impaired credit card loan include credit card loan modification note 1 4 page 2 2 0 2 3 8 jpmorgan chase 2 0 1 0 annual report . the table set forth information firm impair credit card loan . loan consider impair modify tdrs . base historical experience estimate weightedaverage ultimate default rate modify credit card loan 3 7 . 4 0 % june 3 0 2 0 1 1 3 6 . 4 5 % december 3 1 2 0 1 0 . chase exclude washington mutual portfolio washington mutual portfolio total credit cardin millionsjun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 jun 3 0 2 0 1 1 dec 3 1 2 0 1 0 impaired loan allowanceab credit card loan modify payment termsc $ 5 8 2 0 $ 6 6 8 5 $ 1 3 4 5 $ 1 5 7 0 $ 7 1 6 5 $ 8 2 5 5 modified credit card loan revert premodification payment termsd 1 0 8 3 1 4 3 9 2 3 6 3 1 1 1 3 1 9 1 7 5 0 total impair loans $ 6 9 0 3 $ 8 1 2 4 $ 1 5 8 1 $ 1 8 8 1 $ 8 4 8 4 $ 1 0 0 0 5 allowance loan loss relate impair loans $ 2 7 6 5 $ 3 1 7 5 $ 6 8 6 $ 8 9 4 $ 3 4 5 1 $ 4 0 6 9 athe carry value unpaid principal balance credit card impair loans . bthere impaired loan allowance . crepresent credit card loan outstanding borrower enrol credit card modification program date presented . drepresent credit card loan modify tdrs subsequently revert loan premodification payment term . june 3 0 2 0 1 1 december 3 1 2 0 1 0 approximately $ 8 5 0 million $ 1 . 2 billion respectively loan revert premodification payment term loan noncompliance term modify loan . substantial portion loan expect chargedoff accordance firm standard chargeoff policy . remain $ 4 6 9 million $ 5 9 0 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively loan borrower successfully complete shortterm modification program . firm continue report loan tdrs borrower credit line remain closed . follow table present average balance impaired credit card loan interest income recognize loan . average impaired loan interest income impaired loansa month end june 3 0 month end june 3 0 month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 chase exclude washington mutual portfolio $ 7 2 0 5 $ 8 9 6 5 $ 7 4 5 6 $ 8 9 3 8 $ 9 4 $ 1 2 1 $ 1 9 5 $ 2 4 0 washington mutual portfolio 1 6 5 9 2 0 2 2 1 7 2 1 1 9 9 7 2 7 3 1 5 6 6 2 total credit card $ 8 8 6 4 $ 1 0 9 8 7 $ 9 1 7 7 $ 1 0 9 3 5 $ 1 2 1 $ 1 5 2 $ 2 5 1 $ 3 0 2 aas permit regulatory guidance credit card loan generally exempt place nonaccrual status accordingly interest fee relate credit card loan continue accrue loan charge pay . firm separately establish allowance estimate uncollectible portion bill accrue interest fee income credit card loans . 1 4 8 note 1 4 allowance credit lossesfor detailed discussion allowance credit loss related accounting policy note 1 5 page 2 3 9 2 4 3 jpmorgan chase 2 0 1 0 annual report . allowance credit loss loan lendingrelated commitment impairment methodologythe table summarize information allowance loan loss loan impairment methodology . 2 0 1 1 2 0 1 0 six month end june 3 0 millionswholesaleconsumerexclude credit card credit cardtotal wholesaleconsumerexcluding credit card credit cardtotalallowance loan loss begin balance january 1 $ 4 7 6 1 $ 1 6 4 7 1 $ 1 1 0 3 4 $ 3 2 2 6 6 $ 7 1 4 5 $ 1 4 7 8 5 $ 9 6 7 2 $ 3 1 6 0 2 cumulative effect change accounting principlesa 1 4 1 2 7 7 3 5 3 7 4 9 4 gross chargeoffs 3 8 7 2 8 1 7 4 7 6 2 7 9 6 6 1 2 7 8 4 4 2 9 8 9 4 5 1 4 6 5 2 gross recoveries 1 4 2 2 7 5 7 2 6 1 1 4 3 8 8 2 2 8 7 1 2 1 0 2 8 net chargeoffs 2 4 5 2 5 4 2 4 0 3 6 6 8 2 3 1 1 9 0 4 2 0 1 8 2 3 3 1 3 6 2 4 provision loan losses 4 1 4 2 4 4 6 1 0 3 6 3 0 6 8 8 1 2 5 4 5 0 5 7 3 3 1 0 3 7 1 other 1 1 1 2 8 9 9 3 1 7 ending balance june 3 0 $ 4 0 9 1 $ 1 6 3 8 7 $ 8 0 4 2 $ 2 8 5 2 0 $ 5 1 4 8 $ 1 6 1 6 4 $ 1 4 5 2 4 $ 3 5 8 3 6 allowance loan loss impairment methodology assetspecificbcd $ 7 4 9 $ 1 0 4 9 $ 3 4 5 1 $ 5 2 4 9 $ 1 3 2 4 $ 1 0 9 1 $ 4 8 4 6 $ 7 2 6 1 formulabasedd 3 3 4 2 1 0 3 9 7 4 5 9 1 1 8 3 3 0 3 8 2 4 1 2 2 6 2 9 6 7 8 2 5 7 6 4 pci 4 9 4 1 4 9 4 1 2 8 1 1 2 8 1 1 total allowance loan losses $ 4 0 9 1 $ 1 6 3 8 7 $ 8 0 4 2 $ 2 8 5 2 0 $ 5 1 4 8 $ 1 6 1 6 4 $ 1 4 5 2 4 $ 3 5 8 3 6 loans impairment methodology assetspecific $ 3 3 8 0 $ 7 8 5 8 $ 8 4 8 4 $ 1 9 7 2 2 $ 5 6 6 1 $ 5 4 2 8 $ 1 0 8 8 7 $ 2 1 9 7 6 formulabased 2 4 0 7 9 0 2 3 8 3 1 7 1 1 7 0 3 9 5 9 6 1 4 6 2 0 7 2 3 2 2 5 6 9 0 0 1 3 2 1 0 7 5 9 6 2 3 9 pci 5 4 6 8 9 9 4 6 9 0 4 8 9 4 7 6 9 0 1 7 6 9 9 5 total retain loans $ 2 4 4 2 2 4 $ 3 1 5 1 6 9 $ 1 2 5 5 2 3 $ 6 8 4 9 1 6 $ 2 1 2 9 8 7 $ 3 3 9 2 2 9 $ 1 4 2 9 9 4 $ 6 9 5 2 1 0 impair collateraldependent loan net chargeoffse $ 5 9 $ 5 3 $ $ 1 1 2 $ 2 9 7 $ 2 2 7 $ $ 5 2 4 loans measure fair value collateral cost selle 1 1 4 4 8 6 3 f 2 0 0 7 2 0 6 4 8 0 1 f 2 8 6 5 aeffective january 1 2 0 1 0 firm adopt accounting guidance relate vie . adoption guidance firm consolidate firmsponsore credit card securitization trust firmadministered multiseller conduit certain consumer loan securitization entity primarily mortgagerelate . result $ 7 . 4 billion $ 1 4 million $ 1 2 7 million respectively allowance loan loss record onbalance sheet consolidation entity . discussion note 1 6 page 2 4 4 2 5 9 jpmorgan chase 2 0 1 0 annual report . brelate riskrate loan place nonaccrual status loan modify troubled debt restructuring . cat june 3 0 2 0 1 1 2 0 1 0 assetspecific consumer exclude credit card allowance loan loss include troubled debt restructure reserve $ 9 6 2 million $ 9 4 6 million respectively . assetspecific credit card allowance loan loss relate loan modify tdrs . dat june 3 0 2 0 1 1 2 0 1 0 firm allowance loan loss impaired credit card loan reclassify assetspecific allowance . reclassification incremental impact firm allowance loan loss . prior period revise reflect current presentation . eprior period revise conform current presentation . finclude collateraldependent residential mortgage loan charge fair value underlie collateral cost sell . loan consider collateraldependent regulatory guidance involve modification interestonly period provide significant portion principal deferred . 1 4 9 the table summarize information allowance lendingrelated commitment lendingrelated commitment impairment methodology . 2 0 1 1 2 0 1 0 six month end june 3 0 millionswholesaleconsumerexclude credit cardcredit cardtotal wholesaleconsumerexcluding credit cardcredit cardtotalallowance lendingrelated commitment begin balance january 1 $ 7 1 1 $ 6 $ $ 7 1 7 $ 9 2 7 $ 1 2 $ $ 9 3 9 cumulative effect change accounting principlesa 1 8 1 8 provision lendingrelate commitments 8 9 8 9 4 2 2 other 2 2 1 1 1 1 ending balance june 3 0 $ 6 2 0 $ 6 $ $ 6 2 6 $ 9 0 2 $ 1 0 $ $ 9 1 2 allowance lendingrelated commitment impairment methodology assetspecific $ 1 4 4 $ $ $ 1 4 4 $ 2 4 8 $ $ $ 2 4 8 formulabased 4 7 6 6 4 8 2 6 5 4 1 0 6 6 4 total allowance lendingrelate commitments $ 6 2 0 $ 6 $ $ 6 2 6 $ 9 0 2 $ 1 0 $ $ 9 1 2 lendingrelated commitment impairment methodology assetspecific $ 7 9 3 $ $ $ 7 9 3 $ 1 1 9 5 $ $ $ 1 1 9 5 formulabased 3 6 4 8 9 6 6 4 6 4 9 5 3 5 6 2 5 9 6 5 1 7 0 3 2 3 3 5 7 6 9 4 9 9 5 5 0 4 4 2 9 4 3 2 9 8 total lendingrelate commitments $ 3 6 5 6 8 9 $ 6 4 6 4 9 $ 5 3 5 6 2 5 $ 9 6 5 9 6 3 $ 3 2 4 5 5 2 $ 6 9 4 9 9 $ 5 5 0 4 4 2 $ 9 4 4 4 9 3 aeffective january 1 2 0 1 0 firm adopt accounting guidance relate vie . adoption guidance firm consolidate administer multiseller conduit . result relate asset primarily record loan asset consolidated balance sheet . 1 5 0 note 1 5 variable interest entitiesfor description jpmorgan chase accounting policy regard consolidation vie detailed discussion firm principal involvement vie note 1 page 1 6 4 1 6 5 note 1 6 page 2 4 4 2 5 9 respectively jpmorgan chase 2 0 1 0 annual report . the follow table summarize significant type firmsponsore vie business segment . lineofbusinesstransaction typeactivityform 1 0 q page referencecardcredit card securitization trustssecuritization originate purchase credit card receivables 1 5 1 securitization trustssecuritization originated automobile student loans 1 5 1 1 5 3 rfsmortgage securitization trustssecuritization originated purchase residential mortgages 1 5 1 1 5 3 ibmortgage securitization trustssecuritization originate purchase residential commercial mortgage automobile student loans 1 5 1 1 5 3 multiseller conduitsinvestor intermediation activitiesassist client access financial market costefficient manner structure transaction meet investor needs 1 5 3 municipal bond vehicle 1 5 3 1 5 4 creditrelate note asset swap vehicle 1 5 4 the firm invest provide financing service vie sponsor party describe page 1 5 4 note page 2 5 3 jpmorgan chase 2 0 1 0 annual report . significant firmsponsore variable interest entitiescredit card securitizationsfor detailed discussion jpmorgan chase involvement credit card securitization page 2 4 5 2 4 6 jpmorgan chase 2 0 1 0 annual report . as result firm continue involvement firm consider primary beneficiary firmsponsore credit card securitization trust . include firm primary card securitization trust chase issuance trust . firm consolidate $ 5 2 . 7 billion $ 6 8 . 5 billion asset hold firmsponsore creditcard securitization trust $ 3 5 . 7 billion $ 4 4 . 3 billion beneficial interest issue party june 3 0 2 0 1 1 december 3 1 2 0 1 0 . the underlie securitized credit card receivables asset available payment beneficial interest issue securitization trust available pay firm obligation claim firm creditors . firmsponsore mortgage securitization trustsfor detailed description firm involvement firmsponsore mortgage securitization trust accounting treatment relate trust note 1 6 page 2 4 6 jpmorgan chase 2 0 1 0 annual report . the follow table present total unpaid principal asset hold firmsponsore securitization entity firm continue involvement include consolidate consolidate firm . continue involvement include service loan hold senior interest subordinated interest recourse guarantee arrangement derivative transaction . certain instance firm continue involvement service loan . table beneficial interest hold jpmorgan chase equal asset hold nonconsolidated vie existence beneficial interest hold party reflect current outstanding par portion firm retain interest trade asset afs security reflect fair value . securitization activity page 1 5 6 1 5 8 note information regard firm cash flow interest retain nonconsolidated vie . 1 5 1 principal outstanding jpmorgan chase interest securitize asset nonconsolidated viesdefghjune 3 0 2 0 1 1 a billionstotal asset hold securitization viesasset hold consolidated securitization viesasset hold nonconsolidated securitization vie continue involvement trading assetsafssecuritiestotal interest hold jpmorgan chasesecuritizationrelate residential mortgage primeb $ 1 4 0 . 3 $ 2 . 2 $ 1 3 2 . 0 $ 0 . 7 $ $ 0 . 7 subprime 4 1 . 6 1 . 4 3 8 . 5 option arms 3 3 . 7 0 . 3 3 3 . 4 commercial otherc 1 4 4 . 3 9 6 . 4 1 . 6 0 . 7 2 . 3 student 4 . 3 4 . 3 total $ 3 6 4 . 2 $ 8 . 2 $ 3 0 0 . 3 i $ 2 . 3 $ 0 . 7 $ 3 . 0 principal outstanding jpmorgan chase interest securitize asset nonconsolidate viesdefghdecember 3 1 2 0 1 0 a billionstotal asset hold securitization viesasset hold consolidated securitization viesasset hold nonconsolidated securitization vie continue involvement trading assetsafssecuritiestotal interest hold jpmorgan chasesecuritizationrelate residential mortgage primeb $ 1 5 3 . 1 $ 2 . 2 $ 1 4 3 . 8 $ 0 . 7 $ $ 0 . 7 subprime 4 4 . 0 1 . 6 4 0 . 7 option arms 3 6 . 1 0 . 3 3 5 . 8 commercial otherc 1 5 3 . 4 1 0 6 . 2 2 . 0 0 . 9 2 . 9 student 4 . 5 4 . 5 total $ 3 9 1 . 1 $ 8 . 6 $ 3 2 6 . 5 i $ 2 . 7 $ 0 . 9 $ 3 . 6 aexcludes loan sale u . s . government agency . page 1 5 7 note information firm loan sale u . s . government agencies . binclude alta loans . cconsist security commercial loan predominantly real estate nonmortgagerelated consumer receivable purchase party . firm generally retain residual interest sponsored commercial mortgage securitization transaction . include cosponsor commercial securitization include nonjpmorgan chaseoriginate commercial mortgage loans . dexclude retain servicing discussion msrs note 1 6 page 1 5 9 1 6 3 form 1 0 q security retain loan sale u . s . government agencies . eexclude senior subordinated security $ 1 6 5 million $ 2 8 million respectively june 3 0 2 0 1 1 $ 1 8 2 million $ 1 8 million respectively december 3 1 2 0 1 0 firm purchase connection ibs secondary marketmaking activity . fexclude interest rate foreign exchange derivative primarily use manage interest rate foreign exchange risk securitization entity . note 5 page 1 1 7 1 2 4 form 1 0 q information derivatives . ginclude interest hold resecuritization transaction . june 3 0 2 0 1 1 december 3 1 2 0 1 0 6 6 % 6 6 % respectively firm retain securitization interest carry fair value riskrate spequivalent basis . include $ 1 7 5 million $ 1 5 7 million investmentgrade $ 4 8 0 million $ 5 5 2 million noninvestmentgrade retain interest prime residential mortgage june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively $ 2 . 0 billion $ 2 . 6 billion investmentgrade $ 2 8 2 million $ 2 5 0 million noninvestmentgrade retain interest commercial securitization trusts . ithe firm consolidate mortgage securitization servicer power direct significant activity trust hold beneficial interest trust potentially significant trust . june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm consolidate asset firmsponsore nonconsolidated residential mortgage securitization vie firm continue involvement primarily fact firm hold interest trust potentially significant trust . additionally commercial mortgage securitizationrelate vie firm service loan consolidate vie . resecuritization firm engage certain resecuritization transaction debt security transfer vie exchange new beneficial interest . transfer occur agency fannie mae freddie mac ginnie mae nonagency privatelabel sponsor vie residential commercial mortgage . firm consolidation analysis largely dependent firm role interest resecuritization trusts . 1 5 2 most resecuritization firm involve clientdriven transaction specific client group client seek specific return risk profile . transaction firm conclude decisionmake power entity share firm client consider joint effort decision establish resecuritization trust asset significant economic interest client hold resecuritization trust firm consolidate resecuritization vie . in limited circumstance firm create resecuritization trust independently conjunction specific client . circumstance firm deem unilateral ability direct significant activity resecuritization trust decision establishment design trust firm consolidate resecuritization vie firm hold interest potentially significant . additionally firm invest beneficial interest thirdparty securitization generally purchase interest secondary market . circumstance firm unilateral ability direct significant activity resecuritization trust involve initial design trust firm involve independent party sponsor demonstrate share power creation trust firm consolidate resecuritization vie . as june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm consolidate agency resecuritization . june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively firm consolidate $ 3 5 7 million $ 4 7 7 million asset $ 1 5 5 million $ 2 3 0 million liability privatelabel resecuritization . june 3 0 2 0 1 1 december 3 1 2 0 1 0 total asset nonconsolidated firmsponsore privatelabel resecuritization $ 4 . 5 billion $ 3 . 6 billion respectively . month end june 3 0 2 0 1 1 respectively firm transfer $ 8 . 5 billion $ 1 7 . 3 billion security agency vie zero $ 1 9 2 million security privatelabel vie . month end june 3 0 2 0 1 0 respectively firm transfer $ 7 . 8 billion $ 1 4 . 3 billion security agency vie $ 6 6 3 million $ 1 . 0 billion security privatelabel vie . june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively firm hold approximately $ 2 . 8 billion $ 3 . 5 billion interest nonconsolidated agency resecuritization entity $ 1 0 million $ 4 6 million senior subordinated interest nonconsolidated privatelabel resecuritization entity . page 1 5 8 note information interest hold nonconsolidated securitization vie . multiseller conduitsfor detailed description jpmorgan chase principal involvement firmadministered multiseller conduit note 1 6 page 2 4 9 2 5 0 jpmorgan chase 2 0 1 0 annual report . as result firm continue involvement firm consolidate firmadministered multiseller conduit firm power direct significant activity conduit potentially significant economic interest . firm consolidate $ 2 2 . 2 billion $ 2 1 . 7 billion asset hold firmadministered multiseller conduit $ 2 2 . 2 billion $ 2 1 . 6 billion beneficial interest commercial paper issue party june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . the firm provide dealspecific liquidity programwide liquidity credit enhancement firmadministered multiseller conduit eliminate consolidation . firmadministered multiseller conduit provide certain client lendingrelated commitment . unfunded portion commitment $ 1 1 . 3 billion $ 1 0 . 0 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively include offbalance sheet lendingrelate commitment . information offbalance sheet lendingrelate commitment note 2 1 page 1 6 7 1 7 1 form 1 0 q . vies associate investor intermediation activitiesmunicipal bond vehiclesfor detailed description jpmorgan chase principal involvement municipal bond vehicle note 1 6 page 2 5 0 2 5 1 jpmorgan chase 2 0 1 0 annual report . firm exposure nonconsolidated municipal bond vie june 3 0 2 0 1 1 december 3 1 2 0 1 0 include rating profile vie asset follows . in billionsfair value asset hold viesliquidity facilitiesaexcessdeficitbmaximum exposurenonconsolidate municipal bond vehicle june 3 0 2 0 1 1 $ 1 2 . 9 $ 7 . 9 $ 5 . 0 $ 7 . 9 december 3 1 2 0 1 0 1 3 . 7 8 . 8 4 . 9 8 . 8 1 5 3 rating profile vie assetscfair value asset hold vieswt . avg . expected life asset year investmentgrade noninvestment gradein billion notedaaa aaaaa aaa abbb bb bb belowjune 3 0 2 0 1 1 $ 1 . 7 $ 1 0 . 5 $ 0 . 7 $ $ $ 1 2 . 9 9 . 8 december 3 1 2 0 1 0 1 . 9 1 1 . 2 0 . 6 1 3 . 7 1 5 . 5 athe firm serve credit enhancement provider municipal bond vehicle serve liquidity provider . firm provide insurance underlie municipal bond form letter credit $ 1 0 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 . brepresent excessdeficit fair value municipal bond asset available repay liquidity facility drawn . cthe rating scale base firm internal risk rating present spequivalent basis . the firm consolidate $ 3 . 3 billion $ 4 . 6 billion municipal bond vehicle june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively firm residual interests . creditrelate note asset swap vehiclesfor detailed description jpmorgan chase principal involvement creditrelated note asset swap vehicle note 1 6 page 2 4 4 2 5 9 jpmorgan chase 2 0 1 0 annual report . exposure nonconsolidate creditrelated note asset swap vie june 3 0 2 0 1 1 december 3 1 2 0 1 0 follows . june 3 0 2 0 1 1 billionsnet derivative receivables trading assetsa total exposurebpar value collateral hold viesccreditrelate note static structure $ 0 . 7 $ $ 0 . 7 $ 1 0 . 9 managed structure 2 . 1 0 . 1 2 . 2 9 . 5 total creditrelate notes 2 . 8 0 . 1 2 . 9 2 0 . 4 asset swaps 0 . 4 0 . 4 7 . 5 total $ 3 . 2 $ 0 . 1 $ 3 . 3 $ 2 7 . 9 december 3 1 2 0 1 0 billionsnet derivative receivables trading assetsa total exposurebpar value collateral hold viesccreditrelate note static structure $ 1 . 0 $ $ 1 . 0 $ 9 . 5 managed structure 2 . 8 2 . 8 1 0 . 7 total creditrelate notes 3 . 8 3 . 8 2 0 . 2 asset swaps 0 . 3 0 . 3 7 . 6 total $ 4 . 1 $ $ 4 . 1 $ 2 7 . 8 atrading asset principally comprise note issue vie time time hold termination deal support limited marketmaking . bonbalance sheet exposure include net derivative receivables trading asset debt equity instruments . cthe firm maximum exposure arise derivative execute vie exposure vary time change fair value derivative . firm rely collateral hold vie pay derivative vehicle structure inception par value collateral expect sufficient pay derivative contracts . the firm consolidated creditrelate note vehicle collateral fair value $ 1 2 2 million $ 1 4 2 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . firm consolidate asset swap vehicle june 3 0 2 0 1 1 december 3 1 2 0 1 0 . firm consolidate vehicle role secondary marketmaker hold position entity provide firm control certain vehicles . vie sponsor partiesthe firm invest provide financing service vie sponsor party describe page 2 5 3 jpmorgan chase 2 0 1 0 annual report . 1 5 4 investment thirdparty credit card securitization trustthe firm hold interest thirdpartysponsored vie credit card securitization trust credit card receivable issue national retailer . firm primary beneficiary trust firm power direct activity vie significantly impact vie economic performance . firm interest vie include investment classify afs security fair value $ 2 . 9 billion $ 3 . 1 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively interest classify loan fair value approximately $ 1 . 0 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 . information afs security loan note 1 1 1 3 page 1 2 8 1 3 2 1 3 4 1 4 8 respectively form 1 0 q . consolidated vie asset liabilitiesthe follow table present information asset liability relate vie consolidate firm june 3 0 2 0 1 1 december 3 1 2 0 1 0 . asset liabilitiesjune 3 0 2 0 1 1 billionstrade asset debt equity instrumentsloansotherc total assetsd beneficial interest vie assetseotherftotal liabilitiesvie program type firmsponsore credit card trusts $ $ 5 1 . 7 $ 1 . 0 $ 5 2 . 7 $ 3 5 . 7 $ $ 3 5 . 7 firmadministered multiseller conduits 2 1 . 9 0 . 3 2 2 . 2 2 2 . 2 2 2 . 2 mortgage securitization entitiesa 1 . 0 2 . 6 3 . 6 2 . 0 1 . 5 3 . 5 otherb 6 . 1 4 . 2 1 . 4 1 1 . 7 7 . 6 0 . 1 7 . 7 total $ 7 . 1 $ 8 0 . 4 $ 2 . 7 $ 9 0 . 2 $ 6 7 . 5 $ 1 . 6 $ 6 9 . 1 asset liabilitiesdecember 3 1 2 0 1 0 billionstrading asset debt equity instrumentsloansotherc total assetsd beneficial interest vie assetseotherftotal liabilitiesvie program type firmsponsore credit card trusts $ $ 6 7 . 2 $ 1 . 3 $ 6 8 . 5 $ 4 4 . 3 $ $ 4 4 . 3 firmadministered multiseller conduits 2 1 . 1 0 . 6 2 1 . 7 2 1 . 6 0 . 1 2 1 . 7 mortgage securitization entitiesa 1 . 8 2 . 9 4 . 7 2 . 4 1 . 6 4 . 0 otherb 8 . 0 4 . 4 1 . 6 1 4 . 0 9 . 3 0 . 3 9 . 6 total $ 9 . 8 $ 9 5 . 6 $ 3 . 5 $ 1 0 8 . 9 $ 7 7 . 6 $ 2 . 0 $ 7 9 . 6 aincludes residential commercial mortgage securitization resecuritizations . bprimarily comprise student loan municipal bonds . cinclude asset classify cash derivative receivables afs security asset consolidated balance sheets . dthe asset consolidated vie include program type use settle liability entity . difference total asset total liability recognize consolidated vie represent firm interest consolidated vie program type . ethe interestbeare beneficial interest liability issue consolidated vie classify line item consolidated balance sheet title beneficial interest issue consolidated variable interest entity . holder beneficial interest recourse general credit jpmorgan chase . include beneficial interest vie asset longterm beneficial interest $ 4 2 . 9 billion $ 5 2 . 6 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . maturity longterm beneficial interest june 3 0 2 0 1 1 december 3 1 2 0 1 0 follow $ 1 3 . 0 billion $ 1 3 . 9 billion year $ 2 1 . 4 billion $ 2 9 . 0 billion year $ 8 . 5 billion $ 9 . 7 billion years . finclude liability classify account payable liability consolidated balance sheet . supplemental information loan securitizationsthe firm securitize sell variety loan include residential mortgage credit card automobile student commercial primarily relate real estate loan debt security . primary purpose securitization transaction satisfy investor demand generate liquidity firm . 1 5 5 securitization activitythe follow table provide information relate firm securitization activity month end june 3 0 2 0 1 1 2 0 1 0 relate asset hold jpmorgan chasesponsore securitization entity consolidate firm sale accounting achieve base accounting rule effect time securitization . sixmonth period end june 3 0 2 0 1 1 2 0 1 0 mortgage loan securitize commercial cash flow firm spe relate recourse guarantee arrangement . month end june 3 0 2 0 1 1 residential mortgage millionsprimeesubprimeoption armscommercial otherprincipal securitized $ $ $ $ 1 4 4 7 all cash flow perioda proceed new securitizationsb 1 5 3 0 servicing fee collected 5 0 3 6 1 0 0 1 purchase previously transfer financial asset underlie collateralc 2 9 7 4 4 cash flow receive interest continue hold firmd 5 8 4 1 3 7 month end june 3 0 2 0 1 0 residential mortgage millionsprimeesubprimeoption armscommercial otherprincipal securitized $ $ $ $ 5 6 2 all cash flow perioda proceed new securitizationsb 5 9 2 servicing fee collected 8 9 5 3 1 1 8 1 purchase previously transfer financial asset underlie collateralc 5 2 6 cash flow receive interest continue hold firmd 7 3 9 6 3 0 month end june 3 0 2 0 1 1 residential mortgage millionsprimeesubprimeoption armscommercial otherprincipal securitized $ $ $ $ 2 9 4 0 all cash flow perioda proceed new securitizationsb 3 0 8 8 servicing fee collected 1 1 4 9 5 2 0 3 2 purchase previously transfer financial asset underlie collateralc 6 7 6 1 0 1 0 cash flow receive interest continue hold firmd 1 2 2 8 2 8 1 month end june 3 0 2 0 1 0 residential mortgage millionsprimeesubprimeoption armscommercial otherprincipal securitized $ $ $ $ 5 6 2 all cash flow perioda proceed new securitizationsb 5 9 2 servicing fee collected 1 6 4 9 9 2 3 5 2 purchase previously transfer financial asset underlying collateralc 1 0 0 6 cash flow receive interest continue hold firmd 1 5 3 1 9 1 2 6 8 aexcludes sale firm securitize loan include loan sell ginnie mae fannie mae freddie mac . binclude $ 1 . 5 billion $ 5 9 2 million respectively $ 3 . 1 billion $ 5 9 2 million respectively proceed new securitization receive security month end june 3 0 2 0 1 1 2 0 1 0 . security predominantly classify level 2 fair value measurement hierarchy . cinclude cash pay firm reacquire asset offbalance sheet nonconsolidate entity example servicer cleanup calls . dinclude cash flow receive retained interest include example principal repayment interest payments . einclude alta loan resecuritization transactions . 1 5 6 loan sell agency thirdparty sponsor securitization entitiesin addition report securitization activity table firm normal course business sell originate purchase mortgage loan predominantly ginnie mae fannie mae freddie mac agency . loan sell primarily purpose securitization agency provide credit enhancement loan certain guarantee provision . firm consolidate securitization vehicle primary beneficiary . connection loan sale firm certain representation warranty . additional information firm loan sale securitizationrelated indemnification note 2 1 page 1 6 7 1 7 1 form 1 0 q . for detailed description jpmorgan chase principal involvement loan sell government sponsor agency thirdparty sponsor securitization entity note 1 6 page 2 5 7 jpmorgan chase 2 0 1 0 annual report . the follow table summarize activity relate loan sell u . s . government sponsor agency thirdparty sponsor securitization entity . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 carrying value loan soldab $ 3 2 6 0 9 $ 3 0 1 7 3 $ 7 1 8 5 6 $ 6 5 5 4 7 proceed receive loan sale cash 5 6 5 2 6 2 9 0 5 5 9 8 proceed loan sale securitiesc 3 1 5 1 1 2 9 4 4 8 6 9 6 8 3 6 3 8 1 8 total proceed receive loan sales $ 3 2 0 7 6 $ 2 9 7 1 0 $ 7 0 5 8 8 $ 6 4 4 1 6 gains loan sales 3 0 7 0 5 2 9 1 apredominantly u . s . government agencies . bmsrs exclude table . note 1 6 page 1 5 9 1 6 3 form 1 0 q information originate msrs . cpredominantly include security u . s . government agency generally sell shortly receipt . repurchase loan loan subject option repurchase firm service loan ginnie mae typically option repurchase certain delinquent loan . firm similar right certain arrangement u . s . government agency . firm typically elect repurchase delinquent loan ginnie mae continue service andor manage foreclosure process accordance applicable requirement loan continue insure guarantee . firm repurchase option exercisable loan report balance sheet loan offset liability . june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm record consolidated balance sheet $ 1 3 . 2 billion $ 1 3 . 0 billion respectively loan repurchase firm option repurchase agency . predominately present relate loan repurchase ginnie mae . additionally real estate result voluntary repurchase loan sell agency $ 2 . 4 billion $ 1 . 9 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . substantially loan real estate insure guarantee u . s . government agency applicable reimbursement proceed normally . additional information refer note 1 3 page 1 3 4 1 4 8 form 1 0 q note 1 4 jpmorgan chase 2 0 1 0 annual report . 1 5 7 jpmorgan chase interest securitize asset hold fair valuethe follow table outline key economic assumption use determine fair value june 3 0 2 0 1 1 december 3 1 2 0 1 0 certain firm retain interest nonconsolidated vie msrs value use model technique . table outline sensitivity fair value immediate 1 0 % 2 0 % adverse change assumption use determine fair value . discussion msrs note 1 6 page 1 5 9 1 6 3 form 1 0 q . june 3 0 2 0 1 1 residential mortgagecommercialand otherin million rate notedprimedjpmorgan chase interest securitize assetsab $ 6 5 6 $ 2 3 1 5 weightedaverage life years 6 . 7 2 . 7 weightedaverage constant prepayment ratec 7 . 1 % % cpr cprimpact 1 0 % adverse change $ 1 1 $ impact 2 0 % adverse change 2 1 weightedaverage loss assumption 5 . 5 % 0 . 4 % impact 1 0 % adverse change $ 9 $ 8 3 impact 2 0 % adverse change 1 7 1 7 0 weightedaverage discount rate 1 4 . 0 % 2 0 . 6 % impact 1 0 % adverse change $ 2 6 $ 5 9 impact 2 0 % adverse change 4 9 1 0 7 december 3 1 2 0 1 0 residential mortgagecommercialand otherin million rate notedprimedjpmorgan chase interest securitize assetsab $ 7 0 8 $ 2 9 0 6 weightedaverage life years 5 . 5 3 . 3 weightedaverage constant prepayment ratec 7 . 9 % % cpr cprimpact 1 0 % adverse change $ 1 5 $ impact 2 0 % adverse change 2 7 weightedaverage loss assumption 5 . 2 % 2 . 1 % impact 1 0 % adverse change $ 1 2 $ 7 6 impact 2 0 % adverse change 2 1 1 5 1 weightedaverage discount rate 1 1 . 6 % 1 6 . 4 % impact 1 0 % adverse change $ 2 6 $ 6 9 impact 2 0 % adverse change 4 7 1 3 4 athe firm interest subprime securitization $ 2 1 million $ 1 4 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . additionally firm interest option arm securitization $ 2 7 million $ 2 9 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . binclude certain investment acquire secondary market predominantly hold investment purposes . ccpr constant prepayment rate . dinclude retain interest alta loan resecuritization transactions . the sensitivity analysis precede table hypothetical . change fair value base 1 0 % 2 0 % variation assumption generally extrapolate easily relationship change assumption change fair value linear . table effect change particular assumption fair value calculate change assumption . reality change factor result change counteract magnify sensitivity . sensitivity reflect risk management practice firm undertake mitigate risks . 1 5 8 loan delinquency liquidation loss table include information delinquency liquidation loss component offbalance sheet securitize financial asset june 3 0 2 0 1 1 december 3 1 2 0 1 0 . 9 0 day past liquidation loss credit exposure month end june 3 0 month end june 3 0 millionsjune 3 0 2 0 1 1 dec 3 1 2 0 1 0 june 3 0 2 0 1 1 dec 3 1 2 0 1 0 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 securitized loansa residential mortgage prime mortgageb $ 1 3 2 0 4 2 $ 1 4 3 7 6 4 $ 3 1 4 4 4 $ 3 3 0 9 3 $ 1 2 4 4 $ 1 6 9 6 $ 2 7 3 4 $ 3 3 8 5 subprime mortgage 3 8 4 9 7 4 0 7 2 1 1 5 1 8 6 1 5 4 5 6 6 1 6 9 5 1 1 6 1 6 2 1 1 6 option arms 3 3 4 1 2 3 5 7 8 6 1 0 3 5 8 1 0 7 8 8 4 6 5 6 3 7 9 0 8 1 2 2 6 commercial other 9 6 3 6 8 1 0 6 2 4 5 5 0 6 4 5 7 9 1 2 5 0 1 1 6 4 5 4 1 4 3 total loan securitizedc $ 3 0 0 3 1 9 $ 3 2 6 5 1 6 $ 6 2 0 5 2 $ 6 5 1 2 8 $ 2 5 7 5 $ 3 4 0 0 $ 5 7 1 2 $ 6 8 7 0 atotal asset hold securitizationrelate spe $ 3 6 4 . 2 billion $ 3 9 1 . 1 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . $ 3 0 0 . 3 billion $ 3 2 6 . 5 billion loan securitize june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively exclude $ 5 5 . 7 billion $ 5 6 . 0 billion securitize loan firm continue involvement $ 8 . 2 billion $ 8 . 6 billion loan securitization consolidate firm consolidate balance sheet june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . binclude alta loan . c include securitize loan previously record fair value classify trading assets . note 1 6 goodwill intangible assetsfor discussion accounting policy relate goodwill intangible asset note 1 7 page 2 6 0 2 6 3 jpmorgan chase 2 0 1 0 annual report . goodwill intangible asset consist following . millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 goodwill $ 4 8 8 8 2 $ 4 8 8 5 4 mortgage service rights 1 2 2 4 3 1 3 6 4 9 other intangible asset purchase credit card relationships $ 7 4 4 $ 8 9 7 other credit cardrelate intangibles 5 5 8 5 9 3 core deposit intangibles 7 3 4 8 7 9 other intangibles 1 6 4 3 1 6 7 0 total intangible assets $ 3 6 7 9 $ 4 0 3 9 goodwill follow table present goodwill attribute business segment . millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 investment bank $ 5 2 5 0 $ 5 2 7 8 retail financial services 1 6 4 9 0 1 6 4 9 6 card service auto 1 4 5 8 1 1 4 5 2 2 commercial banking 2 8 6 4 2 8 6 6 treasury security services 1 6 7 0 1 6 8 0 asset management 7 6 5 0 7 6 3 5 corporateprivate equity 3 7 7 3 7 7 total goodwill $ 4 8 8 8 2 $ 4 8 8 5 4 1 5 9 the follow table present change carrying goodwill . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 balance beginning perioda $ 4 8 8 5 6 $ 4 8 3 5 9 $ 4 8 8 5 4 $ 4 8 3 5 7 change period business combinations 1 1 1 0 6 1 9 dispositions 1 9 otherb 1 5 4 9 2 2 3 7 balance june 3 0 a $ 4 8 8 8 2 $ 4 8 3 2 0 $ 4 8 8 8 2 $ 4 8 3 2 0 areflects gross goodwill balance firm recognize impairment loss date . binclude foreign currency translation adjustment taxrelated adjustments . goodwill impair june 3 0 2 0 1 1 december 3 1 2 0 1 0 goodwill write impairment month period end june 3 0 2 0 1 1 2 0 1 0 . month end june 3 0 2 0 1 1 firm review current condition prior projection reporting unit . addition firm update discounted cash flow valuation consumer lending business rfs card service auto card business continue elevate risk goodwill impairment exposure u . s . consumer credit risk effect regulatory legislative change . result review firm conclude goodwill business firm report unit impair june 3 0 2 0 1 1 . the firm consumer lending business rfs card remain elevated risk goodwill impairment exposure u . s . consumer credit risk effect economic regulatory legislative change . valuation business particularly dependent economic condition include new unemployment claim home price regulatory legislative change example relate residential mortgage servicing foreclosure loss mitigation activity affect consumer credit card use equity capital require . assumption use discounted cash flow valuation model determine use management good estimate . cost equity reflect related risk uncertainty evaluate comparison relevant market peer . deterioration assumption cause estimate fair value report unit associated goodwill decline result material impairment charge earning future period relate portion associate goodwill . mortgage servicing rightsmortgage servicing right represent fair value expect future cash flow perform servicing activity . fair value consider estimate future fee ancillary revenue offset estimate cost service loan . fair value mortgage servicing right naturally decline time net service cash flow receive effectively amortize msr asset contractual ancillary fee income . description msr asset interest rate risk management valuation msrs note 1 7 page 2 6 0 2 6 3 respectively jpmorgan chase 2 0 1 0 annual report note 3 page 1 0 2 1 1 4 form 1 0 q . in half 2 0 1 1 fair value msr decline primarily change input assumption msr valuation model . quarter 2 0 1 1 firm revise cost service assumption reflect estimate impact high servicing cost enhance servicing process particularly loan modification foreclosure procedure include cost comply consent order enter banking regulator result $ 1 . 1 billion decrease fair value msr asset . increase cost service assumption contemplate significant prolonged increase staffing level core default servicing function specifically consider high cost service certain highrisk vintage . addition msr decrease value decline interest rate tend increase prepayment reduce expect life net service cash flow comprise msr asset . increase cost service assumption decrease interest rate predominantly change fair value msr asset result largely offset impact new capitalization amortization . the decrease fair value msr result low asset value amortize future period contractual ancillary fee income receive future period . expect high level noninter expense associate high servicing cost future period msr amortization effect increase mortgage fee related income . amortization msr reflect table row change fair value . 1 6 0 the follow table summarize msr activity month end june 3 0 2 0 1 1 2 0 1 0 . month end june 3 0 month end june 3 0 million noted 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 fair value beginning period $ 1 3 0 9 3 $ 1 5 5 3 1 $ 1 3 6 4 9 $ 1 5 5 3 1 msr activity origination msrs 5 6 2 5 3 3 1 3 1 9 1 2 2 2 purchase msrs 2 9 3 0 1 4 disposition msrs 5 5 total net additions 5 9 1 5 2 8 1 3 4 9 1 2 3 1 change valuation input assumptionsa 9 6 0 3 5 8 4 1 7 1 1 3 6 8 0 other change fair valueb 4 8 1 6 2 2 1 0 4 4 1 2 2 9 total change fair value msrsc 1 4 4 1 4 2 0 6 2 7 5 5 4 9 0 9 fair value june 3 0 d $ 1 2 2 4 3 $ 1 1 8 5 3 $ 1 2 2 4 3 $ 1 1 8 5 3 change unrealized gainslosse include income relate msrs hold june 3 0 $ 9 6 0 $ 3 5 8 4 $ 1 7 1 1 $ 3 6 8 0 contractual service fee late fee ancillary fee include income $ 9 8 3 $ 1 1 4 8 $ 2 0 0 8 $ 2 2 8 0 thirdparty mortgage loan service june 3 0 billions $ 9 4 9 $ 1 0 6 4 $ 9 4 9 $ 1 0 6 4 servicer advance net june 3 0 billionse $ 1 0 . 9 $ 9 . 3 $ 1 0 . 9 $ 9 . 3 arepresent msr asset fair value adjustment change input interest rate volatility update assumption use valuation model . binclude change msr value model servicing portfolio runoff i . e . amortization time decay . cinclude change relate commercial real estate $ 2 million $ 2 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 4 million $ 4 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . dinclude $ 3 6 million $ 3 7 million relate commercial real estate june 3 0 2 0 1 1 2 0 1 0 respectively . erepresent firm pay servicer e . g . schedule principal interest trust taxis insurance generally reimburse short period time advance future cash flow trust underlie loan . firm credit risk associate advance minimal reimbursement advance senior cash payment investor . addition firm maintain right stop payment collateral insufficient cover advance . the follow table present component mortgage fee related income include impact msr risk management activity month end june 3 0 2 0 1 1 2 0 1 0 . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 rfs mortgage fee related income net production revenue production revenue $ 7 6 7 $ 6 7 6 $ 1 4 4 6 $ 1 1 0 9 repurchase losses 2 2 3 6 6 7 6 4 3 1 0 9 9 net production revenue 5 4 4 9 8 0 3 1 0 net mortgage service revenue operating revenue loan service revenue 1 0 1 1 1 1 8 6 2 0 6 3 2 2 9 3 other change msr asset fair valuea 4 7 8 6 2 0 1 0 4 1 1 2 2 5 total operate revenue 5 3 3 5 6 6 1 0 2 2 1 0 6 8 risk management change msr asset fair value input assumption modelb 9 6 0 3 5 8 4 1 7 1 1 3 6 8 0 derivative valuation adjustment other 9 8 3 3 8 9 5 4 9 7 4 1 4 3 total risk management 2 3 3 1 1 1 2 1 4 4 6 3 total rfs net mortgage service revenue 5 5 6 8 7 7 1 9 2 1 5 3 1 all other 3 2 5 5 mortgage fee related income $ 1 1 0 3 $ 8 8 8 $ 6 1 6 $ 1 5 4 6 aincludes change msr value model servicing portfolio runoff i . e . amortization time decay . brepresent msr asset fair value adjustment change input interest rate volatility update assumption use msr valuation model . 1 6 1 the table outline key economic assumption use determine fair value firm msrs june 3 0 2 0 1 1 december 3 1 2 0 1 0 outline sensitivity fair value immediate adverse change assumption define . million ratesjune 3 0 2 0 1 1 december 3 1 2 0 1 0 weightedaverage prepayment speed assumption cpr 1 0 . 6 3 % 1 1 . 2 9 % impact fair value 1 0 % adverse change $ 7 7 5 $ 8 0 9 impact fair value 2 0 % adverse change 1 5 0 0 1 5 6 8 weightedaverage option adjust spread 3 . 8 5 % 3 . 9 4 % impact fair value 1 0 0 basis point adverse change $ 5 8 7 $ 5 7 8 impact fair value 2 0 0 basis point adverse change 1 1 2 5 1 1 0 9 cpr constant prepayment rate . the sensitivity analysis precede table hypothetical use caution . change fair value base variation assumption generally easily extrapolate relationship change assumption change fair value linear . table effect change particular assumption fair value calculate change assumption . reality change factor result change magnify counteract sensitivities . other intangible asset $ 3 6 0 million decrease intangible asset month end june 3 0 2 0 1 1 predominantly $ 4 2 9 million amortization . the component credit card relationship core deposit intangible asset follow . june 3 0 2 0 1 1 december 3 1 2 0 1 0 gross amountaaccumulate amortizationanetcarrye value gross amountaccumulate amortizationnetcarrye valuein million purchase credit card relationships $ 3 8 3 0 $ 3 0 8 6 $ 7 4 4 $ 5 7 8 9 $ 4 8 9 2 $ 8 9 7 other credit cardrelate intangibles 8 6 1 3 0 3 5 5 8 9 0 7 3 1 4 5 9 3 core deposit intangibles 4 1 3 2 3 3 9 8 7 3 4 4 2 8 0 3 4 0 1 8 7 9 other intangibles 2 4 9 8 8 5 5 1 6 4 3 2 5 1 5 8 4 5 1 6 7 0 athe decrease gross accumulate amortization december 3 1 2 0 1 0 removal fully amortize assets . intangible asset approximately $ 6 0 0 million consist primarily asset management advisory contract determine indefinite life amortize . 1 6 2 amortization expensethe follow table present amortization expense relate credit card relationship core deposit intangible asset . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 purchased credit card relationships $ 7 7 $ 9 7 $ 1 5 7 $ 1 9 4 all intangible credit cardrelate intangibles 2 7 2 6 5 3 5 2 core deposit intangibles 7 2 8 3 1 4 4 1 6 6 other intangibles 3 6 2 9 7 5 6 6 total amortization expense $ 2 1 2 $ 2 3 5 $ 4 2 9 $ 4 7 8 future amortization expensethe follow table present estimate future amortization expense relate credit card relationship core deposit intangible assets . for year millionspurchase credit card relationshipsother credit cardrelate intangiblescore deposit intangiblesother intangiblestotal 2 0 1 1 a $ 2 9 4 $ 1 0 7 $ 2 8 4 $ 1 4 3 $ 8 2 8 2 0 1 2 2 5 4 1 1 0 2 4 0 1 3 7 7 4 1 2 0 1 3 2 1 3 1 0 7 1 9 5 1 3 0 6 4 5 2 0 1 4 1 1 0 1 0 5 1 0 0 1 1 4 4 2 9 2 0 1 5 2 4 9 8 2 5 9 6 2 4 3 ainclude $ 1 5 7 million $ 5 3 million $ 1 4 4 million $ 7 5 million amortization expense relate purchase credit card relationship credit cardrelate intangible core deposit intangible intangible respectively recognize month end june 3 0 2 0 1 1 . 1 6 3 note 1 7 depositsfor discussion deposit note 1 9 page 2 6 3 2 6 4 jpmorgan chase 2 0 1 0 annual report . june 3 0 2 0 1 1 december 3 1 2 0 1 0 noninterestbearing interestbeare deposit follows . in millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 u . s . office noninterestbearing $ 2 8 7 6 5 4 $ 2 2 8 5 5 5 interestbearing demanda 3 4 8 8 9 3 3 3 6 8 savingsb 3 5 0 2 1 6 3 3 4 6 3 2 time include $ 3 5 5 5 $ 2 7 3 3 fair valuec 8 4 5 1 3 8 7 2 3 7 total interestbeare deposits 4 6 9 6 1 8 4 5 5 2 3 7 total deposit u . s . offices 7 5 7 2 7 2 6 8 3 7 9 2 nonu . s . office noninterestbearing 1 3 4 2 2 1 0 9 1 7 interestbeare demand 2 0 4 3 5 1 1 7 4 4 1 7 savings 7 2 1 6 0 7 time include $ 1 2 3 3 $ 1 6 3 6 fair valuec 7 2 9 1 9 6 0 6 3 6 total interestbeare deposits 2 7 7 9 9 1 2 3 5 6 6 0 total deposit nonu . s . offices 2 9 1 4 1 3 2 4 6 5 7 7 total deposits $ 1 0 4 8 6 8 5 $ 9 3 0 3 6 9 ainclude negotiable order withdrawal account certain trust accounts . binclude money market deposit account mmdas . cinclude structure note classify deposit fair value option elect . discussion note 4 page 1 8 7 1 8 9 jpmorgan chase 2 0 1 0 annual report . note 1 8 borrow fundsthe follow table detail component borrow funds . in millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 advance federal home loan banksa $ 5 0 0 $ 2 2 5 0 other 2 9 7 0 8 3 2 0 7 5 total borrow fundsbc $ 3 0 2 0 8 $ 3 4 3 2 5 aeffective january 1 2 0 1 1 $ 2 3 . 0 billion longterm advance fhlb reclassify borrow fund longterm debt . prioryear period revise conform current presentation . binclude borrow fund $ 1 1 . 7 billion $ 9 . 9 billion account fair value june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . cinclude borrow fund $ 9 . 5 billion $ 1 4 . 8 billion secure asset total $ 9 . 6 billion $ 1 5 . 0 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . june 3 0 2 0 1 1 december 3 1 2 0 1 0 jpmorgan chase significant line credit general corporate purposes . 1 6 4 note 1 9 earning sharefor discussion computation basic diluted earning share ep note 2 5 page 2 6 9 jpmorgan chase 2 0 1 0 annual report . follow table present calculation basic diluted ep month period end june 3 0 2 0 1 1 2 0 1 0 . month end june 3 0 month end june 3 0 million share 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 basic earning share net income $ 5 4 3 1 $ 4 7 9 5 $ 1 0 9 8 6 $ 8 1 2 1 preferred stock dividend 1 5 8 1 6 3 3 1 5 3 2 5 net income applicable common equity 5 2 7 3 4 6 3 2 1 0 6 7 1 7 7 9 6 dividend undistributed earning allocate participate security 2 0 6 2 6 9 4 6 8 4 6 1 net income applicable common stockholder $ 5 0 6 7 $ 4 3 6 3 $ 1 0 2 0 3 $ 7 3 3 5 total weightedaverage basic share outstanding 3 9 5 8 . 4 3 9 8 3 . 5 3 9 7 0 . 0 3 9 7 7 . 0 net income share $ 1 . 2 8 $ 1 . 1 0 $ 2 . 5 7 $ 1 . 8 4 month end june 3 0 month end june 3 0 million share 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 dilute earning share net income applicable common stockholder $ 5 0 6 7 $ 4 3 6 3 $ 1 0 2 0 3 $ 7 3 3 5 total weightedaverage basic share outstanding 3 9 5 8 . 4 3 9 8 3 . 5 3 9 7 0 . 0 3 9 7 7 . 0 add employee stock option sar warrantsa 2 4 . 8 2 2 . 1 2 8 . 6 2 3 . 2 total weightedaverage dilute share outstandingb 3 9 8 3 . 2 4 0 0 5 . 6 3 9 9 8 . 6 4 0 0 0 . 2 net income share $ 1 . 2 7 $ 1 . 0 9 $ 2 . 5 5 $ 1 . 8 3 aexclude computation diluted ep antidilutive effect option issue employee benefit plan 2 0 1 0 warrant originally issue 2 0 0 8 u . s . treasury capital purchase program purchase share firm common stock . month end june 3 0 2 0 1 1 aggregate number share issuable exercise option 5 3 million 6 9 million respectively . month end june 3 0 2 0 1 0 aggregate number share issuable exercise option warrant 2 2 4 million 2 3 2 million respectively . bparticipating security include calculation diluted ep use twoclass method computation dilutive calculation use treasury stock method . 1 6 5 note 2 0 accumulate comprehensive incomelossaoci include aftertax change unrealized gain loss afs security foreign currency translation adjustment include impact related derivative cash flow hedging activity net loss prior service costscredit relate firm define benefit pension opeb plans . as month endedunrealize gainslosse afs securitiesb translation adjustmentsnet hedge cash flow hedge net loss prior service costscredit define benefit pension opeb plan accumulate comprehensiveincomeloss june 3 0 2 0 1 1 millionsbalance january 1 2 0 1 1 $ 2 4 9 8 c $ 2 5 3 $ 2 0 6 $ 1 9 5 6 $ 1 0 0 1 net change 7 7 0 d 2 7 e 2 1 1 f 5 1 g 6 3 7 balance june 3 0 2 0 1 1 $ 3 2 6 8 c $ 2 8 0 $ 5 $ 1 9 0 5 $ 1 6 3 8 month endedunrealize gainslosse afs securitiesb translation adjustmentsnet hedge cash flow hedge net loss prior service costscredit define benefit pension opeb plan accumulate comprehensiveincomeloss june 3 0 2 0 1 0 millionsbalance january 1 2 0 1 0 $ 2 0 3 2 c $ 1 6 $ 1 8 1 $ 2 2 8 8 $ 9 1 cumulative effect change accounting principlea 1 2 9 1 2 9 net change 2 3 3 9 d 2 5 e 1 6 5 f 1 4 5 g 2 6 2 4 balance june 3 0 2 0 1 0 $ 4 2 4 2 c $ 4 1 $ 3 4 6 $ 2 1 4 3 $ 2 4 0 4 areflect effect adoption accounting guidance relate consolidation vie . aoci decrease $ 1 2 9 million adoption accounting guidance relate vie result reversal fair value adjustment retain afs security eliminate consolidation discussion note 1 6 page 2 4 4 2 5 9 jpmorgan chase 2 0 1 0 annual report . brepresent aftertax difference fair value amortized cost security account afs . cat june 3 0 2 0 1 1 january 1 2 0 1 1 june 3 0 2 0 1 0 january 1 2 0 1 0 include aftertax unrealized loss relate credit debt security credit loss recognize income $ 6 2 million $ 8 1 million $ 1 2 6 million $ 2 2 6 million respectively . dthe net change month end june 3 0 2 0 1 1 primarily increase market value agency mb municipal security partially offset widening spread nonu . s . corporate debt realization gain portfolio repositioning . net change month end june 3 0 2 0 1 0 primarily narrowing spread mb clos partially offset decline nonu . s . government debt realization gain portfolio repositioning . ethe net change month end june 3 0 2 0 1 1 2 0 1 0 include aftertax gainslosse foreign currency translation operation functional currency u . s . dollar $ 4 9 8 million $ 4 8 9 million respectively partially offset aftertax gainslosse hedge $ 4 7 1 million $ 4 6 4 million respectively . firm hedge entire exposure foreign currency translation net investment foreign operations . fthe net change month end june 3 0 2 0 1 1 include $ 1 1 2 million aftertax gainslosse recognize income $ 9 9 million aftertax gainslosse represent net change derivative fair value report comprehensive income . net change month end june 3 0 2 0 1 0 include $ 6 million aftertax gain recognize income $ 1 7 1 million aftertax gain represent net change derivative fair value report comprehensive income . gthe net change month period end june 3 0 2 0 1 1 2 0 1 0 aftertax adjustment base final yearend actuarial valuation u . s . nonu . s . define benefit pension opeb plan 2 0 1 0 2 0 0 9 respectively amortization net loss prior service credit net periodic benefit cost . 1 6 6 note 2 1 offbalance sheet lendingrelate financial instrument guarantee commitmentsjpmorgan chase provide lendingrelate financial instrument e . g . commitment guarantee meet financing need customer . contractual financial instrument represent maximum possible credit risk firm counterparty draw commitment firm require fulfill obligation guarantee counterparty subsequently fail perform accord term contract . commitment guarantee expire draw default occur . result total contractual instrument firm view representative actual future credit exposure funding requirement . discussion offbalance sheet lendingrelate financial instrument guarantee firm relate accounting policy note 3 0 page 2 7 5 2 8 0 jpmorgan chase 2 0 1 0 annual report . provide risk loss inherent wholesale consumer exclude credit card contract allowance credit loss lendingrelated commitment maintain . note 1 4 page 1 4 9 1 5 0 form 1 0 q discussion regard allowance credit loss lendingrelate commitments . the follow table summarize contractual carry value offbalance sheet lendingrelate financial instrument guarantee commitment june 3 0 2 0 1 1 december 3 1 2 0 1 0 . table credit card home equity lendingrelate commitment represent total available credit product . firm experience anticipate available line credit product utilize time . firm reduce cancel credit card line credit provide borrower notice case notice permit law . firm reduce close home equity line credit significant decrease value underlying property demonstrable decline creditworthiness borrower . 1 6 7 offbalance sheet lendingrelate financial instrument guarantee commitment contractual carry valuejin millionsjune 3 0 2 0 1 1 december 3 1 2 0 1 0 june 3 0 2 0 1 1 december 3 1 2 0 1 0 lendingrelated consumer exclude credit card home equity senior lien $ 1 7 2 6 5 $ 1 7 6 6 2 $ $ home equity junior lien 2 8 5 8 6 3 0 9 4 8 prime mortgage 1 1 1 7 1 2 6 6 subprime mortgage auto 6 7 9 5 5 2 4 6 1 2 business banking 1 0 0 4 6 9 7 0 2 5 4 student other 8 4 0 5 7 9 total consumer exclude credit card 6 4 6 4 9 6 5 4 0 3 6 6 credit card 5 3 5 6 2 5 5 4 7 2 2 7 total consumer 6 0 0 2 7 4 6 1 2 6 3 0 6 6 wholesale unfunded commitment extend creditab 2 1 0 0 2 3 1 9 9 8 5 9 3 0 4 3 6 4 standby letter credit financial guaranteesabcd 9 7 0 5 0 9 4 8 3 7 6 8 6 7 0 5 unuse advise line credit 5 2 8 4 8 4 4 7 2 0 letter creditad 5 7 6 8 6 6 6 3 2 2 total wholesale 3 6 5 6 8 9 3 4 6 0 7 9 9 9 2 1 0 7 1 total lendingrelated $ 9 6 5 9 6 3 $ 9 5 8 7 0 9 $ 9 9 8 $ 1 0 7 7 other guarantee commitment security lend guaranteese $ 2 0 5 4 1 1 $ 1 8 1 7 1 7 nanaderivative qualify guaranteesf 8 4 0 8 9 8 7 7 6 8 $ 3 2 1 $ 2 9 4 unsettled reverse repurchase security borrow agreementsg 5 9 5 7 0 3 9 9 2 7 guarantee commitmentsh 6 1 7 7 6 4 9 2 6 6 loan sale securitizationrelated indemnification repurchase liabilityi nana 3 6 3 1 3 2 8 5 loan sell recourse 1 0 6 2 4 1 0 9 8 2 1 4 1 1 5 3 aat june 3 0 2 0 1 1 december 3 1 2 0 1 0 represent contractual net risk participation total $ 6 0 8 million $ 5 4 2 million respectively unfunded commitment extend credit $ 2 2 . 3 billion $ 2 2 . 4 billion respectively standby letter credit financial guarantee $ 1 . 4 billion $ 1 . 1 billion respectively letter credit . regulatory filing federal reserve board commitment gross risk participations . bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include credit enhancement bond commercial paper liquidity commitment u . s . state municipality hospital notforprofit entity $ 4 6 . 4 billion $ 4 3 . 4 billion respectively . commitment include liquidity facility nonconsolidate municipal bond vie information note 1 5 page 1 5 1 1 5 9 form 1 0 q . cat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include unissued standby letter credit commitment $ 4 1 . 9 billion $ 4 1 . 6 billion respectively . dat june 3 0 2 0 1 1 december 3 1 2 0 1 0 jpmorgan chase hold collateral relate $ 3 9 . 3 billion $ 3 7 . 8 billion respectively standby letter credit $ 1 . 7 billion $ 2 . 1 billion respectively letter credit . eat june 3 0 2 0 1 1 december 3 1 2 0 1 0 collateral hold firm support security lending indemnification agreement $ 2 0 7 . 9 billion $ 1 8 5 . 0 billion respectively . security lend collateral comprise primarily cash security issue government member organisation economic cooperation development oecd u . s . government agencies . frepresent notional derivative qualify guarantee . carry value june 3 0 2 0 1 1 december 3 1 2 0 1 0 reflect derivative payable $ 4 2 0 million $ 3 9 0 million respectively derivative receivables $ 9 9 million $ 9 6 million respectively . gat june 3 0 2 0 1 1 december 3 1 2 0 1 0 commitment relate forward start reverse repurchase agreement security borrowing agreement $ 1 4 . 0 billion $ 1 4 . 4 billion respectively . commitment relate unsettled reverse repurchase agreement security borrow agreement regular way settlement period $ 4 5 . 6 billion $ 2 5 . 5 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . hat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include unfunded commitment $ 8 7 6 million $ 1 . 0 billion respectively thirdparty private equity fund $ 1 . 5 billion $ 1 . 4 billion respectively equity investment . commitment include $ 8 1 5 million $ 1 . 0 billion respectively relate investment generally fair value net asset value discuss note 3 page 1 0 2 1 1 4 form 1 0 q . addition june 3 0 2 0 1 1 december 3 1 2 0 1 0 include letter credit hedge derivative transaction manage market risk basis $ 3 . 8 billion $ 3 . 8 billion respectively . irepresent estimate repurchase liability relate indemnification breach representation warranty loan sale securitization agreement . additional information loan sale securitizationrelate indemnification page 1 7 0 1 7 1 note . jfor lendingrelate product carry value represent allowance lendingrelated commitment guarantee liability derivativerelate product carry value represent fair value . product carry value represent valuation reserve . 1 6 8 other unfunde commitment extend creditother unfunded commitment extend credit generally comprise commitment work capital general corporate purpose extension credit support commercial paper facility bond financing event obligation remarkete new investors . also include unfunded commitment extend credit commitment noninvestmentgrade counterpartie connection leveraged acquisition finance activity $ 7 . 1 billion $ 5 . 9 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . information note 3 note 4 page 1 0 2 1 1 4 1 1 4 1 1 6 respectively form 1 0 q . guaranteesthe firm consider following offbalance sheet lendingrelate arrangement guarantee u . s . gaap standby letter credit financial guarantee security lend indemnification certain indemnification agreement include thirdparty contractual arrangement certain derivative contract . discussion offbalance sheet lendingrelate arrangement firm consider guarantee related accounting policy note 3 0 page 2 7 5 2 8 0 jpmorgan chase 2 0 1 0 annual report . recorded relate guarantee indemnification june 3 0 2 0 1 1 december 3 1 2 0 1 0 exclude allowance credit loss lendingrelated commitment discuss page 1 7 0 1 7 1 note . standby letter credit standby letter credit sblc financial guarantee conditional lending commitment issue firm guarantee performance customer party certain arrangement commercial paper facility bond financing acquisition financing trade similar transaction . carry value standby letter credit $ 6 8 8 million $ 7 0 7 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively classify account payable liability consolidated balance sheet carry value include $ 3 1 6 million $ 3 4 7 million respectively allowance lendingrelated commitment $ 3 7 2 million $ 3 6 0 million respectively guarantee liability correspond asset . the follow table summarize type facility standby letter credit letter credit arrangement outstanding rating profile firm customer june 3 0 2 0 1 1 december 3 1 2 0 1 0 . standby letter credit financial guarantee letter credit june 3 0 2 0 1 1 december 3 1 2 0 1 0 millionsstandby letter credit financial guaranteesother letter credit standby letter credit financial guaranteesother letter creditinvestmentgradea $ 7 4 2 2 2 $ 4 3 9 9 $ 7 0 2 3 6 $ 5 2 8 9 noninvestmentgradea 2 2 8 2 8 1 3 6 9 2 4 6 0 1 1 3 7 4 total contractual amountb $ 9 7 0 5 0 c $ 5 7 6 8 $ 9 4 8 3 7 c $ 6 6 6 3 allowance lendingrelated commitment $ 3 1 4 $ 2 $ 3 4 5 $ 2 commitments collateral 3 9 3 3 5 1 7 4 8 3 7 8 1 5 2 1 2 7 athe rating scale base firm internal rating generally correspond rating define sp moodys . bat june 3 0 2 0 1 1 december 3 1 2 0 1 0 represent contractual net risk participation total $ 2 2 . 3 billion $ 2 2 . 4 billion respectively standby letter credit financial guarantee $ 1 . 4 billion $ 1 . 1 billion respectively letter credit . regulatory filing federal reserve commitment gross risk participations . cat june 3 0 2 0 1 1 december 3 1 2 0 1 0 include unissued standby letter credit commitment $ 4 1 . 9 billion $ 4 1 . 6 billion respectively . derivative qualify guaranteesin addition contract describe firm transact certain derivative contract meet characteristic guarantee u . s . gaap . information derivative note 3 0 page 2 7 5 2 8 0 jpmorgan chase 2 0 1 0 annual report . total notional value derivative firm deem guarantee $ 8 4 . 1 billion $ 8 7 . 8 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . notional generally represent firm maximum exposure derivative qualify guarantee . exposure certain stable value contract contractually limit substantially low percentage notional notional stable value contract $ 2 6 . 2 billion $ 2 5 . 9 billion maximum exposure loss $ 2 . 8 billion $ 2 . 7 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . fair value contract reflect probability firm require perform contract . fair value relate derivative firm deem guarantee derivative payable $ 4 2 0 million $ 3 9 0 million derivative receivable $ 9 9 million $ 9 6 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . firm reduce exposure contract enter offset transaction enter contract hedge market risk relate derivative guarantees . 1 6 9 addition derivative contract meet characteristic guarantee firm purchaser seller credit protection credit derivative market . discussion credit derivative note 5 page 1 1 7 1 2 4 form 1 0 q note 6 page 1 9 1 1 9 9 jpmorgan chase 2 0 1 0 annual report . loan sale securitizationrelated indemnificationsindemnification breach representation warrantiesin connection firm loan sale securitization activity gse loan sale privatelabel securitization transaction describe note 1 3 1 5 page 1 3 4 1 4 8 1 5 1 1 5 9 respectively form 1 0 q note 1 4 1 6 page 2 2 0 2 3 8 2 4 4 2 5 9 respectively jpmorgan chase 2 0 1 0 annual report firm representation warranty loan sell meet certain requirement . firm require repurchase loan andor indemnify gse investor loss material breach representation warranty predominantly repurchase demand receive firm firm loss realize date relate loan sell gses . the firm recognize repurchase liability $ 3 . 6 billion $ 3 . 3 billion june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively report account payable liability net probable recovery parties . substantially estimate assumption underlie firm establish methodology compute record repurchase liability include factor probable future demand purchaser ability firm cure identify defect severity loss repurchase foreclosure recovery party require application significant level management judgment . estimate repurchase liability complicate limited rapidly change historical datum uncertainty surround numerous external factor include macroeconomic factor ii level future demand dependent action party gse mortgage insurer . firm use good information available estimate repurchase liability estimation process inherently uncertain imprecise accordingly loss excess accrue june 3 0 2 0 1 1 reasonably possible . firm believe estimate range reasonably possible loss excess establish repurchase liability $ 0 approximately $ 2 . 2 billion june 3 0 2 0 1 1 . estimate range reasonably possible loss consider firm gserelate exposure base assumed peak trough decline home price 4 5 % additional 1 1 percentage point decline home price firm current assumption derive nationally recognize home price index . firm consider decline home price likely occur decline increase level loan delinquency potentially increase repurchase demand rate gse increase loss severity repurchase loan affect firm repurchase liability . claim relate privatelabel securitization far generally manifest securitiesrelated litigation firm consider litigation matter discuss note 2 3 page 1 7 2 1 7 9 form 1 0 q . actual repurchase loss vary significantly firm record repurchase liability estimate reasonably possible additional loss depend outcome factor include consider above . the follow table summarize change repurchase liability period presented . summary change mortgage repurchase liability month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 repurchase liability begin period $ 3 4 7 4 $ 1 9 8 2 $ 3 2 8 5 $ 1 7 0 5 realized lossesa 2 4 1 3 1 7 4 7 2 5 6 3 provision repurchase losses 3 9 8 6 6 7 8 1 8 1 1 9 0 repurchase liability end period $ 3 6 3 1 $ 2 3 3 2 $ 3 6 3 1 $ 2 3 3 2 aincludes principal loss accrue interest repurchase loan makewhole settlement settlement claimant certain related expense . makewhole settlement $ 1 2 6 million $ 1 5 0 million month end june 3 0 2 0 1 1 2 0 1 0 respectively $ 2 4 1 million $ 2 5 5 million month end june 3 0 2 0 1 1 2 0 1 0 respectively . 1 7 0 loans sell recourse firm provide service mortgage certain commercial lending product recourse nonrecourse basis . nonrecourse service principal credit risk firm cost temporary servicing advance fund i . e . normal servicing advance . recourse service servicer agree share credit risk owner mortgage loan fannie mae freddie mac private investor insurer guarantor . loss recourse servicing predominantly occur foreclosure sale proceed property underlie defaulted loan sum outstanding principal balance plus accrue interest loan cost hold disposing underlying property . firm securitization predominantly nonrecourse effectively transfer risk future credit loss purchaser mortgagebacke security issue trust . june 3 0 2 0 1 1 december 3 1 2 0 1 0 unpaid principal balance loan sell recourse total $ 1 0 . 6 billion $ 1 1 . 0 billion respectively . carry value related liability firm record representative firm view likelihood perform recourse obligation $ 1 4 1 million $ 1 5 3 million june 3 0 2 0 1 1 december 3 1 2 0 1 0 respectively . note 2 2 pledge asset collateralfor discussion firm pledge asset collateral note 3 1 page 2 8 0 2 8 1 jpmorgan chase 2 0 1 0 annual report . pledge assetsat june 3 0 2 0 1 1 asset pledge collateralize repurchase agreement security finance agreement derivative transaction purpose include secure borrowing public deposit . certain pledge asset sell repledge secured party identify financial instrument pledge party consolidated balance sheet . addition june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm pledge $ 2 8 1 . 4 billion $ 2 8 8 . 7 billion respectively financial instrument sell repledge secure party . total asset pledge include asset consolidated vie asset use settle liability entity . note 1 5 page 1 5 1 1 5 9 form 1 0 q note 1 6 page 2 4 4 2 5 9 jpmorgan chase 2 0 1 0 annual report additional information asset liability consolidated vie . information regard pledge asset note 3 1 page 2 8 1 jpmorgan chase 2 0 1 0 annual report . collateralat june 3 0 2 0 1 1 december 3 1 2 0 1 0 firm accept asset collateral sell repledge deliver use fair value approximately $ 7 0 5 . 2 billion $ 6 5 5 . 0 billion respectively . collateral generally obtain resale agreement security borrow agreement customer margin loan derivative agreement . collateral receive approximately $ 5 0 9 . 3 billion $ 5 2 1 . 3 billion respectively sell repledge generally collateral repurchase agreement security lend agreement cover short sale collateralize deposit derivative agreement . information regard collateral note 3 1 page 2 8 1 jpmorgan chase 2 0 1 0 annual report . 1 7 1 note 2 3 litigationcontingencie june 3 0 2 0 1 1 firm subsidiary defendant putative defendant 1 0 0 0 0 legal proceeding form regulatorygovernment investigation private civil litigation . litigation range individual action involve single plaintiff class action lawsuit potentially million class member . investigation involve formal informal proceeding governmental agency selfregulatory organization . legal proceeding vary stage adjudication arbitration investigation involve firm line business geography wide variety claim include common law tort contract claim statutory antitrust security consumer protection claim present novel legal theories . the firm believe estimate aggregate range reasonably possible loss excess reserve establish legal proceeding $ 0 approximately $ 5 . 1 billion june 3 0 2 0 1 1 . estimate aggregate range reasonably possible loss base currently available information proceeding firm involve account firm good estimate loss case estimate . certain case firm believe estimate currently . firm estimate involve significant judgment vary stage proceeding include fact currently preliminary stage existence multiple defendant include firm proceeding share liability determine numerous yetunresolved issue proceeding include issue regard class certification scope claim attendant uncertainty potential outcome proceeding . accordingly firm estimate change time time actual loss current estimate . set forth description firm material legal proceedings . auctionrate security investigation litigation . begin march 2 0 0 8 regulatory authority initiate investigation number industry participant include firm concern possible state federal security law violation connection sale auctionrate security . market security freeze significant number auction security begin fail february 2 0 0 8 . firm behalf affiliate agree settlement principle new york attorney general office provide thing firm offer purchase par certain auctionrate security purchase j . p . morgan security llc jpmorgan security j . p . morgan security inc . chase investment service corp . bear stearn co . inc . individual investor charity small mediumsize business . firm agree substantively similar settlement principle office financial regulation state florida north american security administrator association nasaa task force agree recommend approval settlement remain state puerto rico u . s . virgin island . firm finalize settlement agreement new york attorney general office office financial regulation state florida . settlement agreement provide payment penalty total $ 2 5 million state . firm currently process finalize consent agreement nasaas member state 4 5 consent agreement finalize date . the firm face number civil action relate firm sale auctionrate security include putative security class action united state district court southern district new york seek unspecified damage individual arbitration lawsuit forum bring institutional individual investor seek damage total $ 2 0 0 million relate firm sale auctionrate security . action bring issuer auctionrate security . action generally allege firm firm manipulate market auctionrate security place bid auction affect security clearing rate support auction properly disclose activity . action allege firm misrepresent auctionrate security shortterm instrument . firm file motion dismiss action pende federal court coordinate federal district court new york . motion currently pending . additionally firm putative antitrust class action pende federal district court new york . action allege firm numerous financial institution defendant collude maintain stabilize auctionrate security market withdraw support auctionrate security market . january 2 0 1 0 district court dismiss action . appeal pende united state court appeal second circuit . bear stearn hedge fund matter . bear stearn certain current subsidiary bear stearn include bear stearn asset management inc . bsam bear stearn co . inc . certain individual employ bear stearn defendant collectively bear stearn defendant multiple civil action arbitration relate alleged loss result failure bear stearn high grade structured credit strategy master fund ltd . high grade fund bear stearn high grade structured credit strategy enhance leverage master fund ltd . enhanced leverage fund collectively fund . bsam serve investment manager fund organize u . s . cayman island feeder fund invest substantially asset directly indirectly fund . fund liquidation . 1 7 2 there currently civil action pende united state district court southern district new york relate fund . action involve derivative lawsuit bring behalf purchaser partnership interest u . s . feeder fund allege bear stearn defendant mismanage fund material misrepresentation andor withhold information investor feeder fund . action seek thing unspecified compensatory damage base alleged investor loss . action bring joint voluntary liquidator cayman island feeder fund allegation similar assert derivative lawsuit relate u . s . feeder fund seek compensatory punitive damage . motion dismiss case grant deny . agreement principle reach pursuant bsam pay maximum approximately $ 1 9 million settle derivative action relate feeder fund high grade fund . bsam reserve right proceed settlement plaintiff unable secure participation investor net contribution meet prescribed percentage aggregate net contribution high grade fund . agreement principle remain subject documentation approval court . action party engage courtordered settlement discussion . discovery limit duration process . total alleged loss action exceed $ 1 billion . the fourth action bring bank america banc america security llc bofa allege breach contract fraud connection 2 0 0 7 $ 4 billion securitization know cdosquared bsam serve collateral manager . securitization compose certain collateralized debt obligation holding purchase bofa fund . bank america seek excess $ 3 billion damage . defendant motion dismiss action largely deny amend complaint file discovery ongoing . bear stearn shareholder litigation related matter . shareholder bear stearn commence purported class action bear stearn certain officer andor director behalf person purchase acquire common stock bear stearn december 1 4 2 0 0 6 march 1 4 2 0 0 8 class period . class period bear stearn 1 1 5 million 1 2 0 million common share outstanding price share security decline high $ 1 7 2 . 6 1 low $ 3 0 end period . action originally commence federal court allege defendant issue materially false misleading statement regard bear stearn business financial result result false statement bear stearn common stock trade artificially inflate price class period . separately individual shareholder bear stearn commence threaten commence arbitration proceeding lawsuit assert claim similar putative class action . certain matter dismiss settle . addition bear stearn certain officer andor director defendant number purport class action commence united state district court southern district new york seek represent interest participant bear stearn employee stock ownership plan esop time period december 2 0 0 6 march 2 0 0 8 . action bring employee retirement income security act erisa allege defendant breach fiduciary duty plaintiff participant beneficiary esop failing manage prudently esop investment bear stearn security b fail communicate fully accurately risk esop investment bear stearn stock c fail avoid address alleged conflict interest d fail monitor manage administer esop . bear stearn member bear stearn board director certain bear stearn executive officer defendant shareholder derivative class action suit pende united state district court southern district new york . plaintiff assert claim breach fiduciary duty violation federal security law waste corporate asset gross mismanagement unjust enrichment abuse control indemnification contribution connection loss sustain bear stearn result purchase subprime loan certain repurchase common stock . certain individual defendant allege sell holding bear stearn common stock possession material nonpublic information . plaintiff seek compensatory damage unspecified amount . all abovedescribed action file federal court order transfer join pretrial purpose united state district court southern district new york . defendant dismiss purported security class action shareholder derivative action erisa action . january 2 0 1 1 district court grant motion dismiss derivative erisa action deny motion security action . plaintiff derivative action file motion reconsideration dismissal appeal . plaintiff esop action file motion alter judgment leave amend amend consolidated complaint . discovery ongoing security action . city milan litigation criminal investigation . january 2 0 0 9 city milan italy city issue civil proceeding jpmorgan chase bank n . a . j . p . morgan security ltd . jpmorgan chase district court milan . proceeding relate bond issue city june 2 0 0 5 bond b associate swap transaction subsequently restructure number occasion 2 0 0 5 2 0 0 7 swap . city seek damage andor remedy jpmorgan chase ground alleged fraudulent deceitful act alleged breach advisory obligation connection swap bond related swap transaction counterpartie . judge direct current jpmorgan chase personnel jpmorgan chase bank 1 7 3 n . a . individual bank forward trial start 2 0 1 0 . firm charge crime face criminal liability employee find guilty firm subject administrative sanction include restriction ability conduct business italy monetary penalty . hearing continue weekly basis 2 0 1 0 . enron litigation . jpmorgan chase certain officer director involve lawsuit seek damage arise firm banking relationship enron corp . subsidiary enron . number action proceeding firm previously resolve include class action lawsuit caption newby v . enron corp . adversary proceeding bring enron bankruptcy estate . remain enronrelated action include individual action enron investor action enron counterparty purported class action file behalf jpmorgan chase employee participate firm 4 0 1 k plan assert claim erisa alleged breach fiduciary duty jpmorgan chase director officer . action dismiss appeal united state court appeal second circuit . interchange litigation . group merchant file series putative class action complaint federal court . complaint allege visa mastercard certain bank respective bank hold company conspire set price credit debit card interchange fee enact respective association rule violation antitrust law engage tyingbundling exclusive dealing . complaint seek unspecified damage injunctive relief base theory interchange low eliminate challenge conduct . base publicly available estimate visa mastercard brand payment card generate approximately $ 4 0 billion interchange fee industrywide 2 0 0 9 . case consolidate united state district court eastern district new york pretrial proceeding . court dismiss claim relate period prior january 2 0 0 4 . court rule motion relate remainder case plaintiff class certification motion . fact expert discovery closed . in addition consolidated class action complaint plaintiff file supplemental complaint challenge initial public offering ipos mastercard visa ipo complaint . respect mastercard ipo plaintiff allege offering violate section 7 clayton act section 1 sherman act offering fraudulent conveyance . respect visa ipo plaintiff challenge visa ipo antitrust theory parallel articulate mastercard ipo pleading . defendant file motion dismiss ipo complaint . court rule motion . party file motion seek summary judgment claim complaints . investment management litigation . case file claim investment portfolio manage jpmorgan investment management inc . jpmorgan investment management inappropriately invest security subprime residential real estate collateral . plaintiff claim jpmorgan investment management related defendant liable loss $ 1 billion market value security . case file nm home inc . federal district court new york . follow ruling motion address pleading plaintiff claim breach contract breach fiduciary duty negligence gross negligence survive discovery proceed . second case file assure guaranty u . k . new york state court new york state appellate division allow plaintiff proceed claim breach fiduciary duty gross negligence breach contract base alleged violation delaware insurance code . jpmorgan investment management appeal pende new york state court appeal . discovery proceed . case file ambac assurance uk limited new york state court low court grant jpmorgan investment management motion dismiss . new york state appellate division reverse low court decision allow plaintiff proceed claim . fourth case file cmmf llp new york state court . amend complaint assert claim new york law breach fiduciary duty gross negligence breach contract negligent misrepresentation . low court deny defendant motion dismiss discovery proceeding . lehman brother bankruptcy proceeding . 2 0 1 0 lehman brother holding inc . lbhi official committee unsecured creditor file complaint later amend complaint jpmorgan chase bank n . a . united state bankruptcy court southern district new york assert federal bankruptcy law state common law claim seek relief recover $ 8 . 6 billion collateral transfer jpmorgan chase bank n . a . week precede lbhis bankruptcy . amend complaint seek unspecified damage ground jpmorgan chase bank n . a . s collateral request hasten lbhis demise . firm dismiss plaintiff amend complaint entirety . motion decide . firm file counterclaim lbhi allege lbhi fraudulently induce firm large clearing advance lehman inappropriate collateral leave firm $ 2 5 billion claim estate lehman brokerdealer unpaid firm require return collateral lehman . discovery underway trial schedule 2 0 1 2 . addition april 2 0 1 1 firm sipa trustee lbhis u . s . brokerdealer subsidiary lehman brother inc . lbi announce reach agreement return $ 8 0 0 million alleged lbi customer asset lbi estate distribution customer claimant . late june 2 0 1 1 bankruptcy court approve agreement . firm respond regulatory inquiry regard lehman matter . 1 7 4 madoff litigation . jpmorgan chase co . jpmorgan chase bank n . a . jpmorgan security llc jpmorgan security ltd . defendant lawsuit bring trustee liquidation bernard l . madoff investment security llc trustee . trustee recently serve amend complaint assert 2 8 cause action jpmorgan chase 2 0 seek avoid certain transfer direct indirect jpmorgan chase allege preferential fraudulent federal bankruptcy code new york debtor creditor law . remain cause action thing aid abet fraud aid abet breach fiduciary duty conversion unjust enrichment . complaint generally allege jpmorgan chase madoff longtime bank facilitate maintenance madoff ponzi scheme overlook sign wrongdoe order obtain profit fee . complaint purport seek approximately $ 1 9 billion damage jpmorgan chase recover approximately $ 4 2 5 million transfer jpmorgan chase allegedly receive directly indirectly bernard madoff brokerage firm . jpmorgan chase motion return case bankruptcy court district court grant 2 0 1 1 jpmorgan chase dismiss trustee claims . separately j . p . morgan trust company cayman limit jpmorgan suisse sa j . p . morgan security ltd . bear stearn alternative asset international ltd . defendant suit bankruptcy court state federal court new york arise liquidation proceeding fairfield sentry limited fairfield sigma limit fairfield socalle madoff feeder fund . action advance theory mistake restitution seek recover payment previously defendant fund total approximately $ 1 4 0 million . fairfield madoff trustee reach agreement pursuant complaint cayman suisse jp morgan security ltd . dismiss agreement approve court . in addition purported class action pende jpmorgan chase united state district court southern district new york motion separate potential class plaintiff add claim jpmorgan chase jpmorgan chase bank n . a . j . p . morgan security llc j . p . morgan security ltd . alreadypende purported class action court . allegation complaint largely track raise trustee . jpmorgan chase entity dismiss actions . finally jpmorgan chase defendant action pende new york state court individual action federal court new york . allegation action essentially identical involve claim firm aid abet fraud aid abet breach fiduciary duty conversion unjust enrichment . federal action firm prevail motion dismiss district court decision recently affirm appeal . state court action firm motion dismiss fully brief party await court decision . firm respond governmental inquiry concern madoff matter . mortgagebacked security litigation regulatory investigation . jpmorgan chase affiliate bear stearn affiliate washington mutual affiliate defendant number case role issuer underwriter mortgagebacke security mbs offering . case include purport class action suit action individual purchaser security action insurance company guarantee payment principal interest particular tranche action trustee . allegation vary lawsuit case generally allege offer document $ 1 6 0 billion security issue dozen securitization trust contain material misrepresentation omission include statement regard underwriting standard pursuant underlie mortgage loan issue assert representation warranty relate loan breach time origination . in action firm mbs issuer case underwriter mb offering purport class action pende jpmorgan chase bear stearn andor certain affiliate current employee united state district court eastern southern district new york . defendant dismiss action . motion grant dismiss claim relate offering . motion remain pende . addition washington mutual affiliate wamu asset acceptance corp . wamu capital corp . certain officer director wamu asset acceptance corp . defendant nowconsolidate purported class action case pende western district washington . defendant motion dismiss grant dismiss claim relate mbs offering plaintiff purchaser . defendant judgment pleading claim relate mbs certificate plaintiff purchaser . plaintiff seek leave amend complaint add jpmorgan chase bank n . a . defendant theory successor washington mutual bank . firm oppose request . plaintiff file motion class certification defendant oppose . discovery ongoing . in action bring firm mbs issuer case underwriter certain jpmorgan chase entity bear stearn entity certain washington mutual affiliate defendant separate individual action commence federal home loan bank pittsburgh seattle san francisco chicago indianapolis atlanta boston state court country certain jpmorgan chase bear stearn washington mutual entity defendant separate individual action commence institutional investor federal state courts . 1 7 5 emc mortgage corporation emc subsidiary jpmorgan chase co . certain jpmorgan chase entity defendant pende action commence bond insurer guarantee payment principal interest approximately $ 3 . 6 billion certain class seven different mb offering sponsor emc . action commence assure guaranty corp . syncora guarantee inc . respectively pende united state district court southern district new york . syncora file action new york state court alleging tort claim arise transaction original federal complaint . fourth action file ambac assurance corporation dismiss jurisdictional ground united state district southern district new york . dismissal appeal united state court appeal second circuit . ambac file nearly identical complaint new york state court . sixth action commence cifg assurance north america inc . pende state court texas defendant file motion argue new york superior forum . action plaintiff claim underlie mortgage loan origination defect purportedly violate certain representation warranty emc plaintiff emc breach relevant agreement party fail repurchase allegedly defective mortgage loan . addition ambac cifg syncora complaint allege fraudulent inducement tortious interference tortious interference dismiss ambac federal action immediately jurisdictional dismissal . action seek unspecified damage syncora state complaint order compel emc repurchase loan . cifg complaint seek punitive damages . in action firm solely underwriter issuer mbs offering firm contractual right indemnification issuer indemnity right prove effectively unenforceable issuer defunct affiliate indymac bancorp indymac trust thornburg mortgage thornburg . respect indymac trust jpmorgan security numerous underwriter individual defendant capacity successor bear stearn purported class action pende united state district court southern district new york bring behalf purchaser security indymac trust mb offering . court action dismiss claim certain securitization include offering plaintiff purchase security allow claim offering proceed . plaintiff motion certify class investor certain offering pende discovery ongoing . addition jpmorgan security jpmorgan chase defendant individual action file federal home loan bank pittsburgh connection single offering affiliate indymac bancorp . discovery action ongoing . separately jpmorgan security successor bear stearn co . inc . underwriter certain individual defendant action pende state court california bring mbia insurance corp . mbia . action relate certain security issue indymac trust offering bear stearn underwriter mbia provide guaranty insurance policy . mbia purport subrogate right mb holder seek recovery sum pay pay pursuant policy . discovery ongoing . respect thornburg bear stearn subsidiary defendant purported class action pende united state district court district new mexico number financial institution serve depositor andor underwriter thornburg mb offering . defendant dismiss action . a shareholder complaint file new york state court firm affiliate member board director thereof certain employee assert claim base alleged wrongful action inaction relate residential mortgage origination securitization . action seek accounting damages . in addition abovedescribe litigation firm receive respond number subpoena informal request information federal state authority concern mortgagerelate matter include inquiry concern number transaction involve firm origination purchase loan underwriting issuance mb treatment early payment default potential breach securitization representation warranty diligence connection securitization firm participation offering certain collateralized debt obligations . jpmorgan security resolve investigation secs division enforcement regard certain collateralized debt obligations . in addition mortgagerelate matter firm defendant action commence deutsche bank describe detail respect washington mutual litigation . mortgage foreclosure investigation litigation . multiple state federal official announce investigation procedure follow mortgage servicing company bank include jpmorgan chase co . affiliate relate service foreclosure loss mitigation process . firm cooperate investigation investigation result material fine penalty equitable remedy include require default servicing process change enforcement action significant legal cost respond governmental investigation additional litigation . office comptroller currency federal reserve issue consent order jpmorgan chase bank n . a . jpmorgan chase co . respectively . order regulator mandate significant change firm service default business outline requirement implement change . include requirement retention independent consultant conduct independent review reimbursement borrower sustain economic harm residential foreclosure action proceeding loan service firm pende time january 1 2 0 0 9 december 3 1 2 0 1 0 residential foreclosure sale occur time period . 1 7 6 regulator reserve right impose civil monetary penalty later date . investigation state federal authority remain pende . firm discussion state federal authority potential global settlement claim assurance resolution reached . four purport class action lawsuit file firm relate mortgage foreclosure procedure . additionally firm defend purport class action bring bank america involve emc loan . case voluntarily dismiss prejudice plaintiff . firm dismiss remain case . fourth case plaintiff file amend complaint firm dismiss . a shareholder derivative action file new york state court firm board director allege board fail exercise adequate oversight wrongful conduct firm regard mortgage servicing . action seek declaratory judgment damages . as january 2 0 1 1 firm resume initiation new foreclosure proceeding nearly state previously suspend proceeding utilize revise procedure connection execution affidavit document use firm employee foreclosure process . firm process review pende foreclosure matter determine remediation specific documentation necessary resume pende foreclosure review necessary remediation pende matter complete . municipal derivative investigation litigation . department justice doj conjunction internal revenue service security exchange commission group state attorney general office comptroller currency federal reserve bank new york investigate firm possible antitrust security taxrelated violation connection bidding sale guarantee investment contract derivative municipal issuer . july 2 0 1 1 firm reach settlement government agency resolve investigation . settlement cover conduct prior 2 0 0 6 . term settlement firm enter nonprosecution agreement doj pay net $ 2 1 1 million government agency . firm agree implement measure strengthen board oversight compliance risk management program relate certain type transactions . purported class action lawsuit individual action municipal derivative action file jpmorgan chase bear stearn numerous provider broker allege antitrust violation reportedly $ 1 0 0 billion $ 3 0 0 billion annual market financial instrument relate municipal bond offering refer collectively municipal derivative . municipal derivative action consolidate united state district court southern district new york . court deny grant defendant motion dismiss purported class individual action permit certain claim proceed firm federal california state antitrust law california false claim act . subsequently number additional individual action assert substantially similar claim include claim new york west virginia state antitrust statute file jpmorgan chase bear stearn numerous defendant . case coordinate pretrial purpose united state district court southern district new york . discovery ongoing . followe j . p . morgan security november 4 2 0 0 9 settlement sec connection certain jefferson county alabama county warrant underwriting swap transaction party bring civil litigation firm . county putative class sewer rate payer file complaint firm defendant alabama state court . suit allege firm payment certain party exchange choose underwrite $ 3 billion warrant issue county choose counterparty certain swap execute county . complaint allege firm conceal thirdparty payment concealment county enter transaction . court deny firm motion dismiss complaint proceeding . firm file mandamus petition alabama supreme court seek immediate appellate review decision . mandamus petition countys lawsuit deny april 2 0 1 1 . mandamus petition lawsuit bring sewer ratepayer remain pending . separately insurance company guarantee payment principal interest warrant issue jefferson county file separate action firm new york state court . complaint assert firm fraudulently mislead issue insurance base substantially alleged conduct describe alleged nondisclosure . insurer claim insure aggregate principal nearly $ 1 . 2 billion seek unspecified damage excess $ 4 0 0 million unspecified punitive damage . insurer claim insure aggregate principal $ 3 7 8 million seek recovery $ 4 million allegedly pay policy date future payment unspecified punitive damage . december 2 0 1 0 court deny firm motion dismiss complaint . discovery proceeding . overdraft feedebit post order litigation . jpmorgan chase bank n . a . defendant purport class action relate practice post debit card transaction customer deposit account . plaintiff allege firm improperly reorder debit card transaction high low process transaction order generate unwarranted overdraft fee . plaintiff contend firm process transaction 1 7 7 chronological order authorize . plaintiff seek disgorgement overdraft fee pay firm plaintiff approximately 2 0 0 3 result reordering debit card transaction . claim firm consolidate numerous complaint national bank multidistrict litigation pende united state district court southern district florida . firm motion compel arbitration certain plaintiff claim deny district court . ruling currently appeal . discovery proceed district court . petter bankruptcy related matter . jpmorgan chase certain affiliate include equity partner oep defendant action file connection receivership bankruptcy proceeding pertain thomas j . petter certain entity affiliate petter collectively petter polaroid corporation . principal action jpmorgan chase affiliate bring court appoint receiver civil action file federal government petter trustee bankruptcy proceeding petter entity generally seek avoid fraudulent transfer preference ground certain purported transfer connection 2 0 0 5 acquisition polaroid petter time majorityowne oep ii credit facility jpmorgan chase financial institution enter polaroid iii credit line investment account hold petter . action collectively seek recovery approximately $ 4 5 0 million . defendant dismiss complaint action file petter bankruptcy trustee seek transfer action united state district court district minnesota receiver action pending . securitie lending litigation . jpmorgan chase bank n . a . defendant putative class action assert erisa claim pende united state district court southern district new york bring participant firm security lending business . fifth lawsuit file new york state court individual participant program . purported class action consolidate relate investment approximately $ 5 0 0 million mediumterm note sigma finance inc . sigma . august 2 0 1 0 court certify plaintiff class consist security lend participant hold sigma mediumterm note september 3 0 2 0 0 8 include hold note virtue participation investment cash collateral collective fund hold note virtue investment cash collateral individual account . discovery complete . jpmorgan chase partial summary judgment plaintiff duty loyalty claim allege firm create impermissible conflict interest provide repurchase financing sigma hold sigma mediumterm note security lending account . fourth putative class action concern investment approximately $ 5 0 0 million lehman brother mediumterm note . firm dismiss amend complaint await decision . discovery proceed motion pende . new york state court action class action concern plaintiff allege loss money sigma lehman brother mediumterm note . firm answer complaint . discovery proceeding . service member civil relief act housing economic recovery act investigation litigation . multiple government official announce inquiry firm procedure relate service member civil relief act scra housing economic recovery act 2 0 0 8 hera . inquiry prompt firm public statement scra hera compliance action remedy certain instance firm mistakenly charge active recentlyactive military personnel mortgage interest fee excess permit scra hera number instance foreclose borrower protect scra hera . firm implement number procedural enhancement control strengthen scra hera compliance . addition individual borrower file nationwide class action united state district court south carolina firm allege violation scra relate home loan . firm agree pay $ 2 7 million plus attorney fee addition reimbursement previously pay firm settle class action . settlement receive preliminary approval court subject final court approval . washington mutual litigation . subsequent jpmorgan chase acquisition federal deposit insurance corporation fdic substantially asset certain specified liability washington mutual bank washington mutual bank september 2 0 0 8 washington mutual bank parent hold company washington mutual inc . wmi whollyowned subsidiary wmi investment corp . debtor commence voluntary case chapter 1 1 title 1 1 united state code united state bankruptcy court district delaware bankruptcy case . bankruptcy case debtor assert right interest certain asset . asset dispute include principally follow approximately $ 4 billion trust security contribute wmi washington mutual bank trust security b right tax refund arise overpayment attributable operation washington mutual bank subsidiary c ownership right approximately $ 4 billion wmi contend deposit account washington mutual bank subsidiary d ownership right contract asset collectively disputed assets . wmi jpmorgan chase fdic involve litigation claim pende bankruptcy court united state district court district columbia . 1 7 8 2 0 1 0 wmi jpmorgan chase fdic announce global settlement agreement significant creditor group global settlement agreement . global settlement agreement incorporate wmis propose chapter 1 1 plan plan submit bankruptcy court . approve bankruptcy court global settlement resolve numerous dispute wmi jpmorgan chase fdic capacity receiver washington mutual bank fdic corporate capacity significant creditor group include dispute relate disputed assets . the bankruptcy court consider confirmation plan include global settlement agreement hearing early december 2 0 1 0 . early january 2 0 1 1 bankruptcy court issue opinion conclude global settlement agreement fair reasonable plan confirm party correct certain deficiency include scope release . deficiency relate dispute asset . equity committee represent shareholder wmi file petition seek direct appeal united state court appeal circuit bankruptcy court rule find settlement fair reasonable . revise plan file bankruptcy court february 2 0 1 1 . bankruptcy court conclude evidentiary portion confirmation hearing revise plan july 2 0 1 1 . oral argument schedule august 2 4 2 0 1 1 . court ultimately confirm plan global settlement effective firm currently estimate incur net additional liability reflect balance sheet numerous dispute cover global settlement . other proceeding relate washington mutual failure pende bankruptcy court . action july 2 0 1 0 certain holder trust security commence adversary proceeding bankruptcy court jpmorgan chase wmi entity seek relief declaratory judgment wmi jpmorgan chase right title interest trust security . early january 2 0 1 1 bankruptcy court grant summary judgment jpmorgan chase deny summary judgment plaintiff trust security adversary proceeding . proceeding relate washington mutual failure pende united state district court district columbia include lawsuit bring deutsche bank national trust company initially fdic assert estimate $ 6 billion $ 1 0 billion damage base alleged breach mortgage securitization agreement alleged violation certain representation warranty certain wmi subsidiary connection securitization agreement . case include assertion jpmorgan chase assume liability relate mortgage securitization agreement . april 2 0 1 1 district court deny premature motion firm fdic seek ruling fdic retain liability deutsche bank claim . discovery underway . in addition jpmorgan chase sue action originally file state court texas texas action certain holder wmi common stock debt wmi washington mutual bank seek unspecified damage allege jpmorgan chase acquire substantially asset washington mutual bank fdic allegedly toolow price . texas action transfer united state district court district columbia ultimately grant jpmorgan chase fdic motion dismiss complaint . plaintiff appeal dismissal june 2 4 2 0 1 1 united state court appeal d . c . circuit reverse trial court dismissal remand case proceeding . addition legal proceeding discuss jpmorgan chase subsidiary defendant involve substantial number legal proceeding . firm believe meritorious defense claim assert currently outstanding legal proceeding intend defend vigorously matter . additional legal proceeding initiate time time future . the firm establish reserve currently outstanding legal proceeding . firm accrue potential liability arise proceeding probable liability incur loss reasonably estimate . firm evaluate outstanding legal proceeding quarter assess litigation reserve adjustment reserve upwards downward appropriate base management good judgment consultation counsel . firm incur litigation expense $ 1 . 9 billion $ 7 9 2 million respectively month end june 3 0 2 0 1 1 2 0 1 0 $ 3 . 0 billion $ 3 . 7 billion respectively month end june 3 0 2 0 1 1 2 0 1 0 . assurance firm litigation reserve need adjust future . in view inherent difficulty predict outcome legal proceeding particularly claimant seek large indeterminate damage matter present novel legal theory involve large number party early stage discovery firm state confidence eventual outcome currently pende matter timing ultimate resolution eventual loss fine penalty impact relate matter . jpmorgan chase believe base current knowledge consultation counsel account current litigation reserve legal proceeding currently pende material adverse effect firm consolidate financial condition . firm note light uncertainty involve proceeding assurance ultimate resolution matter significantly exceed reserve currently accrue result outcome particular matter material jpmorgan chase operate result particular period depend factor size loss liability impose level jpmorgan chase income period . 1 7 9 note 2 4 business segment firm manage line business basis . major reportable business segment investment bank retail financial service card service auto commercial banking treasury security service asset management corporateprivate equity segment . business segment determine base product service provide type customer serve reflect manner financial information currently evaluate management . result line business present manage basis . definition manage basis footnote table . discussion concern jpmorgan chase business segment business segment result page 1 7 1 8 form 1 0 q page 6 7 6 8 note 3 4 page 2 9 0 2 9 3 jpmorgan chase 2 0 1 0 annual report . subsequent business segment changescommencing july 1 2 0 1 1 firm business segment reorganize followsauto student lending transfer rfs segment report card single segment . rfs continue segment organize component consumer business bank retail banking mortgage banking include mortgage production servicing real estate portfolios . the business segment information associate rfs card include follow segment result section revise reflect business reorganization retroactive january 1 2 0 1 0 . segment result follow table provide summary firm segment result month end june 3 0 2 0 1 1 2 0 1 0 manage basis . total net revenue noninter revenue net interest income segment present taxequivalent basis . accordingly revenue taxexempt security investment receive tax credit present manage result basis comparable taxable security investment . approach allow management assess comparability revenue arise taxable taxexempt source . corresponding income tax impact relate item record income tax expensebenefit . effective january 1 2 0 1 1 capital allocate card reduce largely reflect portfolio runoff improve risk profile business capital allocate tss increase reflect growth underlying business . firm continue assess level capital require line business assumption methodology use allocate capital business segment refinement implement future periods . segment result reconciliationa month end june 3 0 2 0 1 1 million ratiosinvestmentbankretail financialservicescard service autocommercialbankingtreasury security servicesasset managementcorporateprivate equity reconcile itemsc totalnoninter revenue $ 5 2 3 3 $ 3 1 1 5 $ 1 3 0 6 $ 5 9 8 $ 1 1 8 3 $ 2 1 3 9 $ 1 8 4 7 $ 4 7 8 $ 1 4 9 4 3 net interest income 2 0 8 1 4 0 2 7 3 4 5 5 1 0 2 9 7 4 9 3 9 8 2 1 8 1 2 1 1 1 8 3 6 total net revenue 7 3 1 4 7 1 4 2 4 7 6 1 1 6 2 7 1 9 3 2 2 5 3 7 2 0 6 5 5 9 9 2 6 7 7 9 provision credit losses 1 8 3 9 9 4 9 4 4 5 4 2 1 2 9 1 8 1 0 credit allocation incomeexpenseb 3 2 3 2 noninterest expense 4 3 3 2 5 2 7 1 1 9 8 8 5 6 3 1 4 5 3 1 7 9 4 1 4 4 1 1 6 8 4 2 incomeloss income tax expensebenefit 3 1 6 5 8 7 7 1 8 2 9 1 0 1 0 5 1 3 7 3 1 6 3 3 6 3 1 8 1 2 7 income tax expensebenefit 1 1 0 8 4 9 4 7 1 9 4 0 3 1 8 0 2 9 2 1 3 1 6 3 1 2 6 9 6 net income $ 2 0 5 7 $ 3 8 3 $ 1 1 1 0 $ 6 0 7 $ 3 3 3 $ 4 3 9 $ 5 0 2 $ $ 5 4 3 1 average common equity $ 4 0 0 0 0 $ 2 5 0 0 0 $ 1 6 0 0 0 $ 8 0 0 0 $ 7 0 0 0 $ 6 5 0 0 $ 7 1 5 7 7 $ $ 1 7 4 0 7 7 average assets 8 4 1 3 5 5 2 8 7 2 3 5 1 9 8 0 4 4 1 4 3 5 6 0 5 2 6 8 8 7 4 2 0 6 5 9 5 4 5 5 na 2 1 9 2 5 4 3 return average common equity 2 1 % 6 % 2 8 % 3 0 % 1 9 % 2 7 % nmnm 1 2 % overhead ratio 5 9 7 4 4 2 3 5 7 5 7 1 nmnm 6 3 1 8 0 three month end june 3 0 2 0 1 0 million ratiosinvestmentbankretail financialservicescard service autocommercialbankingtreasury security servicesasset managementcorporateprivate equity reconcile itemsc totalnoninter revenue $ 4 4 3 2 $ 2 7 2 7 $ 1 1 2 6 $ 5 4 6 $ 1 2 2 7 $ 1 6 9 9 $ 1 1 0 3 $ 4 4 6 $ 1 2 4 1 4 net interest income 1 9 0 0 4 2 3 7 3 9 3 6 9 4 0 6 5 4 3 6 9 7 4 7 9 6 1 2 6 8 7 total net revenue 6 3 3 2 6 9 6 4 5 0 6 2 1 4 8 6 1 8 8 1 2 0 6 8 1 8 5 0 5 4 2 2 5 1 0 1 provision credit losses 3 2 5 1 5 4 5 2 3 9 1 2 3 5 1 6 5 2 3 3 6 3 credit allocation incomeexpenseb 3 0 3 0 noninterest expense 4 5 2 2 3 9 4 5 1 7 7 2 5 4 2 1 3 9 9 1 4 0 5 1 0 4 6 1 4 6 3 1 incomeloss income tax expensebenefit 2 1 3 5 1 4 7 4 8 9 9 1 1 7 9 4 6 8 6 5 8 8 0 6 5 1 2 7 1 0 7 income tax expensebenefit 7 5 4 6 2 5 3 6 3 4 8 6 1 7 6 2 6 7 1 5 3 5 1 2 2 3 1 2 net income $ 1 3 8 1 $ 8 4 9 $ 5 3 6 $ 6 9 3 $ 2 9 2 $ 3 9 1 $ 6 5 3 $ $ 4 7 9 5 average common equity $ 4 0 0 0 0 $ 2 4 6 0 0 $ 1 8 4 0 0 $ 8 0 0 0 $ 6 5 0 0 $ 6 5 0 0 $ 5 5 0 6 9 $ $ 1 5 9 0 6 9 average assets 7 1 0 0 0 5 3 1 4 0 2 0 2 1 4 7 0 2 1 3 3 3 0 9 4 2 8 6 8 6 3 4 2 6 5 6 5 3 1 7 na 2 0 4 3 6 4 7 return average common equity 1 4 % 1 4 % 1 2 % 3 5 % 1 8 % 2 4 % nmnm 1 2 % overhead ratio 7 1 5 7 3 5 3 6 7 4 6 8 nmnm 5 8 six month end june 3 0 2 0 1 1 million ratiosinvestmentbankretail financialservicescard service autocommercialbankingtreasury security servicesasset managementcorporateprivate equity reconcile itemsc totalnoninter revenue $ 1 1 4 0 9 $ 4 4 9 5 $ 2 3 5 3 $ 1 1 0 0 $ 2 3 2 0 $ 4 1 5 9 $ 3 3 2 5 $ 9 0 2 $ 2 8 2 5 9 net interest income 4 1 3 8 8 1 1 3 7 1 9 9 2 0 4 3 1 4 5 2 7 8 4 2 5 2 2 4 0 2 3 7 4 1 total net revenue 1 5 5 4 7 1 2 6 0 8 9 5 5 2 3 1 4 3 3 7 7 2 4 9 4 3 3 5 7 7 1 1 4 2 5 2 0 0 0 provision credit losses 6 1 2 2 1 9 3 1 2 9 7 1 0 1 2 1 7 1 9 2 9 7 9 credit allocation incomeexpenseb 5 9 5 9 noninterest expense 9 3 4 8 1 0 1 7 1 3 9 0 5 1 1 2 6 2 8 3 0 3 4 5 4 2 0 0 3 3 2 8 3 7 incomeloss income tax expensebenefit 6 8 1 1 2 4 4 4 3 5 0 1 9 1 6 9 9 9 1 4 7 2 1 5 9 3 1 2 0 1 1 6 1 8 4 income tax expensebenefit 2 3 8 4 2 6 0 1 7 0 6 7 6 3 3 5 0 5 6 7 3 6 9 1 2 0 1 5 1 9 8 net income $ 4 4 2 7 $ 1 6 $ 2 6 4 4 $ 1 1 5 3 $ 6 4 9 $ 9 0 5 $ 1 2 2 4 $ $ 1 0 9 8 6 average common equity $ 4 0 0 0 0 $ 2 5 0 0 0 $ 1 6 0 0 0 $ 8 0 0 0 $ 7 0 0 0 $ 6 5 0 0 $ 6 9 2 5 9 $ $ 1 7 1 7 5 9 average assets 8 2 8 6 6 2 2 9 2 5 5 7 2 0 1 2 2 5 1 4 1 9 8 9 5 0 2 9 4 7 1 5 7 7 5 6 2 4 3 7 na 2 1 4 8 7 4 1 return average common equity 2 2 % % 3 3 % 2 9 % 1 9 % 2 8 % nmnm 1 3 % overhead ratio 6 0 8 1 4 1 3 6 7 5 7 0 nmnm 6 3 1 8 1 six month end june 3 0 2 0 1 0 million ratiosinvestmentbankretail financialservicescard service autocommercialbankingtreasury security servicesasset managementcorporateprivate equity reconcile itemsctotalnoninter revenue $ 1 0 6 2 3 $ 5 2 5 0 $ 2 1 1 3 $ 1 0 4 6 $ 2 3 7 3 $ 3 4 7 3 $ 2 3 8 4 $ 8 8 7 $ 2 6 3 7 5 net interest income 4 0 2 8 8 6 8 4 8 2 0 2 1 8 5 6 1 2 6 4 7 2 6 1 8 2 3 1 8 6 2 6 3 9 7 total net revenue 1 4 6 5 1 1 3 9 3 4 1 0 3 1 5 2 9 0 2 3 6 3 7 4 1 9 9 4 2 0 7 1 0 7 3 5 2 7 7 2 provision credit losses 7 8 7 5 1 0 4 6 0 7 7 2 1 5 5 4 0 1 5 1 0 3 7 3 credit allocation incomeexpenseb 6 0 6 0 noninterest expense 9 3 6 0 7 8 4 2 3 5 1 9 1 0 8 1 2 7 2 4 2 8 4 7 3 3 8 2 3 0 7 5 5 incomeloss income tax expensebenefit 6 0 7 8 9 8 8 7 1 9 1 8 4 2 9 0 8 1 3 1 2 8 1 0 1 0 1 3 1 1 6 4 4 income tax expensebenefit 2 2 2 6 4 3 5 3 2 1 7 5 9 3 3 7 5 2 9 7 1 1 0 1 3 3 5 2 3 net income $ 3 8 5 2 $ 5 5 3 $ 3 9 8 $ 1 0 8 3 $ 5 7 1 $ 7 8 3 $ 8 8 1 $ $ 8 1 2 1 average common equity $ 4 0 0 0 0 $ 2 4 6 0 0 $ 1 8 4 0 0 $ 8 0 0 0 $ 6 5 0 0 $ 6 5 0 0 $ 5 3 5 9 0 $ $ 1 5 7 5 9 0 average assets 6 9 3 1 5 7 3 1 9 9 0 6 2 1 9 8 1 2 1 3 3 1 6 2 4 0 5 8 3 6 2 9 7 8 5 7 1 5 7 9 na 2 0 4 1 1 7 7 return average common equity 1 9 % 5 % 4 % 2 7 % 1 8 % 2 4 % nmnm 1 0 % overhead ratio 6 4 5 6 3 4 3 7 7 5 6 8 nmnm 5 8 ain addition analyze firm result reported basis management review firm line business result manage basis nongaap financial measure . firm definition manage basis start reported u . s . gaap result include certain reclassification discuss impact net income report line business firm whole . bib manage traditional credit exposure relate global corporate bank gcb behalf ib ts . effective january 1 2 0 1 1 ib tss share economic relate firm gcb client . include allocation net revenue provision credit loss expense . prioryear period reflect reimbursement ib portion total cost manage credit portfolio . ib recognize credit allocation component income . csegment manage result reflect revenue fully taxequivalent basis corresponding income tax impact record income tax expensebenefit . adjustment eliminate reconcile item arrive firm report u . s . gaap result . taxequivalent adjustment month end june 3 0 2 0 1 1 2 0 1 0 follow . month end june 3 0 month end june 3 0 millions 2 0 1 1 2 0 1 0 2 0 1 1 2 0 1 0 noninter revenue $ 5 1 0 $ 4 1 6 $ 9 6 1 $ 8 2 7 net interest income 1 2 1 9 6 2 4 0 1 8 6 income tax expense 6 3 1 5 1 2 1 2 0 1 1 0 1 3 1 8 2 report independent register public accounting firm board director stockholder ofjpmorgan chase co . we review consolidated balance sheet jpmorgan chase co . subsidiary firm june 3 0 2 0 1 1 related consolidated statement income threemonth sixmonth period end june 3 0 2 0 1 1 june 3 0 2 0 1 0 consolidated statement cash flow consolidated statement change stockholder equity comprehensive income sixmonth period end june 3 0 2 0 1 1 june 3 0 2 0 1 0 include firm quarterly report form 1 0 q period end june 3 0 2 0 1 1 . interim financial statement responsibility firm management . we conduct review accordance standard public company account oversight board united state . review interim financial information consist principally apply analytical procedure inquiry person responsible financial accounting matter . substantially scope audit conduct accordance standard public company account oversight board unite state objective expression opinion regard financial statement . accordingly express opinion . based review aware material modification consolidated interim financial statement conformity accounting principle generally accept united state america . we previously audit accordance standard public company account oversight board unite state consolidated balance sheet december 3 1 2 0 1 0 related consolidated statement income change stockholder equity comprehensive income cash flow year end present report date february 2 8 2 0 1 1 express unqualified opinion consolidated financial statement . opinion information set forth accompanying consolidated balance sheet december 3 1 2 0 1 0 fairly state material respect relation consolidated balance sheet derived . august 5 2 0 1 1 change composition business segment discuss note 2 4 date november 4 2 0 1 1 pricewaterhousecoopers llp 3 0 0 madison avenue new york ny 1 0 0 1 7 1 8 3 jpmorgan chase co . consolidate average balance sheet interest ratestaxableequivalent interest rate million rate month end june 3 0 2 0 1 1 month end june 3 0 2 0 1 0 averagebalanceinterestrateannualize averagebalanceinterestrateannualize asset deposit banks $ 7 5 8 0 1 $ 1 4 4 0 . 7 6 % $ 5 8 7 3 7 $ 9 2 0 . 6 3 % federal fund sell security purchase resale agreements 2 0 2 0 3 6 6 0 4 1 . 2 0 1 8 9 5 7 3 3 9 8 0 . 8 4 security borrowed 1 2 4 8 0 6 3 0 0 . 1 0 1 1 3 6 5 0 3 2 0 . 1 1 trading asset debt instruments 2 8 5 1 0 4 3 0 0 7 4 . 2 3 2 4 5 5 3 2 2 6 0 1 4 . 2 5 securities 3 4 2 2 4 8 2 6 4 7 3 . 1 0 d 3 2 7 4 2 5 2 5 6 4 3 . 1 4 d loans 6 8 6 1 1 1 9 1 6 3 5 . 3 6 7 0 5 1 8 9 9 9 9 1 5 . 6 8 assetsa 4 8 7 1 6 1 5 8 1 . 3 0 3 4 4 2 9 1 3 7 1 . 6 0 total interestearne assets 1 7 6 4 8 2 2 1 5 7 5 3 3 . 5 8 1 6 7 4 5 3 5 1 5 8 1 5 3 . 7 9 allowance loan losses 2 9 5 4 8 3 7 9 2 9 cash banks 2 7 2 2 6 3 3 5 3 5 trading asset equity instruments 1 3 7 6 1 1 9 5 0 8 0 trading asset derivative receivables 8 2 8 6 0 7 9 4 0 9 goodwill 4 8 8 3 4 4 8 3 4 8 intangible asset mortgage service rights 1 2 6 1 8 1 4 5 1 0 purchase credit card relationships 7 8 1 1 1 0 2 intangibles 2 9 5 7 3 1 6 3 assets 1 4 4 3 8 2 1 3 1 8 9 4 total assets $ 2 1 9 2 5 4 3 $ 2 0 4 3 6 4 7 liability interestbeare deposits $ 7 3 2 7 6 6 $ 1 1 2 3 0 . 6 1 % $ 6 6 8 9 5 3 $ 8 8 3 0 . 5 3 % federal fund purchase security loan sell repurchase agreements 2 8 1 8 4 3 2 0 2 0 . 2 9 2 7 3 6 1 4 4 9 e 0 . 0 7 e commercial paper 4 1 6 8 2 2 0 0 . 1 9 3 7 5 5 7 1 8 0 . 1 9 trading liability debt shortterm liabilitiesbc 2 1 2 8 7 8 6 6 8 1 . 2 6 1 8 9 8 2 6 5 2 7 1 . 1 1 beneficial interest issue consolidated vies 6 9 3 9 9 2 0 2 1 . 1 7 9 0 0 8 5 3 0 6 1 . 3 6 longterm debtc 2 7 3 9 3 4 1 5 8 1 2 . 3 1 2 7 0 0 8 5 1 3 4 7 2 . 0 0 total interestbeare liabilities 1 6 1 2 5 0 2 3 7 9 6 0 . 9 4 1 5 3 0 1 2 0 3 0 3 2 0 . 7 9 noninterestbeare deposits 2 4 7 1 3 7 2 0 9 6 1 5 trading liability equity instruments 3 2 8 9 5 2 1 6 trading liability derivative payables 6 6 0 0 9 6 2 5 4 7 liability include allowance lendingrelated commitments 8 1 7 2 9 6 8 9 2 8 total liabilities 2 0 1 0 6 6 6 1 8 7 6 4 2 6 stockholder equity prefer stock 7 8 0 0 8 1 5 2 common stockholder equity 1 7 4 0 7 7 1 5 9 0 6 9 total stockholder equity 1 8 1 8 7 7 1 6 7 2 2 1 total liability stockholder equity $ 2 1 9 2 5 4 3 $ 2 0 4 3 6 4 7 interest rate spread 2 . 6 4 3 . 0 0 net interest income net yield interestearne asset $ 1 1 9 5 7 2 . 7 2 % $ 1 2 7 8 3 3 . 0 6 % ainclude margin loans . binclude brokerage customer payable . ceffective january 1 2 0 1 1 longterm advance fhlb reclassify borrow fund longterm debt . prioryear period revise conform current presentation average longterm fhlb advance month end june 3 0 2 0 1 0 $ 1 4 . 0 billion . dfor month end june 3 0 2 0 1 1 2 0 1 0 annualize rate afs security base amortized cost 3 . 1 5 % 3 . 1 9 % respectively . ereflect benefit favorable market environment dollarroll financing second quarter 2 0 1 0 . 1 8 4 jpmorgan chase co . consolidate average balance sheet interest ratestaxableequivalent interest rate million rate month end june 3 0 2 0 1 1 month end june 3 0 2 0 1 0 averagebalanceinterestrateannualize averagebalanceinterestrateannualize asset deposit banks $ 5 6 5 8 4 $ 2 4 5 0 . 8 7 % $ 6 1 4 6 8 $ 1 8 7 0 . 6 1 % federal fund sell security purchase resale agreements 2 0 2 2 5 6 1 1 4 7 1 . 1 4 1 7 9 8 5 8 8 0 5 0 . 9 0 security borrowed 1 1 9 7 2 6 7 7 0 . 1 3 1 1 4 1 4 0 6 1 0 . 1 1 trading asset debt instruments 2 8 0 3 3 4 5 9 3 2 4 . 2 7 2 4 6 8 0 4 5 3 9 2 4 . 4 1 securities 3 3 0 6 5 7 4 9 1 8 3 . 0 0 d 3 3 2 4 0 5 5 5 0 8 3 . 3 4 d loans 6 8 7 1 1 7 1 8 6 9 4 5 . 4 9 7 1 5 1 0 8 2 0 5 6 7 5 . 8 0 assetsa 4 9 2 9 9 3 0 6 1 . 2 5 3 1 1 7 5 2 3 0 1 . 4 9 total interestearne assets 1 7 2 5 9 7 3 3 1 3 1 9 3 . 6 6 1 6 8 0 9 5 8 3 2 7 5 0 3 . 9 3 allowance loan losses 3 0 6 6 9 3 8 4 3 0 cash banks 2 8 2 7 4 3 1 7 8 9 trading asset equity instruments 1 3 9 7 6 9 8 9 4 0 8 trading asset derivative receivables 8 4 1 4 1 7 9 0 4 8 goodwill 4 8 8 4 0 4 8 4 4 5 intangible asset mortgage service rights 1 3 3 1 7 1 4 8 3 1 purchase credit card relationships 8 1 9 1 1 4 9 intangibles 3 0 1 4 3 1 3 6 assets 1 3 5 2 6 3 1 3 0 8 4 3 total assets $ 2 1 4 8 7 4 1 $ 2 0 4 1 1 7 7 liability interestbeare deposits $ 7 1 6 9 3 2 $ 2 0 4 5 0 . 5 8 % $ 6 7 3 1 6 9 $ 1 7 2 7 0 . 5 2 % federal fund purchase security loan sell repurchase agreements 2 8 0 0 5 6 3 1 9 0 . 2 3 2 7 2 7 7 9 8 0 e 0 . 0 6 e commercial paper 3 9 2 7 3 3 9 0 . 2 0 3 7 5 0 9 3 5 0 . 1 9 trading liability debt shortterm liabilitiesbc 2 0 3 3 9 8 1 3 5 0 1 . 3 4 1 7 9 5 8 6 1 1 0 3 1 . 2 4 beneficial interest issue consolidated vies 7 1 1 5 6 4 1 6 1 . 1 8 9 4 0 7 2 6 3 6 1 . 3 6 longterm debtc 2 7 1 5 5 9 3 1 6 9 2 . 3 5 2 7 5 8 8 3 2 7 4 6 2 . 0 1 total interestbeare liabilities 1 5 8 2 3 7 4 7 3 3 8 0 . 9 4 1 5 3 2 9 9 8 6 1 6 7 0 . 8 1 noninterestbeare deposits 2 3 8 3 4 7 2 0 4 8 7 1 trading liability equity instruments 5 5 6 8 5 4 7 0 trading liability derivative payables 6 8 6 3 4 6 0 8 0 9 liability include allowance lendingrelated commitments 7 4 2 5 9 7 1 2 8 7 total liabilities 1 9 6 9 1 8 2 1 8 7 5 4 3 5 stockholder equity prefer stock 7 8 0 0 8 1 5 2 common stockholder equity 1 7 1 7 5 9 1 5 7 5 9 0 total stockholder equity 1 7 9 5 5 9 1 6 5 7 4 2 total liability stockholder equity $ 2 1 4 8 7 4 1 $ 2 0 4 1 1 7 7 interest rate spread 2 . 7 2 3 . 1 2 net interest income net yield interestearne asset $ 2 3 9 8 1 2 . 8 0 % $ 2 6 5 8 3 3 . 1 9 % ainclude margin loans . binclude brokerage customer payable . ceffective january 1 2 0 1 1 longterm advance fhlb reclassify borrow fund longterm debt . prioryear period revise conform current presentation average longterm fhlb advance month end june 3 0 2 0 1 0 $ 1 6 . 6 billion . dfor month end june 3 0 2 0 1 1 2 0 1 0 annualize rate afs security base amortized cost 3 . 0 4 % 3 . 3 9 % respectively . ereflect benefit favorable market environment dollarroll financing month end june 3 0 2 0 1 0 . 1 8 5 glossary termsach automate clearing house . advised line credit authorization specify maximum credit facility firm available obligor revolving nonbinde basis . borrower receive write oral advice facility . firm cancel facility time . allowance loan loss total loan represent periodend allowance loan loss divide retain loans . asset management represent asset actively manage behalf private banking institutional retail client . include committed capital earn fee . exclude asset manage american century company inc . firm 4 0 % ownership interest june 3 0 2 0 1 1 . assets supervision represent asset management custody brokerage administration deposit accounts . beneficial interest issue consolidated vie represent interest thirdparty holder debtequity security obligation issue vie jpmorgan chase consolidate . underlie obligation vie consist shortterm borrowing commercial paper longterm debt . related asset consist trading asset availableforsale security loan assets . contractual credit card chargeoff accordance federal financial institution examination council policy credit card loan charge end month account 1 8 0 day past 6 0 day receive notification specific event e . g . bankruptcy borrower whichever earlier . corporateprivate equity include private equity treasury chief investment office corporate include centrally manage expense discontinue operation . credit derivative contractual agreement provide protection credit event referenced credit . nature credit event establish protection buyer protection seller inception transaction event include bankruptcy insolvency failure meet payment obligation . buyer credit derivative pay periodic fee return payment protection seller occurrence credit event . cusip number cusip i . e . committee uniform security identification procedure number identifie security include stock register u . s . canadian company u . s . government municipal bond . cusip system american banker association operate standard poor facilitate clearing settlement process security . number consist character include letter number uniquely identify company issuer type security . similar system use identify foreign security cusip international number system . deposit margin represent net interest income express percentage average deposits . fasb financial accounting standard board . fdic federal deposit insurance corporation . fico score measure consumer credit risk provide credit bureaus typically produce statistical model fair isaac corporation utilize datum collect credit bureaus . forward point represent interest rate differential currency add subtract current exchange rate i . e . spot rate determine forward exchange rate . global corporate bank tss ib form joint venture create firm global corporate bank . team banker global corporate bank serve multinational client provide access tss product service certain ib product include derivative foreign exchange debt . cost effort credit firm extend client share tss ib . headcountrelated expense include salary benefit exclude performancebased incentive noncompensation cost relate employees . iasb international accounting standard board . interchange income fee pay credit card issuer clearing settlement sale cash advance transaction . interest purchase receivables represent ownership interest cash flow underlie pool receivables transfer thirdparty seller bankruptcyremote entity generally trust . investmentgrade indication credit quality base jpmorgan chase internal risk assessment system . investment grade generally represent risk profile similar rating bbb baa 3 define independent rating agencies . 1 8 6 llc limited liability company . loantovalue ltv ratio residential real estate loan relationship express percentage principal loan appraise value collateral i . e . residential real estate secure loan . origination date ltv ratiothe ltv ratio origination date loan . origination date ltv ratio calculate base actual appraise value collateral i . e . loanlevel datum origination date . current estimate ltv ratioan estimate ltv certain date . current estimate ltv ratio calculate use estimate collateral value derive nationally recognize home price index measure msa level . msalevel home price index comprise actual datum extent available forecast datum actual datum available . result estimate collateral value use calculate ratio represent actual appraise loanlevel collateral value result ltv ratio necessarily imprecise view estimates . combine ltv ratiothe ltv ratio consider lien position relate property . combine ltv ratio use junior lien home equity products . manage basis nongaap presentation financial result include reclassification present revenue fully taxableequivalent basis . management use nongaap financial measure segment level believe provide information enable investor understand underlying operational performance trend particular business segment facilitate comparison business segment performance competitors . marktomarket exposure measure point time value derivative foreign exchange contract open market . mtm value positive indicate counterparty owe jpmorgan chase create credit risk firm . mtm value negative jpmorgan chase owe counterparty situation firm liquidity risk . master netting agreement agreement counterpartie multiple derivative contract provide net settlement contract cash collateral single payment single currency event default termination contract . mortgage product typesaltaalta loan generally high credit quality subprime loan characteristic disqualify borrower traditional prime loan . alta lending characteristic include following limited documentation ii high combinedloantovalue cltv ratio iii loan secure nonowner occupy property iv debttoincome ratio normal limit . important characteristic limited documentation . substantial proportion traditional alta loan borrower provide complete documentation asset source income . option armsthe option arm real estate loan product adjustablerate mortgage loan provide borrower option month fully amortize interestonly minimum payment . minimum payment option arm loan base interest rate charge introductory period . introductory rate usually significantly fully index rate . fully index rate calculate use index rate plus margin . introductory period end contractual interest rate charge loan increase fully index rate adjust monthly reflect movement index . minimum payment typically insufficient cover interest accrue prior month unpaid interest defer add principal balance loan . option arm loan subject payment recast convert loan variablerate fully amortizing loan meeting specified loan balance anniversary date triggers . primeprime mortgage loan generally low default risk borrower good credit record monthly income time great monthly housing expense mortgage payment plus taxis debt payment . borrower provide documentation generally reliable payment histories . subprimesubprime loan design customer high risk characteristic include limited unreliable poor payment history ii high ltv ratio great 8 0 % borrowerpaid mortgage insurance iii high debttoincome ratio iv occupancy type loan borrower primary residence v history delinquency late payment loan . 1 8 7 msr risk management revenue include change fair value msr asset marketbase input interest rate volatility update assumption use msr valuation model derivative valuation adjustment represent change fair value derivative instrument use offset impact change marketbase input msr valuation model . multiasset fund account allocate asset management asset class e . g . longterm fix income equity cash real asset private equity hedge funds . na data applicable available period present . net chargeoff rate represent net chargeoff annualize divide average retained loan reporting period . net yield interestearne asset average rate interestearne asset average rate pay source fund . nm meaningful . opeb postretirement employee benefit . overhead ratio noninter expense percentage total net revenue . participate security represent unvested stockbase compensation award contain nonforfeitable right dividend dividend equivalent collectively dividend include earning share calculation use twoclass method . jpmorgan chase grant restrict stock rsus certain employee stockbased compensation program entitle recipient receive nonforfeitable dividend vesting period basis equivalent dividend pay holder common stock . unvested award meet definition participate security . twoclass method earning distribute undistributed allocate class common stock participate security base respective right receive dividends . personal banker retail branch office personnel acquire retain expand new exist customer relationship assess customer need recommend sell appropriate banking product service . portfolio activity describe change risk profile exist lendingrelated exposure impact allowance credit loss change customer profile input use estimate allowance . preprovision profit preprovision profit total net revenue noninterest expense . firm believe financial measure useful assess ability lending institution generate income excess provision credit loss . pretax margin represent income income tax expense divide total net revenue management view comprehensive measure pretax performance derive measure earning cost consideration . basis management use evaluate performance tss performance respective competitors . principal transaction realize unrealized gain loss trading activity include physical commodity inventory generally account low cost fair value change fair value associate financial instrument hold predominantly ib fair value option elect . principal transaction revenue include private equity gain losses . purchase creditimpaire pci loan acquire loan deem creditimpaire fasb guidance pci loan . guidance allow purchaser aggregate creditimpaire loan acquire fiscal quarter pool provide loan common risk characteristic e . g . fico score geographic location . pool account single asset single composite interest rate aggregate expectation cash flow . wholesale loan determined creditimpaire meet definition impaired loan u . s . gaap acquisition date . consumer loan determined creditimpaire base specific risk characteristic loan include product type ltv ratio fico score past status . receivable customer primarily represent margin loan prime retail brokerage customer include accrue interest account receivable consolidated balance sheet wholesale line business . reported basis financial statement prepare u . s . gaap exclude impact taxableequivalent adjustment . retain loan loan heldforinvestment exclude loan heldforsale loan fair value . riskweighte asset rwa riskweighte asset consist onand offbalance sheet asset assign broad risk category weight factor represent risk potential default . onbalance sheet asset riskweighte base perceive credit risk associate obligor counterparty nature collateral guarantor . offbalance sheet asset lendingrelate commitment guarantee derivative applicable offbalance sheet position riskweighte multiply contractual appropriate credit conversion factor determine onbalance sheet credit equivalent riskweighte base factor use on 1 8 8 balance sheet asset . rwa incorporate measure market risk relate applicable trading assetsdebt equity instrument foreign exchange commodity derivative . result riskweighte value risk category aggregate determine total rwa . sale specialist retail branch office personnel specialize marketing single product include mortgage investment business banking partner personal bankers . stress test scenario measure market risk unlikely plausible event abnormal markets . taxableequivalent basis total net revenue business segment firm present taxequivalent basis . accordingly revenue taxexempt security investment receive tax credit present manage result basis comparable fully taxable security investment . nongaap financial measure allow management assess comparability revenue arise taxable taxexempt source . corresponding income tax impact relate item record income tax expense . trouble debt restructuring tdr occur firm modify original term loan agreement grant concession borrower experience financial difficulty . unaudite financial statement information subject auditing procedure sufficient permit independent certify public accountant express opinion . u . s . gaap accounting principle generally accept united state america . u . s . governmentsponsore enterprise obligation obligation agency originally establish charter u . s . government serve public purpose specify u . s . congress obligation explicitly guarantee timely payment principal interest faith credit u . s . government . u . s . treasury u . s . department treasury . valueatrisk var measure dollar potential loss adverse market ordinary market environment . washington mutual transaction september 2 5 2 0 0 8 jpmorgan chase acquire banking operation washington mutual bank washington mutual fdic . additional information note 2 page 1 6 6 1 7 0 jpmorgan chase 2 0 1 0 annual report . line business metricsinvestment bankingibs revenue comprise following investment banking fee include advisory equity underwriting bond underwriting loan syndication fee . fix income market primarily include revenue relate marketmake global fixed income market include foreign exchange interest rate credit commodity market . equity market primarily include revenue relate marketmake global equity product include cash instrument derivative convertible prime services . credit portfolio revenue include net interest income fee loan sale activity gain loss security receive loan restructure ibs credit portfolio . credit portfolio revenue include result risk management relate firm lending derivative activity . retail financial service description select business metric consumer business bank personal banker retail branch office personnel acquire retain expand new exist customer relationship assess customer need recommend sell appropriate banking product services . sale specialist retail branch office personnel specialize marketing single product include mortgage investment business banking partner personal banker . mortgage production service revenue comprise followingnet production revenue include net gain loss origination sale prime subprime mortgage loan productionrelate fee loss relate repurchase previouslysold loans . net mortgage servicing revenue include follow components . aoperate revenue comprises 1 8 9 gross income earn service thirdparty mortgage loan include state service fee excess service fee late fee ancillary fee model servicing portfolio runoff time decay . brisk management comprise change msr asset fair value marketbase input interest rate volatility update assumption use msr valuation model derivative valuation adjustment represent change fair value derivative instrument use offset impact change marketbase input msr valuation model . mortgage origination channel comprise follow retail borrower buy refinance home direct contact mortgage banker employ firm use branch office internet phone . borrower frequently refer mortgage banker banker chase branch real estate broker home builder parties . wholesale thirdparty mortgage broker refer loan application mortgage banker firm . broker independent loan originator specialize find counsel borrower provide funding loan . firm exit broker channel 2 0 0 8 . correspondent bank thrift mortgage bank financial institution sell closed loan firm . correspondent negotiate transaction cnt transaction occur midto largesized mortgage lender bank bankowne mortgage company sell service firm asoriginated basis exclude purchase bulk servicing transaction . transaction supplement traditional production channel provide growth opportunity servicing portfolio stable period rise interest rate . card service autodescription select business metric cardsale volume dollar cardmember purchase net returns . open account cardmember account charge privileges . merchant service business business process bank card transaction merchant . bank card volume dollar transaction process merchants . total transaction number transaction authorization process merchants . auto origination volume dollar loan lease originated . commercial card provide wide range payment service corporate public sector client worldwide commercial card product . service include procurement corporate travel entertainment expense management service businesstobusiness payment solutions . commercial bankingcb client segmentsmiddle market banking cover corporate municipal financial institution notforprofit client annual revenue generally range $ 1 0 million $ 5 0 0 million . corporate client banking cover client annual revenue generally range $ 5 0 0 million $ 2 billion focus client broad investment bank needs . commercial term lending primarily provide term financing real estate investorsowner multifamily property financing office retail industrial properties . real estate banking provide fullservice banking investor developer institutionalgrade real estate properties . other primarily include lending investment activity community development banking chase capital segments . cb revenuelending include variety financing alternative primarily provide basis secure receivables inventory equipment real estate asset . product include term loan revolve line credit bridge financing assetbased structure lease commercial card product standby letter credit . treasury service include broad range product service enable client transfer invest manage receipt disbursement fund provide related information report . product service include u . s . dollar multicurrency clearing ach lockbox disbursement reconciliation service check deposit check currencyrelated service trade finance logistic solution deposit product sweep money market mutual funds . 1 9 0 investment banking product provide client sophisticated capitalraising alternative balance sheet risk management tool loan syndication investmentgrade debt assetbacke security private placement highyield bond equity underwrite advisory interest rate derivative foreign exchange hedge security sales . other product revenue primarily include taxequivalent adjustment generate community development banking segment activity certain income derive principal transactions . cb select business metricsliability balance include deposit deposit sweep onbalance sheet liability e . g . commercial paper federal fund purchase time deposit security loan sell repurchase agreement customer cash management programs . ib revenue gross represent total revenue relate investment banking product sell cb clients . treasury security servicestreasury security service firmwide metric include certain tss product revenue liability balance report line business relate customer customer line business . order capture firmwide impact treasury service tss product revenue management review firmwide metric liability balance revenue overhead ratio assess financial performance tss . firmwide metric necessary management view order understand aggregate tss business . description business metric tss liability balance include deposit deposit sweep onbalance sheet liability e . g . commercial paper federal fund purchase time deposit security loan sell repurchase agreement customer cash management programs . asset managementasset management represent asset actively manage behalf private banking institutional retail client . include committed capital earn fee . exclude asset manage american century company inc . firm 4 0 % ownership interest june 3 0 2 0 1 1 . assets supervision represent asset management custody brokerage administration deposit accounts . multiasset fund account allocate asset management asset class e . g . longterm fix income equity cash real asset private equity hedge funds . alternative asset follow type asset constitute alternative investment hedge fund currency real estate private equity . am client segment comprise followinginstitutional bring comprehensive global investment service include asset management pension analytic assetliability management active risk budgeting strategy corporate public institution endowment foundation notforprofit organization government worldwide . retail provide worldwide investment management service retirement planning administration thirdparty direct distribution range investment vehicle . private banking offer investment advice wealth management service high ultrahighnetworth individual family money manager business owner small corporation worldwide include investment management capital market risk management tax estate planning banking capital raising specialtywealth advisory services . 1 9 1 \n"
     ]
    }
   ],
   "source": [
    "# Checking Largest Normalized Document\n",
    "with open(largest_norm_doc_path) as f:\n",
    "    largest_norm_doc_raw = f.read()\n",
    "\n",
    "largest_norm_doc = normalize_document(largest_norm_doc_raw, debug=True)\n",
    "print()\n",
    "print(largest_norm_doc_path)\n",
    "print()\n",
    "print(largest_norm_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw length of doc: 4158\n",
      "stripped tag length: 2312\n",
      "altered accents length: 2312\n",
      "lower casing length: 2312\n",
      "removing newlines length: 2289\n",
      "strip special char length: 1876\n",
      "lemmatized doc length: 1897\n",
      "removed stop word length: 1765\n",
      "spaced num char length: 1937\n",
      "large words removed char length: 1937\n",
      "removed extra space length: 947\n",
      "\n",
      "/media/Data/Programs/FinTech/data/documents/C/0000950123-02-007241.txt\n",
      "\n",
      " u . s . security exchange commission washington d . c . 2 0 5 4 9 form 8 k current report pursuant section 1 3 1 5 d security exchange act 1 9 3 4 date report date early event report july 2 5 2 0 0 2 citigroup inc . exact registrant specify charter delaware 1 9 9 2 4 5 2 1 5 6 8 0 9 9 state commission irs employer jurisdiction file number identification . incorporation 3 9 9 park avenue new york new york 1 0 0 4 3 address principal executive office zip code 2 1 2 5 5 9 1 0 0 0 registrant telephone number include area code citigroup inc . current report form 8 k item 5 . event . july 2 5 2 0 0 2 citigroup announce july accelerate stock buyback program repurchase nearly $ 2 billion worth stock month . signature pursuant requirement security exchange act 1 9 3 4 registrant duly cause report sign behalf undersigned hereunto duly authorize . date july 2 5 2 0 0 2 citigroup inc . s john r . dye john r . dye title associate general counsel\n"
     ]
    }
   ],
   "source": [
    "# Checking Smallest Normalized Document\n",
    "with open(smallest_norm_doc_path, 'r') as f:\n",
    "    smallest_norm_doc_raw = f.read()\n",
    "\n",
    "smallest_norm_doc = normalize_document(smallest_norm_doc_raw, debug=True)\n",
    "print()\n",
    "print(smallest_norm_doc_path)\n",
    "print()\n",
    "print(smallest_norm_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing seems out of the ordinary about these two normalized documents. The relevant information of the 8-K Document sections of the 8-K filings are still there. The Item #.## sections are still existant in these normalized documents, thus they still contain the information that will be important for analysis, albiet with some noise still"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Vocabulary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second important component of our text data that we must analyze is the vocabulary (the list of unique words) of our normalized document dataset (corpus).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes for constructing vocab.json files\n",
    "\n",
    "def build_vocab(document, file_path):\n",
    "    '''\n",
    "    Adds to the already existing vocabulary file found at :param file_path: the new vocabulary found in the \n",
    "    normalized document :param document:.\n",
    "\n",
    "    :param document: string, normalized document to calculate vocabulary from.\n",
    "    :param file_path: string, path to vocabulary json file\n",
    "    \n",
    "    ---> dict, vocab object, mapping words to their unique integer encodings\n",
    "    '''\n",
    "    \n",
    "    # Loading already established vocabulary\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            vocab = json.load(f)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        vocab  = {}\n",
    "        \n",
    "    # Updating vocabulary dictionary\n",
    "    if not vocab:\n",
    "        last_word_encoding = 0\n",
    "    else:\n",
    "        last_word_encoding = max(vocab.values())\n",
    "    \n",
    "    for word in document.split():\n",
    "        # if a word in the document is not in the current vocab, add it with a word encoding value larger than the largest word encoding value\n",
    "        if word not in vocab:\n",
    "            vocab[word] = last_word_encoding + 1\n",
    "            last_word_encoding = last_word_encoding + 1\n",
    "            \n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(vocab, f)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "def vocab_from_doclist(s, path_to_vocab):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    doclist = json.loads(s)\n",
    "\n",
    "    for docpath in doclist:\n",
    "        with open(docpath, 'r') as f:\n",
    "            doc = f.read()\n",
    "            norm_doc = normalize_document(doc)\n",
    "    \n",
    "        vocab = build_vocab(norm_doc, path_to_vocab)\n",
    "        \n",
    "    return json.dumps(doclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must create our vocab file and load it into a python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing norm_vocab.json file\n",
    "for t in tickers:\n",
    "    df['_'.join(['docs', t])].map(lambda s: vocab_from_doclist(s, 'norm_vocab.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening our norm_vocab.json file    \n",
    "with open('norm_vocab.json', 'r') as f:\n",
    "    norm_vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view some of the words in our normalized vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document', 'false', '0', '7', '2', '9', '1', 'well', 'fargo', 'companymndep', 'shr', 'th', 'int', '.', '5', '8', '%', 'fixtofloat', 'noncum', 'perpetual', 'class', 'pref', 'stock', 'ser', 'qdep', '6', 'r', 'wfcnoncumulativeperpetualclassapreferredstockseriesnmember', 'wfcfixedtofloatingrate', 'noncumulativeperpetualclassapfdstockseriesqmember', 'wfcguaranteeofmediumtermnotesseriesadueoctober', '3', 'ofwellsfargofinancellcmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesymember', 'wfca', 'noncumulativeperpetualconvertibleclassapreferredstockserieslmember', 'usgaapcommonstockmember', 'noncumulativeperpetualclassapfdstockseriesrmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesomember', 'wfcnoncumulativeperpetualclassapreferredstockseriestmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesvmember', 'wfcguaranteeof', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesofwachoviacapitaltrustiiimember', 'wfcnoncumulativeperpetualclassapreferredstockserieswmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesxmember', 'wfcnoncumulativeperpetualclassapreferredstockseriespmember', 'united', 'statessecuritie', 'exchange', 'commissionwashington', 'd', 'c', '4', 'form', 'k', 'current', 'reportpursuant', 'section', 'security', 'act', 'date', 'report', 'early', 'event', 'october', 'company', 'exact', 'registrant', 'specify', 'charterdelaware', 'state', 'jurisdictionof', 'incorporation', 'commission', 'filenumb', 'irs', 'employeridentification', 'montgomery', 'street', 'san', 'francisco', 'california', 'address', 'principal', 'executive', 'office', 'zip', 'coderegistrant', 'telephone', 'number', 'include', 'area', 'code', 'check', 'appropriate', 'box', 'filing', 'intend', 'simultaneously', 'satisfy', 'obligation', 'follow', 'provisionswritten', 'communication', 'pursuant', 'rule', 'cfr', 'soliciting', 'material', 'a', 'precommencement', 'b', 'bprecommencement', 'e', 'csecurities', 'register', 'acttitle', 'classtrading', 'symbolname', 'registeredcommon', 'par', 'value', '$', 'wfcnyse', 'noncumulative', 'convertible', 'preferred', 'series', 'lwfc', 'prlnysedepositary', 'share', 'represent', 'interest', 'prefer', 'nwfc', 'prnnysedepositary', 'owfc', 'pronysedepositary', 'pwfc', 'prpnysedepositary', 'fixedtofloating', 'rate', 'qwfc', 'prqnysedepositary', 'rwfc', 'prrnysedepositary', 'twfc', 'prtnysedepositary', 'vwfc', 'prvnysedepositary', 'wwfc', 'prwnysedepositary', 'xwfc', 'prxnysedepositary', 'ywfc', 'prynyseguarantee', 'normal', 'wachovia', 'income', 'trust', 'capital', 'iiiwbtpnyseguarantee', 'mediumterm', 'note', 'finance', 'llcwfc', 'anyseindicate', 'mark', 'emerge', 'growth', 'define', 'emerging', 'indicate', 'elect', 'use', 'extended', 'transition', 'period', 'comply', 'new', 'revise', 'financial', 'accounting', 'standard', 'provide', 'oitem', 'result', 'operation', 'condition', 'on', 'issue', 'press', 'release', 'regard', 'quarter', 'end', 'september', 'post', 'website', 'q', 'quarterly', 'supplement', 'contain', 'certain', 'additional', 'historical', 'forwardlooke', 'information', 'relate', 'exhibit', 'incorporate', 'reference', 'item', 'consider', 'file', 'purpose', 'shall', 'deem', 'host', 'live', 'conference', 'available', 'webcast', 'discuss', 'matter', 'statement', 'no', 'descriptionlocation', 'herewith', 'furnishe', 'cover', 'page', 'interactive', 'datum', 'embed', 'inline', 'xbrl', 'documentsignaturepursuant', 'requirement', 'duly', 'cause', 'sign', 'behalf', 'undersigned', 'hereunto', 'authorize', 'datedoctober', 'wells', 's', 'richard', 'levy', 'vice', 'president', 'controller', 'officer', 'companymn', 'dep', 'n', 'o', 'p', 't', 'v', 'w', 'x', 'y', 'guarantee', 'iii', 'wfccommonstockparvalue', 'member', 'wfcsec', 'noncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'wfcdepositaryshareseachrepresenting', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesnmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesomember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriespmember', 'thinterestinshareof', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesqmember', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesrmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriestmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesvmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockserieswmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesxmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesymember', 'wfcguaranteeofmediumtermnotesseriesdueoctober', 'iso', 'usd', 'xbrlishare', 'washington', 'charter', 'delaware', 'jurisdiction', 'employer', 'identification', 'applicable', 'change', 'provision', 'write', 'solicit', 'title', 'trading', 'symbol', 'common', 'wfc', 'york', 'nyse', 'l', 'prl', 'depositary', 'prn', 'pro', 'prp', 'prq', 'prr', 'prt', 'prv', 'prw', 'prx', 'pry', 'wbtp', 'llc', 'connection', 'registration', 'nos', 'risk', 'link', 'low', 'performing', 'sp', 'index', 'russell', 'fully', 'unconditionally', 'issuance', 'opinion', 'faegre', 'baker', 'daniel', 'llp', 'description', 'location', 'consent', 'format', 'signature', 'le', 'roy', 'davi', 'senior', 'assistant', 'treasurer', 'msci', 'eafe', 'ii', 'collectively', 'leverage', 'return', 'international', 'equity', 'basket', 'april', 'iv', 'accelerate', 'defense', 'sector', 'vi', 'vii', 'step', 'microsoft', 'corporation', 'viii', 'leveraged', 'november', 'wfcnoncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'march', 'spdr', 'oil', 'gas', 'exploration', 'production', 'etf', 'vaneck', 'vector', 'gold', 'miner', 'ishare', 'market', 'euro', 'stoxx', 'tradingsymbol', 'exchangeon', 'fixedtofloate', 'departure', 'director', 'election', 'appointment', 'compensatory', 'arrangement', 'today', 'announce', 'enter', 'offer', 'letter', 'charle', 'scharf', 'board', 'appoint', 'mr', 'companys', 'chief', 'case', 'effective', 'commencement', 'employment', 'serve', 'bank', 'national', 'association', 'receive', 'comptroller', 'currency', 'occ', 'prior', 'determination', 'supervisory', 'objection', 'scharfs', 'position', 'require', 'order', 'commence', 'allen', 'parker', 'cease', 'interim', 'support', 'key', 'leadership', 'team', 'general', 'counsel', 'age', 'mellon', 'july', 'chairman', 'january', 'visa', 'inc', 'december', 'role', 'jpmorgan', 'chase', 'co', 'june', 'citigroup', 'predecessor', 'trustee', 'johns', 'hopkin', 'university', 'city', 'ballet', 'bachelor', 'art', 'degree', 'm', 'base', 'salary', 'initial', 'annual', 'million', 'target', 'incentive', 'award', 'opportunity', 'maximum', 'subject', 'performance', 'year', 'cash', 'reduce', 'begin', 'eligible', 'longterm', 'compensation', 'plan', 'lticp', 'human', 'resource', 'committee', 'hrc', 'approve', 'ratify', 'grant', 'february', 'vesting', 'agreement', 'determine', 'divide', 'closing', 'price', 'round', 'near', 'future', 'measurement', 'exclude', 'impact', 'penalty', 'charge', 'litigation', 'investigation', 'examination', 'arise', 'retail', 'sale', 'practice', 'regulatory', 'conduct', 'makewhole', 'replace', 'forfeit', 'replacement', 'consist', 'restricted', 'right', 'rsrs', 'approximately', 'outstanding', 'restrict', 'unit', 'vest', 'equal', 'installment', 'fifth', 'anniversary', 'start', 'addition', 'qualify', 'payable', 'continue', 'required', 'approval', 'termination', 'resignation', 'breach', 'disability', 'death', 'term', 'generally', 'operate', 'retirement', 'mean', 'reach', 'complete', 'service', 'favorable', 'treatment', 'apply', 'effect', 'time', 'clawback', 'holding', 'retention', 'ownership', 'policy', 'calculate', 'average', 'day', 'month', 'august', 'extent', 'reduction', 'notice', 'incur', 'reimburse', 'presentation', 'chair', 'acceptable', 'evidence', 'actually', 'recoup', 'cancel', 'ratio', 'set', 'forth', 'obligate', 'action', 'occur', 'directly', 'acceptance', 'inconsistent', 'refer', 'rsr', 'fiscal', 'forego', 'qualified', 'entirety', 'attach', 'hereto', 'purport', 'text', 'news', 'anthony', 'augliera', 'secretary', 'exchangenyse', 'global', 'energy', 'select', 'fund', 'dow', 'jone', 'industrial', 'cap', 'absolute', 'buffer', 'marketlinke', 'ix', 'unite', 'comn', 'biotech', 'wfcseriesnmember', 'wfcseriesomember', 'wfcseriespmember', 'wfcseriesqmember', 'wfcseriesrmember', 'wfcseriestmember', 'wfcseriesvmember', 'wfcserieswmember', 'wfcseriesxmember', 'wfcseriesymember', 'wfcguarantee', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesmember', 'wfcguaranteeofmediumtermnotesseriesdueoctoberofwellsfargofinancellcmember', 'indexsm', 'rguarantee', 'iiidep', 'ndep', 'odep', 'pdep', 'tdep', 'vdep', 'wdep', 'xdep', 'thesecuritie', 'applicableform', 'reportcheck', 'events', 'redeem', 'redemption', 'partial', 'remain', 'filed', 'the', 'herewithsignaturepursuant', 'authorized', 'datedaugust', 'domestic', 'etfs', 'kcurrent', 'companyexact', 'not', 'applicableformer', 'preliminarily', 'derivative', 'settlement', 'superior', 'court', 'county', 'shareholder', 'propose', 'hear', 'hearingfiled', 'signaturepursuant', 'datedjuly', 'vanguard', 'extend', 'nasdaq', 'apreferre', 'redeemable', 'davissenior', 'semiconductor', 'wfcnew', 'h', 'noski', 'increase', 'size', 'independent', 'corporate', 'governance', 'listing', 'guideline', 'audit', 'customary', 'fee', 'accordance', 'nonemployee', 'program', 'describe', 'proxy', 'automatically', 'fair', 'deferral', 'datedmay', 'preliminary', 'district', 'northern', 'allege', 'claim', 'fiduciary', 'duty', 'alleged', 'involvement', 'failure', 'detect', 'prevent', 'practices', 'invesco', 'db', 'commodity', 'tracking', 'perform', 'hold', 'meeting', 'amend', 'restate', 'thing', 'limitation', 'tenth', 'appear', 'definitive', 'copy', 'submission', 'vote', 'holder', 'nominate', 'great', 'cast', 'reflect', 'advisory', 'basis', 'disclose', 'kpmg', 'public', 'firm', 'proposal', 'present', 'final', 'voting', 'nominee', 'abstention', 'brokernonvote', 'john', 'celeste', 'clark', 'theodore', 'f', 'craver', 'jr', 'elizabeth', 'duke', 'wayne', 'hewett', 'donald', 'jam', 'maria', 'morris', 'juan', 'pujada', 'quigley', 'ronald', 'sargent', 'park', 'suzanne', 'vautrinot', 'percentage', 'total', 'resolution', 'broker', 'nonvote', 'incentivebase', 'loss', 'median', 'gender', 'pay', 'gap', 'amendment', 'article', 'bylaw', 'certificate', 'eliminate', 'designation', 'respect', 'esop', 'cumulative', 'incorporated', 'cindicate', 'other', 'earning', 'governor', 'federal', 'reserve', 'system', 'important', 'ongoing', 'constructive', 'engagement', 'focus', 'work', 'firstrate', 'sustainable', 'way', 'unduly', 'believe', 'process', 'feel', 'guidance', 'timing', 'lifting', 'asset', 'cautionary', 'business', 'expectation', 'assumption', 'inherent', 'uncertainty', 'rely', 'actual', 'differ', 'materially', 'speak', 'undertake', 'update', 'factor', 'discussion', 'recent', 'fargos', 'www', 'sec', 'gov', 'datedapril', 'furnished', 'markedlinke', 'timothy', 'j', 'sloan', 'retire', 'inform', 'decision', 'seniormost', 'responsible', 'decide', 'strategic', 'operational', 'previously', 'preside', 'partner', 'law', 'cravath', 'swaine', 'moore', 'development', 'implementation', 'firmwide', 'strategy', 'daytoday', 'analysis', 'management', 'relation', 'deputy', 'manage', 'department', 'join', 'extensive', 'experience', 'broad', 'range', 'banking', 'related', 'earn', 'undergraduate', 'chicago', 'columbia', 'school', 'immediate', 'family', 'loan', 'extension', 'credit', 'andor', 'transaction', 'ordinary', 'course', 'subsidiary', 'lending', 'substantially', 'collateral', 'repayment', 'comparable', 'person', 'involve', 'collectability', 'unfavorable', 'feature', 'account', 'forfeiture', 'discretion', 'portion', 'unpaid', 'occurrence', 'specified', 'evaluate', 'special', 'meet', 'accord', 'schedule', 'achievement', 'goal', 'compliance', 'postemployment', 'restrictive', 'covenant', 'light', 'stand', 'substitute', 'place', 'dexhibit', 'constant', 'maturity', 'swap', 'anticipation', 'posteffective', 'revision', 'realignment', 'segment', 'operating', 'adopt', 'methodology', 'assign', 'funding', 'line', 'reclassification', 'liability', 'liquidity', 'product', 'characteristic', 'granular', 'level', 'affect', 'reportable', 'thesetable', 'furnish', 'solely', 'facilitate', 'comparison', 'consolidated', 'in', 'thereto', 'adoption', 'asu', 'flow', 'topic', 'classification', 'receipt', 'payment', 'disclosure', 'retrospectively', 'enumerate', 'businessitem', 'stockholder', 'issuer', 'purchase', 'securitiesitem', 'operationsitem', 'supplementary', 'originally', 'original', 'firmfile', 'insxbrl', 'instance', 'schxbrl', 'taxonomy', 'schema', 'calxbrl', 'calculation', 'linkbase', 'labxbrl', 'label', 'prexbrl', 'defxbrl', 'definition', 'datedfebruary', 'delta', 'air', 'cad', 'underwriting', 'underwriter', 'barbara', 'brett', 'u', 'real', 'estate', 'fix', 'nasdq', 'fourth', 'dialogue', 'clarify', 'feedback', 'assess', 'progress', 'thoughtful', 'manner', 'implement', 'accept', 'thirdparty', 'review', 'datedjanuary', 'beginning', 'affiliated', 'entity', 'karen', 'peetz', 'reelection', 'ms', 'desire', 'devote', 'commitment', 'activity', 'disagreement', 'alphabet', 'amazon', 'com', 'starbuck', 'targetterm', 'apple', 'midcap', 'mill', 'conagra', 'brand', 'libor', 'consumer', 'discretionary', 'technology', 'honeywell', 'electric', 'organizational', 'administrative', 'hope', 'hardison', 'auditor', 'david', 'julian', 'leave', 'absence', 'longer', 'facebook', 'amendments', 'jfile', 'datedseptember', 'deere', 'horton', 'xerox', 'philip', 'altria', 'group', 'brazil', 'justice', 'residential', 'mortgagebacke', 'ofexhibit', 'mylan', 'american', 'airline', 'intel', 'correspond', 'partof', 'lowes', 'customer', 'remediation', 'rest', 'advance', 'auto', 'abbvie', 'carmax', 'establish', 'distribution', 'agent', 'risksecuritie', 'eventswell', 'investor', 'detailed', 'oversight', 'submit', 'ebay', 'southwest', 'rental', 'allergan', 'plc', 'halliburton', 'jame', 'shareowner', 'reform', 'social', 'responsibility', 'kacurrent', 'explanatory', 'notethis', 'conditionon', 'protection', 'bureau', 'cfpb', 'aggregate', 'billion', 'civil', 'money', 'resolve', 'past', 'automobile', 'insurance', 'mortgage', 'lock', 'extensions', 'this', 'ka', 'legal', 'accrual', 'net', 'accordingly', 'previous', 'subsequent', 'announcement', 'noninter', 'expense', 'tax', 'deductible', 'respectively', 'diluted', 'amended', 'completion', 'procedure', 'discovery', 'eventson', 'penaltyfile', 'averagesm', 'conditionattached', 'data', 'table', 'yeartodate', 'attached', 'tablesfurnishe', 'datedmarch', 'sbarbara', 'chen', 'lloyd', 'dean', 'enrique', 'hernandez', 'federico', 'pena', 'notify', 'threshold', 'record', 'request', 'summary', 'boee', 'cbs', 'walmart', 'chapter', 'micron', 'caterpillar', 'nike', 'motor', 'mgm', 'resort', 'neal', 'blinde', 'powershare', 'qqq', 'trustsm', 'sm', 'i', 'designate', 'power', 'preference', 'relative', 'participate', 'optional', 'qualification', 'restriction', 'thereof', 'polk', 'wardwell', 'michael', 'loughlin', 'anadarko', 'petroleum', 'immediately', 'mary', 'mack', 'head', 'community', 'organization', 'celgene', 'gilead', 'science', 'ethic', 'waiver', 'high', 'integrity', 'transparency', 'principle', 'enhance', 'clarifie', 'exist', 'alignment', 'vision', 'treat', 'consistent', 'nonretaliation', 'regulation', 'avoid', 'conflict', 'appearance', 'manager', 'identify', 'timely', 'g', 'assist', 'understanding', 'wellsfargo', 'comaboutcorporategovernance', 'usi', 'acquisition', 'usa', 'wfis', 'brokerage', 'consult', 'employee', 'benefit', 'property', 'casualty', 'safehold', 'small', 'student', 'individual', 'health', 'private', 'pretax', 'gain', 'discrete', 'second', 'agree', 'sell', 'dateddecember', 'cvs', 'hr', 'block', 'harleydavidson', 'etrade', 'norwegian', 'cruise', 'ltd', 'phd', 'dr', 'pension', 'balance', 'actuarial', 'interstate', 'bancorp', 'acquire', 'legacy', 'servicebase', 'contribution', 'assume', 'preexist', 'merger', 'norw', 'dismissal', 'franklin', 'codel', 'ford', 'multiplepointofentry', 'singlepointofentry', 'agency', 'method', 'electronic', 'transmission', 'expand', 'secretaryexhibit', 'pujadas', 'stephen', 'sanger', 'cynthia', 'milligan', 'susan', 'swenson', 'succeed', 'composition', 'electronictransmission', 'berkshire', 'hathaway', 'signaturespursuant', 'officerexhibit', 'classaction', 'commissionfile', 'socalle', 'livingwill', 'parent', 'intermediate', 'ihc', 'wfs', 'clearing', 'wfcs', 'indirect', 'transfer', 'significant', 'majority', 'deposit', 'liquid', 'intercompany', 'type', 'distress', 'repurchase', 'facility', 'subordinate', 'committed', 'dividend', 'expect', 'usual', 'access', 'necessary', 'debt', 'metric', 'fall', 'trigger', 'subordinated', 'forgive', 'terminate', 'adversely', 'ability', 'bankruptcy', 'proceeding', 'respective', 'secure', 'carroll', 'wealth', 'investment', 'jabbari', 'lawsuit', 'inclination', 'party', 'motion', 'respond', 'plaintiff', 'finalize', 'open', 'checking', 'saving', 'unsecured', 'card', 'enrol', 'circumstance', 'identity', 'theft', 'assurance', 'different', 'dated', 'plus', 'accumulate', 'excess', 'currently', 'cusip', 'float', 'pa', 'frequency', 'recommendation', 'divest', 'noncore', 'lobby', 'indigenous', 'people', 'representative', 'dtc', 'citibank', 'london', 'branch', 'bys', 'authorizes', 'liquidation', 'layton', 'finger', 'ofthe', 'codenot', 'citem', 'apppropriate', 'claw', 'stumpf', 'carrie', 'tolstedt', 'stumpfs', 'tolstedts', 'option', 'finding', 'reinvestment', 'cra', 'rating', 'need', 'improve', 'impose', 'nonbank', 'engage', 'nature', 'regulator', 'application', 'expedite', 'processing', 'prepay', 'relocate', 'welfare', 'relationship', 'municipality', 'limit', 'influence', 'satisfactory', 'engel', 'upcoming', 'defer', 'vested', 'seventh', 'supplemental', 'indenture', 'fdic', 'jointly', 'adequately', 'remedy', 'deficiency', 'foreign', 'fail', 'brokerdealer', 'remedie', 'consultation', 'stability', 'council', 'able', 'satisfaction', 'living', 'notification', 'statementsthis', 'shrewsberry', 'presidentelect', 'trump', 'intent', 'elaine', 'chao', 'transportation', 'honor', 'resign', 'confirm', 'chaos', 'structure', 'conform', 'add', 'annually', 'remove', 'conforming', 'lead', 'ciii', 'miscellaneous', 'separate', 'retainer', 'lieu', 'revocation', 'relief', 'consequence', 'enforcement', 'occs', 'exhibitno', 'datednovember', 'western', 'digital', 'underwrite', 'nonexecutive', 'wholesale', 'retain', 'formation', 'virtual', 'solution', 'innovation', 'avid', 'modjtabai', 'perry', 'pelo', 'exercise', 'conclusion', 'authority', 'ensure', 'pende', 'precautionary', 'rescind', 'local', 'government', 'attorney', 'prosecutor', 'congressional', 'formal', 'informal', 'inquiry', 'los', 'angeles', 'seek', 'nongovernmental', 'damage', 'industrytm', 'correct', 'error', 'bad', 'doddfrank', 'wall', 'credible', 'orderly', 'stringent', 'unable', 'iboxx', 'yield', 'bond', 'maintain', 'ethical', 'core', 'good', 'emphasize', 'confidential', 'protect', 'efficiently', 'accountability', 'adherence', 'violation', 'environment', 'jurisdictioncommission', 'fileir', 'incorporationnumberidentification', 'southern', 'housing', 'urban', 'administration', 'fha', 'potential', 'although', 'documentation', 'dc', 'judith', 'runstad', 'periodic', 'aiv', 'clarification', 'summarize', 'nomination', 'permit', 'continuously', 'percent', 'constitute', 'uncontested', 'informational', 'instrument', 'short', 'relocation', 'specifie', 'entitle', 'taking', 'adjourn', 'declaration', 'content', 'preparation', 'list', 'quorum', 'transact', 'affirmative', 'minimum', 'scope', 'convene', 'recess', 'inspector', 'prescribe', 'absent', 'disqualify', 'lose', 'steal', 'destroy', 'offile', 'like', 'linkedto', 'later', 'unique', 'turn', 'schaffner', 'paul', 'ackerman', 'ge', 'commercial', 'vendor', 'platform', 'anticipate', 'neutral', 'modestly', 'accretive', 'transitionrelated', 'cost', 'minimal', 'borrowing', 'long', 'deposits', 'attract', 'talent', 'encourage', 'creation', 'overall', 'balanced', 'mix', 'competitive', 'evaluation', 'strong', 'numberof', 'performancebased', 'downturn', 'misconduct', 'commit', 'reasonably', 'reputational', 'harm', 'involuntary', 'displacement', 'divestiture', 'nondisclosure', 'trade', 'secret', 'nonsolicitation', 'employ', 'aftertax', 'delay', 'modify', 'revoke', 'recover', 'advisable', 'recoupment', 'equivalent', 'reinveste', 'distribute', 'underlie', 'homebuilder', 'er', 'optionally', 'exchangeable', 'kind', 'morgan', 'filenumber', 'betsy', 'southtrust', 'successor', 'archerdanielsmidland', 'importance', 'motivate', 'valuable', 'overarching', 'stipulation', 'hearing', 'strother', 'internal', 'control', 'servicing', 'foreclosure', 'rcz', 'belowlisted', 'hoyt', 'specialized', 'capacity', 'cofounde', 'sullivan', 'cromwell', 'lennar', 'howard', 'rick', 'richardson', 'personal', 'healthrelated', 'reason', 'ae', 'fannie', 'mae', 'originate', 'pricing', 'home', 'freddie', 'mac', 'medium', 'paper', 'heidi', 'dzieweczynski', 'performancebase', 'withdraw', 'xii', 'tier', 'principalamount', 'accumulateddistributionsper', 'nysetradingsymbol', 'redemptiondate', 'trusteepayingagent', 'enhancedtrust', 'preferredsecuritie', 'bwf', 'newyork', 'trustcompany', 'marquette', 'ave', 'floor', 'macn', 'minneapolis', 'mn', 'duejanuary', 'trusteepaye', 'trup', 'wpk', 'gwf', 'toprssm', 'jwf', 'defendant', 'laurel', 'holschuh', 'staff', 'recommend', 'ubs', 'jump', 'brent', 'crude', 'nikkei', 'upside', 'participation', 'reit', 'downside', 'multipli', 'tender', 'contingent', 'trustpreferredsecuritie', 'wbprc', 'nationalassociation', 'xi', 'fwf', 'bankn', 'corporatetrust', 'livingston', 'avenue', 'st', 'nichola', 'contest', 'allow', 'candidate', 'inclusion', 'wbprb', 'declare', 'jonesubs', 'mackey', 'mcdonald', 'informed', 'benson', 'concern', 'origination', 'joint', 'federalstate', 'frb', 'assessment', 'stepup', 'callable', 'bancorporation', 'wyome', 'placer', 'statutory', 'aaa', 'govern', 'passage', 'hand', 'wb', 'xiii', 'pps', 'eaa', 'wfcpp', 'xiv', 'wco', 'xv', 'aa', 'wfcppsb', 'vk', 'ex', 'exhibitnumber', 'mmcapssm', 'z', 'saa', 'century', 'na', 'oman', 'mmcap', 'gbb', 'raa', 'fixedfloate', 'execute', 'favor', 'debtholder', 'efficient', 'junior', 'deferrable', 'debenture', 'recognize', 'proceed', 'mandatorily', 'redesignation', 'capitalize', 'meaning', 'thereunto', 'corestate', 'passthrough', 'ac', 'union', 'institutional', 'contract', 'takedown', 'precede', 'paragraph', 'sk', 'atkin', 'depend', 'criterion', 'adjustment', 'upward', 'downward', 'threeyear', 'peer', 'noncompetition', 'suisse', 'stanley', 'secondary', 'unrelated', 'reporting', 'esq', 'aii', 'proper', 'procedural', 'calling', 'stockholderrequested', 'design', 'similar', 'recently', 'soon', 'close', 'roger', 'affidavit', 'securitization', 'restructuring', 'division', 'kevin', 'rhein', 'robert', 'steel', 'mayor', 'economic', 'patricia', 'callahan', 'treasury', 'offering', 'warrant', 'deutsche', 'allocation', 'auction', 'automatic', 'shelf', 'lockup', 'exception', 'additionally', 'speciman', 'mccormick', 'nonbinde', 'charitable', 'political', 'jeannine', 'zahn', 'messrs', 'entirely', 'partially', 'abovenamed', 'reinstate', 'revenue', 'suspend', 'deductibility', 'tarp', 'repay', 'comprise', 'kbw', 'retentionperformance', 'permanent', 'nondisparagement', 'consultant', 'competition', 'affiliate', 'geographic', 'footprint', 'recovery', 'julie', 'white', 'goldman', 'sachs', 'underwritten', 'discount', 'prospectus', 'hereinafter', 'prudential', 'noncontrolle', 'venture', 'carry', 'noncontrolling', 'entire', 'troubled', 'detail', 'achieve', 'participant', 'objective', 'promote', 'establishment', 'relevant', 'calendar', 'emergency', 'stabilization', 'eesa', 'ratification', 'positive', 'combination', 'realize', 'measure', 'qualitative', 'dilute', 'consolidate', 'adjust', 'convention', 'annualize', 'accrue', 'comprehensive', 'discontinue', 'extraordinary', 'unusual', 'nonrecurre', 'separately', 'quantify', 'temporary', 'suspension', 'blackout', 'yearend', 'conversion', 'central', 'eastern', 'week', 'staggered', 'approach', 'obtain', 'inservice', 'withdrawal', 'direct', 'diversify', 'send', 'beneficiary', 'sarbanesoxley', 'btr', 'insider', 'prohibit', 'indirectly', 'selling', 'interested', 'contact', 'jeanine', 'sundt', 'prohibition', 'possession', 'nonpublic', 'function', 'comaboutcorporatecorporategovernance', 'ar', 'nationwide', 'buy', 'diversified', 'kovacevich', 'kovacevichs', 'spaul', 'merge', 'emily', 'janowsky', 'withholding', 'deduction', 'payroll', 'nyseonly', 'cpp', 'sole', 'twothird', 'onethird', 'joss', 'portfolio', 'integration', 'combined', 'substantive', 'proprietary', 'leader', 'htm', 'generate', 'publisher', 'un', 'derwrite', 'statementsan', 'arb', 'fas', 'minority', 'component', 'sheet', 'attributable', 'computation', 'kbody', 'fd', 'stress', 'test', 'remarketing', 'accrete', 'caption', 'consideration', 'appreciate', 'sar', 'count', 'instead', 'onehalf', 'nonqualifie', 'restore', 'freeze', 'irsimposed', 'slide', 'specific', 'highly', 'compensated', 'enactment', 'deduct', 'tarps', 'alternative', 'assistance', 'otherthantemporary', 'impairment', 'noncash', 'unrealized', 'fullyear', 'vkza', 'refile', 'book', 'incorrectly', 'eightkbody', 'convert', 'create', 'bcl', 'unaudited', 'forma', 'condense', 'bsp', 'nbsp', 'eightkseriesm', 'elimination', 'disposition', 'survive', 'fractional', 'equalization', 'oneone', 'thousandth', 'converte', 'equitybased', 'ticker', 'wfcprj', 'wfcprl', 'exchangeliste', 'pm', 'modification', 'following', 'associate', 'farg', 'pin', 'tee', 'astro', 'titan', 'industry', 'astros', 'metal', 'china', 'alternext', 'body', 'ock', 'erve', 'nominating', 'argo', 'exercisable', 'requisite', 'dec', 'mecklenburg', 'north', 'carolina', 'irve', 'ehrenhaus', 'et', 'al', 'therewith', 'kwells', 'mandatory', 'primarily', 'ceo', 'successful', 'independence', 'agenda', 'session', 'nonmanagement', 'coordinated', 'coverage', 'sounding', 'nb', 'nbs', 'recognition', 'intention', 'belief', 'analyst', 'estimate', 'illustra', 'tive', 'projection', 'crisis', 'severe', 'wachovias', 'inability', 'integrate', 'successfully', 'expected', 'attrition', 'disruption', 'difficult', 'overnmental', 'exposure', 'evp', 'unanimously', 'identical', 'consummation', 'stockbased', 'governmental', 'expiration', 'waiting', 'accuracy', 'representation', 'warranty', 'significantly', 'secs', 'find', 'mail', 'statementprospectus', 'urge', 'read', 'free', 'nd', 'attention', 'center', 'south', 'college', 'charlotte', 'solicitation', 'entry', 'accrued', 'nonvoting', 'issuable', 'antidilution', 'split', 'expire', 'gross', 'placement', 'exempt', 'promptly', 'practicable', 'contractual', 'foregoing', 'unregistered', 'securityholder', 'regular', 'aside', 'agreementstandard', 'whollyowned', 'font', 'capitalization', 'know', 'materiality', 'view', 'investo', 'rs', 'allocate', 'fact', 'factual', 'conjunction', 'nonappealable', 'denial', 'injunction', 'cure', 'newly', 'wacho', 'ntacte', 'sixth', 'minnesota', 'bring', 'deadline', 'earlier', 'beneficial', 'owner', 'hedge', 'questionnaire', 'proponent', 'indemnification', 'publicly', 'lehman', 'brother', 'petition', 'cent', 'dollar', 'counterparty', 'advantage', 'ofincorporation', 'remarketable', 'stripped', 'bny', 'wilmington', 'preclose', 'overallotment', 'zipcode', 'bnym', 'merrill', 'lynch', 'pierce', 'fenner', 'smith', 'settle', 'appreciation', 'shareforshare', 'eligibility', 'administer', 'gnc', 'nondiscriminatory', 'selection', 'exceed', 'certify', 'exercisability', 'nee', 'deliver', 'reorganization', 'reverse', 'spinoff', 'cancellation', 'accelerated', 'equitable', 'lticps', 'reprice', 'nonrecurring', 'nonu', 'dilution', 'enlargement', 'interpret', 'construe', 'thereunder', 'faith', 'lapse', 'rata', 'fill', 'vacancy', 'newlycreated', 'directorship', 'nonqualified', 'transferability', 'physically', 'attestation', 'difference', 'tandem', 'bonus', 'determined', 'encumber', 'acceleration', 'limited', 'pool', 'versus', 'continued', 'preestablished', 'cycle', 'qualifying', 'notwithstanding', 'individually', 'alternatively', 'cumulatively', 'transferable', 'assignable', 'familyrelate', 'duration', 'waive', 'taxable', 'payforsuperiorperformance', 'sexual', 'orientation', 'racial', 'disparity', 'infrastructure', 'bb', 'byreference', 'preclosing', 'tighten', 'largely', 'channel', 'financing', 'stop', 'specifically', 'wholesaler', 'combine', 'loantovalue', 'correspondent', 'institution', 'liquidating', 'vintage', 'highest', 'concentrate', 'abrupt', 'steep', 'decline', 'lien', 'deterioration', 'outlook', 'diminish', 'chargeoff', 'adequate', 'visarelate', 'network', 'single', 'judgment', 'sharing', 'membership', 'conclude', 'concur', 'immaterial', 'sufficient', 'quality', 'unemployment', 'tranche', 'extendible', 'fy', 'hm', 'bbu', 'bbz', 'md', 'between', 'nqso', 'collectibility', 'regional', 'ratefloate', 'emission', 'reject', 'separation', 'hmda', 'severance', 'job', 'mutually', 'plurality', 'irrevocable', 'certification', 'abstain', 'httpwww', 'sybase', 'enterprise', 'software', 'headquarter', 'dublin', 'twoforone', 'bookentry', 'withhold', 'continuation', 'pricewaterhousecooper', 'professional', 'moor', 'world', 'modern', 'dgcl', 'means', 'affair', 'examiner', 'attest', 'forward', 'look', 'incorrect', 'attain', 'presidentchief', 'catholic', 'healthcare', 'west', 'notforprofit', 'care', 'reelect', 'payday', 'lend', 'predatory', 'coupon', 'attend', 'teleconference', 'worth', 'blackschole', 'prorate', 'blanchard', 'reatha', 'king', 'rice', 'wright', 'basketsm', 'consensus', 'task', 'force', 'contingently', 'eitf', 'entitys', 'retroactively', 'dilutive', 'default', 'effectiveness', 'inflation', 'headline', 'station', 'casino', 'otherjurisdiction', 'corenotessm', 'corenote', 'point', 'notessm', 'quicklink', 'click', 'rapidly', 'navigate', 'cexhibit', 'purchaser', 'buyer', 'possible', 'registered', 'exemption', 'unconditional', 'wffi', 'wholly', 'wffc', 'canadian', 'canada', 'oath', 'les', 'quock', 'prepare', 'agust', 'debeture', 'pooling', 'appendix', 'preeffective', 'reg', 'accountant', 'securitiessm', 'authorization', 'accretion', 'word', 'expression', 'conditional', 'verb', 'difficulty', 'unanticipated', 'rod', 'jacob', 'ross', 'kari', 'jpmdepositarysharesonefourhundredthinterestinashareof', 'noncumulativepreferredstockseriesymember', 'jpmguaranteeofcushing', 'mlpindexetnsduejune', 'ofjpmorganchasefinancialcompanyllcmember', 'noncumulativepreferredstockseriespmember', 'noncumulativepreferredstockseriesaamember', 'noncumulativepreferredstockseriesddmember', 'jpmalerianmlpindexetnsduemay', 'noncumulativepreferredstockserieseemember', 'noncumulativepreferredstockseriesbbmember', 'jpmguaranteeofcallablesteupfixedratenotesdueapril', 'organizationcommission', 'numberi', 'madison', 'avenuenew', 'yorknew', 'classtrade', 'symbolsname', 'stockjpmthe', 'exchangedepositary', 'onefour', 'hundredth', 'pjpm', 'pr', 'athe', 'yjpm', 'fthe', 'aajpm', 'gthe', 'bbjpm', 'hthe', 'ddjpm', 'dthe', 'eejpm', 'cthe', 'exchangealerian', 'mlp', 'etns', 'amjnyse', 'arca', 'llcjpm', 'exchangeguarantee', 'cushe', 'llcpplnnyse', 'disclosureon', 'earnings', 'furthermore', 'httpsjpmorganchaseco', 'gcsweb', 'comfinancialinformationsecfiling', 'exhibitsd', 'extensible', 'language', 'registrantbys', 'nicole', 'gile', 'officerdatedoctober', 'dof', 'compare', 'statements', 'results', 'nysearca', 'jpm', 'dd', 'ee', 'alerian', 'amj', 'ppln', 'onetenth', 'jordan', 'costa', 'managing', 'legality', 'simpson', 'thacher', 'bartlett', 'frn', 'noncumulativepreferredstockserieswmember', 'instruction', 'hka', 'hkb', 'hhq', 'hlw', 'hhs', 'delivery', 'making', 'blue', 'sky', 'onwhich', 'ff', 'computershare', 'rank', 'parity', 'declared', 'privilege', 'thereund', 'provisionso', 'bo', 'wjpm', 'ethe', 'officerdatedjuly', 'object', 'ccar', 'datedjune', 'companyrun', 'dfast', 'hypothetical', 'scenario', 'shock', 'severely', 'adverse', 'httpswww', 'federalreserve', 'govsupervisionregdfastresstests', 'furnishing', 'indication', 'caution', 'draw', 'inference', 'actions', 'incorporationcommission', 'officerscompensatory', 'officers', 'william', 'weldon', 'eve', 'burke', 'todd', 'comb', 'mellody', 'hobson', 'holders', 'aregistrant', 'tuesday', 'bthe', 'proposalsproposal', 'nameforagainstabstainbroker', 'nonvoteslinda', 'bammann', 'james', 'bell', 'combs', 'crown', 'dimon', 'flynn', 'laban', 'jackson', 'lee', 'raymond', 'compensationforagainstabstainbroker', 'nonvotes', 'foragainstabstainbroker', 'reportforagainstabstainbroker', 'accessforagainstabstainbroker', 'votingforagainstabstainbroker', 'kf', 'gillis', 'gillismanage', 'directordate', 'thach', 'jennifer', 'piepszak', 'marianne', 'lake', 'career', 'positioningprincipal', 'prime', 'businesses', 'molly', 'carpenter', 'officerdatedapril', 'outside', 'kingdom', 'protectionbase', 'latham', 'watkin', 'llcs', 'scott', 'slides', 'speaker', 'biographies', 'officersjpmorgan', 'variable', 'psus', 'unchanged', 'psu', 'tangible', 'rotce', 'payout', 'provisions', 'category', 'clientcustomerstakeholder', 'teamwork', 'we', 'invest', 'strengthen', 'reinforce', 'culture', 'longstanding', 'drive', 'inclusive', 'raise', 'trillion', 'businesse', 'client', 'nonprofit', 'nearly', 'demonstrate', 'discipline', 'score', 'fortress', 'help', 'decade', 'initiative', 'wage', 'most', 'under', 'stewardship', 'repurchases', 'nongaap', 'restatement', 'recapture', 'enable', 'unvested', 'unexercisable', 'directors', 'renew', 'merchant', 'hospital', 'officerdatedjanuary', 'jpmws', 'thursday', 'friday', 'cutoff', 'monday', 'depository', 'dtcc', 'sunday', 'any', 'dtccs', 'void', 'directordatedoctober', 'reminder', 'httpinvestor', 'comjpmorganchasesec', 'cfm', 'charges', 'requirements', 'launch', 'fixedrate', 'liquidate', 'extinguish', 'quantitative', 'charterdelawarestate', 'bylawsforagainstabstainbroker', 'chairmanforagainstabstainbroker', 'serviceforagainstabstainbroker', 'tie', 'genocideforagainstabstainbroker', 'holly', 'youngwood', 'youngwoodmanage', 'kaexplanatory', 'assignment', 'crandall', 'bowle', 'directordatedmay', 'directordatedapril', 'ariel', 'jpmorganchase', 'comcorporateinvestorrelationsinvestorrelations', 'pinto', 'gordon', 'copresident', 'cochief', 'jamie', 'version', 'secretarydatedjanuary', 'clientcustomer', 'items', 'cut', 'tcja', 'directordatedjanuary', 'initially', 'seven', 'xxiii', 'xxi', 'nbd', 'corresponding', 'cc', 'contingency', 'herein', 'secretarydatedoctober', 'neila', 'radin', 'registrantby', 'frequently', 'yeartwo', 'yearsthree', 'yearsabstainbroker', 'reevaluate', 'votes', 'directordatedjune', 'matthew', 'zame', 'thirteen', 'closely', 'smooth', 'come', 'followsmarianne', 'oversee', 'officetreasury', 'managerial', 'intelligent', 'markets', 'erdoe', 'doug', 'petno', 'coo', 'military', 'planning', 'procurement', 'services', 'ninetyday', 'garden', 'nonsolicitationhire', 'postgarden', 'stacey', 'friedman', 'counseldatedjune', 'bowles', 'compensationonetwothreeabstainbroker', 'amendmentforagainstabstainbroker', 'equityforagainstabstainbroker', 'countedforagainstabstainbroker', 'meetingsforagainstabstainbroker', 'carpentercorporate', 'secretarydate', 'supersede', 'typographical', 'ny', 'master', 'indeterminate', 'dispute', 'challenge', 'custodian', 'triparty', 'adversary', 'sufficiency', 'sustained', 'cjpmorgan', 'linda', 'america', 'fka', 'banker', 'continuance', 'insolvency', 'consolidation', 'conveyance', 'lease', 'odonovan', \"o'donovan\", 'cpa', 'joined', 'internationally', 'jpmc', 'doj', 'hiring', 'official', 'asia', 'pacific', 'region', 'jpmsapl', 'hong', 'kongbase', 'whollyowne', 'nonprosecution', 'monetary', 'advise', 'jpmsapls', 'criminal', 'disgorgement', 'prejudgment', 'fine', 'acknowledge', 'cooperation', 'cooperate', 'watter', 'boston', 'ma', 'haa', 'laa', 'yaa', 'kaa', 'uaa', 'periodically', 'rapid', 'spoe', 'jpmcs', 'improvement', 'iteration', 'aspect', 'rationalization', 'mechanism', 'shortcoming', 'outsource', 'remediate', 'status', 'subsection', 'govregulationsreformresplansindex', 'html', 'govbankinforegresolutionplans', 'prepositioning', 'entering', 'jpmcb', 'effort', 'contribute', 'indebtedness', 'owe', 'monitor', 'idiosyncratic', 'initiate', 'ameliorate', 'framework', 'critical', 'defined', 'escalation', 'indicator', 'model', 'basel', 'transitional', 'project', 'outflow', 'dynamic', 'forecast', 'dedicated', 'utilize', 'castle', 'partnership', 'found', 'endowment', 'foundation', \"'\", 'ccb', 'dbntc', 'receiver', 'fdicreceiver', 'mutual', 'wmb', 'liabilitie', 'assert', 'mortgagebacked', 'sponsor', 'appeal', 'circuit', 'indemnity', 'receivership', 'judicial', 'wmbrelate', 'directordatedjuly', 'govbankinforegccar', 'statementnameforagainstabstainbroker', 'chairforagainstabstainbroker', 'ignore', 'abstentionsforagainstabstainbroker', 'voluntary', 'valueforagainstabstainbroker', 'lawforagainstabstainbroker', 'philosophy', 'reputationforagainstabstainbroker', 'registering', 'sidley', 'austin', 'nonobjection', 'noteholder', 'insurer', 'ambac', 'segregated', 'insured', 'rmb', 'emc', 'ambacs', 'bear', 'stearn', 'consequential', 'rsus', 'notionally', 'earned', 'twoyear', 'recapturerecoupment', 'variety', 'ofjame', 'dimonmarianne', 'lakemary', 'erdoesdaniel', 'pintomatthew', 'zamesrestricte', 'units', 'remainder', 'european', 'directive', 'crd', 'consecutive', 'nonsubstantive', 'consistency', 'of', 'horan', 'comjpmorganchase', 'keynote', 'las', 'vegas', 'for', 'video', 'visit', 'chasepay', 'regularly', 'statesin', 'demand', 'clawedback', 'contemplate', 'exacerbate', 'threaten', 'arbitration', 'violate', 'privacy', 'promulgate', 'guide', 'obligor', 'erf', 'presidentdatedjuly', 'expendituresforagainstabstainbroker', 'againstforagainstabstainbroker', 'executivesforagainstabstainbroker', 'fx', 'plead', 'guilty', 'antitrust', 'remedial', 'adviser', 'subadviser', 'exchangetrade', 'labor', 'qpam', 'fxrelate', 'plea', 'ask', 'question', 'advanced', 'understand', 'ccarform', 'kpart', 'offset', 'equitybase', 'plans', 'exhibits', 'xxix', 'investordayform', 'jan', 'jd', 'colleague', 'secretarydateddecember', 'fca', 'cftc', 'org', 'uk', 'jpmorganonline', 'mobile', 'cyberattack', 'user', 'phone', 'email', 'compromise', 'household', 'affected', 'password', 'birth', 'attack', 'fraud', 'incident', 'liable', 'unauthorized', 'alert', 'vigilantly', 'situation', 'investigate', 'diagnose', 'medical', 'secretarydatedjuly', 'presidentdatedjune', 'foragainstabstainbrok', 'lobbyingforagainstabstainbroker', 'provisionsforagainstabstainbroker', 'oneshare', 'onevoteforagainstabstainbroker', 'govbankinforegbcreg', 'pdf', 'hud', 'veteran', 'va', 'mortgagerelate', 'fhas', 'endorsement', 'lender', 'firrea', 'sustain', 'face', 'predate', 'fortify', 'capability', 'flat', 'upcome', 'bernard', 'madoff', 'blmis', 'prosecution', 'dpa', 'nontaxdeductible', 'antimoney', 'laundering', 'suspicious', 'secrecy', 'dismiss', 'prejudice', 'complaint', 'victim', 'remission', 'accompanying', 'actantimoney', 'crime', 'fincen', 'satisfied', 'courtappointe', 'govusaonys', 'negotiate', 'rmbsrelate', 'defend', 'federally', 'insure', 'major', 'gibb', 'brun', 'bind', 'appropriately', 'remaining', 'fhfa', 'mb', 'conservator', 'large', 'maes', 'mbsrelate', 'fungible', 'cftcs', 'londonbase', 'trader', 'cio', 'enhancement', 'supervision', 'particular', 'ciorelated', 'massachusetts', 'hereof', 'per', 'late', 'manulife', 'principles', 'cochair', 'swear', 'collection', 'servicemember', 'ago', 'billing', 'monitoring', 'enrollment', 'mid', 'refund', 'cfpbs', 'extensively', 'pursue', 'physical', 'reaffirm', 'traditional', 'vaulting', 'precious', 'advice', 'cote', 'ellen', 'futter', 'correspondingly', \"management's\", 'trend', 'delinquency', 'allowance', 'likely', 'nonvotesjame', 'consentforagainstabstainbroker', 'reapproval', 'ceoforagainstabstainbroker', 'ageforagainstabstainbroker', 'violationsforagainstabstainbroker', 'recipient', 'namesforagainstabstainbroker', 'nzd', 'frank', 'bisignano', 'corp', 'weakness', 'testing', 'govnewseventspressbcregbcreg', 'qa', 'ofincorporationcommission', 'numberir', 'substance', 'websitehttpwww', 'orders', 'observation', 'synthetic', 'lesson', 'learn', 'includingrevampe', 'mandate', 'cioimplemente', 'numerous', 'interaction', 'expert', 'advisor', 'analyze', 'voluminous', 'documentary', 'interview', 'issues', 'better', 'focused', 'clear', 'emphasis', 'profile', 'adequacy', 'staffing', 'stature', 'personnelmore', 'systematic', 'response', 'excession', 'coordination', 'concurrence', 'firing', 'setting', 'expertise', 'systematically', 'audits', 'implementationa', 'multiyear', 'riskadjuste', 'rewarding', 'behavior', 'wholeperformance', 'broadbase', 'success', 'input', 'functionsa', 'talenta', 'reasonable', 'grow', 'businessesvery', 'strict', 'perquisite', 'golden', 'parachute', 'andalthough', 'riskrelate', 'primary', 'priority', 'competitor', 'thestrength', 'performancethird', 'rotcerecord', 'roe', 'eps', 'competitorsuninterrupted', 'recession', 'maintenance', 'sheetcontinue', 'organic', 'strengthening', 'develop', 'succession', 'newgeneration', 'capable', 'with', 'mistake', 'meaningful', 'ultimate', 'importantly', 'aware', 'seriousness', 'forcefully', 'thorough', 'firmreplace', 'lossestook', 'involvedforme', 'half', 'distinct', 'tenyear', 'uncertaintie', 'efficacy', 'reputation', 'principally', 'bsaaml', 'js', 'ifr', 'staley', 'bluemountain', 'lossmitigation', 'borrower', 'prevention', 'fulfil', 'shannon', 'warren', 'kgoldmansachs', 'douglas', 'braunstein', 'officerdateddecember', 'rfs', 'ib', 'tss', 'cib', 'cb', 'aforementioned', 'online', 'corporateprivate', 'corppe', 'previouslyfiled', 'previouslyissue', 'previouslyissued', 'irc', 'unify', 'chasebranded', 'formally', 'align', 'morganbrande', 'franchise', 'cohead', 'horantitle', 'exhibitsexhibit', 'comments', 'previouslyfile', 'nonreliance', 'valuation', 'previouslyreporte', 'andpercentage', 'basic', 'cios', 'vcg', 'verifie', 'external', 'midmarket', 'benchmark', 'bidoffer', 'spread', 'verification', 'discover', 'suggest', 'confident', 'consequently', 'adjusted', 'daily', 'var', 'recalculate', 'recompute', 'thenende', 'irregularity', 'riskweighte', 'negative', 'testify', 'senate', 'oral', 'testimony', 'comand', 'nonpartisanshipforagainstabstainbroker', 'genocidefree', 'ina', 'fixed', 'comjpmorganchaseannual', 'gray', 'novak', 'johnson', 'execution', 'refinance', 'underwater', 'forbearance', 'unemployed', 'homeowner', 'prescribed', 'adhere', 'enhanced', 'mitigation', 'bankruptcyrelated', 'gse', 'concurrently', 'incremental', 'reallocation', 'generation', 'privately', 'highlight', 'unaudite', 'headcount', 'as', 'selected', 'preprovision', 'profita', 'shareb', 'periodend', 'pricec', 'roa', 'overhead', 'depositstoloans', 'ratiod', 'periodende', 'securities', 'debte', 'retained', 'creditimpaire', 'loansf', 'nonperforming', 'chargeoffsg', 'rateg', 'apreprovision', 'profit', 'noninterest', 'useful', 'losses', 'bon', 'cshare', 'tokyo', 'dtier', 'eeffective', 'fhlb', 'reclassify', 'borrow', 'fexclude', 'pci', 'gnet', 'realizable', 'delinquent', 'managements', 'analysisof', 'operationsthis', 'mda', 'glossary', 'forwardlooking', 'kin', 'introductionjpmorgan', 'country', 'prominent', 'securitie', 'organize', 'deep', 'capitalraising', 'sophisticated', 'marketmaking', 'research', 'atms', 'thirdlargest', 'nationally', 'secondlargest', 'clock', 'salesperson', 'florida', 'nation', 'spending', 'paymentech', 'dealership', 'universitie', 'knowledge', 'investorsowner', 'ts', 'provider', 'midsized', 'multinational', 'worldwide', 'globally', 'highnetworth', 'moneymarket', 'ams', 'actively', 'overview', 'reader', 'environmentthe', 'pace', 'slow', 'supply', 'chain', 'earthquake', 'tsunami', 'japan', 'sharp', 'rise', 'weak', 'struggle', 'construction', 'depressed', 'equipment', 'fast', 'longerterm', 'zero', 'onequarter', 'ratios', 'changeselected', 'overviewjpmorgan', 'secondquarter', 'currentquarter', 'foreclosurerelated', 'predominantly', 'mortgagerelated', 'decrease', 'noncompensation', 'matters', 'solid', 'underlying', 'negatively', 'elevated', 'quarterend', 'improved', 'modest', 'middlemarket', 'trial', 'homeowners', 'prioryear', 'lower', 'creditrelated', 'debit', 'depositrelate', 'runoff', 'defaultrelated', 'kohls', 'legislative', 'reversal', 'marketing', 'volume', 'wide', 'compression', 'headcountrelate', 'endofperiod', 'gcb', 'inflow', 'custody', 'relatively', 'expansion', 'margin', 'seed', 'narrow', 'reserves', 'backdrop', 'economie', 'geopolitical', 'governmentsponsored', 'particularly', 'procedures', 'severity', 'foreseeable', 'run', 'redeployment', 'stabilize', 'throughthecycle', 'eventually', 'abate', 'imply', 'persistent', 'volatility', 'volatile', 'economy', 'investmentspecific', 'repositioning', 'pressure', 'mbs', 'inherently', 'uncertain', 'continually', 'deploy', 'stockbase', 'excellent', 'planned', 'unprecedented', 'diligently', 'implication', 'substantial', 'underway', 'durbin', 'mitigate', 'mitigating', 'volcker', 'de', 'minimis', 'timeframe', 'exit', 'attempt', 'shortterm', 'movement', 'typically', 'segregate', 'organizationally', 'clientdriven', 'activities', 'fsb', 'systemically', 'gsibs', 'systemic', 'disincentive', 'phase', 'ahead', 'operationsthe', 'comparative', 'reported', 'revenuethree', 'millions', 'changeinvestment', 'fees', 'transactions', 'commissions', 'gains', 'industrywide', 'strength', 'depth', 'lende', 'introduction', 'nonsufficient', 'fundoverdraft', 'nsfod', 'slightly', 'depositrelated', 'lendingrelated', 'rebalancing', 'msr', 'interchange', 'revenueshare', 'contrarevenue', 'kohl', 'feebase', 'receivables', 'interestearne', 'taxableequivalent', 'fte', 'legislation', 'lossesthree', 'changewholesale', 'expensethree', 'changecompensation', 'expensea', 'occupancy', 'otherbc', 'amortization', 'intangibles', 'employees', 'bincluded', 'cinclude', 'foreclosed', 'defaultrelate', 'serviced', 'mention', 'intangible', 'taxis', 'deferred', 'explanation', 'reconciliation', 'measuresthe', 'gaap', 'track', 'consistently', 'taxexempt', 'comparability', 'source', 'tce', 'goodwill', 'identifiable', 'msrs', 'businesssegment', 'similarly', 'companies', 'ratiosreportedresult', 'taxequivalent', 'managedbasisrevenue', 'assets', 'nm', 'endedin', 'millionsjune', 'less', 'liabilitiesa', 'arepresent', 'taxdeductible', 'nontaxable', 'oth', 'resultsthe', 'changescommencing', 'reorganize', 'followsauto', 'portfolios', 'retroactive', 'methodologyresult', 'essentially', 'standalone', 'derive', 'marketbase', 'refinement', 'changeseach', 'basisa', 'indicated', 'three', 'profitin', 'bankb', 'equityb', 'equityin', 'nmnmtotal', 'six', 'bcorporateprivate', 'ibs', 'incomeexpense', 'bankfor', 'datathree', 'changerevenue', 'all', 'incomea', 'revenueb', 'revenuec', 'marketsd', 'marketse', 'portfolioaf', 'nmtotal', 'aib', 'reimbursement', 'btotal', 'affordable', 'municipal', 'dfixe', 'marketmake', 'eequitie', 'fcredit', 'restructure', 'resultsnet', 'consisting', 'loans', 'currentyear', 'metricsthree', 'retaineda', 'heldforsale', 'assetsdebt', 'instruments', 'assetsderivative', 'assetsb', 'statistic', 'chargeoffs', 'nonaccrual', 'retainedac', 'satisfactions', 'nonperforme', 'lendingrelate', 'commitments', 'ratead', 'retainedad', 'retainedacd', 'riskaverage', 'confidence', 'equities', 'commodities', 'diversificatione', 'varf', 'varg', 'aloan', 'badjuste', 'minus', 'resale', 'vie', 'assettoequity', 'commonly', 'callowance', 'dloan', 'eaverage', 'valueatrisk', 'sum', 'diversification', 'perfectly', 'correlate', 'usually', 'themselves', 'ftrading', 'sensitivity', 'syndicate', 'parameter', 'capture', 'example', 'correlation', 'dva', 'structured', 'details', 'gcredit', 'cva', 'marktomarket', 'mtm', 'accorde', 'dealogic', 'equityrelate', 'endedjune', 'rankingsamarket', 'ranking', 'rankingsglobal', 'feesb', 'syndicated', 'debtc', 'globald', 'announced', 'asource', 'bglobal', 'deals', 'clongterm', 'investmentgrade', 'highyield', 'supranational', 'sovereigns', 'assetbacke', 'abs', 'dequity', 'chinese', 'ashares', 'eglobal', 'managerequal', 'removal', 'changetotal', 'revenuea', 'europemiddle', 'eastafrica', 'asiapacific', 'latin', 'americacaribbean', 'periodendb', 'aregional', 'domicile', 'desk', 'binclude', 'servicesfor', 'nmfinancial', 'intangiblesb', 'atotal', 'brfs', 'cdi', 'valuea', 'loansbcd', 'assetsbcd', 'ratee', 'loansef', 'retainede', 'retainedbef', 'loansb', 'classify', 'bexcludes', 'composite', 'pastdue', 'ccertain', 'dat', 'normally', 'eloan', 'life', 'bankingselecte', 'changenoninter', 'intangiblesa', 'aconsumer', 'build', 'noted', 'changebusiness', 'owned', 'savings', 'branches', 'bankers', 'sales', 'specialists', 'active', 'thousands', 'servicingselecte', 'changenoninterest', 'incomeloss', 'expensebenefit', 'nmnet', 'nmoverhead', 'excluding', 'rates', 'armsa', 'armsab', 'chargeoffsrecoverie', 'arms', 'chargeoffrecovery', 'armsb', 'ratecd', 'millionse', 'wholesalef', 'correspondentf', 'cnt', 'valueg', 'ending', 'multipleh', 'detailsin', 'changenet', 'modeli', 'nmmortgage', 'apredominantly', 'ginnie', 'baverage', 'cat', 'eat', 'finclude', 'rural', 'guidelines', 'gloan', 'hrepresent', 'iof', 'portfoliosselecte', 'spreads', 'trends', 'foreclose', 'billions', 'changeloan', 'pcia', 'subprime', 'loansa', 'apci', 'estimable', 'contractually', 'undiscounted', 'collect', 'accretable', 'residual', 'prepayment', 'weightedaverage', 'slowly', 'positively', 'statisticsthree', 'assetsc', 'aexclude', 'bat', 'cexclude', 'autofor', 'dataathree', 'incomeb', 'revenued', 'expensee', 'nmincome', 'ratiosa', 'aeffective', 'dtotal', 'einclude', 'withprior', 'periods', 'selecte', 'periodenda', 'averagea', 'loansc', 'headcountd', 'changedelinquency', 'gh', 'assetsi', 'studentg', 'opened', 'accountsj', 'akl', 'ctotal', 'dheadcount', 'faverage', 'gperiodend', 'heldfor', 'hexclude', 'education', 'ffelp', 'iat', 'jreflect', 'ksupplemental', 'lfor', 'mas', 'nrepresent', 'ototal', 'pat', 'qat', 'athis', 'intentionally', 'blankcommercial', 'bankingfor', 'lendingc', 'servicesc', 'grossd', 'middle', 'bankinge', 'acb', 'lowincome', 'ceffective', 'standby', 'drepresent', 'clients', 'ecorporate', 'midcorporate', 'higher', 'balances', 'bankinga', 'retainedb', 'acorporate', 'ballowance', 'incomeexpensea', 'regionb', 'brevenue', 'cloan', 'overdraft', 'revised', 'mainly', 'expenses', 'changets', 'cba', 'averagec', 'ratioad', 'ach', 'originated', 'thousandse', 'thousandsf', 'btss', 'cfirmwide', 'doverhead', 'tssrelate', 'einternational', 'automate', 'house', 'fwholesale', 'store', 'managementfor', 'changenumber', 'advisorsa', 'brokers', 'star', 'fundsb', 'aum', 'quartilesc', 'years', 'bderive', 'morningstar', 'luxembourg', 'france', 'kong', 'taiwan', 'nomura', 'cquartile', 'lipper', 'supervisionasset', 'supervisiona', 'multiasset', 'alternatives', 'custodybrokerageadministrationdeposits', 'institutionalb', 'retailb', 'aexcludes', 'bin', 'hierarchy', 'rollforward', 'marketperformanceother', 'millionsa', 'equityfor', 'expensec', 'subtotal', 'nmcorporate', 'anet', 'cincluded', 'changesecuritie', 'gainsa', 'areflects', 'reposition', 'nontrade', 'ratesensitive', 'changeprivate', 'gainslosse', 'nmunrealize', 'gainslossesa', 'investments', 'nmthirdparty', 'gainslossesb', 'nmprivate', 'informationc', 'changepublicly', 'quoted', 'investmentsd', 'aunrealized', 'realized', 'cfor', 'dunfunded', 'operationsdure', 'counterpartie', 'emea', 'clientserve', 'personnel', 'locate', 'prioritized', 'frontoffice', 'emeaasiapacificlatin', 'americacaribbeanin', 'notedthree', 'monthsende', 'totalheadcounta', 'significantclientsb', 'depositsaveragec', 'loansperiodendd', 'ciotreasury', 'bsignificant', 'trail', 'cdeposit', 'booking', 'analysisselecte', 'banks', 'agreements', 'borrowed', 'receivable', 'premise', 'rights', 'fundsa', 'payables', 'liabilities', 'vies', 'debta', 'instrumentstrade', 'payablesderivative', 'securitiessecurities', 'lossesloan', 'seasonal', 'receivableaccrue', 'rightsmsrs', 'predominately', 'assetsthe', 'depositsdeposit', 'inactive', 'lowbalance', 'agreementssecuritie', 'fundscommercial', 'sweep', 'tsss', 'accounts', 'liabilitiesaccount', 'viesbeneficial', 'firmsponsore', 'offbalance', 'equitytotal', 'afs', 'widening', 'realization', 'flowhedge', 'arrangementsjpmorgan', 'specialpurpose', 'spe', 'entitiesspe', 'isolate', 'assetbacked', 'sperelate', 'downgrade', 'moodys', 'poor', 'fitch', 'nonconsolidated', 'refinancing', 'administrator', 'structurer', 'entitiesathree', 'multiseller', 'conduits', 'intermediation', 'entitiesb', 'aincludes', 'bexclude', 'securitize', 'parties', 'commitmentsjpmorgan', 'fulfill', 'subsequently', 'demonstrable', 'creditworthiness', 'securitizationrelated', 'pages', 'millionsexpire', 'totallendingrelate', 'unfunded', 'creditab', 'guaranteesabcd', 'unuse', 'creditad', 'guaranteese', 'guaranteesf', 'unsettle', 'commitmentsg', 'aat', 'participations', 'nonconsolidate', 'unissued', 'organisation', 'oecd', 'agencies', 'frepresent', 'notional', 'gat', 'liabilityin', 'privatelabel', 'indemnify', 'misrepresentation', 'undisclosed', 'appraise', 'gses', 'from', 'servicer', 'loanlevel', 'viable', 'far', 'manifest', 'securitiesrelated', 'liabilityto', 'ithe', 'unresolved', 'demandsiiestimate', 'probable', 'liquidated', 'rescission', 'iiithe', 'defect', 'ivthe', 'vthe', 'originator', 'andvithe', 'typea', 'insurers', 'overlapping', 'populationb', 'aprior', 'bbecause', 'vintagea', 'pre', 'received', 'securitizations', 'receivedb', 'bmortgage', 'ultimately', 'lagged', 'because', 'miss', 'vary', 'observe', 'correspondentoriginate', 'outofbusiness', 'sought', 'compute', 'complicate', 'surround', 'dependent', 'estimation', 'imprecise', 'potentially', 'evolve', 'presented', 'lossesa', 'claimant', 'repurchasesa', 'maeb', 'othercd', 'package', 'rha', 'cpredominantly', 'dnonaccrual', 'heldforinvestment', 'warranties', 'managementthe', 'tocover', 'activitiesmaintain', 'wellcapitalize', 'requirementsachieve', 'targetsretain', 'flexibility', 'andbuild', 'riskbase', 'ratiosjminimum', 'ratiosjin', 'ratiosjune', 'commonb', 'riskweightedcd', 'averagee', 'af', 'totalg', 'leverageh', 'rwa', 'element', 'criskweighte', 'weight', 'onbalance', 'perceive', 'guarantor', 'multiply', 'creditequivalent', 'dinclude', 'eadjuste', 'disallowed', 'nonfinancial', 'fti', 'adjustments', 'gtotal', 'ti', 'htier', 'iasset', 'jas', 'krepresent', 'lthe', 'below', 'goodwilla', 'assetsa', 'hybrid', 'interestsb', 'agoodwill', 'bprimarily', 'trusts', 'iithe', 'publish', 'risksensitive', 'timeline', 'iiiin', 'introduce', 'conservation', 'gsib', 'interconnectedness', 'lack', 'substitutability', 'crossjurisdictional', 'complexity', 'comment', 'rulesthe', 'aoci', 'availableforsale', 'postretirement', 'plansrelate', 'estimated', 'rulesa', 'rulesb', 'akey', 'resecuritization', 'alter', 'prolong', 'phasedin', 'rulemaking', 'capitaljpmorgan', 'efficiencies', 'tentative', 'riskassessment', 'othera', 'areflect', 'objectives', 'independently', 'billionsjune', 'actionsdividendson', 'normalize', 'repurchaseson', 'predefined', 'managementrisk', 'holistic', 'spectrum', 'awareness', 'collaboration', 'appetite', 'context', 'formalize', 'clearly', 'surplus', 'crucial', 'diversity', 'highlyliquid', 'unencumbered', 'availability', 'tenor', 'concentration', 'governancethe', 'assetliability', 'formulate', 'centralize', 'maximize', 'minimize', 'frequent', 'continuous', 'monitoringthe', 'analyse', 'reliance', 'depositstoloan', 'horizon', 'pledge', 'produce', 'uniquely', 'peers', 'companyliquidity', 'prefunde', 'conservative', 'prefunding', 'reservein', 'secured', 'governmentissue', 'fdicguaranteed', 'quickly', 'window', 'highquality', 'marketable', 'fundingsource', 'stable', 'sensitive', 'eurodollar', 'pittsburgh', 'fundingthe', 'overnight', 'choose', 'mature', 'governmentissued', 'fluctuate', 'match', 'advances', 'notes', 'dure', 'maturities', 'flowscash', 'activitiesjpmorgan', 'needs', 'depreciation', 'paydown', 'activitiesthe', 'interbank', 'gradually', 'ease', 'loweryielde', 'promotional', 'normalization', 'willing', 'diverse', 'stream', 'moodysspfitch', 'moodysspfitchjpmorgan', 'aaajpmorgan', 'aaaachase', 'aaaathe', 'sps', 'fitchs', 'uplift', 'likelihood', 'affirm', 'confirmation', 'if', 'notch', 'several', 'reviews', 'portfoliofor', 'jp', 'calculations', 'nonperformingdef', 'averageannual', 'ratehin', 'nana', 'nanareceivables', 'receivablesa', 'creditrelate', 'commitmentsb', 'nanaasset', 'ownednana', 'nanaothernana', 'nanatotal', 'satisfactionsna', 'notionalc', 'nanaliquid', 'derivatives', 'nanaareceivable', 'seller', 'bankruptcyremote', 'crepresent', 'singlename', 'ffiec', 'chargedoff', 'whichever', 'eexclude', 'fat', 'gfor', 'hfor', 'portfolioas', 'partly', 'compose', 'nonperformingdin', 'sheets', 'dexcludes', 'scale', 'ig', 'profilee', 'profilejune', 'due', 'lessdue', 'yearsdue', 'yearstotal', 'noninvestmentgradetotaltotal', 'igin', 'aaaaaa', 'bbbbaa', 'bbba', 'belowloan', 'valuebc', 'receivablesc', 'notionald', 'profiledecember', 'bloan', 'cfrom', 'perspective', 'collateralize', 'criticize', 'ccccaa', 'accruingloansyeartodate', 'chargeoffsrecoveriescredit', 'hedgeseliquid', 'derivativereceivablesas', 'noninvestment', 'gradejune', 'creditexposuredinvestment', 'gradenoncriticizedcriticize', 'performingcriticize', 'nonperformingin', 'millionstop', 'industriesa', 'governmentsb', 'managers', 'utilities', 'products', 'machinery', 'manufacturing', 'metalsmining', 'telecom', 'media', 'builde', 'materialsconstruction', 'holde', 'chemicalsplastics', 'exchanges', 'automotive', 'agriculturepaper', 'aerospace', 'otherc', 'gradedecember', 'building', 'aall', 'dcredit', 'erepresent', 'millionsloanslendingrelate', 'commitmentsderivative', 'receivablestotal', 'loansaderivativeslendingrelatedcommitmentstotal', 'non', 'performingasset', 'andaccrue', 'loanseuropemiddle', 'nareceivables', 'nananananatotal', 'loansin', 'additions', 'returne', 'additionsreduction', 'chargeoffsthree', 'contractsin', 'fluctuation', 'legally', 'enforceable', 'initiation', 'nondaily', 'mtmrating', 'equivalentjune', 'ratiosexposure', 'collateralaaaaaa', 'aaaa', 'spot', 'distinguish', 'dealerclient', 'millionsprotection', 'purchasedbprotection', 'purchasedprotection', 'soldtotal', 'totalcredit', 'swaps', 'derivativesa', 'aprimarily', 'options', 'businesswithin', 'derivativesnotional', 'soldin', 'purchased', 'sold', 'contrast', 'riskmanage', 'asymmetry', 'true', 'commitmentsthree', 'gainslosses', 'contracts', 'loanequivalent', 'unused', 'exposurethe', 'crossborder', 'locally', 'privatesector', 'referenced', 'namespecific', 'sovereignreference', 'greece', 'portugal', 'spain', 'italy', 'ireland', 'sovereign', 'manageable', 'nonsovereign', 'valuations', 'extreme', 'conditions', 'top', 'exposurejune', 'exposurein', 'billionslendingatradingbotherctotallocaldbrazil', 'india', 'korea', 'malaysia', 'mexico', 'arab', 'emirates', 'chile', 'thailand', 'russia', 'alending', 'interestsearne', 'undrawn', 'btrade', 'cother', 'entities', 'dlocal', 'denominate', 'portfoliojpmorgan', 'highrisk', 'ltv', 'fico', 'earlystage', 'latestage', 'elongate', 'onset', 'loanshi', 'ratej', 'ratejin', 'liena', 'lienb', 'autoc', 'pcid', 'nanaprime', 'nanasubprime', 'nanaoption', 'heldforsalee', 'lienaf', 'lienbf', 'retainedg', 'commitmentsf', 'memo', 'arepresents', 'brepresent', 'leaserelated', 'dchargeoff', 'ginclude', 'bill', 'uncollectible', 'amounts', 'hat', 'iexclude', 'javerage', 'cardloan', 'heloan', 'helocs', 'closedend', 'amortize', 'openende', 'revolve', 'heloc', 'revolving', 'fullyamortize', 'nearterm', 'at', 'pose', 'higherrisk', 'regardless', 'probability', 'adjustablerate', 'arm', 'ficos', 'interestonly', 'recast', 'usedcar', 'primequality', 'credits', 'elevate', 'prospectively', 'lifetime', 'nonaccretable', 'deplete', 'estimatesa', 'lossesbin', 'blifetodate', 'ltvs', 'loansthe', 'geographically', 'arizona', 'michigan', 'willingness', 'necessarily', 'ratiosunpaid', 'acurrent', 'ratiobnet', 'valuedratio', 'netcarrye', 'valueto', 'balanceacurrent', 'brepresents', 'dnet', 'priorperiod', 'currentperiod', 'while', 'nonpci', 'activitiesfor', 'tdrs', 'drop', 'mha', 'financially', 'distressed', 'hamp', 'mp', 'concession', 'forgiveness', 'deferment', 'reunderwritten', 'permanently', 'redefault', 'macroeconomic', 'driver', 'season', 'weighted', 'favorably', 'restructured', 'millionsonbalance', 'loansnonaccrual', 'loansd', 'loansdrestructure', 'loansab', 'naprime', 'nasubprime', 'naoption', 'natotal', 'naaamount', 'reperform', 'camounts', 'tdr', 'assure', 'terms', 'stay', 'completed', 'welldefine', 'multiple', 'statebystate', 'nonjudicial', 'instruct', 'temporarily', 'eviction', 'resume', 'proceedings', 'loansbc', 'redefaulte', 'reo', 'enhancements', 'servicingdure', 'outline', 'corrective', 'mortgageservicing', 'establishing', 'functions', 'ensuring', 'mer', 'merscorps', 'develope', 'risks', 'includeestablishe', 'draft', 'adde', 'upgrade', 'supervisor', 'pilot', 'rollout', 'injury', 'outreach', 'cardtotal', 'seasonality', 'especially', 'wellseasone', 'rewardsbase', 'texas', 'illinoi', 'modifications', 'modified', 'revert', 'premodification', 'neighborhood', 'moderate', 'states', 'lossesjpmorgan', 'riskrate', 'absorb', 'repayments', 'wholesaleconsumer', 'cardcredit', 'totalin', 'principlesa', 'recoveries', 'assetspecificbcd', 'formulabasedc', 'assetspecific', 'formulabased', 'ratese', 'loansdf', 'carddf', 'conduit', 'echargeoffs', 'lossesfor', 'yearago', 'lossesin', 'statistical', 'activitie', 'crossbusiness', 'outcome', 'simulation', 'tailloss', 'approximate', 'predict', 'avg', 'minmax', 'nmb', 'aaverage', 'bdesignate', 'portfoliodiversification', 'measurementib', 'pricebase', 'structural', 'pipeline', 'warehouse', 'hedges', 'mezzanine', 'taxoriente', 'etc', 'investing', 'resultsa', 'reduced', 'changes', 'backteste', 'backtesting', 'tradingrelate', 'histogram', 'illustrate', 'chart', 'inset', 'graph', 'depict', 'onebasispoint', 'parallel', 'shift', 'curve', 'fashion', 'recognized', 'millionsone', 'basispoint', 'spreadjune', 'economicvalue', 'testingwhile', 'unlikely', 'plausible', 'abnormal', 'dynamically', 'redefine', 'stresst', 'nontrading', 'revenueatrisk', 'earningsatriskinterest', 'earningsatrisk', 'optionality', 'nonparallel', 'outcomes', 'profiles', 'bp', 'bpjune', 'nma', 'adownward', 'fed', 'sixmonth', 'lowprobability', 'assumed', 'widen', 'compress', 'quotations', 'regulationthe', 'dividendsat', 'regulators', 'firmjpmorgan', 'integral', 'complex', 'ascertain', 'wellcontrolle', 'brief', 'express', 'offsetting', 'onenotch', 'isolated', 'geography', 'directionally', 'inventory', 'recur', 'valuethe', 'billionstotal', 'valuetotal', 'assetstrade', 'instrumentsa', 'netting', 'otherb', 'basisc', 'ainclude', 'dderivative', 'exclusive', 'valuationfor', 'arrive', 'observability', 'empirical', 'finally', 'constraint', 'unobservable', 'imprecision', 'impairmentmanagement', 'discounted', 'forecasting', 'estimates', 'impair', 'associated', 'interpretation', 'accounte', 'developmentsfair', 'disclosuresin', 'fasb', 'categorize', 'restructuringin', 'creditor', 'operations', 'resell', 'incomein', 'statementsfrom', 'strictly', 'aspiration', 'orally', 'others', 'eventschange', 'newlyenacted', 'legislationchange', 'lawssecuritie', 'volatilitychange', 'sentiment', 'behaviorability', 'effectively', 'liquiditychange', 'subsidiariesdamage', 'reputationability', 'deal', 'slowdown', 'disruptiontechnology', 'institute', 'competitorsmerger', 'acquisitionsability', 'including', 'originationability', 'businessacceptance', 'marketplace', 'employeesability', 'expensecompetitive', 'pressureschange', 'counterpartiesadequacy', 'frameworkadverse', 'proceedingschange', 'policiesability', 'accurate', 'liabilitiesoccurrence', 'natural', 'manmade', 'disaster', 'calamity', 'commodityrelate', 'stockholders', 'shares', 'inreclassifie', 'unauditedin', 'datajune', 'retaine', 'rsu', 'recourse', 'programwide', 'firmadministered', 'preferre', 'accumulated', 'reissuance', 'reconcile', 'heldtomaturity', 'proceeds', 'purchases', 'dispositions', 'inprovide', 'funds', 'dividends', 'paid', 'byuse', 'noteeffective', 'see', 'unauditednote', 'presentationjpmorgan', 'conformity', 'references', 'developmentsincrease', 'dividendon', 'timetable', 'measurementfor', 'millionslevel', 'hlevel', 'hnetting', 'adjustmentstotal', 'valuefederal', 'agenciesa', 'nonagency', 'municipalities', 'commoditiesc', 'instrumentsd', 'receivablese', 'collateralized', 'obligations', 'investmentsf', 'basisg', 'payablese', 'governmentsponsore', 'firstlien', 'cphysical', 'dbalance', 'uniform', 'cusips', 'eas', 'fprivate', 'and', 'significance', 'observable', 'quote', 'validate', 'realizedunrealizedgainslosse', 'andorout', 'gfair', 'atjune', 'unrealizedgainslosse', 'heldat', 'millionspurchasesfsalesissuancessettlementsasset', 'millionspurchasesfsalesissuancessettlementsliabilitiesa', 'gainslossespurchase', 'nettransfer', 'millionsasset', 'millionsliabilitiesa', 'alevel', 'bpredominantly', 'crealized', 'oci', 'remeasurement', 'dchange', 'elargely', 'floan', 'gall', 'basiscertain', 'unfunde', 'valueloan', 'liabilitiesb', 'heldforsalec', 'dfor', 'collateraldependent', 'appraisal', 'analysislevel', 'clos', 'longdate', 'subordination', 'issuing', 'vehicle', 'seniority', 'mortality', 'borrowerspecific', 'changeslevel', 'portfoliosfor', 'lossesinclude', 'ratesinclude', 'qincluded', 'hedging', 'cvaa', 'dvabc', 'aderivative', 'bstructure', 'cstructure', 'dvab', 'aderivatives', 'billionscarryingvalueestimatedfair', 'valueappreciationdepreciation', 'carryingvalueestimatedfair', 'valueappreciationdepreciationfinancial', 'valueb', 'depreciationappreciation', 'afair', 'emergence', 'beffective', 'billionscarryingvalueaestimatedfair', 'carryingvalueaestimatedfair', 'valuewholesale', 'inception', 'guarantees', 'instrumentsab', 'abalance', 'optionfor', 'instrumentspecific', 'electionthe', 'millionsprincipaltransactionsotherincometotal', 'changesin', 'principaltransactionsotherincometotal', 'recordedfederal', 'depositsa', 'riska', 'bstructured', 'tailor', 'creporte', 'dreporte', 'millionscontractualprincipaloutstande', 'valuefair', 'valueoverundercontractualprincipal', 'contractualprincipaloutstande', 'outstandingloan', 'principalprotecte', 'nonprincipalprotected', 'debtana', 'debtna', 'nalongterm', 'interestsna', 'naaremaining', 'unlike', 'principalprotected', 'nonprincipalprotecte', 'bwhere', 'zerocoupon', 'instrumentsfor', 'contractsthe', 'amountsbin', 'futures', 'forwards', 'written', 'crosscurrency', 'simply', 'payments', 'sheetsthe', 'freestande', 'payablesjune', 'millionsnot', 'hedgesdesignated', 'hedgestotal', 'payablestrade', 'exchangeb', 'adjustmentc', 'carrying', 'payablesdecember', 'currencydenominate', 'cu', 'payablesin', 'incomefair', 'tothree', 'millionsderivativeshedge', 'itemstotal', 'hedgeineffectivenessd', 'componentsecontract', 'ratea', 'commodityc', 'tosix', 'cconsist', 'dhedge', 'ineffectiveness', 'exactly', 'hedged', 'ecertain', 'gainloss', 'ocilosscthree', 'millionsderivative', 'incomehedge', 'incomedtotal', 'impactderivative', 'ocitotal', 'periodcontract', 'incomelosscthree', 'incomelosscsix', 'liborindexed', 'floatingrate', 'dollardenominate', 'forecasted', 'over', 'length', 'millionsexcluded', 'incomeaeffective', 'portionrecorde', 'ocicontract', 'acertain', 'instrumentsthe', 'transform', 'creditb', 'exchangec', 'commodityb', 'agains', 'bgain', 'cgain', 'lossesthe', 'exchangea', 'ain', 'featuresthe', 'singlenotch', 'twonotch', 'receivablespayablesa', 'receivedpaida', 'carrye', 'transferredin', 'collaterala', 'collateralb', 'collateralc', 'aas', 'payoutnotional', 'amountjune', 'soldprotection', 'underlyingsbnet', 'soldpurchasedcother', 'purchaseddin', 'millionscredit', 'amountdecember', 'cdoe', 'ratingsamaturity', 'amountfair', 'valuebrisk', 'noninvestmentgrade', 'bamount', 'revenuefor', 'maker', 'purposes', 'commoditya', 'segments', 'feesa', 'clearance', 'expensefor', 'interestbeare', 'liabilitiesbc', 'plansfor', 'opeb', 'plansthree', 'costcredit', 'plansa', 'planssix', 'unrecognized', 'costscredit', 'determinable', 'incentivesfor', 'fullcareer', 'expensethe', 'expensebc', 'securitiessecuritie', 'gainsb', 'aproceeds', 'millionsamortize', 'costgross', 'gainsgross', 'lossesfair', 'valueavailableforsale', 'alta', 'securitiesb', 'securitiesc', 'bconsist', 'governmentguaranteed', 'enterprises', 'millionsfair', 'valuegross', 'lossestotal', 'lossesavailableforsale', 'ottithe', 'afor', 'otti', 'securitiesthe', 'lossesgross', 'otherthantemporarily', 'nonagencyas', 'amortized', 'attribute', 'possess', 'geographical', 'higheryielde', 'deceleration', 'spur', 'netherland', 'obligationsas', 'yieldsthe', 'by', 'maturityin', 'millionsdue', 'yearsctotalavailableforsale', 'securitiesa', 'yieldb', 'certificates', 'au', 'premium', 'stated', 'dealer', 'agreementsa', 'borrowedb', 'agreementsc', 'loansloan', 'frameworkthe', 'categoriesoriginate', 'heldforsaleloan', 'valuepci', 'heldforinvestmentfor', 'portfoliothe', 'wholesalea', 'cardb', 'mortgageother', 'bankingc', 'mutualainclude', 'classes', 'segmentjune', 'millionswholesaleconsumer', 'excludingcredit', 'unearned', 'unamortized', 'exposures', 'cardtotalpurchase', 'adjustmentsa', 'portfoliowholesale', 'highnet', 'estatein', 'grade', 'noncriticized', 'criticized', 'distributiona', 'delinquencyb', 'accruing', 'accruingc', 'bfor', 'wellcollateralize', 'dother', 'spes', 'multifamily', 'lessorsin', 'pagefinancial', 'otherd', 'totalretaine', 'loansjune', 'pagecommercial', 'impaired', 'commercialand', 'financialinstitution', 'without', 'allowancea', 'awhen', 'institutions', 'totala', 'restructuringsa', 'athese', 'portfolioconsumer', 'paymentoption', 'riskrated', 'stage', 'includefor', 'refresh', 'scored', 'unwilling', 'lengthening', 'lienin', 'delinquencya', 'guaranteedb', 'ratioscdef', 'illinois', 'ohio', 'jersey', 'otherg', 'bthese', 'curtail', 'djunior', 'erefreshed', 'ffor', 'pagemortgage', 'pciin', 'allowancec', 'loanse', 'bthere', 'cwhen', 'off', 'onimpaire', 'basisain', 'mortgages', 'ratiosjun', 'jun', 'ratingsc', 'djune', 'consumercin', 'millionsjun', 'cthere', 'consumera', 'restructuringsab', 'badditional', 'loansfor', 'lossesb', 'balancecde', 'acarrying', 'bmanagement', 'drefreshed', 'efor', 'variablerate', 'flowsa', 'aother', 'refine', 'assumptions', 'since', 'higherthanexpected', 'longerthanexpected', 'insight', 'tend', 'lagging', 'cardholder', 'excludingwashington', 'portfolioc', 'cardin', 'pennsylvania', 'virginia', 'georgia', 'scoresb', 'brefreshe', 'statistically', 'random', 'sample', 'allowanceab', 'termsc', 'termsd', 'noncompliance', 'closed', 'methodologythe', 'millionswholesaleconsumerexclude', 'wholesaleconsumerexcluding', 'cardtotalallowance', 'formulabasedd', 'chargeoffse', 'selle', 'brelate', 'eprior', 'entitiesfor', 'lineofbusinesstransaction', 'typeactivityform', 'referencecardcredit', 'trustssecuritization', 'rfsmortgage', 'ibmortgage', 'conduitsinvestor', 'activitiesassist', 'costefficient', 'entitiescredit', 'securitizationsfor', 'creditcard', 'securitized', 'creditors', 'trustsfor', 'existence', 'viesdefghjune', 'viesasset', 'assetsafssecuritiestotal', 'chasesecuritizationrelate', 'primeb', 'viesdefghdecember', 'nonmortgagerelated', 'sponsored', 'cosponsor', 'nonjpmorgan', 'chaseoriginate', 'dexclude', 'spequivalent', 'securitizationrelate', 'decisionmake', 'unilateral', 'conduitsfor', 'dealspecific', 'activitiesmunicipal', 'vehiclesfor', 'follows', 'billionsfair', 'viesliquidity', 'facilitiesaexcessdeficitbmaximum', 'exposurenonconsolidate', 'assetscfair', 'vieswt', 'gradein', 'notedaaa', 'aaaaa', 'abbb', 'belowjune', 'excessdeficit', 'drawn', 'interests', 'billionsnet', 'exposurebpar', 'viesccreditrelate', 'static', 'managed', 'atrading', 'bonbalance', 'marketmaker', 'vehicles', 'partiesthe', 'trustthe', 'thirdpartysponsored', 'retailer', 'liabilitiesthe', 'liabilitiesjune', 'billionstrade', 'instrumentsloansotherc', 'assetsd', 'assetseotherftotal', 'liabilitiesvie', 'entitiesa', 'liabilitiesdecember', 'billionstrading', 'resecuritizations', 'bonds', 'securitizationsthe', 'activitythe', 'chasesponsore', 'millionsprimeesubprimeoption', 'armscommercial', 'otherprincipal', 'perioda', 'securitizationsb', 'collected', 'firmd', 'reacquire', 'cleanup', 'calls', 'entitiesin', 'soldab', 'bmsrs', 'shortly', 'technique', 'mortgagecommercialand', 'otherin', 'notedprimedjpmorgan', 'assetsab', 'ratec', 'cpr', 'cprimpact', 'ccpr', 'variation', 'extrapolate', 'easily', 'linear', 'reality', 'counteract', 'magnify', 'mortgageb', 'securitizedc', 'assetsfor', 'relationships', 'cardrelate', 'combinations', 'translation', 'taxrelated', 'rightsmortgage', 'ancillary', 'naturally', 'prolonged', 'row', 'assumptionsa', 'msrsc', 'billionse', 'decay', 'insufficient', 'modelb', 'ratesjune', 'speed', 'sensitivities', 'amountaaccumulate', 'amortizationanetcarrye', 'amountaccumulate', 'amortizationnetcarrye', 'valuein', 'indefinite', 'millionspurchase', 'relationshipsother', 'intangiblescore', 'intangiblesother', 'intangiblestotal', 'depositsfor', 'noninterestbearing', 'interestbearing', 'demanda', 'savingsb', 'valuec', 'offices', 'negotiable', 'mmdas', 'fundsthe', 'banksa', 'fundsbc', 'sharefor', 'ep', 'undistributed', 'warrantsa', 'outstandingb', 'antidilutive', 'bparticipating', 'twoclass', 'incomelossaoci', 'endedunrealize', 'adjustmentsnet', 'comprehensiveincomeloss', 'millionsbalance', 'principlea', 'narrowing', 'functional', 'valuejin', 'nanaderivative', 'unsettled', 'agreementsg', 'commitmentsh', 'liabilityi', 'irepresent', 'jfor', 'derivativerelate', 'creditother', 'remarkete', 'investors', 'also', 'guaranteesthe', 'recorded', 'sblc', 'millionsstandby', 'guaranteesother', 'creditinvestmentgradea', 'noninvestmentgradea', 'amountb', 'guaranteesin', 'indemnificationsindemnification', 'warrantiesin', 'gserelate', 'peak', 'trough', 'above', 'nonrecourse', 'defaulted', 'disposing', 'collateralfor', 'assetsat', 'repledge', 'collateralat', 'litigationcontingencie', 'putative', 'regulatorygovernment', 'selfregulatory', 'adjudication', 'tort', 'novel', 'theories', 'yetunresolved', 'attendant', 'auctionrate', 'charity', 'mediumsize', 'substantively', 'nasaa', 'puerto', 'rico', 'virgin', 'island', 'nasaas', 'unspecified', 'forum', 'manipulate', 'bid', 'properly', 'misrepresent', 'coordinate', 'pending', 'collude', 'bsam', 'cayman', 'feeder', 'there', 'mismanage', 'liquidator', 'allegation', 'punitive', 'deny', 'courtordered', 'banc', 'bofa', 'cdosquared', 'purported', 'misleading', 'artificially', 'inflate', 'erisa', 'failing', 'prudently', 'communicate', 'accurately', 'suit', 'waste', 'mismanagement', 'unjust', 'enrichment', 'abuse', 'amount', 'abovedescribed', 'pretrial', 'reconsideration', 'milan', 'occasion', 'ground', 'fraudulent', 'deceitful', 'judge', 'sanction', 'weekly', 'enron', 'newby', 'enronrelated', 'mastercard', 'conspire', 'enact', 'tyingbundling', 'dealing', 'injunctive', 'theory', 'ipos', 'ipo', 'clayton', 'sherman', 'articulate', 'pleading', 'complaints', 'inappropriately', 'ruling', 'negligence', 'guaranty', 'appellate', 'cmmf', 'negligent', 'lbhi', 'lbhis', 'hasten', 'demise', 'counterclaim', 'fraudulently', 'induce', 'inappropriate', 'sipa', 'lbi', 'preferential', 'debtor', 'aid', 'abet', 'longtime', 'ponzi', 'scheme', 'overlook', 'wrongdoe', 'allegedly', 'claims', 'sa', 'fairfield', 'sentry', 'sigma', 'restitution', 'alreadypende', 'prevail', 'await', 'dozen', 'omission', 'wamu', 'nowconsolidate', 'oppose', 'seattle', 'indianapolis', 'atlanta', 'courts', 'syncora', 'alleging', 'jurisdictional', 'cifg', 'argue', 'purportedly', 'defective', 'inducement', 'tortious', 'interference', 'compel', 'damages', 'prove', 'unenforceable', 'defunct', 'indymac', 'thornburg', 'mbia', 'subrogate', 'depositor', 'wrongful', 'inaction', 'abovedescribe', 'subpoena', 'diligence', 'reached', 'four', 'voluntarily', 'declaratory', 'bidding', 'reportedly', 'statute', 'followe', 'jefferson', 'alabama', 'sewer', 'payer', 'conceal', 'concealment', 'mandamus', 'supreme', 'countys', 'ratepayer', 'mislead', 'feedebit', 'improperly', 'reorder', 'unwarranted', 'contend', 'chronological', 'reordering', 'multidistrict', 'petter', 'oep', 'pertain', 'thomas', 'polaroid', 'majorityowne', 'virtue', 'collective', 'loyalty', 'impermissible', 'answer', 'scra', 'hera', 'prompt', 'mistakenly', 'recentlyactive', 'wmi', 'overpayment', 'disputed', 'wmis', 'evidentiary', 'argument', 'assertion', 'premature', 'sue', 'toolow', 'remand', 'meritorious', 'vigorously', 'upwards', 'eventual', 'footnote', 'reconciliationa', 'ratiosinvestmentbankretail', 'financialservicescard', 'autocommercialbankingtreasury', 'servicesasset', 'managementcorporateprivate', 'itemsc', 'totalnoninter', 'incomeexpenseb', 'nmnm', 'itemsctotalnoninter', 'whole', 'bib', 'csegment', 'ofjpmorgan', 'threemonth', 'analytical', 'based', 'unqualified', 'fairly', 'derived', 'pricewaterhousecoopers', 'ratestaxableequivalent', 'averagebalanceinterestrateannualize', 'noninterestbeare', 'ereflect', 'dollarroll', 'termsach', 'advised', 'debtequity', 'centrally', 'identifie', 'character', 'bureaus', 'isaac', 'differential', 'subtract', 'headcountrelated', 'iasb', 'bbb', 'baa', 'ratiothe', 'ratioan', 'msa', 'msalevel', 'competitors', 'typesaltaalta', 'combinedloantovalue', 'cltv', 'nonowner', 'occupy', 'debttoincome', 'proportion', 'armsthe', 'introductory', 'monthly', 'amortizing', 'triggers', 'primeprime', 'reliable', 'histories', 'subprimesubprime', 'unreliable', 'history', 'borrowerpaid', 'residence', 'nonforfeitable', 'onand', 'specialist', 'specialize', 'trouble', 'auditing', 'congress', 'explicitly', 'metricsinvestment', 'bankingibs', 'syndication', 'followingnet', 'productionrelate', 'previouslysold', 'components', 'aoperate', 'comprises', 'brisk', 'internet', 'builder', 'thrift', 'midto', 'largesized', 'bankowne', 'asoriginated', 'bulk', 'autodescription', 'cardsale', 'cardmember', 'returns', 'privileges', 'merchants', 'travel', 'entertainment', 'businesstobusiness', 'solutions', 'bankingcb', 'segmentsmiddle', 'properties', 'fullservice', 'developer', 'institutionalgrade', 'revenuelending', 'bridge', 'assetbased', 'disbursement', 'multicurrency', 'lockbox', 'currencyrelated', 'logistic', 'tool', 'metricsliability', 'programs', 'servicestreasury', 'managementasset', 'am', 'followinginstitutional', 'analytic', 'budgeting', 'ultrahighnetworth', 'raising', 'specialtywealth', 'languageinteractive', 'nameanthony', 'titlecorporate', 'reportableoperate', 'mapping', 'furtherance', 'maclin', 'comanage', 'recasting', 'louis', 'rauchenberger', 'validity', 'carryover', 'ltip', 'nonpartisanship', 'chamber', 'commerce', 'validly', 'canary', 'wharf', 'england', 'headquarters', 'victoria', 'embankment', 'accommodate', 'norma', 'corio', 'cavanagh', 'miller', 'henderson', 'nevada', 'consequent', 'intellectual', 'sponsorship', 'pe', 'nsion', 'abovereference', 'galveston', 'kccllc', 'counter', 'rfss', 'previouslyreported', 'render', 'xxviii', 'conformed', 'cazenove', 'penny', 'xxvii', 'delawarestate', 'officeregistrant', 'santhony', 'horanname', 'recital', 'estop', 'disregard', 'expressly', 'witness', 'whereof', 'coriotitle', 'onetime', 'sharebased', 'fsp', 'unveste', 'kepp', 'carbon', 'scap', 'stressed', 'asr', 'bsc', 'bsb', 'bsgah', 'substitution', 'deed', 'programme', 'caribbean', 'bscah', 'emtn', 'map', 'warran', 'discharge', 'indice', 'efc', 'emailform', 'jpmchase', 'bancanalyst', 'annum', 'therefor', 'pari', 'passu', 'dissolution', 'wind', 'british', 'pound', 'sterle', 'japanese', 'yen', 'aig', 'gbi', 'knockout', 'equally', 'dual', 'directional', 'ftsetm', 'topix', 'bearish', 'inversely', 'investable', 'rotator', 'longshort', 'gscitm', 'amex', 'ftsexinhua', 'singapore', 'sterling', 'bric', 'barrier', 'habit', 'emailedfm', 'lipp', 'brysam', 'water', 'macs', 'precise', 'emailedform', 'rcc', 'incomefx', 'incomeem', 'uncertainitie', 'commis', 'sion', 'sstephen', 'cutler', 'cutl', 'jpmchasejuly', 'ate', 'heret', 'bearlink', 'etn', 'registe', 'red', 'poll', 'german', 'australian', 'samurai', 'sydney', 'commonwealth', 'australia', 'thirteenth', 'citicorp', 'kredietbank', 'luxembourgeoise', 'best', 'optimal', 'transmit', 'accessible', 'elec', 'tronic', 'shorten', 'incumb', 'ent', 'writing', 'uncertificated', 'indemnified', 'advancement', 'heading', 'mirror', 'ein', 'euronext', 'onefourth', 'jpmpre', 'jpmprf', 'jpmprg', 'stearnss', 'courtapproved', 'journal', 'convenience', 'indentur', 'es', 'punctual', 'di', 'ssolution', 'windingup', 'duplication', 'theretofore', 'setoff', 'thereon', 'sx', 'freeportmcmoran', 'copper', 'semiannual', 'doubt', 'sfas', 'condensed', 'taxesan', 'overwrite', 'bxmsm', 'google', 'qualcomm', 'peabody', 'schlumberger', 'exxon', 'mobil', 'reapprove', 'voted', 'energizer', 'hershey', 'xxvi', 'ci', 'site', 'proctor', 'gamble', 'enjoin', 'deloitte', 'touche', 'delete', 'sentence', 'clause', 'monsanto', 'exbibit', 'semi', 'vectorsgold', 'synergy', 'du', 'pont', 'nemour', 'cocacola', 'hansen', 'agriculture', 'walt', 'disney', 'cre', 'carveout', 'tab', 'stea', 'rnss', 'bearstearns', 'feed', 'elapse', 'resubmit', 'delegate', 'seriously', 'jeopardize', 'viability', 'tenday', 'nding', 'sooner', 'admission', 'disc', 'ab', 'ove', 'lon', 'ger', 'hughe', 'reset', 'procter', 'emailfm', 'reportedmarch', 'verizon', 'to', 'companhia', 'vale', 'rio', 'doce', 'marathon', 'mosaic', 'medtronic', 'scientific', 'garmin', 'hewlettpackard', 'reportedfebruary', 'alcoa', 'lm', 'ericsson', 'glaxosmithkline', 'sifma', 'child', 'premier', 'extremely', 'corning', 'outperformance', 'att', 'ceradyne', 'food', 'lowe', 'oracle', 'ryland', 'intuitive', 'surgical', 'edward', 'son', 'schwab', 'incapital', 'keegan', 'rbc', 'dain', 'rauscher', 'dba', 'baidu', 'sandisk', 'tesoro', 'macys', 'schnitzer', 'ceceeur', 'suntech', 'irma', 'caracciolo', 'cemex', 'pfizer', 'jetblue', 'airway', 'kld', 'socialsm', 'zimmer', 'elan', 'unassociated', 'livestock', 'davis', 'flextronic', 'nutrisystem', 'xxiv', 'eagle', 'outfitter', 'goldcorp', 'controllerprincipal', 'noncontested', 'prospective', 'indemnitee', 'interoil', 'phlx', 'sectorsm', 'bowater', 'amr', 'cameco', 'evergreen', 'champion', 'motorola', 'registranta', 'alaska', 'amgen', 'dendreon', 'slavery', 'apology', 'fiveyear', 'homebuilding', 'russian', 'kuala', 'lumpur', 'vistaprint', 'arch', 'coal', 'astrazeneca', 'ellis', 'countrywide', 'joy', 'flag', 'harrison', 'space', 'utilization', 'car', 'aircraft', 'netjet', 'theregistrant', 'foster', 'wheeler', 'relating', 'lexington', 'lady', 'gentleman', 'regula', 'tion', 'genuineness', 'authenticity', 'duplicate', 'consummate', 'insofar', 'truly', 'imax', 'wci', 'wynn', 'abbott', 'laboratory', 'colgatepalmolive', 'wyeth', 'sand', 'xxii', 'rccs', 'ftse', 'joseph', 'sclafani', 'tm', 'streettracksr', 'isharesr', 'grey', 'wolf', 'mitchell', 'titus', 'ernst', 'young', 'disclaimer', 'satisfactorily', 'silver', 'mrs', 'spring', 'centex', 'kb', 'pulte', 'homebuilde', 'lookback', 'lobbying', 'smallbusiness', 'xix', 'xx', 'berry', 'disposal', 'longlived', 'practical', 'aetna', 'aigcommodity', 'xviii', 'ot', 'misclassification', 'flowsexemption', 'annuity', 'protective', 'depot', 'rambus', 'withheld', 'biggs', 'kessler', 'manoogian', 'poison', 'pill', 'overcommitted', 'memorandum', 'apr', 'secpublisher', 'saturday', 'fixedadjustable', 'stockunit', 'performancerelated', 'han', 'becherer', 'lawrence', 'bossidy', 'involuntarily', 'posttermination', 'dental', 'steven', 'black', 'winter', 'coceo', 'entitlement', 'coulter', 'nonhire', 'adam', 'farrell', 'joan', 'guggenheimer', 'samuel', 'jay', 'mandelbaum', 'mcdavid', 'don', 'wilson', 'jpmi', 'brownco', 'jpmis', 'jpminvest', 'jpminv', 'restricting', 'compete', 'postclose', 'wait', 'hart', 'rodino', 'restrain', 'decree', 'reciprocal', 'postclosing', 'contracting', 'button', 'grantee', 'nontransferable', 'selfemployment', 'noncompetitor', 'profession', 'self', 'selfemploye', 'releasecertification', 'die', 'hire', 'divert', 'supplier', 'wh', 'ose', 'known', 'interfere', 'supervise', 'referral', 'confidentialinformation', 'foresee', 'embarrass', 'preclude', 'truthfully', 'irreparable', 'competent', 'enforce', 'convey', 'hereunder', 'supercede', 'preempt', 'indictment', 'conviction', 'felony', 'embezzlement', 'moral', 'turpitude', 'abide', 'injurious', 'monetarily', 'indicative', 'houston', 'wrongdoing', 'erein', 'smichael', 'europe', 'reportedmay', 'ratably', 'moran', 'martha', 'gallo', 'supplementfirst', 'worldcom', 'kristin', 'lemkau', 'ann', 'borowiec', 'stafford', 'pharmaceutical', 'jack', 'wise', 'deeply', 'manufacturer', 'workforce', 'quinnipiac', 'liberty', 'lemkaujpmorgan', 'jpmp', 'forgoing', 'optionssar', 'survivor', 'vastera', 'morrell', 'rd', 'dina', 'dublon', 'east', 'africa', 'salomon', 'barney', 'style', 'sixteen', 'logo', 'nysejpm', 'nyseone', 'bankone', 'sixthlarg', 'bennack', 'helene', 'kaplan', 'adjournment', 'evelyn', 'ruddy', 'seiu', 'dee', 'missionary', 'oblate', 'immaculate', 'churchrelate', 'overthecounter', 'brotherhood', 'auditrelate', 'exhbit', 'reproduce', 'differencemany', 'controlinclude', 'technological', 'accomplish', 'expensive', 'unforeseen', 'carefully', 'expose', 'interestrate', 'adapt', 'inadequate', 'react', 'nominal', 'reinvest', 'atm', 'customerfacing', 'despite', 'zurich', 'sound', 'subjective', 'incomefully', 'fin', 'insurancerelate', 'defensively', 'problem', 'annualized', 'writedown', 'telecommunication', 'efficiency', 'fuel', 'programming', 'spend', 'freight', 'postage', 'taxadvantage', 'nondeductible', 'continual', 'incomefte', 'benefits', 'oreo', 'thousand', 'nmnot', 'safe', 'deficient', 'fundsoverdraft', 'collectionsrelate', 'array', 'noncredit', 'exclusively', 'memorevenue', 'borrowings', 'recoverie', 'arranger', 'league', 'standingrank', 'standingmarket', 'deteriorate', 'compensate', 'cobrand', 'affinity', 'sport', 'mailing', 'cobrande', 'circulation', 'thirdlarg', 'memonet', 'cardmemberservices', 'processor', 'allocating', 'lag', 'seasoned', 'volumedriven', 'reward', 'nonbankruptcy', 'yieldrelate', 'derecognize', 'img', 'investmentrelate', 'assetsend', 'inforce', 'directassume', 'subadvise', 'nonmanaged', 'unallocated', 'expensefte', 'mergerrelated', 'undivided', 'migration', 'soundness', 'profitability', 'unacceptable', 'improper', 'nonconformance', 'moody', 'direction', 'unavailable', 'remote', 'managementnontrading', 'strive', 'customeroriente', 'little', 'variancecovariance', 'pair', 'span', 'oneday', 'equate', 'deviation', 'predominant', 'break', 'prediction', 'highervolume', 'markedtomarket', 'interval', 'calculated', 'alm', 'mismatch', 'basecase', 'defensive', 'bias', 'measured', 'prudent', 'super', 'historic', 'partsauto', 'louisiana', 'kentucky', 'indiana', 'colorado', 'apartment', 'industrialwarehouse', 'lot', 'hotel', 'uncollected', 'doubtful', 'wellsecure', 'days', 'payoff', 'syndicationrelate', 'economically', 'plain', 'vanilla', 'pattern', 'variability', 'nonderivative', 'clearinghouse', 'qspe', 'shortfall', 'highlyrated', 'historically', 'publiclyrate', 'overcollateralization', 'surety', 'monoline', 'nondefaulte', 'equitytangible', 'howaldtswerkedeutsche', 'werft', 'hdw', 'manufacture', 'nonnuclear', 'submarine', 'instant', 'imaging', 'occasionally', 'triggering', 'aim', 'equityasset', 'double', 'nonqualifye', 'commissioner', 'naic', 'buyback', 'flexible', 'unexpected', 'solvency', 'allot', 'hurdle', 'accompany', 'balancedecember', 'securitiesavailable', 'balancemarch', 'cashflow', 'endorse', 'activation', 'activate', 'pronouncement', 'deconsolidate', 'longduration', 'aicpa', 'nontraditional', 'sop', 'contractholder', 'morbidity', 'reinsurer', 'modifie', 'irlcs', 'bulletin', 'sab', 'elgin', 'leading', 'license', 'brokersinsurance', 'teacher', 'reinsure', 'escrow', 'restructuringrelate', 'aggregation', 'revenuefte', 'subdivision', 'quotation', 'marketrelate', 'finite', 'mo', 'instrumentscash', 'plansb', 'costbenefit', 'apb', 'casebycase', 'predetermine', 'securitys', 'negligible', 'pervasive', 'regulate', 'stockforstock', 'taxfree', 'acquiror', 'illustrative', 'explain', 'chasebank', 'ko', 'column', 'numerical', 'reflective', 'fairvalue', 'mergerrelate', 'riskfree', 'straightline', 'acknowledgement', 'revaluation', 'revalue', 'optimum', 'formulation', 'may', 'registrar', 'authenticate', 'plaza', 'suite', 'abovereferenced', 'edelson', 'rationalize', 'teller', 'instal', 'steady', 'cautious', 'posture', 'unwound', 'presence', 'sony', 'aarp', 'citys', 'cobranded', 'plainenglish', 'commensurate', 'unrestricte', 'publiclytrade', 'investee', 'prospect', 'persistency', 'universal', 'poli', 'cie', 'overfunde', 'prepaid', 'interestcrediting', 'bps', 'transferor', 'extinguishment', 'demonstrably', 'anexsys', 'possibility', 'higherrate', 'gts', 'positioning', 'volumerelated', 'compensating', 'monogram', 'slight', 'equiserve', 'salarie', 'restructuringrelated', 'insource', 'rent', 'renegotiate', 'insourcing', 'advertising', 'expenditure', 'renegotiation', 'usage', 'hour', 'interior', 'upgraded', 'functionality', 'nonbranded', 'fixedincome', 'compensationrelated', 'conversionrelate', 'web', 'memosecuritize', 'mileage', 'unsuccessful', 'purge', 'inactivity', 'superprime', 'imgs', 'boia', 'pcs', 'yearoveryear', 'lifes', 'tell', 'ment', 'optimistic', 'amicable', 'internalize', 'save', 'investmentrelated', 'portfoliosand', 'inhouse', 'publicmarket', 'underperforming', 'routinely', 'cochaire', 'subcommittee', 'linkage', 'divestment', 'assesse', 'alco', 'productsprogram', 'monitoringcontrol', 'comprehensively', 'proactively', 'riskreward', 'prevalent', 'encompass', 'workout', 'creditscore', 'oneyear', 'substandard', 'creditscored', 'roll', 'assetsrelated', 'producttype', 'riskreduction', 'preserve', 'costeffective', 'targeted', 'marginal', 'competitively', 'quantity', 'partyadministere', 'termdebt', 'gamma', 'nonstatistical', 'equallyweighte', 'aged', 'reside', 'repricing', 'apprise', 'internally', 'gradual', 'sudden', 'flattening', 'conversely', 'primebased', 'primebase', 'breakdown', 'suffer', 'defin', 'ition', 'businessowned', 'riskcontrol', 'selfassessment', 'disciplined', 'prioritize', 'fulfillment', 'selfidentify', 'mathematical', 'corporatewide', 'streamlining', 'push', 'enrich', 'root', 'escalate', 'goforward', 'old', 'impractical', 'respec', 'tively', 'automotiveloanslease', 'chargeoffsaverage', 'wellseasoned', 'deliberate', 'increasingly', 'comfortable', 'con', 'sistent', 'spite', 'leasing', 'estaterelate', 'frame', 'burden', 'nonrelationship', 'excessive', 'portfoliolevel', 'modeling', 'allocable', 'segmentation', 'funded', 'stresstest', 'simulate', 'trendbased', 'irrespective', 'dedesignate', 'aoase', 'discontinuance', 'prorata', 'verify', 'fixedpay', 'fixedreceive', 'onemonth', 'adjustable', 'strip', 'paripassu', 'facil', 'itie', 'noncontingent', 'expend', 'accommodation', 'deconsolidation', 'contrary', 'eventspecific', 'majorityowned', 'resold', 'orient', 'derivitive', 'reliably', 'recoverable', 'structuring', 'collectable', 'wear', 'tear', 'reconditioning', 'surrender', 'transferee', 'leasehold', 'repair', 'inter', 'est', 'policyholder', 'investmenttype', 'shortduration', 'dac', 'premiumpaye', 'reinsurance', 'schaumburg', 'aging', 'smallbalance', 'homogeneous', 'predetermined', 'germany', 'amor', 'tize', 'magnitude', 'correctly', 'categorization', 'columbus', 'oklahoma', 'wheelingsteubenville', 'rebalance', 'broadly', 'retiree', 'grandfathere', 'noncontributory', 'contributory', 'veba', 'onepercentagepoint', 'medicare', 'prescription', 'drug', 'modernization', 'subsidy', 'heath', 'authoritative', 'proforma', 'reload', 'restorative', 'wtd', 'designated', 'permissible', 'optionprice', 'grantdate', 'carryforward', 'completely', 'prof', 'onerous', 'comfort', 'varie', 'inspect', 'agreedupon', 'expiry', 'pointintime', 'subjectivity', 'dispose', 'nonperformance', 'lent', 'receivablessubsidiarie', 'continuedparent', 'misstatement', 'examine', 'lo', 'accruable', 'acquirer', 'notably', 'coy', 'jpmsis', 'jpmsi', 'admit', 'aftermarket', 'contravention', 'nasd', 'persuade', 'cold', 'promise', 'oversubscribe', 'resolving', 'bullet', 'lossbased', 'risktransfer', 'moderately', 'liquidityadjuste', 'overallocation', 'interoffice', 'cfo', 'litigationrelate', 'outsourcing', 'ibm', 'voice', 'fourthquarter', 'strongly', 'jury', 'verdict', 'pleased', 'is', 'transformation', 'groundbreake', 'sevenyear', 'fixedcost', 'contractor', 'desktop', 'competency', 'inside', 'exciting', 'ketchum', 'computing', 'utility', 'disparate', 'backend', 'server', 'storage', 'device', 'reliability', 'heavily', 'dramatically', 'elix', 'infusion', 'retrospective', 'augment', 'finalization', 'cable', 'nii', 'challenging', 'smarc', 'shapiro', 'marc', 'disappointed', 'listen', 'dial', 'audio', 'replay', 'daylight', 'fortune', 'boilerplate', 'pretty', 'message', 'swilliam', 'sumitomo', 'stem', 'supplemented', 'presidentand', 'yesterday', 'tragic', 'aftermath', 'diplomatic', 'publiclyheld', 'writeoff', 'privatelyheld', 'figure', 'systemsintegration', 'manhattan', 'fleme', 'fleming', 'heritage', 'feegenerate', 'compound', 'spin', 'proportional', 'digit', 'inconsistency', 'worsening', 'abroad', 'intensify', 'ecommerce', 'nondepository', 'traditionally', 'internetbased', 'crossindustry', 'larger', 'bettercapitalize', 'instability', 'expropriation', 'nationalization', 'confiscation', 'accentuate', 'outsider', 'clerical', 'recordkeeping', 'faulty', 'computer', 'repeat', 'rectify', 'dependence', 'technical', 'flaw', 'tampering', 'manipulation', 'predictable', 'marketsensitive', 'standing', 'timetotime', 'valid', 'devaluation', 'abstaining', 'ccp', 'unaffiliated', 'coinvest', 'alongside', 'companyobligate', 'benefitexpense', 'issueddistribute', 'capitalinvestment', 'knowledgeable', 'marketbased', 'rigorous', 'nonmarketable', 'nontraded', 'earningasset', 'translate', 'inflationary', 'sbic', 'enduser', 'nontradingrelated', 'replicate', 'nonamortize', 'imbed', 'collectible', 'aqr', 'bottomup', 'appropriateness', 'overestimate', 'grid', 'lessen', 'environmental', 'componentbycomponent', 'internaluse', 'ready', 'intrinsicvaluebased', 'fairvaluebased', 'intrinsic', 'fairvaluebase', 'appre', 'ciation', 'depre', 'netb', 'netc', 'commitmentsc', 'euroclearrelated', 'eva', 'grossup', 'consol', 'idate', 'appreciationdepreciation', 'corporateowne', 'euroclear', 'productivity', 'excessshortfall', 'corporatea', 'firstquarter', 'refocus', 'severancerelate', 'sublease', 'furniture', 'fixture', 'clientfocuse', 'societe', 'cooperative', 'marketowned', 'agreementin', 'brussel', 'operator', 'reshape', 'agreementinprinciple', 'changeover', 'afterward', 'knowhow', 'signing', 'land', 'offbalancesheet', 'sourcesb', 'otherthantrading', 'otherthantrade', 'privatization', 'handle', 'handling', 'safekeepe', 'gainslossa', 'noload', 'noninterestearne', 'governmenta', 'display', 'mortgagebackeda', 'costb', 'freely', 'telecommunications', 'receivablespayables', 'standardize', 'tobeannounced', 'whenissue', 'strike', 'writer', 'onbalancesheet', 'otherthantradingab', 'otherthantradinga', 'optionsc', 'tradingd', 'intermediary', 'swiss', 'franc', 'french', 'italian', 'lira', 'unrealize', 'worthless', 'drawdown', 'riskadjusted', 'ccc', 'cyclical', 'noncyclical', 'chargeoffsa', 'provisionprovision', 'chargeoffsb', 'chargeoffsc', 'lossa', 'provisionreversal', 'fromto', 'lossb', 'constructioninprogress', 'depreciationamortization', 'foreigncountryrelate', 'denomination', 'monthend', 'distortion', 'purposesb', 'cf', 'obligationg', 'purposesh', 'commodityindexed', 'comp', 'jpmifca', 'jpmci', 'jpmifc', 'compp', 'renewal', 'redetermine', 'impute', 'thencurrent', 'euromedium', 'issuesa', 'formula', 'unremitted', 'semiannually', 'iihave', 'paying', 'qualifie', 'amountsa', 'ratiosb', 'amountsc', 'goodwillb', 'subsidiariesb', 'critically', 'undercapitalized', 'commingle', 'coli', 'curtailment', 'unrecognize', 'capita', 'taxdeferre', 'stockrelated', 'nonveste', 'dividendyield', 'determinant', 'numerator', 'denominator', 'optionsa', 'awardsd', 'othere', 'mortgaged', 'monie', 'noncancelable', 'apportion', 'taker', 'revenuesa', 'europeb', 'americac', 'operationsd', 'thirdquarter', 'overseas', 'unsafe', 'unsound', 'nonbanking', 'nonaffiliated', 'brokerdealera', 'securitiesrelatedb', 'debenturesc', 'sept', 'mar', 'tape', 'compre', 'hensive', 'increasedecrease', 'deliberation', 'interestearning', 'nonassessable', 'developed', 'euroclearrelate', 'capitala', 'ackmn', 'anticipated', 'redundant', 'beacon', 'reiterate', 'explore', 'cmc', 'rfh', 'compulsorily', 'compulsory', 'publication', 'ofpound', 'fraction', 'wish', 'despatch', 'irg', 'versa', 'us', 'midpoint', 'enquiry', 'anderson', 'afford', 'that', 'costsaving', 'portolio', 'npas', 'sjoseph', 'threefortwo', 'borden', 'jill', 'blumenfeld', 'nysecmb', 'publiclytraded', 'triton', 'cellular', 'nc', 'ncs', 'rowe', 'trowe', 'pricefleme', 'rpfi', 'ebitda', 'logarithmic', 'regression', 'hambrecht', 'quist', 'computerized', 'recordkeepe', 'correction', 'defalcation', 'finn', 'threequarter', 'bacfloatingratepreferredhybridincometermsecuritiesmember', 'bacseries', 'preferredstockmember', 'bacseniormediumtermnotesseriesastepupcallablenotesmember', 'bacincomecapitalobligationnotesmember', 'bacserieseepreferredstockmember', 'bacseriesllpreferredstockmember', 'bacserieslpreferredstockmember', 'bacserieskkpreferredstockmember', 'baca', 'fixedtofloatingratepreferredhybridincometermsecuritiesmember', 'usgaapseriesepreferredstockmember', 'bacserieshhpreferredstockmember', 'bacseriesypreferredstockmember', 'bacseriesccpreferredstockmember', 'bacseriesggpreferredstockmember', 'reportedoctober', 'tryon', 'sharebacnew', 'ebac', 'prenew', 'ybac', 'prynew', 'ccbac', 'prcnew', 'eebac', 'pranew', 'ggbac', 'prbnew', 'hhbac', 'prknew', 'lbac', 'prlnew', 'bml', 'prgnew', 'exchangebank', 'prhnew', 'prjnew', 'bac', 'theretobacpfnew', 'theretobacpgnew', 'exchangeincome', 'corporationmer', 'exchangesenior', 'bnew', 'exchangenovember', 'kkbac', 'prmnew', 'llbac', 'prnnew', 'exchangeindicate', 'disclaim', 'provided', 'xbrlsignaturespursuant', 'rudolf', 'bless', 'officerdate', 'gg', 'hh', 'kk', 'usgaapnoncumulativepreferredstockmember', 'prc', 'pra', 'prb', 'prk', 'prg', 'prh', 'prj', 'bacpf', 'bacpg', 'prm', 'mcguirewood', 'jeffrie', 'reportedseptember', 'sharebac', 'edepositary', 'exchangeof', 'ydepositary', 'ccdepositary', 'eedepositary', 'ggdepositary', 'sharebml', 'ratenoncumulative', 'floating', 'capitalbacpfnew', 'securitiesbacpgnew', 'theretoincome', 'ofmer', 'corporationsenior', 'duebac', 'guaranteeof', 'theretodepositary', 'kkindicate', 'routine', 'simplification', 'bacserieswpreferredstockmember', 'prwnew', 'wdepositary', 'cet', 'corporationexact', 'streetcharlotte', 'wbac', 'exchangefloate', 'theretobac', 'oif', 'denise', 'ramo', 'itt', 'phillip', 'reportedjuly', 'owritten', 'osolicite', 'oprecommencement', 'informationsignaturespursuant', 'herewithexhibit', 'jj', 'corporationss', 'osecuritie', 'mlpf', 'mlpfs', 'mtn', 'internote', 'secregistered', 'bofaml', 'finra', 'unless', 'bacs', 'nameross', 'titledeputy', 'numberirs', 'provisionsowritten', 'actoitem', 'nonvotessharon', 'bies', 'bovender', 'bramble', 'sr', 'pierre', 'weck', 'arnold', 'hudson', 'monica', 'lozano', 'brian', 'moynihan', 'lionel', 'nowell', 'rose', 'woods', 'yost', 'zuber', 'nonbinding', 'against', 'brok', 'plansignature', 'reportedapril', 'allocations', 'includeformatdriven', 'changesthe', 'captions', 'changesinter', 'reattribute', 'refined', 'reclassifications', 'changessignaturespursuant', 'philanthropic', 'timebase', 'americas', 'payforperformance', 'reearn', 'reearne', 'forfeited', 'standardthis', 'cashsettle', 'stocksettle', 'policies', 'alltime', 'favorability', 'contributing', 'notable', 'euromoney', 'magazine', 'catalyst', 'winner', 'empowerment', 'woman', 'reportedjanuary', 'passing', 'terrence', 'laughlin', 'bowdoin', 'exchangeact', 'ghp', 'aab', 'undue', 'numbersisin', 'lows', 'connect', 'clean', 'environmentally', 'supportive', 'volunteer', 'goals', 'attache', 'scientist', 'aeronautic', 'textron', 'cindicated', 'every', 'study', 'statementscertain', 'made', 'these', 'filings', 'reportednovember', 'codification', 'asc', 'nonrefundable', 'catchup', 'preferable', 'aligns', 'insignificant', 'part', 'sch', 'cal', 'lab', 'def', 'blessname', 'blesstitle', 'materials', 'unaccreted', 'redesignate', 'gfq', 'reportedaugust', 'estatesecure', 'strategically', 'characterize', 'realign', 'recurring', 'classifications', 'documentsignaturespursuant', 'governmentinsure', 'officerson', 'directv', 'pepsico', 'resolvability', 'deficiencie', 'imposition', 'retirementeligible', 'receipts', 'tbv', 'simplify', 'straightforward', 'rebuild', 'crisisera', 'darnell', 'resubmitte', 'bgary', 'leitch', 'signatures', 'bdavid', 'bruce', 'thompson', 'cpaul', 'donofrio', 'rename', 'oneforone', 'gifford', 'climate', 'reportproposal', 'upon', 'cbb', 'gwim', 'intersegment', 'subsegment', 'bylaws', 'distributions', 'holliday', 'neil', 'cotty', 'blesss', 'crudolf', 'ag', 'locationdescription', 'amendmentarticle', 'adds', 'clarifies', 'standards', 'revisionsin', 'directorscalling', 'directorsserving', 'liaison', 'directorsin', 'boardin', 'andbee', 'filingo', 'sharessignaturespursuant', 'corporationby', 'morrison', 'foerster', 'therein', 'resubmission', 'resubmitted', 'nonvotescommon', 'tsignature', 'standardized', 'overstatement', 'countercyclical', 'sifi', 'millionspreliminary', 'estimaterevise', 'asreporte', 'capitalnana', 'rationana', 'surcharge', 'reconciliations', 'applicableitem', 'mlco', 'nonpayment', 'twentieth', 'amendeda', 'issuedan', 'mizuho', 'andan', 'mitsubishi', 'ufj', 'toprs', 'icon', 'clarity', 'easy', 'followinglocationdescription', 'postpone', 'reschedule', 'householding', 'postponement', 'ledger', 'disqualification', 'renumber', 'unanimous', 'reissue', 'likewise', 'bringing', 'severable', 'bacform', 'fixedfloating', 'lb', 'andthe', 'abstainbroker', 'nonvotessignature', 'bennett', 'stockthe', 'lauren', 'mogensen', 'mukesh', 'ambani', 'transcription', 'aconsent', 'bconsent', 'scully', 'xa', 'numberdescription', 'acquisitionrelate', 'pressman', 'sharon', 'cj', 'randall', 'shearer', 'nonvotesmukesh', 'virgis', 'colbert', 'powell', 'rossotti', 'grassroot', 'freedom', 'speech', 'craig', 'beazer', 'gbam', 'cottyname', 'cottytitle', 'corporationexhibit', 'contactkevin', 'stitt', 'mcentire', 'reporter', 'contactdan', 'frahm', 'dan', 'frahmbankofamerica', 'combank', 'matterscharlotte', 'deedsinlieu', 'homeownership', 'homes', 'fhainsure', 'commitmentsbank', 'followingapproximately', 'upfront', 'up', 'commitmentsunder', 'unmatched', 'awardwinne', 'industryleade', 'innovative', 'easytouse', 'exclusion', 'negotiation', 'newsroom', 'bankofamerica', 'eighteenth', 'nineteenth', 'fourteenth', 'hit', 'governing', 'teresa', 'brenner', 'unconsolidated', 'remuneration', 'goe', 'securitiesaggregate', 'reportoverall', 'fixedto', 'floate', 'fleet', 'bankamerica', 'bankboston', 'mbna', 'predictgoal', 'settlements', 'unsolicited', 'minitender', 'ipic', 'bidder', 'tendered', 'nocost', 'unconventional', 'promoter', 'obtaining', 'tip', 'govinvestorpubsminitend', 'dissemination', 'govdivisionsmarketregminitenderssia', 'orgwebgroupsindustryipregnoticedocumentsnoticesp', 'orprincipal', 'blank', 'sallie', 'krawcheck', 'joe', 'confidentiality', 'outplacement', 'lump', 'montag', 'biographical', 'annex', 'transferrable', 'postexercise', 'nontax', 'lp', 'hls', 'secondlien', 'countrywideissue', 'asserted', 'trustbased', 'effectuate', 'nongse', 'assetsale', 'nongseexposure', 'aggressively', 'balboa', 'blackrock', 'bie', 'chuck', 'ed', 'okeefe', 'assured', 'govnewseventspressbcreg', 'permission', 'differently', 'eic', 'csu', 'prsu', 'attainment', 'rolling', 'csus', 'prsus', 'antihedgingderivative', 'detrimental', 'foreclosurerelate', 'centralized', 'maine', 'toll', 'luther', 'councel', 'boardman', 'atwill', 'terminable', 'chemical', 'angele', 'northrop', 'grumman', 'haskin', 'blackstone', 'honorable', 'jed', 'rakoff', 'kenneth', 'lewis', 'martin', 'invoke', 'csrsu', 'csrsus', 'moynihanchief', 'pricepresident', 'desoerpresident', 'search', 'fleetboston', 'sink', 'asconverte', 'arrearage', 'bana', 'bnp', 'paribas', 'banas', 'ocala', 'taylor', 'bean', 'whitaker', 'tbw', 'backing', 'reporteddecember', 'desoer', 'thirtysix', 'usg', 'unusually', 'outofpocket', 'chad', 'liam', 'mcgee', 'collin', 'barnet', 'gary', 'countryman', 'rosato', 'nationsbank', 'transmittal', 'midnight', 'admiral', 'prueher', 'tommy', 'jackie', 'ward', 'tillman', 'amy', 'wood', 'brinkley', 'gregory', 'curl', 'temple', 'atthemarket', 'nongovernment', 'offeringsm', 'treasurysecuritie', 'reserved', 'thenoutstanding', 'preemptive', 'apart', 'arrear', 'sinking', 'analogous', 'confer', 'accumulation', 'undeclared', 'thenapplicable', 'fundamental', 'contemporaneously', 'alteration', 'repeal', 'costly', 'unanticipate', 'div', 'lossearning', 'lossincome', 'nineteen', 'thain', 'ken', 'guaranteed', 'weighting', 'indexed', 'noncumulatively', 'keith', 'philanthropy', 'onefortieth', 'onetwelve', 'pri', 'lastly', 'altered', 'hammond', 'ric', 'struther', 'tlg', 'silvestri', 'silvestribankofamerica', 'anchor', 'cornerstone', 'deepen', 'fourthlarg', 'riskmanagement', 'bankofamericacorporation', 'ks', 'mergerlitigation', 'chancery', 'deposition', 'confirmatory', 'fairness', 'reasonableness', 'weekend', 'perception', 'exploratory', 'background', 'reuter', 'merit', 'familiarity', 'employme', 'nt', 'hing', 'lynchs', 'rector', 'ir', 'ml', 'definit', 'threat', 'terrorist', 'liq', 'uidity', 'downsize', 'sub', 'nonconvertible', 'precision', 'impede', 'chl', 'oak', 'lasalle', 'you', 'basl', 'businessesdeposit', 'estateand', 'helm', 'mulliss', 'wicker', 'pllc', 'script', 'comerica', 'toussaint', 'cabrera', 'muriel', 'siebert', 'steresa', 'eugene', 'abn', 'amro', 'nv', 'reopen', 'loop', 'ramirez', 'burton', 'fifteenth', 'thelegality', 'castleoak', 'abnboa', 'midwest', 'amros', 'hartscottrodino', 'partys', 'inaccuracy', 'compl', 'etion', 'embody', 'cer', 'tain', 'characterization', 'omit', 'supplementally', 'guaranteewith', 'xivs', 'covered', 'cg', 'az', 'twentyfive', 'wagner', 'alvaro', 'molina', 'hsbc', 'blaylock', 'ninety', 'guzman', 'disseminate', 'euribor', 'securtie', 'twelfth', 'misuse', 'corporationsponsore', 'nonunited', 'realigned', 'eleventh', 'registry', 'ey', 'chan', 'mdc', 'boehl', 'pwc', 'uhy', 'dorazil', 'perrin', 'mostyn', 'cv', 'attendance', 'chairperson', 'conflicting', 'fidelity', 'serp', 'excise', 'administratively', 'taxqualified', 'restoration', 'frozen', 'actuarially', 'oken', 'researchrelate', 'bas', 'eighth', 'argentina', 'uruguay', 'clientmanaged', 'maryland', 'mbnas', 'bankingrelated', 'omitted', 'corporationbank', 'sarle', 'taxqualifie', 'makeup', 'jacqueline', 'jarvis', 'jarvi', 'civ', 'mcmillan', 'bacap', 'distributor', 'nyag', 'richmond', 'columbiafunds', 'compdffundsscheduleafinal', 'nationsfunds', 'comdocreponyagschedulea', 'feereduction', 'pdfrequesternationsfunds', 'textual', 'memorialize', 'kas', 'renumbere', 'try', 'wrongfully', 'emotional', 'renewable', 'consulting', 'northeast', 'companyprovided', 'secretarial', 'companyrelated', 'ticket', 'sox', 'game', 'entitled', 'hance', 'buckeye', 'road', 'phoenix', 'certificateholder', 'unto', 'overalloted', 'unclear', 'enrico', 'bondi', 'parmalat', 'asheville', 'perpetuate', 'amending', 'bradford', 'warner', 'jones', 'euronote', 'tim', 'arnoult', 'antonio', 'luzi', 'luis', 'moncada', 'luca', 'sala', 'mcquade', 'greg', 'norwood', 'rhode', 'newlydesignated', 'onefifth', 'subscribe', 'thirty', 'illegal', 'desist', 'finanziera', 'spa', 'berger', 'beneficially', 'perfect', 'dissenter', 'americafleetboston', 'ofamerica', 'formaadjustment', 'americafleetbostoncombined', 'ofamericacorporation', 'sharecontinue', 'executory', 'signage', 'factually', 'supportable', 'ofamericafleetbostoncombine', 'police', 'twelveyear', 'play', 'markettiming', 'picture', 'santander', 'hispanos', 'mexican', 'grupo', 'financiero', 'serfin', 'hispano', 'andprincipal', 'hereinafer', 'noteserie', 'donnelley', 'polke', 'polkingexecutive', 'wake', 'simultaneous', 'eurobond', 'inadvertent', 'precedessor', 'nationscredit', 'grantor', 'windward', 'concourse', 'alpharetta', 'church', 'alpharettageorgia', 'omni', 'jahanbani', 'barnett', 'nbna', 'bbna', 'payahead', 'wacwam', 'chargesextension', 'bdfs', 'sequentially', 'hugh', 'mccoll', 'momentum', 'copmletion', 'lore', 'spricewaterhousecooper', 'attachment', 'carr', 'bob', 'stickler', 'tucker', 'aboveaverage', 'smoothly', 'relationshipbase', 'widely', 'sharply', 'turbulence', 'healthy', 'somewhat', 'technologyrelate', 'asian', 'virtually', 'convenient', 'cominvestor', 'pershare', 'bankcard', 'fulltime', 'oustande', 'nondepositrelate', 'derivativedealer', 'directindirect', 'cds', 'ira', 'incomeyield', 'adjustmentnet', 'regioncountry', 'indonesia', 'pakistan', 'philippine', 'federation', 'colombia', 'venezuela', 'import', 'export', 'preexport', 'cvelocitysharesshortliboretnsdueaugust', 'ofcgmhimember', 'cvelocityshareslongliboretnsdueaugust', 'cvelocityshares', 'xlongcrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'xinversecrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'csixpointeighttwoninepercentfixedratefloatingrateenhancedtrustpreferredsecuritiesofcitigroupcapitalxviiimember', 'csevenpointsixtwofivepercenttrustpreferredsecuritiesofcitigroupcapitaliiimember', 'csevenpointeightsevenfivepercentfixedratefloatingratetrustpreferredsecuritiesofcitigroupcapitalxiiimember', 'cmediumtermseniornotesseriesncallablestepupcouponnotesduemarch', 'cmediumtermseniornotesseriesgcallablefixedratenotesduejanuary', 'cexchangetradednotesbasedontheperformanceofthevelocitysharesdaily', 'xlongusdvs', 'jpyindexduedecember', 'gbpindexduedecember', 'eurindexduedecember', 'chfindexduedecember', 'audindexduedecember', 'xlongjpyvs', 'usdindexduedecember', 'xlonggbpvs', 'xlongeurvs', 'xlongchfvs', 'xlongaudvs', 'cdepositorysharesrepresenting', 'thinterestinashareof', 'noncumulativepreferredstockserieskmember', 'noncumulativepreferredstockseriessmember', 'cctracksexchangetradednotesonthemillerhowardmlpfundamentalindexseriesbduejuly', 'cctracksexchangetradednotesmillerhowardstrategicdividendreinvestordueseptember', 'cctracksexchangetradednotesbasedontheperformanceofthemillerhowardmlpfundamentalindexdueseptember', 'incorporationcommissionfile', 'greenwich', 'yorknyaddress', 'numberinclude', 'codecheck', 'kitem', 'raja', 'akramraja', 'akramcontroller', 'skadden', 'arps', 'slate', 'meagher', 'flom', 'politi', 'ufalse', 'cvelocitysharesshortliboretnmember', 'cvelocityshareslongliboretnmember', 'cvelocityshareslongcrudeoiletnmember', 'cvelocitysharesinversecrudeoiletnmember', 'cvelocitysharesdailylongusdvsjpymember', 'cvelocitysharesdailylongusdvsgbpmember', 'cvelocitysharesdailylongusdvseurmember', 'cvelocitysharesdailylongusdvschfmember', 'cvelocitysharesdailylongusdvsaudmember', 'cvelocitysharesdailylongjpyvsusdmember', 'cvelocitysharesdailylonggbpvsusdmember', 'cvelocitysharesdailylongeurvsusdmember', 'cvelocitysharesdailylongchfvsusdmember', 'cvelocitysharesdailylongaudvsusdmember', 'cseriesspreferredstockmember', 'cseriesnmediumtermseniornotesmember', 'cserieskpreferredstockmember', 'cseriesgmediumtermseniornotesmember', 'cctracksmillerhowardstrategicdividendreinvestormember', 'cctracksmillerhowardmlpfundamentalindexseriesbmember', 'cctracksmillerhowardmlpfundamentalindexmember', 'ccitigroupcapitalxviiimember', 'ccitigroupcapitalxiiimember', 'ccitigroupcapitaliiimember', 'yorkaddress', 'grace', 'dailey', 'alexander', 'wynaendts', 'aegon', 'subsidiaries', 'rohan', 'weerasinghename', 'weerasinghe', 'shearman', 'jimmy', 'yang', 'citi', 'citis', 'akram', 'corbat', 'costello', 'dugan', 'duncan', 'henne', 'peter', 'henry', 'leslie', 'lew', 'renee', 'reiner', 'diana', 'turley', 'deborah', 'ernesto', 'zedillo', 'ponce', 'leon', 'forese', 'mason', 'gerspach', 'icg', 'provisional', 'depiction', 'scorecard', 'exceptional', 'fiveday', 'oneill', 'chf', 'eur', 'gerspachs', 'pimco', 'promotion', 'weerasinghegeneral', 'franz', 'humer', 'santomero', 'reattribution', 'corporateother', 'optimize', 'quartile', 'stakehold', 'jeffrey', 'walsh', 'intelligence', 'covington', 'burling', 'nyaddress', 'ocheck', 'walshjeffrey', 'walshcontroller', 'indexexhibit', \"o'neill\", 'barclay', 'treasuryrelate', 'icgs', 'winddown', 'interpolation', 'imprudent', 'risktake', 'artificial', 'cliff', 'meaningfully', 'doubledigit', 'incentivize', 'calibrate', 'safety', 'bird', 'fellow', 'carver', 'expatriate', 'localization', 'resident', 'isin', 'xs', 'territory', 'guam', 'samoa', 'mariana', 'instrumentality', 'counselcapital', 'epp', 'rodin', 'spero', 'banco', 'stakeholder', 'robust', 'totalshareholder', 'returnpercentile', 'targetperformance', 'shareunit', 'eightfirm', 'outperform', 'aud', 'performanceveste', 'simple', 'tsr', 'manual', 'bmo', 'xl', 'manuel', 'medinamora', 'banamex', 'nacional', 'medinamoras', 'five', 'revenues', 'probation', 'interlock', 'leach', 'investmentsequity', 'opening', 'blair', 'universitys', 'leonard', 'stern', 'osoliciting', 'liborrelate', 'evolution', 'tarpley', 'ccitigroup', 'segmentlevel', 'jpy', 'ch', 'ryan', 'outgoing', 'gbp', 'cofound', 'atrevida', 'soro', 'cofounder', 'promontory', 'credicard', 'noncitibank', 'atlantic', 'ern', 'nonbanke', 'responsive', 'gather', 'sayon', 'scorecardbased', 'commencing', 'preset', 'fouryear', 'sayonpay', 'talk', 'frederic', 'cook', 'measurable', 'purely', 'formulaic', 'mechanical', 'unintende', 'troublesome', 'multipleyear', 'resetting', 'budget', 'corbats', 'inaccurate', 'knowingly', 'performancesensitive', 'percentile', 'unearne', 'averaging', 'bailey', 'smartha', 'graduate', 'summa', 'cum', 'laude', 'princeton', 'electrical', 'engineering', 'stanford', 'rejoin', 'banamexaccival', 'banacci', 'universidad', 'iberoamericana', 'twodollar', 'memoranda', 'adult', 'spouse', 'energyrelate', 'cleary', 'gottlieb', 'steen', 'hamilton', 'vikram', 'pandit', 'haven', 'undelivered', 'executing', 'away', 'steered', 'bolster', 'steer', 'grateful', 'harvard', 'jv', 'mssb', 'implied', 'bonocore', 'afternoon', 'appraiser', 'cgmi', 'cgmis', 'markedly', 'unexpectedly', 'turnbull', 'holdingslocal', 'citicorpnorth', 'defeat', 'ricciardi', 'helfername', 'helfer', 'akbank', 'eric', 'aboaf', 'parson', 'alain', 'belda', 'aboaftreasurer', 'citimortgage', 'discontinued', 'attribution', 'equitycommon', 'wainhouse', 'cdo', 'intentional', 'reckless', 'jerry', 'grundhofer', 'dougla', 'deployment', 'sustainability', 'kepsp', 'citiwide', 'survey', 'incente', 'holdback', 'dollarbase', 'abovemarket', 'unexercised', 'splitadjuste', 'morning', 'tdecs', 'preservation', 'partisanship', 'andrew', 'liveris', 'alberto', 'verme', 'sharpen', 'undergoe', 'citifinancial', 'tirelessly', 'spearhead', 'accomplishment', 'visavi', 'unaffected', 'operative', 'regist', 'ration', 'ninth', 'harold', 'worsen', 'main', 'dedicate', 'worthy', 'training', 'accountable', 'notary', 'nowrevoke', 'safeguard', 'dalla', 'precaution', 'qualitycontrol', 'kelly', 'cspp', 'slm', 'subprimerelate', 'socalled', 'supersenior', 'injured', 'crittenden', 'arthur', 'tildesley', 'losssharing', 'cse', 'ratified', 'reformatte', 'armstrong', 'anne', 'mulcahy', 'deutch', 'noncommon', 'worthiness', 'disallow', 'taxpayer', 'volk', 'ne', 'ned', 'nikko', 'cordial', 'chang', 'mitsui', 'xchange', 'japaneseliste', 'balan', 'ce', 'citicapital', 'traveler', 'metlife', 'legg', 'matching', 'xxxiii', 'superintendent', 'wolfensohn', 'ripplewood', 'ph', 'knight', 'professor', 'westpac', 'armslength', 'etrup', 'cfocao', 'penn', 'andersen', 'utah', 'prdis', 'ajay', 'banga', 'felner', 'discourage', 'preownership', 'careful', 'onemillionth', 'twice', 'inadvertently', 'inkind', 'satisfie', 'endanger', 'dollarfordollar', 'concurrent', 'commercially', 'antitakeover', 'protocol', 'piggyback', 'registrable', 'enjoining', 'crosspoint', 'parkway', 'getzville', 'docservecitigroup', 'quilter', 'onetimer', 'feb', 'qtd', 'smbc', 'smfg', 'alliance', 'pass', 'publicity', 'standstill', 'policie', 'pte', 'gic', 'wa', 'martinelli', 'externally', 'obscure', 'evident', 'roberto', 'mutuel', 'germanybased', 'qs', 'sir', 'win', 'bischoff', 'winfrie', 'restraint', 'disapprove', 'uncured', 'designee', 'veto', 'noncompete', 'brokersinbranche', 'contributed', 'ceasing', 'route', 'nonresidential', 'successive', 'profitable', 'rubin', 'counselor', 'citigroupform', 'sgd', 'thb', 'prefered', 'helf', 'investoranalyst', 'transcript', 'gwm', 'quartertodate', 'tatement', 'decembe', 'exhi', 'bit', 'klein', 'complie', 'rotation', 'privatkunden', 'kgaa', 'allcash', 'citigroupinc', 'lane', 'multistrategy', 'nonciti', 'bookrunner', 'hkd', 'sek', 'collapse', 'citigrouprelated', 'creditlinke', 'cln', 'protract', 'george', 'lowering', 'dexia', 'banque', 'internationale', 'anonyme', 'druskin', 'citiadvise', 'distinguished', 'schroder', 'reopening', 'dkk', 'unregistere', 'abu', 'dhabi', 'adia', 'stake', 'upper', 'decs', 'collar', 'volumeweighte', 'threeday', 'english', 'charles', 'prince', 'inthemoney', 'primerica', 'sb', 'onmarket', 'dislocation', 'comcitigroupfin', 'wentzel', 'klaus', 'kleinfeld', 'purchasing', 'anita', 'romero', 'shelley', 'dropkin', 'gp', 'xvii', 'broadrange', 'expressbrande', 'machine', 'breakeven', 'assistan', 'cibs', 'xvi', 'turkish', 'zuckert', 'refrain', 'citiflight', 'flight', 'aviation', 'yendenominate', 'equitylinked', 'pacerssm', 'valero', 'elk', 'tenaris', 'indexrdue', 'upturn', 'cpos', 'strategysm', 'sequinssm', 'sanford', 'weill', 'bradesco', 'stockmarket', 'laserssm', 'newmont', 'mining', 'indicatorsmanaged', 'lendingprovide', 'loansprovide', 'educational', 'academic', 'autoprovides', 'franchised', 'indexhistorical', 'indexr', 'petrochina', 'cboe', 'buywrite', 'genworth', 'syndecssm', 'stocksm', 'manageme', 'wit', 'citistreet', 'annuitys', 'belgium', 'poland', 'argentine', 'tpc', 'willumstad', 'dye', 'ths', 'nonsolicitiation', 'bankingmexico', 'bankinglatin', 'suitability', 'relinquish', 'fsa', 'kaden', 'exchang', 'hibit', 'prop', 'erty', 'ltws', 'federated', 'federate', 'subtransfer', 'millionshare', 'crossing', 'streamline', 'summer', 'contemplated', 'hannon', 'ebusiness', 'jurisdictione', 'andrall', 'pearson', 'toronto', 'jane', 'sherburne', 'deryck', 'maughan', 'scaturro', 'thomson', 'bernstein', 'guy', 'whittaker', 'fobaproa', 'shareholding', 'samba', 'anot', 'bnot', 'newlyadopte', 'sear', 'dynegy', 'keycorp', 'warburg', 'orme', 'dominion', 'suntrust', 'utendahl', 'sandler', 'previouslyannounce', 'upheaval', 'intense', 'scrutiny', 'testament', 'dedication', 'contributor', 'objectivity', 'tremendous', 'welcome', 'gsb', 'foothold', 'hispanic', 'shanghai', 'pudong', 'garner', 'topranke', 'financeasia', 'pesification', 'tight', 'citibanking', 'citibanke', 'ceemea', 'gcib', 'fc', 'transactional', 'constrain', 'phrase', 'businessrelated', 'aftertaxa', 'aftertaxb', 'changesc', 'incomed', 'citicard', 'diner', 'club', 'preeminent', 'vs', 'ytd', 'eop', 'citicards', 'dollars', 'coincident', 'pfs', 'uit', 'nav', 'pf', 'qq', 'annuitie', 'amt', 'excl', 'retailprivate', 'equitybalance', 'marketsliquidity', 'bllion', 'nonmoney', 'lever', 'noninsurance', 'businessesin', 'paidin', 'decr', 'cashbasis', 'jena', 'repossessed', 'repossess', 'settlementinprinciple', 'spinniningrelate', 'stephanie', 'mudick', 'cogeneral', 'conjuction', 'westlb', 'cdc', 'ixis', 'lambert', 'scotia', 'bbt', 'stringfellow', 'lyonnais', 'royal', 'scotland', 'exceptionally', 'overcome', 'foremost', 'mind', 'talented', 'trusted', 'mike', 'masin', 'newlyformed', 'companywide', 'edge', 'ftc', 'winstar', 'controllable', 'argentinarelate', 'sizable', 'ssb', 'boost', 'atmonly', 'agencie', 'melvin', 'barrack', 'proration', 'trademark', 'umbrella', 'brooklyn', 'leah', 'christina', 'pretto', 'sheri', 'ptashek', 'randel', 'precipitate', 'dear', 'tap', 'enthusiasm', 'sincerely', 'offense', 'mechanic', 'electronically', 'taxation', 'straddle', 'integrated', 'untrue', 'transport', 'exdistribution', 'compile', 'insurancerelated', 'worker', 'boiler', 'trucking', 'agribusiness', 'ocean', 'inland', 'marine', 'specialty', 'gulf', 'peril', 'fire', 'ally', 'sipc', 'selfinsure', 'carrier', 'field', 'connecticut', 'tighi', 'tollfree', 'correspondence', 'providence', 'ri', 'room', 'incometax', 'nysec', 'privateletter', 'wednesday', 'tradingrelated', 'underscore', 'poise', 'unparalleled', 'rightly', 'tough', 'tightly', 'legislator', 'alarming', 'surface', 'scandal', 'applaud', 'bush', 'salute', 'senator', 'sarbane', 'congressman', 'oxley', 'disturbing', 'revelation', 'unambiguously', 'outpace', 'marufuku', 'eab', 'aggressive', 'regionally', 'citiinsurance', 'egypt', 'depress', 'weatherrelate', 'td', 'catastrophe', 'nonproperty', 'recentlyannounced', 'commerzbank', 'piper', 'jaffray', 'mercury', 'mafco', 'macandrew', 'forbes', 'hunter', 'glenford', 'gerald', 'asbestos', 'resumption', 'peso', 'certainty', 'roughly', 'taihei', 'afore', 'seguro', 'redenomination', 'econsumer', 'gl', 'locationsunmanne', 'kiosk', 'fundsuit', 'marketsresearch', 'da', 'ldc', 'salesrefinance', 'em', 'phibro', 'crosssell', 'turmoil', 'inevitably', 'extraordinarily', 'turbulent', 'immune', 'reap', 'pare', 'intently', 'separatelymanage', 'citidirect', 'crossmarkete', 'overshadow', 'graphic', 'consumerbankinglending', 'bankinglende', 'bankinglending', 'icerc', 'admin', 'minorityowne', 'robinson', 'humphrey', 'citigrouplogo', 'arcadia', 'trupin', 'evacuate', 'backup', 'seamless', 'proud', 'tragedy', 'exemplary', 'marketleade', 'bright', 'highteen', 'buildout', 'interruption', 'ensue', 'want', 'commend', 'hard', 'continuity', 'unspeakable', 'scholarship', 'weakening', 'kraft', 'crossmarketing', 'yearonyear', 'sever', 'funduit', 'premiumsa', 'premiumsb', 'expensesc', 'treaty', 'alternate', 'pbg', 'redwood', 'whittak', 'precisely', 'excite', 'metropolitan', 'smartsafe', 'unimat', 'confia', 'fubon', 'copelco', 'aoltime', 'geneva', 'closelyheld', 'fdicinsure', 'handlowy', 'frontier', 'garante', 'siembra', 'eciti', 'discontinuation', 'derr', 'reuben', 'truck', 'gomez', 'forrester', 'enormous', 'delighted', 'wellaccepted', 'numberone', 'myciti', 'it', 'persontoperson', 'surge', 'recruitment', 'licensing', 'nonproprietary', 'citibankssb', 'toprate', 'accolade', 'aol', 'digest', 'stride', 'wrap', 'highmargin', 'triple', 'penetration', 'internetrelate', 'startup', 'mutal', 'mgr', 'othernet', 'bruxelle', 'sg', 'cowen', 'juris', 'diction', 'greatly', 'solidify', 'guthrie', 'cross', 'hurricane', 'floyd', 'israel', 'bulgaria', 'ast', 'netwrite', 'presention', 'firoz', 'tarapore', 'precedent', 'crossselle', 'welldeserve', 'stateoftheart', 'czar', 'experienced', 'propertycasualty', 'middleoffice', 'integrating', 'danceon', 'museum', 'contemporary', 'headway', 'widerange', 'broaden', 'engine', 'stabletoimprove', 'brazilian', 'excellence', 'eurozone', 'inccrease', 'minorityowned', 'daiwa', 'ibj', 'sanwa', 'tokyomitsubishi', 'seize', 'wellestablishe', 'celebrate', 'apparent', 'horowitz', 'costreduction', 'pioneer', 'fastgrowe', 'cellphone', 'citipro', 'consultative', 'train', 'emurelate', 'firming', 'billon', 'sectorbase', 'expensesd', 'ratioc', 'salespeople', 'revenuesprincipally', 'reed', 'worldclass', 'collaborative', 'powerful', 'coming', 'arena', 'impressive', 'vibrant', 'wellpositione', 'forge', 'pioneering', 'clickcredit', 'citiplaza', 'shopping', 'portal', 'couple', 'vault', 'coordinator', 'ntt', 'docomo', 'nikkossb', 'ucs', 'reclass', 'municipals', 'threeperson', 'skill', 'mt', 'sinai']\n"
     ]
    }
   ],
   "source": [
    "print(list(norm_vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be alot of nonsense words that seem like they could have come from either column names of tables included in the documents, or badly normalized urls. Removing such words from our documents would thus decrease the noise in our data source. Ideally we would alter our normalization process to split such nonsense words up into real words, but this would be a taxing proces. Alternatively we can prescribe a test of some attribute of a word that is designed to flag most of these nonsense words, and if a word violates our test we remove it from the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these nonsense words also appear to be very long in character length, which implies we might test for nonsense words by testing for word length. Lets analyze the distribution of word length and see if we can choose a cut off for word length that captures most of these nonsense words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5wcVZ338c+XhDuBBJjNAwkwQRCJuAJGLiK8EHgUEIXHRUBBAoJ5VlFBUIzK410X1gvgqrgISFBBEPEBQUU2gAG5GUCJXISIQBISMlwSwsWFwG//OGdIpZmeOTOZ6Z6e/r5fr3lN1anbqa6u+nadqq5WRGBmZtaX1ZpdATMzaw0ODDMzK+LAMDOzIg4MMzMr4sAwM7MiDgwzMyvStoEh6QeS/t8gzWtzSc9IGpX7r5d07GDMO8/vN5KmDtb8+rHcr0p6XNKiRi+7J5IekrRPs+vRG0nnS/rqIMxnvKRZkpZJ+tZg1G24kxSStsrdg7Z/VuZ/lKQbB3Oeq2pV3i/NWJ8RGRj5wPJ83tmWSLpJ0r9KemV9I+JfI+IrhfPq9SAVEY9ExHoR8dIg1P2Lkn5SM//9ImLGqs67n/XYHDgJmBwR/6uH4X+VdGilf7e8w9eWLZM0ugH1HZQDdT+XOZQ77DTgcWD9iDhpVWeW6xqSTq4pny9pz1Wd/2Ar3T8Hg6S18nFirx6GnS7p0kbUoxWMyMDI3hURY4AtgFOBTwPnDvZCGnEwbJLNgSciYnGd4bOAPSr9ewD39VB2c0Qs78+CR/Br2h9bAPfEAL5Z28vr9yRwsqQxq1Sz3pfRciLiH8DFwJHV8txi8D6goR/WGmGg228kBwYAEbE0Iq4ADgWmStoOVv5EKmljSVfmTxlPSrpB0mqSfkw6cP4qNzmdLKkzf1I7RtIjwLWVsupGeI2k2yQ9LelySRvmZe0paX61jt1nMZL2BT4LHJqX9+c8/JUmrlyvUyQ9LGmxpAskbZCHdddjqqRHcnPS5+q9NpI2yNN35fmdkue/D3ANsGmux/k9TF4bGLsDp/VQNqsf9X7lNc3lH8jjP9HbevRF0uskXZO37V8lHVIZdr6k70m6Kp8N3SrpNZXhb8/TLJX0fUm/l3SspG2BHwC75tdoSWWR43qan5LT8/o/LWlO9/uxpr7nA1NJB/dn8ntjTUlnSHo0/50hac08/p5KZwqfVmo+/FGdl+Je4GbgxDqvU7+WUSk7Oa/TQkkHSdpf0v359f5sZf47SbpZaT9bKOm7ktaoU5fq/tm9/3X/vSzpqIJtu5GkK/JrfRvwmp6Wlc0A/kXSOpWyd5COkb/J89tWaV9cIuluSe+uLGttSd/K79elkm6UtHYe9nNJi3L5LEmvr1n2xnkdluX31xZ5ulcdV9RLc7ekMyXNy+t7u6TdK8O+KOlSST+R9DQwXdJzkjaqjLOj0rFg9bqvUkSMuD/gIWCfHsofAT6cu88Hvpq7/42086+e/3YH1NO8gE4ggAuAdYG1K2Wj8zjXAwuA7fI4vwB+koftCcyvV1/gi93jVoZfDxybuz8IzAW2BNYDLgN+XFO3H+Z6vRH4b2DbOq/TBcDlwJg87f3AMfXqWTPtFsDLwIaknWpxXua8StlSYI9+1Lv6mk4GniEF0JrAt4HlPW3X2u1ZU75urtPRwGhgB1JTz+TKdE8AO+XhPwV+lodtDDwNvCcPOx54sbItjgJu7KEe9eb3DuB2YCwgYFtgk5L1Ab4M3AL8E9AB3AR8pbKtlpMCe01g7R7mdxRwI7A98BSwYS6fD+w5kGVUyj5P2m8+BHQBF5LeU68Hngcm5Xm8Cdglvy6dpAA7oVLHALbqY3vuBzwKbFawbX8GXJLH2460T97Y0+udx78fOKLSfxFwRu5enfT+/SywBrAXsAzYJg//Hmk/nQCMAt4CrFl574/Jr9sZwJ9qtvMyVrzPz+yuIzXHlR6OBUdV1wc4AtgovxYnAYuAtSrHlReBg0j75trAr8nHwzzO6cB/9HpsbcQBvNF/1A+MW4DP1b4hSTvK5d1v1t7mVdmIW/ZQVg2MUyvDJwMv5DfSnqxaYMwEPlIZtk1+I3TvhAFMrAy/DTish/Uales0uVL2f4HrKweIuoFRqfeBpB31D5WdtLvseVbsNCX1rr6mnycfaHP/urm+/Q2MQ4Ebasr+E/hCZbpzKsP2B+7L3UeSmtS6h4l0gOorMOrNby/SQWkXYLU+XtuV1gf4G7B/pf8dwEOVbfUC+eBQZ36v1JV0ED0td1cDo1/LyGXPA6Ny/5i8HXeujHM7cFCdOp0A/LLS32tgAK8lfTB5a1/blvT+fhF4XWXY12u3V820pwC/y93rA88BO+T+3UkH4NUq419E2l9Xy6/DG3vbpnmasXk9N6isZ/V9vh7wEikQO+lHYPSwrKe665TrOauHfaN7vx2V12+n3uo/4pukakwgtePW+gbp08PvJD0oaXrBvOb1Y/jDpE8oGxfVsneb5vlV5z0aGF8pq97V9BzpTVhr41yn2nlN6Eddupul9gBuyGU3Vspui4j/7ke9q6/ZptX+iHiW9Mm9v7YAds7NCEty09HhQPVCfr3Xq7YOQTrA9qXH+UXEtcB3SZ9GF0s6W9L6hevR0+u3aaW/K1JbfInPAx+WNL6mfCDLeCJW3OzxfP7/WGX48+T1l/RapabfRblZ5OsU7hNKzZeXA6dERPeNBr1t2w7S+6t2P+zNj4G3SdoUOBj4W0TcmYdtCsyLiJdr5jchr8NapMCtrfcoSadK+lte54fyoOp6V99jz5COUdXXvYikT0q6Nzd9LQE2qLec7HJgsqRJwP8GlkbEbb0to20CQ9KbSRv3VXe1RMSyiDgpIrYE3g2cKGnv7sF1ZlmvvNtmle7NSZ92HgeeBV5pJ1W6sNbRj/k+StpRqvNezso7aYnHc51q57WgH/PoDozdWREYN1TKZlXGLal3dd0XUnkNc9vyRvTfPOD3ETG28rdeRHy4YNqFwMRKHVTtp+9t9SoR8Z2IeBPprPO1wKcKJ+3p9Xt0IHWJiPtITYK114UGbRl1nEW6MWLriFif1LyjviZSurvxQuC6iDi7Mqi3bdtFen/V7od1RcTDpPfvEcAHWPli96PAZqrcacmK/eVx4B/0fI3k/aQz7n1IB/DO7tWqjFN9n69HatJ9lHSsgMrxgpU/6LwiX684GTgEGBcRY0lNwtXlrLT9cvhfUlnfH/c076oRHxiS1pd0AKmp5CcRMaeHcQ6QtFU+ICwlnRJ2f5J4jNTu3l9HSJqcD3RfBi7Nn8TuB9aS9M58cekUUttlt8eAzpo3ZtVFwCckTcpvrq8DF0c/70TKdbkE+JqkMflC24nAT3qfciWzSE1PewB/yGVzgEnA21g5MPpb70uBAyS9NV8Y/TJ9v19HKd0i2f23BnAl8FqlC+ir5783K1207stVwBuULuSOBo5j5R32MWCi6ly4rZWXu3Pe7s+SDjIv9zFZt4uAUyR1SNqYdJbQn21V60uktv+xQ7iMWmNI14SekfQ6oCS0Ab5GapI8vqa87rbN7+/LgC9KWkfSZNKNBH2ZAXwU2I10/anbraSzxZPzcvYE3kVqTnoZOA/4tqRN81nFrko3DIwhXUd8gnTg/3oPy9y/8j7/CnBLRMyLiC5SIB2R5/lB6l+4H0MKyC5gtKTPk5rV+nIBqWnr3bR5YPxK0jLSp5DPkS6aHl1n3K2B/yJdZL0Z+H5EXJeH/RtpJ1oi6ZP9WP6PSe2Ti0inqx+HdNcW8BHgHNKb4VlWbub4ef7/hKQ7epjveXnes4C/kw46H+tHvao+lpf/IOnM68I8/yIRcT/pDbooIpbkspdJ103WJ100HVC9I+Ju0gH6QtIn/afouzloOqkJpPvv2ohYBrwdOIz0qW0RKy7c9rV+jwPvBf6dtMNPBmaTDgCQ7ua6G1gk6fG+5kd6TX6Y1+XhPM9vFEwH8NW87LtIoXxHLhuQiPg7aXusO1TL6MEnSZ+4l5Feh4sLp3sf6brPU1pxp9ThBdv2o6TmsEWkffFHBcv6BekT/syIWNhdGBEvkAJiP9IZxfeBI/PZWve6zQH+SGpSOo10fL2AtK0XAPeQrqPWupB03eVJ0o0BR1SGfYh0FvoE6SaCm141dXI18FvSB9KHSftXX83mRMQfSB9a7shnWL3qvhPIzPqQz/rmA4dXPlCYtTRJ1wIXRsQ5fY07ks8wzFaZpHdIGpubF7rb3Hv6lGjWcvK13R0pPNtzYJj1blfS3S+Pk5okDoqI53ufxGz4kzSD1BR/Qm7e63saN0mZmVkJn2GYmVmREfMAsaqNN944Ojs7m10NM7OWcvvttz8eER31ho/IwOjs7GT27NnNroaZWUuR1OuttW6SMjOzIg4MMzMr4sAwM7MiDgwzMyviwDAzsyIODDMzK+LAMDOzIg4MMzMr4sAwM7MiDowh1Dn9qmZXwcxs0DgwzMysiAPDzMyKODAGSef0q9wEZWYj2pAFhqTzJC2W9JdK2YaSrpH0QP4/LpdL0nckzZV0l6QdK9NMzeM/IGnqUNXXzMx6N5RnGOcD+9aUTQdmRsTWwMzcD7AfsHX+mwacBSlggC8AOwM7AV/oDhkzM2usIQuMiJgFPFlTfCAwI3fPAA6qlF8QyS3AWEmbAO8AromIJyPiKeAaXh1CZmbWAI2+hjE+Ihbm7kXA+Nw9AZhXGW9+LqtX/iqSpkmaLWl2V1fX4NbazMyad9E7IgKIQZzf2RExJSKmdHTU/YVBMzMboEYHxmO5qYn8f3EuXwBsVhlvYi6rV25mZg3W6MC4Aui+02kqcHml/Mh8t9QuwNLcdHU18HZJ4/LF7rfnsmHNt9ia2Ug0eqhmLOkiYE9gY0nzSXc7nQpcIukY4GHgkDz6r4H9gbnAc8DRABHxpKSvAH/M4305ImovpJuZWQMMWWBExPvqDNq7h3EDOK7OfM4DzhvEqpmZ2QD4m95mZlbEgWFmZkUcGGZmVsSBYWZmRRwYZmZWxIFhZmZFHBhmZlbEgWFmZkUcGGZmVsSBYWZmRRwYZmZWxIFhZmZFHBhmZlbEgWFmZkUcGA3iH1Qys1bnwDAzsyIODDMzK+LAMDOzIg4MMzMr4sAwM7MiDgwzMyviwDAzsyIODDMzK+LAMDOzIg4MMzMr4sAwM7MiDgwzMyviwDAzsyIODDMzK+LAMDOzIg6MJvBvY5hZK2pKYEj6hKS7Jf1F0kWS1pI0SdKtkuZKuljSGnncNXP/3Dy8sxl1NjNrdw0PDEkTgI8DUyJiO2AUcBhwGnB6RGwFPAUckyc5Bngql5+exzMzswZrVpPUaGBtSaOBdYCFwF7ApXn4DOCg3H1g7icP31uSGlhXMzOjCYEREQuAbwKPkIJiKXA7sCQilufR5gMTcvcEYF6ednkef6Pa+UqaJmm2pNldXV1DuxJmZm2oGU1S40hnDZOATYF1gX1Xdb4RcXZETImIKR0dHas6OzMzq9GMJql9gL9HRFdEvAhcBuwGjM1NVAATgQW5ewGwGUAevgHwRGOrbGZmzQiMR4BdJK2Tr0XsDdwDXAccnMeZClyeu6/I/eTh10ZENLC+dXVOv8q3yJpZ22jGNYxbSRev7wDm5DqcDXwaOFHSXNI1inPzJOcCG+XyE4Hpja6zmZmlu5UaLiK+AHyhpvhBYKcexv0H8N5G1MvMzOrzN73NzKyIA8PMzIo4MMzMrIgDw8zMijgwzMysiAPDzMyKODDMzKyIA8PMzIo4MMzMrIgDw8zMijgwzMysiAPDzMyKODDMzKyIA8PMzIo4MPrJP5pkZu3KgWFmZkUcGGZmVsSBYWZmRRwYZmZWxIFhZmZFHBhmZlbEgWFmZkUcGGZmVsSBYWZmRRwYTeZvjZtZq3BgmJlZEQeGmZkVcWCYmVkRB4aZmRVxYJiZWZF+B4akcZL+eSgqY2Zmw1dRYEi6XtL6kjYE7gB+KOnbA12opLGSLpV0n6R7Je0qaUNJ10h6IP8fl8eVpO9ImivpLkk7DnS5ZmY2cKVnGBtExNPAe4ALImJnYJ9VWO6ZwG8j4nXAG4F7genAzIjYGpiZ+wH2A7bOf9OAs1ZhuWZmNkClgTFa0ibAIcCVq7JASRsAewDnAkTECxGxBDgQmJFHmwEclLsPJIVURMQtwNhcFzMza6DSwPgScDUwNyL+KGlL4IEBLnMS0AX8SNKdks6RtC4wPiIW5nEWAeNz9wRgXmX6+blsJZKmSZotaXZXV9cAq2ZmZvWUBsbCiPjniPgIQEQ8CAz0GsZoYEfgrIjYAXiWFc1P5PkHEP2ZaUScHRFTImJKR0fHAKtmZmb1lAbGfxSWlZgPzI+IW3P/paQAeay7qSn/X5yHLwA2q0w/MZeZmVkDje5toKRdgbcAHZJOrAxaHxg1kAVGxCJJ8yRtExF/BfYG7sl/U4FT8//L8yRXAB+V9DNgZ2BppenKzMwapNfAANYA1svjjamUPw0cvArL/RjwU0lrAA8CR5POdi6RdAzwMOkCO8Cvgf2BucBzeVwzM2uwXgMjIn4P/F7S+RHx8GAtNCL+BEzpYdDePYwbwHGDtWwzMxuYvs4wuq0p6WygszpNROw1FJUyM7PhpzQwfg78ADgHeGnoqmNmZsNVaWAsjwh/w9rMrI2V3lb7K0kfkbRJfubThvm5UmZm1iZKzzCm5v+fqpQFsOXgVsfMzIarosCIiElDXREzMxveigJD0pE9lUfEBYNbHTMzG65Km6TeXOlei/R9iTsAB4aZWZsobZL6WLVf0ljgZ0NSIzMzG5YG+pvez5IeU25mZm2i9BrGr1jxuPFRwLbAJUNVKTMzG35Kr2F8s9K9HHg4IuYPQX3MzGyYKmqSyg8hvI/0xNpxwAtDWSkzMxt+igJD0iHAbcB7SY8dv1XSqjze3MzMWkxpk9TngDdHxGIASR3Af5F+Lc/MzNpA6V1Sq3WHRfZEP6Y1M7MRoPQM47eSrgYuyv2Hkn4Jz8zM2kRfv+m9FTA+Ij4l6T3AW/Ogm4GfDnXlhovO6VcB8NCp72xyTczMmqevM4wzgM8ARMRlwGUAkt6Qh71rSGtnZmbDRl/XIcZHxJzawlzWOSQ1MjOzYamvwBjby7C1B7MiZmY2vPUVGLMlfai2UNKxwO1DUyUzMxuO+rqGcQLwS0mHsyIgpgBrAP9nKCvWjnxx3cyGs14DIyIeA94i6W3Adrn4qoi4dshrZmZmw0rp72FcB1w3xHUxM7NhzN/WNjOzIg4MMzMr4sAwM7MiDgwzMyviwDAzsyIODDMzK9K0wJA0StKdkq7M/ZMk3SpprqSLJa2Ry9fM/XPz8M5m1dnMrJ018wzjeODeSv9pwOkRsRXwFHBMLj8GeCqXn57HMzOzBmtKYEiaCLwTOCf3C9iLFT/5OgM4KHcfmPvJw/fO45uZWQM16wzjDOBk4OXcvxGwJCKW5/75wITcPQGYB5CHL83jr0TSNEmzJc3u6uoayrqbmbWlhgeGpAOAxRExqE+7jYizI2JKREzp6OgYzFmbmRnlv+k9mHYD3i1pf2AtYH3gTGCspNH5LGIisCCPvwDYDJgvaTSwAfBE46ttZtbeGn6GERGfiYiJEdEJHAZcGxGHkx5ueHAebSpwee6+IveTh18bEdHAKpuZGcPrexifBk6UNJd0jeLcXH4usFEuPxGY3qT6mZm1tWY0Sb0iIq4Hrs/dDwI79TDOP4D3NrRiZmb2KsPpDMPMzIYxB8Yw1Tn9qld+stXMbDhwYJiZWREHhpmZFXFgmJlZEQeGmZkVcWCYmVkRB4aZmRVxYJiZWREHhpmZFXFgmJlZEQeGmZkVcWCYmVkRB4aZmRVxYJiZWREHhpmZFXFgmJlZEQeGmZkVcWCYmVkRB4aZmRVxYJiZWREHhpmZFXFgmJlZEQeGmZkVcWAMc53Tr2p2FczMAAeGmZkVcmCYmVkRB4aZmRVxYJiZWREHhpmZFXFgmJlZkYYHhqTNJF0n6R5Jd0s6PpdvKOkaSQ/k/+NyuSR9R9JcSXdJ2rHRdTYzs+acYSwHToqIycAuwHGSJgPTgZkRsTUwM/cD7Adsnf+mAWc1vspmZtbwwIiIhRFxR+5eBtwLTAAOBGbk0WYAB+XuA4ELIrkFGCtpkwZX28ys7TX1GoakTmAH4FZgfEQszIMWAeNz9wRgXmWy+bmsdl7TJM2WNLurq2vI6mxm1q6aFhiS1gN+AZwQEU9Xh0VEANGf+UXE2RExJSKmdHR0DGJNzcwMmhQYklYnhcVPI+KyXPxYd1NT/r84ly8ANqtMPjGXmZlZAzXjLikB5wL3RsS3K4OuAKbm7qnA5ZXyI/PdUrsASytNV2Zm1iCjm7DM3YAPAHMk/SmXfRY4FbhE0jHAw8Ahedivgf2BucBzwNGNra6ZmUETAiMibgRUZ/DePYwfwHFDWikzM+uTv+ltZmZFHBhmZlbEgWFmZkUcGHV0Tr9q2P086nCrj5m1FweGmZkVcWCYmVkRB0aLcvOUmTWaA8PMzIo4MMzMrIgDw8zMijgwzMysiAPDzMyKODDMzKyIA8PMzIo4MMzMrIgDYwTwl/jMrBEcGGZmVsSBYWZmRRwYZmZWxIFhZmZFHBgjjC+Am9lQcWCYmVkRB8YI5rMNMxtMDgwzMyviwDAzsyIOjBGuc/pVbpoys0HhwOiBD7BmZq/mwDAzsyIOjDblpioz6y8HhpmZFXFgtBGfVZjZqmiZwJC0r6S/SporaXqz69NO6gVNSQANZkg57MyaqyUCQ9Io4HvAfsBk4H2SJje3ViNH9aBee4CvPUiXhEdfIVFvWLsHQqusv89U21dLBAawEzA3Ih6MiBeAnwEHNrlO1g/9DYna0OopuPrq7qs+PQVcSXd/5l1veH8M9ODsg7oNNkVEs+vQJ0kHA/tGxLG5/wPAzhHx0co404BpuXcb4K/9XMzGwOODUN3haiSv30heN/D6tbpWWr8tIqKj3sDRjazJUIqIs4GzBzq9pNkRMWUQqzSsjOT1G8nrBl6/VjeS1q9VmqQWAJtV+ifmMjMza5BWCYw/AltLmiRpDeAw4Iom18nMrK20RJNURCyX9FHgamAUcF5E3D3Iixlwc1aLGMnrN5LXDbx+rW7ErF9LXPQ2M7Pma5UmKTMzazIHhpmZFWn7wBhpjxyRtJmk6yTdI+luScfn8g0lXSPpgfx/XLPruiokjZJ0p6Qrc/8kSbfm7XhxvjmiJUkaK+lSSfdJulfSriNp+0n6RH5v/kXSRZLWauXtJ+k8SYsl/aVS1uP2UvKdvJ53SdqxeTXvv7YOjBH6yJHlwEkRMRnYBTgur9N0YGZEbA3MzP2t7Hjg3kr/acDpEbEV8BRwTFNqNTjOBH4bEa8D3khazxGx/SRNAD4OTImI7Ug3sRxGa2+/84F9a8rqba/9gK3z3zTgrAbVcVC0dWAwAh85EhELI+KO3L2MdLCZQFqvGXm0GcBBzanhqpM0EXgncE7uF7AXcGkepWXXT9IGwB7AuQAR8UJELGEEbT/S3ZlrSxoNrAMspIW3X0TMAp6sKa63vQ4ELojkFmCspE0aU9NV1+6BMQGYV+mfn8tGBEmdwA7ArcD4iFiYBy0CxjepWoPhDOBk4OXcvxGwJCKW5/5W3o6TgC7gR7nJ7RxJ6zJCtl9ELAC+CTxCCoqlwO2MnO3Xrd72auljTrsHxoglaT3gF8AJEfF0dVike6lb8n5qSQcAiyPi9mbXZYiMBnYEzoqIHYBnqWl+avHtN470KXsSsCmwLq9uzhlRWnl71Wr3wBiRjxyRtDopLH4aEZfl4se6T33z/8XNqt8q2g14t6SHSE2Ie5Ha/MfmJg5o7e04H5gfEbfm/ktJATJStt8+wN8joisiXgQuI23TkbL9utXbXi19zGn3wBhxjxzJ7fnnAvdGxLcrg64ApubuqcDlja7bYIiIz0TExIjoJG2vayPicOA64OA8Wiuv3yJgnqRtctHewD2MkO1HaoraRdI6+b3avX4jYvtV1NteVwBH5ruldgGWVpquhr22/6a3pP1JbeLdjxz5WpOrtEokvRW4AZjDijb+z5KuY1wCbA48DBwSEbUX6lqKpD2BT0bEAZK2JJ1xbAjcCRwREf/dzPoNlKTtSRf01wAeBI4mfbgbEdtP0peAQ0l39N0JHEtqx2/J7SfpImBP0mPMHwO+APx/etheOSS/S2qGew44OiJmN6PeA9H2gWFmZmXavUnKzMwKOTDMzKyIA8PMzIo4MMzMrIgDw8zMijgwrO1IOl3SCZX+qyWdU+n/lqQTV2H+X5T0ydLywSKpU9L7K/1HSfruUC3P2o8Dw9rRH4C3AEhajXT//Osrw98C3FQyo8q3k4eDTuD9fY1kNlAODGtHNwG75u7XA38BlkkaJ2lNYFvgjvxt3G/k322YI+lQSF8YlHSDpCtI31JG0uck3S/pRmCbVy+yPklHSLpN0p8k/Wd+7D6SnpH0NUl/lnSLpPG5/DW5f46kr0p6Js/qVGD3PJ9P5LJNJf02/y7Dvw/4FTPDgWFtKCIeBZZL2px0NnEz6ZvwuwJTgDn5cffvAbYn/SbFPsA3Ko+i3hE4PiJeK+lNpMeUbA/sD7y5tC6StiV963m3iNgeeAk4PA9eF7glIt4IzAI+lMvPBM6MiDeQnj3VbTpwQ0RsHxGn57Lt8/zfABwqqfocI7N+cWBYu7qJFBbdgXFzpf8PeZy3AhdFxEsR8Rjwe1aEwW0R8ffcvTvwy4h4Lj8ZuD/PI9sbeBPwR0l/yv1b5mEvAFfm7ttJTU6Qgu3nufvCPuY/MyKWRsQ/SGdDW/SjbmYrGU7tr2aN1H0d4w2kJql5wEnA08CPCqZ/dpDqIWBGRHymh2Evxopn97zEwPbX6vOYBjoPM8BnGNa+bgIOAJ7MZxBPAmNJn967L3jfQGrGGSWpg/RLeLf1MK9ZwEGS1pY0BnhXP+oxEzhY0j/BK78F3ddZwC3Av+Tuwyrly4Ax/Vi2Wb84MKxdzSHdHXVLTdnSiHg89/8SuAv4M3AtcHJ+/PhK8k/iXpzH+w3psfn1nCJpfvdfRNwDnAL8TtJdwDVAXz/ZeQJwYh5/K9Kv1pHr+lK+SP6JulObDZCfVmvWYiStAzwfESHpMOB9EdHSv0VvrcHtmXiDbkMAAAA5SURBVGat503Ad/NvKywBPtjk+lib8BmGmZkV8TUMMzMr4sAwM7MiDgwzMyviwDAzsyIODDMzK/I/L0X+Fgb/EGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_lens = list(map(len, norm_vocab.keys()))\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(word_lens, bins=200)\n",
    "ax.set_title('Distribution of Word Lengths for Normalized Vocabulary')\n",
    "ax.set_xlabel('Word Length')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are very few words with character lengths over 20 characters. This implies that if we choose our cut off to be 20 characters or more, we should not be removing too many words that actually contribute to valuable information when applying our cut off test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wfcnoncumulativeperpetualclassapreferredstockseriesnmember', 'wfcfixedtofloatingrate', 'noncumulativeperpetualclassapfdstockseriesqmember', 'wfcguaranteeofmediumtermnotesseriesadueoctober', 'ofwellsfargofinancellcmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesymember', 'noncumulativeperpetualconvertibleclassapreferredstockserieslmember', 'usgaapcommonstockmember', 'noncumulativeperpetualclassapfdstockseriesrmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesomember', 'wfcnoncumulativeperpetualclassapreferredstockseriestmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesvmember', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesofwachoviacapitaltrustiiimember', 'wfcnoncumulativeperpetualclassapreferredstockserieswmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesxmember', 'wfcnoncumulativeperpetualclassapreferredstockseriespmember', 'commissionwashington', 'employeridentification', 'iiiwbtpnyseguarantee', 'documentsignaturepursuant', 'wfccommonstockparvalue', 'noncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'wfcdepositaryshareseachrepresenting', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesnmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesomember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriespmember', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesqmember', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesrmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriestmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesvmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockserieswmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesxmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesymember', 'wfcguaranteeofmediumtermnotesseriesdueoctober', 'wfcnoncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesmember', 'wfcguaranteeofmediumtermnotesseriesdueoctoberofwellsfargofinancellcmember', 'herewithsignaturepursuant', 'comaboutcorporategovernance', 'multiplepointofentry', 'electronictransmission', 'jurisdictioncommission', 'incorporationnumberidentification', 'archerdanielsmidland', 'accumulateddistributionsper', 'trustpreferredsecuritie', 'stockholderrequested', 'retentionperformance', 'comaboutcorporatecorporategovernance', 'payforsuperiorperformance', 'pricewaterhousecooper', 'jpmdepositarysharesonefourhundredthinterestinashareof', 'noncumulativepreferredstockseriesymember', 'jpmguaranteeofcushing', 'ofjpmorganchasefinancialcompanyllcmember', 'noncumulativepreferredstockseriespmember', 'noncumulativepreferredstockseriesaamember', 'noncumulativepreferredstockseriesddmember', 'jpmalerianmlpindexetnsduemay', 'noncumulativepreferredstockserieseemember', 'noncumulativepreferredstockseriesbbmember', 'jpmguaranteeofcallablesteupfixedratenotesdueapril', 'organizationcommission', 'httpsjpmorganchaseco', 'comfinancialinformationsecfiling', 'noncumulativepreferredstockserieswmember', 'govsupervisionregdfastresstests', 'incorporationcommission', 'officerscompensatory', 'nameforagainstabstainbroker', 'compensationforagainstabstainbroker', 'foragainstabstainbroker', 'reportforagainstabstainbroker', 'accessforagainstabstainbroker', 'votingforagainstabstainbroker', 'positioningprincipal', 'clientcustomerstakeholder', 'directordatedoctober', 'charterdelawarestate', 'bylawsforagainstabstainbroker', 'chairmanforagainstabstainbroker', 'serviceforagainstabstainbroker', 'genocideforagainstabstainbroker', 'comcorporateinvestorrelationsinvestorrelations', 'secretarydatedjanuary', 'directordatedjanuary', 'secretarydatedoctober', 'compensationonetwothreeabstainbroker', 'amendmentforagainstabstainbroker', 'equityforagainstabstainbroker', 'countedforagainstabstainbroker', 'meetingsforagainstabstainbroker', 'govregulationsreformresplansindex', 'govbankinforegresolutionplans', 'statementnameforagainstabstainbroker', 'chairforagainstabstainbroker', 'abstentionsforagainstabstainbroker', 'valueforagainstabstainbroker', 'lawforagainstabstainbroker', 'reputationforagainstabstainbroker', 'expendituresforagainstabstainbroker', 'againstforagainstabstainbroker', 'executivesforagainstabstainbroker', 'secretarydateddecember', 'foragainstabstainbrok', 'lobbyingforagainstabstainbroker', 'provisionsforagainstabstainbroker', 'onevoteforagainstabstainbroker', 'consentforagainstabstainbroker', 'ceoforagainstabstainbroker', 'ageforagainstabstainbroker', 'violationsforagainstabstainbroker', 'namesforagainstabstainbroker', 'govnewseventspressbcregbcreg', 'ofincorporationcommission', 'competitorsuninterrupted', 'officerdateddecember', 'nonpartisanshipforagainstabstainbroker', 'comjpmorganchaseannual', 'introductionjpmorgan', 'ratiosreportedresult', 'custodybrokerageadministrationdeposits', 'marketperformanceother', 'emeaasiapacificlatin', 'securitiessecurities', 'arrangementsjpmorgan', 'securitizationrelated', 'correspondentoriginate', 'moodysspfitchjpmorgan', 'noninvestmentgradetotaltotal', 'accruingloansyeartodate', 'chargeoffsrecoveriescredit', 'derivativereceivablesas', 'creditexposuredinvestment', 'gradenoncriticizedcriticize', 'materialsconstruction', 'millionsloanslendingrelate', 'commitmentsderivative', 'loansaderivativeslendingrelatedcommitmentstotal', 'purchasedbprotection', 'billionslendingatradingbotherctotallocaldbrazil', 'portfoliodiversification', 'earningsatriskinterest', 'impairmentmanagement', 'disruptiontechnology', 'counterpartiesadequacy', 'liabilitiesoccurrence', 'presentationjpmorgan', 'developmentsincrease', 'realizedunrealizedgainslosse', 'unrealizedgainslosse', 'millionspurchasesfsalesissuancessettlementsasset', 'millionspurchasesfsalesissuancessettlementsliabilitiesa', 'millionsliabilitiesa', 'billionscarryingvalueestimatedfair', 'valueappreciationdepreciation', 'carryingvalueestimatedfair', 'valueappreciationdepreciationfinancial', 'depreciationappreciation', 'billionscarryingvalueaestimatedfair', 'carryingvalueaestimatedfair', 'millionsprincipaltransactionsotherincometotal', 'principaltransactionsotherincometotal', 'millionscontractualprincipaloutstande', 'valueoverundercontractualprincipal', 'contractualprincipaloutstande', 'nonprincipalprotected', 'nonprincipalprotecte', 'millionsderivativeshedge', 'hedgeineffectivenessd', 'receivablespayablesa', 'valueavailableforsale', 'governmentguaranteed', 'lossesavailableforsale', 'otherthantemporarily', 'yearsctotalavailableforsale', 'heldforinvestmentfor', 'millionswholesaleconsumer', 'financialinstitution', 'millionswholesaleconsumerexclude', 'wholesaleconsumerexcluding', 'lineofbusinesstransaction', 'trustssecuritization', 'assetsafssecuritiestotal', 'chasesecuritizationrelate', 'securitizationrelate', 'facilitiesaexcessdeficitbmaximum', 'exposurenonconsolidate', 'instrumentsloansotherc', 'millionsprimeesubprimeoption', 'mortgagecommercialand', 'amortizationanetcarrye', 'amortizationnetcarrye', 'comprehensiveincomeloss', 'creditinvestmentgradea', 'indemnificationsindemnification', 'litigationcontingencie', 'regulatorygovernment', 'ratiosinvestmentbankretail', 'financialservicescard', 'autocommercialbankingtreasury', 'managementcorporateprivate', 'pricewaterhousecoopers', 'ratestaxableequivalent', 'averagebalanceinterestrateannualize', 'followinginstitutional', 'releasecertification', 'confidentialinformation', 'managementnontrading', 'overcollateralization', 'howaldtswerkedeutsche', 'restructuringrelated', 'automotiveloanslease', 'wheelingsteubenville', 'receivablessubsidiarie', 'componentbycomponent', 'appreciationdepreciation', 'agreementinprinciple', 'constructioninprogress', 'depreciationamortization', 'foreigncountryrelate', 'bacfloatingratepreferredhybridincometermsecuritiesmember', 'preferredstockmember', 'bacseniormediumtermnotesseriesastepupcallablenotesmember', 'bacincomecapitalobligationnotesmember', 'bacserieseepreferredstockmember', 'bacseriesllpreferredstockmember', 'bacserieslpreferredstockmember', 'bacserieskkpreferredstockmember', 'fixedtofloatingratepreferredhybridincometermsecuritiesmember', 'usgaapseriesepreferredstockmember', 'bacserieshhpreferredstockmember', 'bacseriesypreferredstockmember', 'bacseriesccpreferredstockmember', 'bacseriesggpreferredstockmember', 'xbrlsignaturespursuant', 'usgaapnoncumulativepreferredstockmember', 'bacserieswpreferredstockmember', 'informationsignaturespursuant', 'changessignaturespursuant', 'documentsignaturespursuant', 'sharessignaturespursuant', 'followinglocationdescription', 'followingapproximately', 'govinvestorpubsminitend', 'govdivisionsmarketregminitenderssia', 'orgwebgroupsindustryipregnoticedocumentsnoticesp', 'govnewseventspressbcreg', 'antihedgingderivative', 'silvestribankofamerica', 'bankofamericacorporation', 'compdffundsscheduleafinal', 'comdocreponyagschedulea', 'pdfrequesternationsfunds', 'americafleetbostoncombined', 'ofamericacorporation', 'ofamericafleetbostoncombine', 'spricewaterhousecooper', 'cvelocitysharesshortliboretnsdueaugust', 'cvelocityshareslongliboretnsdueaugust', 'xlongcrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'xinversecrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'csixpointeighttwoninepercentfixedratefloatingrateenhancedtrustpreferredsecuritiesofcitigroupcapitalxviiimember', 'csevenpointsixtwofivepercenttrustpreferredsecuritiesofcitigroupcapitaliiimember', 'csevenpointeightsevenfivepercentfixedratefloatingratetrustpreferredsecuritiesofcitigroupcapitalxiiimember', 'cmediumtermseniornotesseriesncallablestepupcouponnotesduemarch', 'cmediumtermseniornotesseriesgcallablefixedratenotesduejanuary', 'cexchangetradednotesbasedontheperformanceofthevelocitysharesdaily', 'cdepositorysharesrepresenting', 'thinterestinashareof', 'noncumulativepreferredstockserieskmember', 'noncumulativepreferredstockseriessmember', 'cctracksexchangetradednotesonthemillerhowardmlpfundamentalindexseriesbduejuly', 'cctracksexchangetradednotesmillerhowardstrategicdividendreinvestordueseptember', 'cctracksexchangetradednotesbasedontheperformanceofthemillerhowardmlpfundamentalindexdueseptember', 'incorporationcommissionfile', 'cvelocitysharesshortliboretnmember', 'cvelocityshareslongliboretnmember', 'cvelocityshareslongcrudeoiletnmember', 'cvelocitysharesinversecrudeoiletnmember', 'cvelocitysharesdailylongusdvsjpymember', 'cvelocitysharesdailylongusdvsgbpmember', 'cvelocitysharesdailylongusdvseurmember', 'cvelocitysharesdailylongusdvschfmember', 'cvelocitysharesdailylongusdvsaudmember', 'cvelocitysharesdailylongjpyvsusdmember', 'cvelocitysharesdailylonggbpvsusdmember', 'cvelocitysharesdailylongeurvsusdmember', 'cvelocitysharesdailylongchfvsusdmember', 'cvelocitysharesdailylongaudvsusdmember', 'cseriesspreferredstockmember', 'cseriesnmediumtermseniornotesmember', 'cserieskpreferredstockmember', 'cseriesgmediumtermseniornotesmember', 'cctracksmillerhowardstrategicdividendreinvestormember', 'cctracksmillerhowardmlpfundamentalindexseriesbmember', 'cctracksmillerhowardmlpfundamentalindexmember', 'ccitigroupcapitalxviiimember', 'ccitigroupcapitalxiiimember', 'ccitigroupcapitaliiimember', 'performancesensitive', 'settlementinprinciple', 'consumerbankinglending']\n"
     ]
    }
   ],
   "source": [
    "cut_off = 20\n",
    "words_greater_than = [word for word in norm_vocab.keys() if cut_off <= len(word)]\n",
    "print(words_greater_than)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wfcnoncumulativeperpetualclassapreferredstockseriesnmember', 'wfcfixedtofloatingrate', 'noncumulativeperpetualclassapfdstockseriesqmember', 'wfcguaranteeofmediumtermnotesseriesadueoctober', 'ofwellsfargofinancellcmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesymember', 'noncumulativeperpetualconvertibleclassapreferredstockserieslmember', 'usgaapcommonstockmember', 'noncumulativeperpetualclassapfdstockseriesrmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesomember', 'wfcnoncumulativeperpetualclassapreferredstockseriestmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesvmember', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesofwachoviacapitaltrustiiimember', 'wfcnoncumulativeperpetualclassapreferredstockserieswmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesxmember', 'wfcnoncumulativeperpetualclassapreferredstockseriespmember', 'commissionwashington', 'employeridentification', 'iiiwbtpnyseguarantee', 'descriptionlocation', 'documentsignaturepursuant', 'wfccommonstockparvalue', 'noncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'wfcdepositaryshareseachrepresenting', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesnmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesomember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriespmember', 'thinterestinshareof', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesqmember', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesrmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriestmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesvmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockserieswmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesxmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesymember', 'wfcguaranteeofmediumtermnotesseriesdueoctober', 'wfcnoncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesmember', 'wfcguaranteeofmediumtermnotesseriesdueoctoberofwellsfargofinancellcmember', 'herewithsignaturepursuant', 'comaboutcorporategovernance', 'multiplepointofentry', 'singlepointofentry', 'electronictransmission', 'signaturespursuant', 'jurisdictioncommission', 'incorporationnumberidentification', 'archerdanielsmidland', 'accumulateddistributionsper', 'trusteepayingagent', 'preferredsecuritie', 'trustpreferredsecuritie', 'nationalassociation', 'stockholderrequested', 'retentionperformance', 'comaboutcorporatecorporategovernance', 'otherthantemporary', 'statementprospectus', 'payforsuperiorperformance', 'pricewaterhousecooper', 'jpmdepositarysharesonefourhundredthinterestinashareof', 'noncumulativepreferredstockseriesymember', 'jpmguaranteeofcushing', 'mlpindexetnsduejune', 'ofjpmorganchasefinancialcompanyllcmember', 'noncumulativepreferredstockseriespmember', 'noncumulativepreferredstockseriesaamember', 'noncumulativepreferredstockseriesddmember', 'jpmalerianmlpindexetnsduemay', 'noncumulativepreferredstockserieseemember', 'noncumulativepreferredstockseriesbbmember', 'jpmguaranteeofcallablesteupfixedratenotesdueapril', 'organizationcommission', 'exchangedepositary', 'httpsjpmorganchaseco', 'comfinancialinformationsecfiling', 'officerdatedoctober', 'noncumulativepreferredstockserieswmember', 'govsupervisionregdfastresstests', 'incorporationcommission', 'officerscompensatory', 'nameforagainstabstainbroker', 'compensationforagainstabstainbroker', 'foragainstabstainbroker', 'reportforagainstabstainbroker', 'accessforagainstabstainbroker', 'votingforagainstabstainbroker', 'positioningprincipal', 'clientcustomerstakeholder', 'officerdatedjanuary', 'directordatedoctober', 'comjpmorganchasesec', 'charterdelawarestate', 'bylawsforagainstabstainbroker', 'chairmanforagainstabstainbroker', 'serviceforagainstabstainbroker', 'genocideforagainstabstainbroker', 'directordatedapril', 'comcorporateinvestorrelationsinvestorrelations', 'secretarydatedjanuary', 'directordatedjanuary', 'secretarydatedoctober', 'yearsabstainbroker', 'nonsolicitationhire', 'compensationonetwothreeabstainbroker', 'amendmentforagainstabstainbroker', 'equityforagainstabstainbroker', 'countedforagainstabstainbroker', 'meetingsforagainstabstainbroker', 'carpentercorporate', 'govregulationsreformresplansindex', 'govbankinforegresolutionplans', 'govbankinforegccar', 'statementnameforagainstabstainbroker', 'chairforagainstabstainbroker', 'abstentionsforagainstabstainbroker', 'valueforagainstabstainbroker', 'lawforagainstabstainbroker', 'reputationforagainstabstainbroker', 'recapturerecoupment', 'presidentdatedjuly', 'expendituresforagainstabstainbroker', 'againstforagainstabstainbroker', 'executivesforagainstabstainbroker', 'secretarydateddecember', 'secretarydatedjuly', 'presidentdatedjune', 'foragainstabstainbrok', 'lobbyingforagainstabstainbroker', 'provisionsforagainstabstainbroker', 'onevoteforagainstabstainbroker', 'govbankinforegbcreg', 'consentforagainstabstainbroker', 'ceoforagainstabstainbroker', 'ageforagainstabstainbroker', 'violationsforagainstabstainbroker', 'namesforagainstabstainbroker', 'govnewseventspressbcregbcreg', 'ofincorporationcommission', 'competitorsuninterrupted', 'officerdateddecember', 'nonpartisanshipforagainstabstainbroker', 'comjpmorganchaseannual', 'introductionjpmorgan', 'foreclosurerelated', 'governmentsponsored', 'investmentspecific', 'changecompensation', 'ratiosreportedresult', 'managedbasisrevenue', 'chargeoffsrecoverie', 'custodybrokerageadministrationdeposits', 'marketperformanceother', 'emeaasiapacificlatin', 'americacaribbeanin', 'significantclientsb', 'payablesderivative', 'securitiessecurities', 'agreementssecuritie', 'liabilitiesaccount', 'arrangementsjpmorgan', 'commitmentsjpmorgan', 'securitizationrelated', 'totallendingrelate', 'correspondentoriginate', 'activitiesmaintain', 'requirementsachieve', 'interconnectedness', 'crossjurisdictional', 'actionsdividendson', 'activitiesjpmorgan', 'moodysspfitchjpmorgan', 'noninvestmentgradetotaltotal', 'accruingloansyeartodate', 'chargeoffsrecoveriescredit', 'derivativereceivablesas', 'creditexposuredinvestment', 'gradenoncriticizedcriticize', 'performingcriticize', 'materialsconstruction', 'millionsloanslendingrelate', 'commitmentsderivative', 'loansaderivativeslendingrelatedcommitmentstotal', 'additionsreduction', 'millionsprotection', 'purchasedbprotection', 'purchasedprotection', 'derivativesnotional', 'sovereignreference', 'billionslendingatradingbotherctotallocaldbrazil', 'portfoliodiversification', 'earningsatriskinterest', 'impairmentmanagement', 'subsidiariesdamage', 'disruptiontechnology', 'acquisitionsability', 'originationability', 'businessacceptance', 'expensecompetitive', 'counterpartiesadequacy', 'liabilitiesoccurrence', 'presentationjpmorgan', 'developmentsincrease', 'governmentsponsore', 'realizedunrealizedgainslosse', 'unrealizedgainslosse', 'millionspurchasesfsalesissuancessettlementsasset', 'millionspurchasesfsalesissuancessettlementsliabilitiesa', 'gainslossespurchase', 'millionsliabilitiesa', 'collateraldependent', 'billionscarryingvalueestimatedfair', 'valueappreciationdepreciation', 'carryingvalueestimatedfair', 'valueappreciationdepreciationfinancial', 'depreciationappreciation', 'billionscarryingvalueaestimatedfair', 'carryingvalueaestimatedfair', 'instrumentspecific', 'millionsprincipaltransactionsotherincometotal', 'principaltransactionsotherincometotal', 'millionscontractualprincipaloutstande', 'valueoverundercontractualprincipal', 'contractualprincipaloutstande', 'nonprincipalprotected', 'principalprotected', 'nonprincipalprotecte', 'currencydenominate', 'millionsderivativeshedge', 'hedgeineffectivenessd', 'componentsecontract', 'millionsderivative', 'receivablespayablesa', 'soldpurchasedcother', 'noninvestmentgrade', 'securitiessecuritie', 'valueavailableforsale', 'governmentguaranteed', 'lossesavailableforsale', 'otherthantemporarily', 'yearsctotalavailableforsale', 'categoriesoriginate', 'heldforinvestmentfor', 'millionswholesaleconsumer', 'portfoliowholesale', 'financialinstitution', 'higherthanexpected', 'longerthanexpected', 'excludingwashington', 'millionswholesaleconsumerexclude', 'wholesaleconsumerexcluding', 'cardtotalallowance', 'lineofbusinesstransaction', 'referencecardcredit', 'trustssecuritization', 'securitizationsfor', 'assetsafssecuritiestotal', 'chasesecuritizationrelate', 'nonmortgagerelated', 'securitizationrelate', 'activitiesmunicipal', 'facilitiesaexcessdeficitbmaximum', 'exposurenonconsolidate', 'thirdpartysponsored', 'instrumentsloansotherc', 'assetseotherftotal', 'liabilitiesdecember', 'securitizationsthe', 'millionsprimeesubprimeoption', 'mortgagecommercialand', 'notedprimedjpmorgan', 'amortizationanetcarrye', 'amortizationnetcarrye', 'relationshipsother', 'noninterestbearing', 'comprehensiveincomeloss', 'creditinvestmentgradea', 'noninvestmentgradea', 'indemnificationsindemnification', 'litigationcontingencie', 'regulatorygovernment', 'ratiosinvestmentbankretail', 'financialservicescard', 'autocommercialbankingtreasury', 'managementcorporateprivate', 'itemsctotalnoninter', 'pricewaterhousecoopers', 'ratestaxableequivalent', 'averagebalanceinterestrateannualize', 'combinedloantovalue', 'businesstobusiness', 'institutionalgrade', 'followinginstitutional', 'languageinteractive', 'previouslyreported', 'controllerprincipal', 'performancerelated', 'releasecertification', 'confidentialinformation', 'cardmemberservices', 'managementnontrading', 'variancecovariance', 'industrialwarehouse', 'overcollateralization', 'howaldtswerkedeutsche', 'securitiesavailable', 'restructuringrelate', 'restructuringrelated', 'compensationrelated', 'automotiveloanslease', 'wheelingsteubenville', 'onepercentagepoint', 'receivablessubsidiarie', 'systemsintegration', 'componentbycomponent', 'intrinsicvaluebased', 'appreciationdepreciation', 'agreementinprinciple', 'telecommunications', 'receivablespayables', 'otherthantradingab', 'provisionprovision', 'constructioninprogress', 'depreciationamortization', 'foreigncountryrelate', 'securitiesrelatedb', 'bacfloatingratepreferredhybridincometermsecuritiesmember', 'preferredstockmember', 'bacseniormediumtermnotesseriesastepupcallablenotesmember', 'bacincomecapitalobligationnotesmember', 'bacserieseepreferredstockmember', 'bacseriesllpreferredstockmember', 'bacserieslpreferredstockmember', 'bacserieskkpreferredstockmember', 'fixedtofloatingratepreferredhybridincometermsecuritiesmember', 'usgaapseriesepreferredstockmember', 'bacserieshhpreferredstockmember', 'bacseriesypreferredstockmember', 'bacseriesccpreferredstockmember', 'bacseriesggpreferredstockmember', 'xbrlsignaturespursuant', 'usgaapnoncumulativepreferredstockmember', 'securitiesbacpgnew', 'bacserieswpreferredstockmember', 'informationsignaturespursuant', 'provisionsowritten', 'includeformatdriven', 'changessignaturespursuant', 'documentsignaturespursuant', 'retirementeligible', 'locationdescription', 'sharessignaturespursuant', 'millionspreliminary', 'followinglocationdescription', 'corporationexhibit', 'frahmbankofamerica', 'followingapproximately', 'securitiesaggregate', 'govinvestorpubsminitend', 'govdivisionsmarketregminitenderssia', 'orgwebgroupsindustryipregnoticedocumentsnoticesp', 'govnewseventspressbcreg', 'antihedgingderivative', 'silvestribankofamerica', 'bankofamericacorporation', 'corporationsponsore', 'compdffundsscheduleafinal', 'comdocreponyagschedulea', 'pdfrequesternationsfunds', 'americafleetboston', 'americafleetbostoncombined', 'ofamericacorporation', 'ofamericafleetbostoncombine', 'spricewaterhousecooper', 'cvelocitysharesshortliboretnsdueaugust', 'cvelocityshareslongliboretnsdueaugust', 'xlongcrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'xinversecrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'csixpointeighttwoninepercentfixedratefloatingrateenhancedtrustpreferredsecuritiesofcitigroupcapitalxviiimember', 'csevenpointsixtwofivepercenttrustpreferredsecuritiesofcitigroupcapitaliiimember', 'csevenpointeightsevenfivepercentfixedratefloatingratetrustpreferredsecuritiesofcitigroupcapitalxiiimember', 'cmediumtermseniornotesseriesncallablestepupcouponnotesduemarch', 'cmediumtermseniornotesseriesgcallablefixedratenotesduejanuary', 'cexchangetradednotesbasedontheperformanceofthevelocitysharesdaily', 'jpyindexduedecember', 'gbpindexduedecember', 'eurindexduedecember', 'chfindexduedecember', 'audindexduedecember', 'usdindexduedecember', 'cdepositorysharesrepresenting', 'thinterestinashareof', 'noncumulativepreferredstockserieskmember', 'noncumulativepreferredstockseriessmember', 'cctracksexchangetradednotesonthemillerhowardmlpfundamentalindexseriesbduejuly', 'cctracksexchangetradednotesmillerhowardstrategicdividendreinvestordueseptember', 'cctracksexchangetradednotesbasedontheperformanceofthemillerhowardmlpfundamentalindexdueseptember', 'incorporationcommissionfile', 'cvelocitysharesshortliboretnmember', 'cvelocityshareslongliboretnmember', 'cvelocityshareslongcrudeoiletnmember', 'cvelocitysharesinversecrudeoiletnmember', 'cvelocitysharesdailylongusdvsjpymember', 'cvelocitysharesdailylongusdvsgbpmember', 'cvelocitysharesdailylongusdvseurmember', 'cvelocitysharesdailylongusdvschfmember', 'cvelocitysharesdailylongusdvsaudmember', 'cvelocitysharesdailylongjpyvsusdmember', 'cvelocitysharesdailylonggbpvsusdmember', 'cvelocitysharesdailylongeurvsusdmember', 'cvelocitysharesdailylongchfvsusdmember', 'cvelocitysharesdailylongaudvsusdmember', 'cseriesspreferredstockmember', 'cseriesnmediumtermseniornotesmember', 'cserieskpreferredstockmember', 'cseriesgmediumtermseniornotesmember', 'cctracksmillerhowardstrategicdividendreinvestormember', 'cctracksmillerhowardmlpfundamentalindexseriesbmember', 'cctracksmillerhowardmlpfundamentalindexmember', 'ccitigroupcapitalxviiimember', 'ccitigroupcapitalxiiimember', 'ccitigroupcapitaliiimember', 'weerasinghegeneral', 'performancesensitive', 'previouslyannounce', 'settlementinprinciple', 'consumerbankinglending', 'revenuesprincipally']\n"
     ]
    }
   ],
   "source": [
    "cut_off = 18\n",
    "words_greater_than = [word for word in norm_vocab.keys() if cut_off <= len(word)]\n",
    "print(words_greater_than)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wfcnoncumulativeperpetualclassapreferredstockseriesnmember', 'wfcfixedtofloatingrate', 'noncumulativeperpetualclassapfdstockseriesqmember', 'wfcguaranteeofmediumtermnotesseriesadueoctober', 'ofwellsfargofinancellcmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesymember', 'noncumulativeperpetualconvertibleclassapreferredstockserieslmember', 'usgaapcommonstockmember', 'noncumulativeperpetualclassapfdstockseriesrmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesomember', 'wfcnoncumulativeperpetualclassapreferredstockseriestmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesvmember', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesofwachoviacapitaltrustiiimember', 'wfcnoncumulativeperpetualclassapreferredstockserieswmember', 'wfcnoncumulativeperpetualclassapreferredstockseriesxmember', 'wfcnoncumulativeperpetualclassapreferredstockseriespmember', 'commissionwashington', 'employeridentification', 'provisionswritten', 'bprecommencement', 'registeredcommon', 'prlnysedepositary', 'prnnysedepositary', 'pronysedepositary', 'prpnysedepositary', 'prqnysedepositary', 'prrnysedepositary', 'prtnysedepositary', 'prvnysedepositary', 'prwnysedepositary', 'prxnysedepositary', 'prynyseguarantee', 'iiiwbtpnyseguarantee', 'descriptionlocation', 'documentsignaturepursuant', 'wfccommonstockparvalue', 'noncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'wfcdepositaryshareseachrepresenting', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesnmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesomember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriespmember', 'thinterestinshareof', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesqmember', 'fixedtofloatingratenoncumulativeperpetualclasspreferredstockseriesrmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriestmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesvmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockserieswmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesxmember', 'thinterestinshareofnoncumulativeperpetualclasspreferredstockseriesymember', 'wfcguaranteeofmediumtermnotesseriesdueoctober', 'wfcnoncumulativeperpetualconvertibleclasspreferredstockserieslmember', 'wfcseriesnmember', 'wfcseriesomember', 'wfcseriespmember', 'wfcseriesqmember', 'wfcseriesrmember', 'wfcseriestmember', 'wfcseriesvmember', 'wfcserieswmember', 'wfcseriesxmember', 'wfcseriesymember', 'fixedtofloatingratenormalwachoviaincometrustsecuritiesmember', 'wfcguaranteeofmediumtermnotesseriesdueoctoberofwellsfargofinancellcmember', 'herewithsignaturepursuant', 'applicableformer', 'signaturepursuant', 'reclassification', 'conditionattached', 'comaboutcorporategovernance', 'multiplepointofentry', 'singlepointofentry', 'secretaryexhibit', 'electronictransmission', 'signaturespursuant', 'jurisdictioncommission', 'incorporationnumberidentification', 'transitionrelated', 'performancebased', 'archerdanielsmidland', 'accumulateddistributionsper', 'nysetradingsymbol', 'trusteepayingagent', 'preferredsecuritie', 'trustpreferredsecuritie', 'nationalassociation', 'stockholderrequested', 'retentionperformance', 'nondisparagement', 'comaboutcorporatecorporategovernance', 'otherthantemporary', 'statementprospectus', 'agreementstandard', 'nondiscriminatory', 'payforsuperiorperformance', 'pricewaterhousecooper', 'otherjurisdiction', 'jpmdepositarysharesonefourhundredthinterestinashareof', 'noncumulativepreferredstockseriesymember', 'jpmguaranteeofcushing', 'mlpindexetnsduejune', 'ofjpmorganchasefinancialcompanyllcmember', 'noncumulativepreferredstockseriespmember', 'noncumulativepreferredstockseriesaamember', 'noncumulativepreferredstockseriesddmember', 'jpmalerianmlpindexetnsduemay', 'noncumulativepreferredstockserieseemember', 'noncumulativepreferredstockseriesbbmember', 'jpmguaranteeofcallablesteupfixedratenotesdueapril', 'organizationcommission', 'exchangedepositary', 'exchangeguarantee', 'httpsjpmorganchaseco', 'comfinancialinformationsecfiling', 'officerdatedoctober', 'noncumulativepreferredstockserieswmember', 'officerdatedjuly', 'govsupervisionregdfastresstests', 'incorporationcommission', 'officerscompensatory', 'proposalsproposal', 'nameforagainstabstainbroker', 'compensationforagainstabstainbroker', 'foragainstabstainbroker', 'reportforagainstabstainbroker', 'accessforagainstabstainbroker', 'votingforagainstabstainbroker', 'positioningprincipal', 'officerdatedapril', 'officersjpmorgan', 'clientcustomerstakeholder', 'officerdatedjanuary', 'directordatedoctober', 'comjpmorganchasesec', 'charterdelawarestate', 'bylawsforagainstabstainbroker', 'chairmanforagainstabstainbroker', 'serviceforagainstabstainbroker', 'genocideforagainstabstainbroker', 'directordatedmay', 'directordatedapril', 'comcorporateinvestorrelationsinvestorrelations', 'secretarydatedjanuary', 'directordatedjanuary', 'secretarydatedoctober', 'yearsabstainbroker', 'directordatedjune', 'nonsolicitationhire', 'counseldatedjune', 'compensationonetwothreeabstainbroker', 'amendmentforagainstabstainbroker', 'equityforagainstabstainbroker', 'countedforagainstabstainbroker', 'meetingsforagainstabstainbroker', 'carpentercorporate', 'govregulationsreformresplansindex', 'govbankinforegresolutionplans', 'directordatedjuly', 'govbankinforegccar', 'statementnameforagainstabstainbroker', 'chairforagainstabstainbroker', 'abstentionsforagainstabstainbroker', 'valueforagainstabstainbroker', 'lawforagainstabstainbroker', 'reputationforagainstabstainbroker', 'recapturerecoupment', 'comjpmorganchase', 'presidentdatedjuly', 'expendituresforagainstabstainbroker', 'againstforagainstabstainbroker', 'executivesforagainstabstainbroker', 'secretarydateddecember', 'secretarydatedjuly', 'presidentdatedjune', 'foragainstabstainbrok', 'lobbyingforagainstabstainbroker', 'provisionsforagainstabstainbroker', 'onevoteforagainstabstainbroker', 'govbankinforegbcreg', 'nontaxdeductible', 'consentforagainstabstainbroker', 'ceoforagainstabstainbroker', 'ageforagainstabstainbroker', 'violationsforagainstabstainbroker', 'namesforagainstabstainbroker', 'govnewseventspressbcregbcreg', 'ofincorporationcommission', 'includingrevampe', 'wholeperformance', 'performancethird', 'competitorsuninterrupted', 'officerdateddecember', 'corporateprivate', 'previouslyissued', 'previouslyreporte', 'nonpartisanshipforagainstabstainbroker', 'comjpmorganchaseannual', 'bankruptcyrelated', 'introductionjpmorgan', 'overviewjpmorgan', 'foreclosurerelated', 'governmentsponsored', 'investmentspecific', 'organizationally', 'changeinvestment', 'taxableequivalent', 'changecompensation', 'ratiosreportedresult', 'managedbasisrevenue', 'changescommencing', 'methodologyresult', 'bcorporateprivate', 'assetsderivative', 'diversificatione', 'americacaribbean', 'servicingselecte', 'changenoninterest', 'chargeoffsrecoverie', 'chargeoffrecovery', 'portfoliosselecte', 'changedelinquency', 'supervisionasset', 'custodybrokerageadministrationdeposits', 'marketperformanceother', 'emeaasiapacificlatin', 'americacaribbeanin', 'significantclientsb', 'depositsaveragec', 'instrumentstrade', 'payablesderivative', 'securitiessecurities', 'receivableaccrue', 'agreementssecuritie', 'liabilitiesaccount', 'arrangementsjpmorgan', 'commitmentsjpmorgan', 'creditworthiness', 'securitizationrelated', 'totallendingrelate', 'misrepresentation', 'securitiesrelated', 'demandsiiestimate', 'correspondentoriginate', 'heldforinvestment', 'activitiesmaintain', 'requirementsachieve', 'creditequivalent', 'interconnectedness', 'substitutability', 'crossjurisdictional', 'availableforsale', 'resecuritization', 'actionsdividendson', 'companyliquidity', 'governmentissued', 'activitiesjpmorgan', 'moodysspfitchjpmorgan', 'nonperformingdef', 'bankruptcyremote', 'nonperformingdin', 'noninvestmentgradetotaltotal', 'accruingloansyeartodate', 'chargeoffsrecoveriescredit', 'derivativereceivablesas', 'creditexposuredinvestment', 'gradenoncriticizedcriticize', 'performingcriticize', 'materialsconstruction', 'chemicalsplastics', 'agriculturepaper', 'millionsloanslendingrelate', 'commitmentsderivative', 'receivablestotal', 'loansaderivativeslendingrelatedcommitmentstotal', 'loanseuropemiddle', 'additionsreduction', 'collateralaaaaaa', 'millionsprotection', 'purchasedbprotection', 'purchasedprotection', 'derivativesnotional', 'commitmentsthree', 'sovereignreference', 'billionslendingatradingbotherctotallocaldbrazil', 'portfoliojpmorgan', 'millionsonbalance', 'loansdrestructure', 'mortgageservicing', 'includeestablishe', 'wholesaleconsumer', 'assetspecificbcd', 'portfoliodiversification', 'earningsatriskinterest', 'impairmentmanagement', 'developmentsfair', 'legislationchange', 'volatilitychange', 'subsidiariesdamage', 'reputationability', 'disruptiontechnology', 'competitorsmerger', 'acquisitionsability', 'originationability', 'businessacceptance', 'employeesability', 'expensecompetitive', 'counterpartiesadequacy', 'frameworkadverse', 'proceedingschange', 'liabilitiesoccurrence', 'firmadministered', 'presentationjpmorgan', 'developmentsincrease', 'adjustmentstotal', 'governmentsponsore', 'realizedunrealizedgainslosse', 'unrealizedgainslosse', 'millionspurchasesfsalesissuancessettlementsasset', 'millionspurchasesfsalesissuancessettlementsliabilitiesa', 'gainslossespurchase', 'millionsliabilitiesa', 'collateraldependent', 'borrowerspecific', 'billionscarryingvalueestimatedfair', 'valueappreciationdepreciation', 'carryingvalueestimatedfair', 'valueappreciationdepreciationfinancial', 'depreciationappreciation', 'billionscarryingvalueaestimatedfair', 'carryingvalueaestimatedfair', 'instrumentspecific', 'millionsprincipaltransactionsotherincometotal', 'principaltransactionsotherincometotal', 'millionscontractualprincipaloutstande', 'valueoverundercontractualprincipal', 'contractualprincipaloutstande', 'principalprotecte', 'nonprincipalprotected', 'principalprotected', 'nonprincipalprotecte', 'hedgesdesignated', 'payablesdecember', 'currencydenominate', 'millionsderivativeshedge', 'hedgeineffectivenessd', 'componentsecontract', 'millionsderivative', 'impactderivative', 'incomelosscthree', 'dollardenominate', 'millionsexcluded', 'incomeaeffective', 'receivablespayablesa', 'soldpurchasedcother', 'ratingsamaturity', 'noninvestmentgrade', 'securitiessecuritie', 'millionsamortize', 'valueavailableforsale', 'governmentguaranteed', 'lossesavailableforsale', 'otherthantemporarily', 'yearsctotalavailableforsale', 'categoriesoriginate', 'heldforinvestmentfor', 'millionswholesaleconsumer', 'cardtotalpurchase', 'portfoliowholesale', 'wellcollateralize', 'financialinstitution', 'portfolioconsumer', 'restructuringsab', 'higherthanexpected', 'longerthanexpected', 'excludingwashington', 'millionswholesaleconsumerexclude', 'wholesaleconsumerexcluding', 'cardtotalallowance', 'lineofbusinesstransaction', 'typeactivityform', 'referencecardcredit', 'trustssecuritization', 'conduitsinvestor', 'activitiesassist', 'securitizationsfor', 'assetsafssecuritiestotal', 'chasesecuritizationrelate', 'viesdefghdecember', 'nonmortgagerelated', 'securitizationrelate', 'activitiesmunicipal', 'facilitiesaexcessdeficitbmaximum', 'exposurenonconsolidate', 'viesccreditrelate', 'thirdpartysponsored', 'instrumentsloansotherc', 'assetseotherftotal', 'liabilitiesdecember', 'resecuritizations', 'securitizationsthe', 'millionsprimeesubprimeoption', 'securitizationsb', 'mortgagecommercialand', 'notedprimedjpmorgan', 'amountaaccumulate', 'amortizationanetcarrye', 'amountaccumulate', 'amortizationnetcarrye', 'millionspurchase', 'relationshipsother', 'intangiblesother', 'intangiblestotal', 'noninterestbearing', 'comprehensiveincomeloss', 'derivativerelate', 'creditinvestmentgradea', 'noninvestmentgradea', 'indemnificationsindemnification', 'litigationcontingencie', 'regulatorygovernment', 'ratiosinvestmentbankretail', 'financialservicescard', 'autocommercialbankingtreasury', 'managementcorporateprivate', 'itemsctotalnoninter', 'pricewaterhousecoopers', 'ratestaxableequivalent', 'averagebalanceinterestrateannualize', 'noninterestbeare', 'headcountrelated', 'combinedloantovalue', 'subprimesubprime', 'metricsinvestment', 'productionrelate', 'businesstobusiness', 'institutionalgrade', 'metricsliability', 'servicestreasury', 'followinginstitutional', 'ultrahighnetworth', 'languageinteractive', 'reportableoperate', 'previouslyreported', 'officeregistrant', 'reportedfebruary', 'controllerprincipal', 'colgatepalmolive', 'misclassification', 'performancerelated', 'releasecertification', 'confidentialinformation', 'telecommunication', 'collectionsrelate', 'cardmemberservices', 'investmentrelate', 'managementnontrading', 'variancecovariance', 'industrialwarehouse', 'syndicationrelate', 'overcollateralization', 'howaldtswerkedeutsche', 'securitiesavailable', 'brokersinsurance', 'restructuringrelate', 'interestcrediting', 'restructuringrelated', 'compensationrelated', 'conversionrelate', 'investmentrelated', 'monitoringcontrol', 'partyadministere', 'automotiveloanslease', 'chargeoffsaverage', 'wheelingsteubenville', 'onepercentagepoint', 'receivablessubsidiarie', 'liquidityadjuste', 'litigationrelate', 'systemsintegration', 'bettercapitalize', 'issueddistribute', 'capitalinvestment', 'nontradingrelated', 'componentbycomponent', 'intrinsicvaluebased', 'euroclearrelated', 'appreciationdepreciation', 'agreementinprinciple', 'otherthantrading', 'noninterestearne', 'telecommunications', 'receivablespayables', 'otherthantradingab', 'otherthantradinga', 'provisionprovision', 'provisionreversal', 'constructioninprogress', 'depreciationamortization', 'foreigncountryrelate', 'commodityindexed', 'undercapitalized', 'securitiesrelatedb', 'increasedecrease', 'bacfloatingratepreferredhybridincometermsecuritiesmember', 'preferredstockmember', 'bacseniormediumtermnotesseriesastepupcallablenotesmember', 'bacincomecapitalobligationnotesmember', 'bacserieseepreferredstockmember', 'bacseriesllpreferredstockmember', 'bacserieslpreferredstockmember', 'bacserieskkpreferredstockmember', 'fixedtofloatingratepreferredhybridincometermsecuritiesmember', 'usgaapseriesepreferredstockmember', 'bacserieshhpreferredstockmember', 'bacseriesypreferredstockmember', 'bacseriesccpreferredstockmember', 'bacseriesggpreferredstockmember', 'exchangenovember', 'exchangeindicate', 'xbrlsignaturespursuant', 'usgaapnoncumulativepreferredstockmember', 'reportedseptember', 'ratenoncumulative', 'securitiesbacpgnew', 'corporationsenior', 'theretodepositary', 'bacserieswpreferredstockmember', 'corporationexact', 'oprecommencement', 'informationsignaturespursuant', 'provisionsowritten', 'includeformatdriven', 'reclassifications', 'changessignaturespursuant', 'payforperformance', 'statementscertain', 'reportednovember', 'documentsignaturespursuant', 'governmentinsure', 'retirementeligible', 'locationdescription', 'amendmentarticle', 'directorscalling', 'directorsserving', 'sharessignaturespursuant', 'millionspreliminary', 'followinglocationdescription', 'disqualification', 'nonvotessignature', 'numberdescription', 'acquisitionrelate', 'corporationexhibit', 'frahmbankofamerica', 'matterscharlotte', 'followingapproximately', 'commitmentsunder', 'securitiesaggregate', 'govinvestorpubsminitend', 'govdivisionsmarketregminitenderssia', 'orgwebgroupsindustryipregnoticedocumentsnoticesp', 'countrywideissue', 'govnewseventspressbcreg', 'antihedgingderivative', 'foreclosurerelate', 'reporteddecember', 'treasurysecuritie', 'contemporaneously', 'silvestribankofamerica', 'bankofamericacorporation', 'mergerlitigation', 'businessesdeposit', 'characterization', 'corporationsponsore', 'administratively', 'compdffundsscheduleafinal', 'comdocreponyagschedulea', 'pdfrequesternationsfunds', 'certificateholder', 'americafleetboston', 'americafleetbostoncombined', 'ofamericacorporation', 'ofamericafleetbostoncombine', 'polkingexecutive', 'alpharettageorgia', 'chargesextension', 'spricewaterhousecooper', 'relationshipbase', 'technologyrelate', 'nondepositrelate', 'derivativedealer', 'cvelocitysharesshortliboretnsdueaugust', 'cvelocityshareslongliboretnsdueaugust', 'xlongcrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'xinversecrudeoiletnslinkedtothespgscicrudeoilindexerduedecember', 'csixpointeighttwoninepercentfixedratefloatingrateenhancedtrustpreferredsecuritiesofcitigroupcapitalxviiimember', 'csevenpointsixtwofivepercenttrustpreferredsecuritiesofcitigroupcapitaliiimember', 'csevenpointeightsevenfivepercentfixedratefloatingratetrustpreferredsecuritiesofcitigroupcapitalxiiimember', 'cmediumtermseniornotesseriesncallablestepupcouponnotesduemarch', 'cmediumtermseniornotesseriesgcallablefixedratenotesduejanuary', 'cexchangetradednotesbasedontheperformanceofthevelocitysharesdaily', 'jpyindexduedecember', 'gbpindexduedecember', 'eurindexduedecember', 'chfindexduedecember', 'audindexduedecember', 'usdindexduedecember', 'cdepositorysharesrepresenting', 'thinterestinashareof', 'noncumulativepreferredstockserieskmember', 'noncumulativepreferredstockseriessmember', 'cctracksexchangetradednotesonthemillerhowardmlpfundamentalindexseriesbduejuly', 'cctracksexchangetradednotesmillerhowardstrategicdividendreinvestordueseptember', 'cctracksexchangetradednotesbasedontheperformanceofthemillerhowardmlpfundamentalindexdueseptember', 'incorporationcommissionfile', 'cvelocitysharesshortliboretnmember', 'cvelocityshareslongliboretnmember', 'cvelocityshareslongcrudeoiletnmember', 'cvelocitysharesinversecrudeoiletnmember', 'cvelocitysharesdailylongusdvsjpymember', 'cvelocitysharesdailylongusdvsgbpmember', 'cvelocitysharesdailylongusdvseurmember', 'cvelocitysharesdailylongusdvschfmember', 'cvelocitysharesdailylongusdvsaudmember', 'cvelocitysharesdailylongjpyvsusdmember', 'cvelocitysharesdailylonggbpvsusdmember', 'cvelocitysharesdailylongeurvsusdmember', 'cvelocitysharesdailylongchfvsusdmember', 'cvelocitysharesdailylongaudvsusdmember', 'cseriesspreferredstockmember', 'cseriesnmediumtermseniornotesmember', 'cserieskpreferredstockmember', 'cseriesgmediumtermseniornotesmember', 'cctracksmillerhowardstrategicdividendreinvestormember', 'cctracksmillerhowardmlpfundamentalindexseriesbmember', 'cctracksmillerhowardmlpfundamentalindexmember', 'ccitigroupcapitalxviiimember', 'ccitigroupcapitalxiiimember', 'ccitigroupcapitaliiimember', 'weerasinghegeneral', 'totalshareholder', 'returnpercentile', 'targetperformance', 'performanceveste', 'investmentsequity', 'performancesensitive', 'docservecitigroup', 'brokersinbranche', 'citigrouprelated', 'indicatorsmanaged', 'nonsolicitiation', 'previouslyannounce', 'marketsliquidity', 'settlementinprinciple', 'spinniningrelate', 'insurancerelated', 'recentlyannounced', 'locationsunmanne', 'separatelymanage', 'consumerbankinglending', 'propertycasualty', 'revenuesprincipally']\n"
     ]
    }
   ],
   "source": [
    "cut_off = 16\n",
    "words_greater_than = [word for word in norm_vocab.keys() if cut_off <= len(word)]\n",
    "print(words_greater_than)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above inspection real words like: 'undercapitalized' are captured in the 16 character length cutoff while most real words are not captured in the other cutoffs. This implies that we should use a cutoff of 18 characters or more because it is the largest cutoff that captures the least amount of real words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our exploratory analysis of the raw dataset we can conclude that our pricing data seems to fit the assumptions one usually assumes about stock pricing data. This means that the stock pricing data should be distributed log-normally and implies that the log returns of a stock over a period of time should be distributed normally. Our exploratory analysis of our text data shows there is nothing unusual about our raw text data, and it should fit into memory fine. It also shows that our text preprocessing methods still preserve the important parts of our text data and thus should not pose a future issue for analysis. From these findings we can conclude that our raw text data is useable, our text preprocessing methods are useable, and our price data is useable. Since the log returns of our pricing data (Adjusted Daily Closing Price) appear to fit a Gaussian distribution pretty well, our predictor variable in analysis should be log returns (as opposed to Adjusted Daily Closing Price) because the Gaussian distribution has some nice mathematical properties that might be leveraged further on in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting Raw DataFrame\n",
    "df = pd.read_csv(os.path.join(path_to_data, 'raw.csv'), parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the raw DataFrame was loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5031 entries, 0 to 5030\n",
      "Data columns (total 37 columns):\n",
      "timestamp                5031 non-null datetime64[ns]\n",
      "open_WFC                 5031 non-null float64\n",
      "high_WFC                 5031 non-null float64\n",
      "low_WFC                  5031 non-null float64\n",
      "close_WFC                5031 non-null float64\n",
      "adjusted_close_WFC       5031 non-null float64\n",
      "volume_WFC               5031 non-null float64\n",
      "dividend_amount_WFC      5031 non-null float64\n",
      "split_coefficient_WFC    5031 non-null float64\n",
      "open_JPM                 5031 non-null float64\n",
      "high_JPM                 5031 non-null float64\n",
      "low_JPM                  5031 non-null float64\n",
      "close_JPM                5031 non-null float64\n",
      "adjusted_close_JPM       5031 non-null float64\n",
      "volume_JPM               5031 non-null float64\n",
      "dividend_amount_JPM      5031 non-null float64\n",
      "split_coefficient_JPM    5031 non-null float64\n",
      "open_BAC                 5031 non-null float64\n",
      "high_BAC                 5031 non-null float64\n",
      "low_BAC                  5031 non-null float64\n",
      "close_BAC                5031 non-null float64\n",
      "adjusted_close_BAC       5031 non-null float64\n",
      "volume_BAC               5031 non-null float64\n",
      "dividend_amount_BAC      5031 non-null float64\n",
      "split_coefficient_BAC    5031 non-null float64\n",
      "open_C                   5031 non-null float64\n",
      "high_C                   5031 non-null float64\n",
      "low_C                    5031 non-null float64\n",
      "close_C                  5031 non-null float64\n",
      "adjusted_close_C         5031 non-null float64\n",
      "volume_C                 5031 non-null float64\n",
      "dividend_amount_C        5031 non-null float64\n",
      "split_coefficient_C      5031 non-null float64\n",
      "docs_WFC                 5031 non-null object\n",
      "docs_JPM                 5031 non-null object\n",
      "docs_BAC                 5031 non-null object\n",
      "docs_C                   5031 non-null object\n",
      "dtypes: datetime64[ns](1), float64(32), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining Functions and Classes for Normalizing Documents\n",
    "\n",
    "def extract_8k(doc):\n",
    "    eight_k = re.findall('<DOCUMENT>\\n<TYPE>8-K.*?<SEQUENCE>1(.*?)</DOCUMENT>', doc, re.DOTALL | re.IGNORECASE)\n",
    "    text = re.findall('<TEXT>(.*?)</TEXT>', eight_k[0], re.DOTALL | re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def extract_html(doc):\n",
    "    html = re.findall('<HTML(?:>| .*?>).*?</HTML>', doc, re.DOTALL | re.IGNORECASE)\n",
    "    return html\n",
    "\n",
    "def strip_tags(doc):\n",
    "    # extracting 8-K <DOCUMENT> tag from the filing\n",
    "    eight_k = extract_8k(doc)\n",
    "    assert len(eight_k) == 1, 'Check re for 8-K extraction, either multiple 8-K DOCUMENT tags or bad re'\n",
    "    \n",
    "    # extracting <html> tag if any\n",
    "    html = extract_html(eight_k[0])\n",
    "    assert 0 <= len(html) <= 1, 'Check re for extracting html tags'\n",
    "    \n",
    "    # if html exists\n",
    "    if len(html) == 1:\n",
    "        html = html[0]\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        stripped = soup.get_text()\n",
    "    else:\n",
    "        soup = BeautifulSoup(eight_k[0], 'lxml')\n",
    "        stripped = soup.get_text()\n",
    "    \n",
    "    return stripped\n",
    "\n",
    "def strip_accented_chars(doc):\n",
    "    doc = unicodedata.normalize('NFKD', doc).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return doc\n",
    "\n",
    "def strip_special_chars(doc):\n",
    "    doc = re.sub('[^$A-Za-z0-9%\\s.\\']', '', doc)\n",
    "    return doc\n",
    "\n",
    "def lemmatize(doc):\n",
    "    document = nlp(doc)\n",
    "    doc = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in document])\n",
    "    return doc\n",
    "\n",
    "def strip_stop_words(doc):\n",
    "    document = nlp(doc)\n",
    "    doc = ' '.join([word.text for word in document if not word.is_stop])\n",
    "    return doc\n",
    "\n",
    "def strip_large_words(doc, cut_off=20):\n",
    "    return ' '.join([word for word in doc.split() if len(word) <= cut_off])\n",
    "\n",
    "def normalize_document(doc, tags_strip=True, accent_char_strip=True, lower_case=True,\n",
    "                       no_newlines=True, special_char_strip=True, space_nums=True,\n",
    "                       lemmatize_words=True, remove_stop_words=True, strip_extra_spaces=True,\n",
    "                       remove_large_words=False, debug=False):\n",
    "    '''\n",
    "    Preprocesses the document :param doc: and returns the normalized document.\n",
    "    \n",
    "    :param doc: string, document to normalize\n",
    "    :param xml_strip: bool, set to True to strip the xml tags\n",
    "    :param accent_char_strip: bool, set to True to replace accented characters with their non accented versions\n",
    "    :param lower_case: bool, set to True to lower case the document.\n",
    "    :param no_newlines: bool, set to True to remove all newlines characters and replace them with spaces\n",
    "    :param special_char_strip: bool, set to True to remove all characters that are \n",
    "                                     not letters, numbers, $, ., %, or spaces\n",
    "    :param lemmatize_words: bool, set to True to map each word to its lemma\n",
    "    :param remove_stop_words: bool, set to True to remove stop words\n",
    "    :param strip_extra_spaces: bool, set to True to replace multiple spaces with one\n",
    "    :param remove_large_words: int, set to the integer cutoff where words larger than :param remove_large_words:\n",
    "                               are removed from the text. Set to False if there is no cutoff\n",
    "    \n",
    "    ---> string, normalized document\n",
    "    '''\n",
    "    if debug:\n",
    "        print('raw length of doc: {}'.format(len(doc)))\n",
    "        \n",
    "    # stripping tags\n",
    "    if tags_strip:\n",
    "        doc = strip_tags(doc)\n",
    "    if debug:\n",
    "        print('stripped tag length: {}'.format(len(doc)))\n",
    "    \n",
    "    # stripping accented characters\n",
    "    if accent_char_strip:\n",
    "        doc = strip_accented_chars(doc)\n",
    "    if debug:\n",
    "        print('altered accents length: {}'.format(len(doc)))\n",
    "        \n",
    "    # lower casing the document\n",
    "    if lower_case:\n",
    "        doc = doc.lower()\n",
    "    if debug:\n",
    "        print('lower casing length: {}'.format(len(doc)))\n",
    "    \n",
    "    # removing new lines and carriage returns and replacing them with spaces\n",
    "    if no_newlines:\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ', doc)\n",
    "    if debug:\n",
    "        print('removing newlines length: {}'.format(len(doc)))\n",
    "    \n",
    "    # removing special characters\n",
    "    if special_char_strip:\n",
    "        doc = strip_special_chars(doc)\n",
    "    if debug:\n",
    "        print('strip special char length: {}'.format(len(doc)))\n",
    "    \n",
    "    # lemmatizing the words\n",
    "    if lemmatize_words:\n",
    "        doc = lemmatize(doc)\n",
    "    if debug:\n",
    "        print('lemmatized doc length: {}'.format(len(doc)))\n",
    "    \n",
    "    # stripping stop words\n",
    "    if remove_stop_words:\n",
    "        doc = strip_stop_words(doc)\n",
    "    if debug:\n",
    "        print('removed stop word length: {}'.format(len(doc)))\n",
    "    \n",
    "    # adding spaces in between numbers and remaining special characters\n",
    "    if space_nums:\n",
    "        doc = re.sub(r'([\\d$%.])', r' \\1 ', doc)\n",
    "    if debug:\n",
    "        print('spaced num char length: {}'.format(len(doc)))\n",
    "        \n",
    "    # Removing large words\n",
    "    if remove_large_words:\n",
    "        doc = strip_large_words(doc, cut_off=remove_large_words)\n",
    "    if debug:\n",
    "        print('large words removed char length: {}'.format(len(doc)))\n",
    "        \n",
    "    # removing extra whitespace\n",
    "    if strip_extra_spaces:\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "    if debug:\n",
    "        print('removed extra space length: {}'.format(len(doc)))\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes for Building vocab.json Files\n",
    "\n",
    "def build_vocab(document, file_path):\n",
    "    '''\n",
    "    Adds to the already existing vocabulary file or creates a vocabulary file found at :param file_path:\n",
    "    the new vocabulary found in the normalized document :param document:.\n",
    "\n",
    "    :param document: string, normalized document to calculate vocabulary from.\n",
    "    :param file_path: string, path to vocabulary json file\n",
    "    \n",
    "    ---> :param file_path:\n",
    "    '''\n",
    "    \n",
    "    # Loading already established vocabulary\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            vocab = json.load(f)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        vocab  = {}\n",
    "        \n",
    "    # Updating vocabulary dictionary\n",
    "    if not vocab:\n",
    "        last_word_encoding = 0\n",
    "    else:\n",
    "        last_word_encoding = max(vocab.values())\n",
    "    \n",
    "    for word in document.split():\n",
    "        # if a word in the document is not in the current vocab, add it with a word encoding value larger than the largest word encoding value\n",
    "        if word not in vocab:\n",
    "            vocab[word] = last_word_encoding + 1\n",
    "            last_word_encoding = last_word_encoding + 1\n",
    "            \n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(vocab, f)\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes for Preprocessing the numerical and text features of the Dataset\n",
    "\n",
    "def preprocess_features(df, cut_off):\n",
    "    '''\n",
    "    Preprocesses data, by normalizing all the documents refrenced in df, calculatating the adjusted logarithmic \n",
    "    returns for each stock ticker, creating a vocab.json file for the corresponding dataset, and encoding all\n",
    "    documents refrenced in df according to the created vocab.json file.\n",
    "    \n",
    "    :param df: pd.DataFrame, with structure specified in....\n",
    "    :param cut_off: int, specifies at what character length do we start removing words from a document in\n",
    "                    the normalization process\n",
    "    \n",
    "    ---> pd.DataFrame, preprocessed DataFrame containing refrences to encoded documents and relevant calculations\n",
    "    '''\n",
    "    \n",
    "    # Deep copying input DataFrame making sure that the input isn't modified as a result of this function\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    def normalize_save_document(link, cut_off, endpoint):\n",
    "        '''\n",
    "        Normalize, and save normalized document located at link. The normalized document is saved at location endpoint.\n",
    "        Returns a path to the saved normalized document.\n",
    "        \n",
    "        :param link: string, path to document to be normalized\n",
    "        :param endpoint: string, path to location to save normalized document\n",
    "        \n",
    "        ---> string, path to saved normalized document\n",
    "        '''\n",
    "        \n",
    "        doc_name = os.path.split(link)[-1]\n",
    "        \n",
    "        if not os.path.isdir(endpoint):\n",
    "            os.mkdir(endpoint)\n",
    "            \n",
    "        with open(link, 'r') as file:\n",
    "            raw_document = file.read()\n",
    "            \n",
    "        norm_doc = normalize_document(raw_document, remove_large_words=cut_off)\n",
    "        \n",
    "        with open(os.path.join(endpoint, doc_name), 'w') as normalized_file:\n",
    "            normalized_file.write(norm_doc)\n",
    "        \n",
    "        return os.path.join(endpoint, doc_name)\n",
    "      \n",
    "    def norm_doclist(s):\n",
    "        '''\n",
    "        Takes a json formated string :param s: which contains a list of raw document paths, normalizes each document\n",
    "        in the list, and returns an updated json formated string containing the list of normlized document paths.\n",
    "        \n",
    "        :param s: string, json formated, when loaded contains a list of paths to raw documents\n",
    "        \n",
    "        ---> string, json formatted, updated list of paths to normalized documents\n",
    "        '''\n",
    "        doclist = json.loads(s)\n",
    "        updated_doclist = []\n",
    "        \n",
    "        for docpath in doclist:\n",
    "            save_point = os.path.join(os.path.split(docpath)[0], 'normalized')\n",
    "            norm_docpath = normalize_save_document(docpath, cut_off=cut_off, endpoint=save_point)\n",
    "            updated_doclist.append(norm_docpath)\n",
    "            \n",
    "        return json.dumps(updated_doclist)\n",
    "    \n",
    "    # Normalizing and updating documents  \n",
    "    for t in tickers:\n",
    "        df['_'.join(['docs', t])] = df['_'.join(['docs', t])].map(norm_doclist)\n",
    "        \n",
    "    # Preprocessing numerical data\n",
    "    for t in tickers:\n",
    "        df['_'.join(['log_adj_close', t])] = np.log(df['_'.join(['adjusted_close', t])])\n",
    "        df['_'.join(['log_adj_daily_returns', t])] = df['_'.join(['log_adj_close', t])] - df['_'.join(['log_adj_close', t])].shift(-1)\n",
    "        \n",
    "    df = df.dropna(subset=['_'.join(['log_adj_daily_returns', tickers[0]])])\n",
    "    \n",
    "    def vocab_from_doclist(s, path_to_vocab):\n",
    "        '''\n",
    "        Takes a json formated string :param s: that contains a list of document paths, and constructs or adds to an\n",
    "        already existing vocab.json file, the unique words found in the documents refrenced in the list of document\n",
    "        paths.\n",
    "        \n",
    "        :param s: string, json formated, contains a list of paths to documents\n",
    "        :param path_to_vocab: string, path to vocab.json file\n",
    "        \n",
    "        ---> :param s:\n",
    "        '''\n",
    "        \n",
    "        doclist = json.loads(s)\n",
    "        \n",
    "        for docpath in doclist:\n",
    "            with open(docpath, 'r') as f:\n",
    "                doc = f.read()\n",
    "            \n",
    "            vocab = build_vocab(doc, path_to_vocab)\n",
    "        \n",
    "        return json.dumps(doclist) \n",
    "    \n",
    "    # Building vocabulary json file\n",
    "    path_to_vocab = os.path.join(path_to_data, 'vocab.json')\n",
    "    \n",
    "    for t in tickers:\n",
    "        df['_'.join(['docs', t])].map(lambda s: vocab_from_doclist(s, path_to_vocab))\n",
    "    \n",
    "    def encode_doclist(s, vocab):\n",
    "        '''\n",
    "        Takes a json formated string :param s: which contains a list of document paths, encodes each document\n",
    "        in the list according to :param vocab: and saves it as a pickle in a file named encoded, and \n",
    "        returns an updated json formated string containing the list of encoded document paths.\n",
    "        \n",
    "        :param s: string, json formated, when loaded contains a list of paths to documents to encode\n",
    "        :param vocab: dict, mapping individual words in documents to another python object that encodes an\n",
    "                      individual word\n",
    "        \n",
    "        ---> string, json formated updated list of paths to encoded document files\n",
    "        '''\n",
    "        \n",
    "        def encode_save_document(docpath):\n",
    "            '''\n",
    "            Takes a path to a document and encodes it according to outside state vocab, then saves encoded document\n",
    "            as a pickle in a file named encoded.\n",
    "            \n",
    "            :param docpath: string, path to document to encode\n",
    "            \n",
    "            ---> string, path to encoded document pickle\n",
    "            '''\n",
    "            \n",
    "            root, doc_name = os.path.split(docpath)\n",
    "            \n",
    "            # Defining save point for encoded documents\n",
    "            save_point = os.path.join(root, 'encoded')\n",
    "            if not os.path.isdir(save_point):\n",
    "                os.mkdir(save_point)\n",
    "            \n",
    "            with open(docpath, 'r') as tfile:\n",
    "                text = tfile.read()\n",
    "                \n",
    "            # Encoding document\n",
    "            encoded_document = [vocab[word] for word in text.split()]\n",
    "            \n",
    "            # Saving encoded document\n",
    "            doc_name = '.'.join([os.path.splitext(doc_name)[0], 'pickle'])\n",
    "            with open(os.path.join(save_point, doc_name), 'wb') as bfile:\n",
    "                pickle.dump(encoded_document, bfile)\n",
    "            \n",
    "            return os.path.join(save_point, doc_name)\n",
    "        \n",
    "        return json.dumps(list(map(encode_save_document, json.loads(s))))\n",
    "    \n",
    "    # Encoding documents according to vocabulary\n",
    "    with open(path_to_vocab, 'r') as f:\n",
    "        vocab = json.load(f)\n",
    "    \n",
    "    for t in tickers:\n",
    "        df['_'.join(['docs', t])] = df['_'.join(['docs', t])].map(lambda s: encode_doclist(s, vocab))         \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Functions and Classes for Preprocessing the DataFrame to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame:\n",
      "    numbers letters\n",
      "25       26       z\n",
      "24       25       y\n",
      "23       24       x\n",
      "22       23       w\n",
      "21       22       v\n",
      "20       21       u\n",
      "19       20       t\n",
      "18       19       s\n",
      "17       18       r\n",
      "16       17       q\n",
      "15       16       p\n",
      "14       15       o\n",
      "13       14       n\n",
      "12       13       m\n",
      "11       12       l\n",
      "10       11       k\n",
      "9        10       j\n",
      "8         9       i\n",
      "7         8       h\n",
      "6         7       g\n",
      "5         6       f\n",
      "4         5       e\n",
      "3         4       d\n",
      "2         3       c\n",
      "1         2       b\n",
      "0         1       a\n",
      "\n",
      "Windowed DataFrame with a window size of n_trail+1\n",
      "    numbers(t-5) letters(t-5)  numbers(t-4) letters(t-4)  numbers(t-3)  \\\n",
      "24          20.0            t          21.0            u          22.0   \n",
      "23          19.0            s          20.0            t          21.0   \n",
      "22          18.0            r          19.0            s          20.0   \n",
      "21          17.0            q          18.0            r          19.0   \n",
      "20          16.0            p          17.0            q          18.0   \n",
      "19          15.0            o          16.0            p          17.0   \n",
      "18          14.0            n          15.0            o          16.0   \n",
      "17          13.0            m          14.0            n          15.0   \n",
      "16          12.0            l          13.0            m          14.0   \n",
      "15          11.0            k          12.0            l          13.0   \n",
      "14          10.0            j          11.0            k          12.0   \n",
      "13           9.0            i          10.0            j          11.0   \n",
      "12           8.0            h           9.0            i          10.0   \n",
      "11           7.0            g           8.0            h           9.0   \n",
      "10           6.0            f           7.0            g           8.0   \n",
      "9            5.0            e           6.0            f           7.0   \n",
      "8            4.0            d           5.0            e           6.0   \n",
      "7            3.0            c           4.0            d           5.0   \n",
      "6            2.0            b           3.0            c           4.0   \n",
      "5            1.0            a           2.0            b           3.0   \n",
      "\n",
      "   letters(t-3)  numbers(t-2) letters(t-2)  numbers(t-1) letters(t-1)  \\\n",
      "24            v          23.0            w          24.0            x   \n",
      "23            u          22.0            v          23.0            w   \n",
      "22            t          21.0            u          22.0            v   \n",
      "21            s          20.0            t          21.0            u   \n",
      "20            r          19.0            s          20.0            t   \n",
      "19            q          18.0            r          19.0            s   \n",
      "18            p          17.0            q          18.0            r   \n",
      "17            o          16.0            p          17.0            q   \n",
      "16            n          15.0            o          16.0            p   \n",
      "15            m          14.0            n          15.0            o   \n",
      "14            l          13.0            m          14.0            n   \n",
      "13            k          12.0            l          13.0            m   \n",
      "12            j          11.0            k          12.0            l   \n",
      "11            i          10.0            j          11.0            k   \n",
      "10            h           9.0            i          10.0            j   \n",
      "9             g           8.0            h           9.0            i   \n",
      "8             f           7.0            g           8.0            h   \n",
      "7             e           6.0            f           7.0            g   \n",
      "6             d           5.0            e           6.0            f   \n",
      "5             c           4.0            d           5.0            e   \n",
      "\n",
      "    numbers(t+0) letters(t+0)  numbers(t+1) letters(t+1)  \n",
      "24            25            y          26.0            z  \n",
      "23            24            x          25.0            y  \n",
      "22            23            w          24.0            x  \n",
      "21            22            v          23.0            w  \n",
      "20            21            u          22.0            v  \n",
      "19            20            t          21.0            u  \n",
      "18            19            s          20.0            t  \n",
      "17            18            r          19.0            s  \n",
      "16            17            q          18.0            r  \n",
      "15            16            p          17.0            q  \n",
      "14            15            o          16.0            p  \n",
      "13            14            n          15.0            o  \n",
      "12            13            m          14.0            n  \n",
      "11            12            l          13.0            m  \n",
      "10            11            k          12.0            l  \n",
      "9             10            j          11.0            k  \n",
      "8              9            i          10.0            j  \n",
      "7              8            h           9.0            i  \n",
      "6              7            g           8.0            h  \n",
      "5              6            f           7.0            g  \n"
     ]
    }
   ],
   "source": [
    "def window_df(df, columns, n_trail=1, n_lead=1):\n",
    "    '''\n",
    "    :param df: DataFrame, dataframe object where the columns are the features and labels and the rows are days\n",
    "    :param columns: list of strings, names of the features and labels (columns of df) to be used in the time series\n",
    "    :param n_trail: int, number of days behind day 0 that will be used to predict days after day 0\n",
    "    :param n_lead: int, number of days ahead of day 0 that will be predicted\n",
    "    \n",
    "    ---> DataFrame, dataframe object structured like a time series where each row represents an element in the time\n",
    "                    series, and each column is a feature or label a certain amount of days in the future or past.\n",
    "    '''\n",
    "    df = df[columns]\n",
    "    dfs = []\n",
    "    col_names = []\n",
    "    \n",
    "    # Create trailing columns\n",
    "    for i in range(n_trail, 0, -1):\n",
    "        dfs.append(df.shift(-i))\n",
    "        col_names += [(col_name + '(t-{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    # Create leading columns\n",
    "    for i in range(0, n_lead+1):\n",
    "        dfs.append(df.shift(i))\n",
    "        col_names += [(col_name + '(t+{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    agg = pd.concat(dfs, axis=1)\n",
    "    agg.columns = col_names\n",
    "    \n",
    "    agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg\n",
    "\n",
    "def test_function():\n",
    "    \n",
    "    test_df = pd.DataFrame([(1, 'a'), (2, 'b'), (3, 'c'),\n",
    "                            (4, 'd'), (5, 'e'), (6, 'f'),\n",
    "                            (7, 'g'), (8, 'h'), (9, 'i'),\n",
    "                            (10, 'j'), (11, 'k'), (12, 'l'),\n",
    "                            (13, 'm'), (14, 'n'), (15, 'o'),\n",
    "                            (16, 'p'), (17, 'q'), (18, 'r'),\n",
    "                            (19, 's'), (20, 't'), (21, 'u'),\n",
    "                            (22, 'v'), (23, 'w'), (24, 'x'),\n",
    "                            (25, 'y'), (26, 'z')], columns=['numbers', 'letters'])\n",
    "    test_df = test_df.reindex(index=test_df.index[::-1])\n",
    "    print('Test DataFrame:')\n",
    "    print(test_df)\n",
    "    df = window_df(test_df, columns=test_df.columns, n_trail=5)\n",
    "    print()\n",
    "    print('Windowed DataFrame with a window size of n_trail+1')\n",
    "    print(df)\n",
    "    return None\n",
    "\n",
    "test_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(feature_names, ticker, df):\n",
    "    cols = map(lambda fname: '_'.join([fname, ticker]), feature_names)\n",
    "    return df[cols]\n",
    "\n",
    "def extract_dataset(df, feature_names, ticker, n_trail=1, n_lead=1):\n",
    "    selected_df = extract_features(feature_names, ticker, df)\n",
    "    windowed_df = window_df(selected_df, selected_df.columns, n_trail=n_trail, n_lead=n_lead)\n",
    "    dataset = {fname: windowed_df[filter(lambda name: True if fname in name else False, windowed_df.columns)].values\n",
    "                     for fname in feature_names}\n",
    "    return dataset\n",
    "\n",
    "def extract_labels(dataset, label_names):\n",
    "    labels = {'_'.join([fname, 'target']): dataset[fname][:, -1] for fname in dataset.keys() if fname in label_names}\n",
    "    features = {fname: dataset[fname][:, :-1] for fname in dataset.keys()}\n",
    "    return features, labels\n",
    "\n",
    "def reshape_docs_feature(dataset, seed):\n",
    "    \n",
    "    def flatten_docs_feature(docs_feature):\n",
    "        docs = []\n",
    "        for timestep in docs_feature:\n",
    "            docs_list = json.loads(timestep)\n",
    "            docs.extend(docs_list)\n",
    "        return docs\n",
    "    \n",
    "    def sample_docs(docs_feature, seed):\n",
    "        np.random.seed(seed)\n",
    "        docs_names = flatten_docs_feature(docs_feature)\n",
    "        if len(docs_names) != 0:\n",
    "            windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "            with open(windows_doc_name, 'rb') as f:\n",
    "                windows_doc = pickle.load(f)\n",
    "            window = windows_doc\n",
    "        else:\n",
    "            window = []\n",
    "        return np.asarray(window)\n",
    "    \n",
    "    features = dataset[0]\n",
    "    labels = dataset[1]\n",
    "\n",
    "    features_reshaped = {key: (value if key != 'docs' \n",
    "                               else list(map(lambda docf: sample_docs(docf, seed), value))) \n",
    "                         for key, value in features.items()}\n",
    "\n",
    "    return features_reshaped, labels\n",
    "\n",
    "def filter_dataset(dataset):\n",
    "    features = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    mask = [(sample.shape[0] != 0) for sample in features['docs']]\n",
    "    features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                               else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                         for key, value in features.items()}\n",
    "    labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "    return features_filtered, labels_filtered\n",
    "\n",
    "def add_datasets(dataset_1, dataset_2):\n",
    "    features_1 = dataset_1[0]\n",
    "    labels_1 = dataset_1[1]\n",
    "    features_2 = dataset_2[0]\n",
    "    labels_2 = dataset_2[1]\n",
    "    assert (features_1.keys() == features_2.keys()) and (labels_1.keys() == labels_2.keys())\n",
    "    feature_names = features_1.keys()\n",
    "    label_names = labels_1.keys()\n",
    "    features = {fname: (np.concatenate((features_1[fname], features_2[fname]))\n",
    "                        if fname != 'docs' else features_1[fname] + features_2[fname])\n",
    "                for fname in feature_names}\n",
    "    labels = {lname: np.concatenate((labels_1[lname], labels_2[lname])) for lname in label_names}\n",
    "    return features, labels\n",
    "\n",
    "def pad_documents(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, longest_doc_len - arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)\n",
    "\n",
    "def pad_dataset(dataset):\n",
    "    features = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    pad_document_feature = lambda fname, f: (fname, pad_documents(f)) if fname == 'docs' else (fname, f)\n",
    "    padded_features = dict(map(lambda item: pad_document_feature(item[0], item[1]), features.items()))\n",
    "    return padded_features, labels\n",
    "\n",
    "def shuffle_dataset(dataset, seed):\n",
    "    np.random.seed(seed)\n",
    "    features = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    dataset_size = len(next(iter(features.values())))\n",
    "    shuffled_indices = np.random.choice(dataset_size, size=dataset_size, replace=False)\n",
    "    features_shuffled = {fname: feature[shuffled_indices] for fname, feature in features.items()}\n",
    "    labels_shuffled = {lname: label[shuffled_indices] for lname, label in labels.items()}\n",
    "    return features_shuffled, labels_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(feature_names, label_feature_names, window_size, tickers, df, seed):\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "    except FileNotFoundError:\n",
    "    \n",
    "    datasets = map(lambda t: extract_dataset(df, feature_names, ticker=t, n_trail=window_size-1), tickers)\n",
    "    datasets = map(lambda ds: extract_labels(ds, label_feature_names), datasets)\n",
    "    datasets = map(lambda ds: reshape_docs_feature(ds, seed), datasets)\n",
    "    datasets = map(filter_dataset, datasets)\n",
    "    dataset = reduce(add_datasets, datasets)\n",
    "    dataset = pad_dataset(dataset)\n",
    "    dataset = shuffle_dataset(dataset, seed)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the raw DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = preprocess_features(df, cut_off=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if our DataFrame was preprocessed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5030 entries, 0 to 5029\n",
      "Data columns (total 45 columns):\n",
      "timestamp                    5030 non-null datetime64[ns]\n",
      "open_WFC                     5030 non-null float64\n",
      "high_WFC                     5030 non-null float64\n",
      "low_WFC                      5030 non-null float64\n",
      "close_WFC                    5030 non-null float64\n",
      "adjusted_close_WFC           5030 non-null float64\n",
      "volume_WFC                   5030 non-null float64\n",
      "dividend_amount_WFC          5030 non-null float64\n",
      "split_coefficient_WFC        5030 non-null float64\n",
      "open_JPM                     5030 non-null float64\n",
      "high_JPM                     5030 non-null float64\n",
      "low_JPM                      5030 non-null float64\n",
      "close_JPM                    5030 non-null float64\n",
      "adjusted_close_JPM           5030 non-null float64\n",
      "volume_JPM                   5030 non-null float64\n",
      "dividend_amount_JPM          5030 non-null float64\n",
      "split_coefficient_JPM        5030 non-null float64\n",
      "open_BAC                     5030 non-null float64\n",
      "high_BAC                     5030 non-null float64\n",
      "low_BAC                      5030 non-null float64\n",
      "close_BAC                    5030 non-null float64\n",
      "adjusted_close_BAC           5030 non-null float64\n",
      "volume_BAC                   5030 non-null float64\n",
      "dividend_amount_BAC          5030 non-null float64\n",
      "split_coefficient_BAC        5030 non-null float64\n",
      "open_C                       5030 non-null float64\n",
      "high_C                       5030 non-null float64\n",
      "low_C                        5030 non-null float64\n",
      "close_C                      5030 non-null float64\n",
      "adjusted_close_C             5030 non-null float64\n",
      "volume_C                     5030 non-null float64\n",
      "dividend_amount_C            5030 non-null float64\n",
      "split_coefficient_C          5030 non-null float64\n",
      "docs_WFC                     5030 non-null object\n",
      "docs_JPM                     5030 non-null object\n",
      "docs_BAC                     5030 non-null object\n",
      "docs_C                       5030 non-null object\n",
      "log_adj_close_WFC            5030 non-null float64\n",
      "log_adj_daily_returns_WFC    5030 non-null float64\n",
      "log_adj_close_JPM            5030 non-null float64\n",
      "log_adj_daily_returns_JPM    5030 non-null float64\n",
      "log_adj_close_BAC            5030 non-null float64\n",
      "log_adj_daily_returns_BAC    5030 non-null float64\n",
      "log_adj_close_C              5030 non-null float64\n",
      "log_adj_daily_returns_C      5030 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(40), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>docs_C</th>\n",
       "      <th>log_adj_close_WFC</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_close_JPM</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_close_BAC</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_close_C</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>50.44</td>\n",
       "      <td>51.02</td>\n",
       "      <td>50.23</td>\n",
       "      <td>50.62</td>\n",
       "      <td>50.62</td>\n",
       "      <td>18007709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.45</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.924347</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>4.826632</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>3.440418</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>4.277499</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>50.28</td>\n",
       "      <td>50.50</td>\n",
       "      <td>50.18</td>\n",
       "      <td>50.46</td>\n",
       "      <td>50.46</td>\n",
       "      <td>19409100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.05</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.921181</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>4.816646</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>3.434632</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>4.274024</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>49.34</td>\n",
       "      <td>50.22</td>\n",
       "      <td>49.32</td>\n",
       "      <td>49.97</td>\n",
       "      <td>49.97</td>\n",
       "      <td>21199500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.911423</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>4.792148</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>3.412797</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>4.244774</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>49.98</td>\n",
       "      <td>50.17</td>\n",
       "      <td>49.48</td>\n",
       "      <td>49.61</td>\n",
       "      <td>49.61</td>\n",
       "      <td>20560100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.75</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.904192</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>4.790404</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>3.409827</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>4.242765</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>50.04</td>\n",
       "      <td>50.28</td>\n",
       "      <td>49.45</td>\n",
       "      <td>49.59</td>\n",
       "      <td>49.59</td>\n",
       "      <td>23728400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.96</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.903789</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>4.784822</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>3.406848</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>4.241327</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "0 2019-10-22     50.44     51.02    50.23      50.62               50.62   \n",
       "1 2019-10-21     50.28     50.50    50.18      50.46               50.46   \n",
       "2 2019-10-18     49.34     50.22    49.32      49.97               49.97   \n",
       "3 2019-10-17     49.98     50.17    49.48      49.61               49.61   \n",
       "4 2019-10-16     50.04     50.28    49.45      49.59               49.59   \n",
       "\n",
       "   volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "0  18007709.0                  0.0                    1.0    123.45  ...   \n",
       "1  19409100.0                  0.0                    1.0    122.05  ...   \n",
       "2  21199500.0                  0.0                    1.0    120.00  ...   \n",
       "3  20560100.0                  0.0                    1.0    120.75  ...   \n",
       "4  23728400.0                  0.0                    1.0    119.96  ...   \n",
       "\n",
       "                                            docs_BAC  docs_C  \\\n",
       "0                                                 []      []   \n",
       "1                                                 []      []   \n",
       "2                                                 []      []   \n",
       "3                                                 []      []   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...      []   \n",
       "\n",
       "   log_adj_close_WFC  log_adj_daily_returns_WFC  log_adj_close_JPM  \\\n",
       "0           3.924347                   0.003166           4.826632   \n",
       "1           3.921181                   0.009758           4.816646   \n",
       "2           3.911423                   0.007230           4.792148   \n",
       "3           3.904192                   0.000403           4.790404   \n",
       "4           3.903789                  -0.010431           4.784822   \n",
       "\n",
       "   log_adj_daily_returns_JPM  log_adj_close_BAC  log_adj_daily_returns_BAC  \\\n",
       "0                   0.009986           3.440418                   0.005786   \n",
       "1                   0.024498           3.434632                   0.021836   \n",
       "2                   0.001743           3.412797                   0.002970   \n",
       "3                   0.005583           3.409827                   0.002979   \n",
       "4                  -0.002337           3.406848                   0.014691   \n",
       "\n",
       "   log_adj_close_C  log_adj_daily_returns_C  \n",
       "0         4.277499                 0.003475  \n",
       "1         4.274024                 0.029250  \n",
       "2         4.244774                 0.002009  \n",
       "3         4.242765                 0.001438  \n",
       "4         4.241327                -0.024447  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open_WFC</th>\n",
       "      <th>high_WFC</th>\n",
       "      <th>low_WFC</th>\n",
       "      <th>close_WFC</th>\n",
       "      <th>adjusted_close_WFC</th>\n",
       "      <th>volume_WFC</th>\n",
       "      <th>dividend_amount_WFC</th>\n",
       "      <th>split_coefficient_WFC</th>\n",
       "      <th>open_JPM</th>\n",
       "      <th>...</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>docs_C</th>\n",
       "      <th>log_adj_close_WFC</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_close_JPM</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_close_BAC</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_close_C</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>23.500</td>\n",
       "      <td>23.594</td>\n",
       "      <td>23.156</td>\n",
       "      <td>23.438</td>\n",
       "      <td>13.5640</td>\n",
       "      <td>10083800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.625</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.607419</td>\n",
       "      <td>-0.021111</td>\n",
       "      <td>3.432670</td>\n",
       "      <td>-0.043183</td>\n",
       "      <td>2.956113</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>5.568721</td>\n",
       "      <td>-0.016260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5026</td>\n",
       "      <td>1999-10-29</td>\n",
       "      <td>24.250</td>\n",
       "      <td>24.531</td>\n",
       "      <td>23.625</td>\n",
       "      <td>23.938</td>\n",
       "      <td>13.8534</td>\n",
       "      <td>11853400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.125</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.628531</td>\n",
       "      <td>-0.024500</td>\n",
       "      <td>3.475853</td>\n",
       "      <td>-0.014929</td>\n",
       "      <td>2.949348</td>\n",
       "      <td>0.006816</td>\n",
       "      <td>5.584981</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5027</td>\n",
       "      <td>1999-10-28</td>\n",
       "      <td>24.063</td>\n",
       "      <td>24.969</td>\n",
       "      <td>23.875</td>\n",
       "      <td>24.531</td>\n",
       "      <td>14.1970</td>\n",
       "      <td>24287800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.500</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.653031</td>\n",
       "      <td>0.053643</td>\n",
       "      <td>3.490782</td>\n",
       "      <td>0.067882</td>\n",
       "      <td>2.942532</td>\n",
       "      <td>0.046985</td>\n",
       "      <td>5.582674</td>\n",
       "      <td>0.056094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5028</td>\n",
       "      <td>1999-10-27</td>\n",
       "      <td>22.563</td>\n",
       "      <td>23.250</td>\n",
       "      <td>22.438</td>\n",
       "      <td>23.250</td>\n",
       "      <td>13.4555</td>\n",
       "      <td>11327200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.063</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.599388</td>\n",
       "      <td>0.039760</td>\n",
       "      <td>3.422900</td>\n",
       "      <td>0.061522</td>\n",
       "      <td>2.895547</td>\n",
       "      <td>0.046078</td>\n",
       "      <td>5.526580</td>\n",
       "      <td>0.056370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5029</td>\n",
       "      <td>1999-10-26</td>\n",
       "      <td>22.375</td>\n",
       "      <td>22.719</td>\n",
       "      <td>22.219</td>\n",
       "      <td>22.344</td>\n",
       "      <td>12.9310</td>\n",
       "      <td>11607400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.313</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>2.559628</td>\n",
       "      <td>0.008426</td>\n",
       "      <td>3.361378</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>2.849469</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>5.470209</td>\n",
       "      <td>0.014276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  open_WFC  high_WFC  low_WFC  close_WFC  adjusted_close_WFC  \\\n",
       "5025 1999-11-01    23.500    23.594   23.156     23.438             13.5640   \n",
       "5026 1999-10-29    24.250    24.531   23.625     23.938             13.8534   \n",
       "5027 1999-10-28    24.063    24.969   23.875     24.531             14.1970   \n",
       "5028 1999-10-27    22.563    23.250   22.438     23.250             13.4555   \n",
       "5029 1999-10-26    22.375    22.719   22.219     22.344             12.9310   \n",
       "\n",
       "      volume_WFC  dividend_amount_WFC  split_coefficient_WFC  open_JPM  ...  \\\n",
       "5025  10083800.0                  0.0                    1.0    86.625  ...   \n",
       "5026  11853400.0                  0.0                    1.0    88.125  ...   \n",
       "5027  24287800.0                  0.0                    1.0    85.500  ...   \n",
       "5028  11327200.0                  0.0                    1.0    78.063  ...   \n",
       "5029  11607400.0                  0.0                    1.0    78.313  ...   \n",
       "\n",
       "      docs_BAC                                             docs_C  \\\n",
       "5025        []                                                 []   \n",
       "5026        []                                                 []   \n",
       "5027        []                                                 []   \n",
       "5028        []                                                 []   \n",
       "5029        []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "      log_adj_close_WFC  log_adj_daily_returns_WFC  log_adj_close_JPM  \\\n",
       "5025           2.607419                  -0.021111           3.432670   \n",
       "5026           2.628531                  -0.024500           3.475853   \n",
       "5027           2.653031                   0.053643           3.490782   \n",
       "5028           2.599388                   0.039760           3.422900   \n",
       "5029           2.559628                   0.008426           3.361378   \n",
       "\n",
       "      log_adj_daily_returns_JPM  log_adj_close_BAC  log_adj_daily_returns_BAC  \\\n",
       "5025                  -0.043183           2.956113                   0.006765   \n",
       "5026                  -0.014929           2.949348                   0.006816   \n",
       "5027                   0.067882           2.942532                   0.046985   \n",
       "5028                   0.061522           2.895547                   0.046078   \n",
       "5029                  -0.001605           2.849469                   0.001077   \n",
       "\n",
       "      log_adj_close_C  log_adj_daily_returns_C  \n",
       "5025         5.568721                -0.016260  \n",
       "5026         5.584981                 0.002306  \n",
       "5027         5.582674                 0.056094  \n",
       "5028         5.526580                 0.056370  \n",
       "5029         5.470209                 0.014276  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our preprocessed DataFrame checks out. Next, we will save our preprocessed DataFrame to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving preprocessed DataFrame to Disk\n",
    "preprocessed_df.to_csv(os.path.join(path_to_data, 'preprocessed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to discover whether we can construct a deep learning model that correlates (predicts) stock price data with unstructured text data found in company 8-K forms. Specifically for our first models we will try to correlate the logarithmic returns of a stock with the previous logarithmic returns of the stock in a given window of time, along with the text data stored in the companies 8-K forms that were released in the given window of time. If there are multiple 8-K documents released in the given window of time then our text data fed to the model will be derived from a single 8-K document uniformly sampled from the 8-K documents released in the given window of time. This window size (in days) along with architecture of the model will be the hyperparameters that can be tuned when experiment with different model designs. Modeling will consist of two phases: Preparing Data, and Evaluating Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fractions import Fraction\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Random Seed\n",
    "seed = 20\n",
    "tf.random.set_seed(seed)\n",
    " \n",
    "# Model Hyperparameters    \n",
    "## Model Hyperparameters that require reshaping Dataset\n",
    "TIMESTEPS = 8\n",
    "BATCH_SIZE = 64\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "## Model 1 Hyperparameters\n",
    "DOC_EMBEDDING_UNITS = 1000\n",
    "TS_LAYER_1_UNITS = None\n",
    "TS_LAYER_2_UNITS = 1000\n",
    "TS_LAYER_3_UNITS = 1000\n",
    "OPTIMIZER = tf.keras.optimizers.Adam\n",
    "LOSS = tf.keras.losses.BinaryCrossentropy()\n",
    "METRICS = ['accuracy']\n",
    "LEARNING_RATE=None\n",
    "dataset_size = 1000\n",
    "\n",
    "\n",
    "# Accessing Cleaned Data\n",
    "df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics, callbacks=None):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model is the bare minimum model we can manually construct from just our Exploratory Data Analysis. This model will give us baselines that hopefully our trained models will beat. Since the problem we are dealing with is a regression problem with only one target variable, we can represent any model that fits this problem description as: \n",
    "\n",
    "$$E(Y|X=X) = W \\cdot X + b$$\n",
    "\n",
    "In the case of simple linear regression then $X$ directly represents the input features to the model, and $W$ and $b$ the weights and biases that the model learns. On the other hand if this equation represents a deep model architecture, then $W$ and $b$ would represent only the weights and biases that the model learns for the **output layer**. This implies that $X$ would be a function of the input features to the model and would represent the input passed to the output layer of the model, or in other words $X$ represents the features the previous layers of the model **learned** to extract from the given original input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express our baseline model as one that predicts the expected value of the target variable no matter what the predictor variable happens to be. If we assume that there exists a relation between our predictor variables and target variable, and we average across all values of our predictor variables, then we find that any trained model of the relationship between predictor and target variables should on average predict the expected value of the target variable. This means that the bare minimum we can ask a model is that on average it predicts the expected value of the target variable. This implies that if we were to design a model that predicts the target variable without taking the predictor variable into account, then inorder to satisfy the bare minimum constraint, this model would need to predict the mean of our target variable. Mathematically we can express or baseline model as:\n",
    "\n",
    "$E(Y|X=X) = E(Y) = \\mu = W \\cdot X + b$ such that $W = 0$ in order to satisfy the input independent constraint.\n",
    "\n",
    "This implies $b = \\mu$.\n",
    "\n",
    "This also implies that we can convert any model to a model equivalent to the baseline model, as long as we initialize its output layers weights to zero, and its bias to the expected value of our target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our specific case we know from our exploratory data analysis that the means of all our target variables, logarithmic adjusted returns, are close to zero for each stock. This is also supported by theory, which predicts that the logarthimic return on a stock should follow a normal distribution centered around zero (or at least very closely conform to a normal distribution). This means to build our baseline model we must create a linear regression model where both the weights and bias are initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(output_bias, input_features):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    inputs = {fname: tf.keras.Input(**input_features[fname]) for fname in input_features.keys()}\n",
    "    output = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias,\n",
    "                                   name='log_adj_daily_returns_target')(inputs['log_adj_daily_returns'])\n",
    "    model = tf.keras.Model(inputs, output, name='baseline_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Baseline Model: 0.0007446739561454383\n"
     ]
    }
   ],
   "source": [
    "output_bias = 0\n",
    "window_size = 6\n",
    "hparams = {'output_bias': output_bias, \n",
    "           'input_features': {'log_adj_daily_returns': {'shape': (window_size,),\n",
    "                                                        'name': 'log_adj_daily_returns', 'dtype': tf.float32},\n",
    "                              'docs': {'shape': (None,), 'name': 'docs', 'dtype': tf.int64}}}\n",
    "\n",
    "X, y = preprocess(['log_adj_daily_returns', 'docs'], ['log_adj_daily_returns'], window_size, tickers, df, seed)\n",
    "\n",
    "baseline_m = build_compiled_model(baseline_model, hparams, loss='mse', optimizer='adam', metrics=None)\n",
    "baseline_predictions = baseline_m.predict(X)\n",
    "assert all((pred == baseline_predictions[0]) for pred in baseline_predictions)\n",
    "baseline_results = baseline_m.evaluate(X, y, verbose=0)\n",
    "print('Loss for Baseline Model: {}'.format(baseline_results))\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, model_name, baseline_model, preprocess_func, zero_features, subsample_func,\n",
    "               df, batch_size=None, epochs=100, sample_size=1.0, small_sample_size=2, verbose=1):\n",
    "    '''\n",
    "    Unit tests a model.\n",
    "\n",
    "    :param model: function, that returns a tf.keras.Model that performs binary classification.\n",
    "    :param baseline_model: function, that returns a tf.keras.Model that performs binary classification.\n",
    "                           This baseline model is usually more light weight than the model to be tested.\n",
    "    :param preprocess_func: function, that preprocess that the data accessed through :param df:. This function\n",
    "                            should return a (X, y) where X are the features to be processed, and y are the labels\n",
    "    :param zero_features: function, that takes X and returns an X that contains only the zero features.\n",
    "    :param subsample_func: function, that takes (X, y, sample_size, stratify) such that sample_size can be of type\n",
    "                           int representing the number of samples to draw, or type float representing the proportion \n",
    "                           of data to draw.\n",
    "    :param df: pandas.DataFrame, that stores the dataset\n",
    "    :param batch_size: int, batch size to use when training model\n",
    "    :param epochs: int, amount of epochs to train the model for\n",
    "    :param sample_size: int or float, sample size of the dataset that will be used in testing\n",
    "    :param small_sample_size: int or float, sample size of the small dataset the model will be overfit on \n",
    "    :param verbose: int, determines how much the function should print to screen \n",
    "    \n",
    "    ---> None\n",
    "    '''\n",
    "    \n",
    "    output_bias_init = 0\n",
    "    \n",
    "    # Printing Summary of model, and generating a picture of its graph\n",
    "    m = model()\n",
    "    print(m.summary())\n",
    "    print()\n",
    "    tf.keras.utils.plot_model(m, '_'.join([model_name,'model.png']))\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Preprocessing Data\n",
    "    dataset = preprocess_func(df)\n",
    "    X, y = subsample_func(features, labels, sample_size=1.0, stratify=True)\n",
    "    \n",
    "    # Checking that when initialized properly model == baseline model\n",
    "    print('Testing if the untrained model when initialized properly is equivalent to the baseline model')\n",
    "    baseline_m = build_compiled_model(baseline_model, {'output_bias_init': output_bias_init}, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    baseline_results = baseline_m.evaluate(X, y, verbose=0)\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    hparams1 = {'output_kernel_init': 'zeros', 'output_bias_init': output_bias_init}\n",
    "    m1 = build_compiled_model(model, hparams1, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m1_results = m1.evaluate(X, y, verbose=0)\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    assert m1_results == baseline_results\n",
    "    \n",
    "    # Checking that input independent model performs worse than when given correct data\n",
    "    print('Testing that the model performs better when trained on data than when trained on null data')\n",
    "    X_zeros = zero_features(X)\n",
    "    \n",
    "    hparams2 = {'output_bias_init': output_bias_init}\n",
    "    \n",
    "    m2 = build_compiled_model(model, hparams2, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m2_history = m2.fit(X_zeros, y, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "    m2_results = m2.evaluate(X, y, verbose=0)\n",
    "    loss_trained_on_zeros = m2_results[0]\n",
    "    if verbose > 0:\n",
    "        print()\n",
    "        print('Metrics for model trained on zeroed features.')\n",
    "        print()\n",
    "        print('Loss for Model: {}'.format(m2_results[0]))\n",
    "        print('True Positives for Model: {}'.format(m2_results[1]))\n",
    "        print('False Positives for Model: {}'.format(m2_results[2]))\n",
    "        print('True Negatives for Model: {}'.format(m2_results[3]))\n",
    "        print('False Negatives for Model: {}'.format(m2_results[4]))\n",
    "        print('Accuracy for Model: {}'.format(m2_results[5]))\n",
    "        print('Precision for Model: {}'.format(m2_results[6]))\n",
    "        print('Recall for Model: {}'.format(m2_results[7]))\n",
    "        print('AUC for Model: {}'.format(m2_results[8]))\n",
    "        print()\n",
    "    tf.keras.backend.clear_session()\n",
    "        \n",
    "    m3 = build_compiled_model(model, hparams2, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m3_history = m3.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "    m3_results = m3.evaluate(X, y, verbose=0)\n",
    "    loss_trained_on_data = m3_results[0]\n",
    "    if verbose > 0:\n",
    "        print()\n",
    "        print('Metrics for model trained on actual data.')\n",
    "        print()\n",
    "        print('Loss for Model: {}'.format(m3_results[0]))\n",
    "        print('True Positives for Model: {}'.format(m3_results[1]))\n",
    "        print('False Positives for Model: {}'.format(m3_results[2]))\n",
    "        print('True Negatives for Model: {}'.format(m3_results[3]))\n",
    "        print('False Negatives for Model: {}'.format(m3_results[4]))\n",
    "        print('Accuracy for Model: {}'.format(m3_results[5]))\n",
    "        print('Precision for Model: {}'.format(m3_results[6]))\n",
    "        print('Recall for Model: {}'.format(m3_results[7]))\n",
    "        print('AUC for Model: {}'.format(m3_results[8]))\n",
    "        print()\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    assert loss_trained_on_data < loss_trained_on_zeros\n",
    "    \n",
    "    # Overfitting on small sample of data\n",
    "    print('Testing if model can overfit on a small sample of data')\n",
    "    X_small, y_small = subsample_func(X, y, sample_size=small_sample_size, stratify=False)\n",
    "    \n",
    "    m4 = build_compiled_model(model, hparams2, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m4_pred_untrained = m4.predict(X_small) > 0.5\n",
    "    plot_errors(m4_pred_untrained, y_small, 'Before Training')\n",
    "    m4_history = m4.fit(X_small, y_small, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "    m4_pred_trained = m4.predict(X_small) > 0.5\n",
    "    plot_errors(m4_pred_trained, y_small, 'After Training')\n",
    "    \n",
    "    metrics = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "    for m in metrics:\n",
    "        plot_metric(m4_history, metric=m)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct model layers\n",
    "\n",
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                     weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                     input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                     embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                     activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                     mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/900\n",
      "10/10 [==============================] - 9s 931ms/sample - loss: 0.7232 - binary_accuracy: 0.4000 - precision: 0.4444 - recall: 0.8000 - val_loss: 0.6295 - val_binary_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.6247 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.5701 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.5637 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.5005 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4850 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.4236 - val_binary_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4067 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.3399 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.3082 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.1929 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.2051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.1055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0878 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0811 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0553 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0464 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0359 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0340 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0291 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0283 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0228 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0173 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0148 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0124 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0121 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0107 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0103 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9966e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9281e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7411e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4426e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2621e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2054e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0421e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.9851e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7769e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6302e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.5853e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4349e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.3829e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2519e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2021e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0748e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9037e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.8589e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7370e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6948e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5338e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4239e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3872e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.2373e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0947e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9945e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8377e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7343e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.7029e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6128e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5798e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4651e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3824e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.3501e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2733e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2459e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1667e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1396e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0647e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 6.0375e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9670e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.9406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8726e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.8479e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7810e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.7583e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6928e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.6716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6077e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.5861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5256e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.5047e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4458e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4245e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.3498e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2936e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2740e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2215e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2052e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1507e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1344e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0827e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0174e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0007e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9531e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8908e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 101/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8760e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8296e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 102/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7709e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 103/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7546e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7135e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 104/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.6983e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6571e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 105/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.6431e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 106/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.5876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 107/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.5349e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4964e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 108/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.4840e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4452e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 109/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4329e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 110/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 111/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3010e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 112/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.2893e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2545e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 113/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2428e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 114/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1986e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1653e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 115/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1222e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 116/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0803e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 117/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.0695e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0390e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 118/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0277e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9985e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 119/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9873e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 120/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9473e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9187e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 121/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9077e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8797e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 122/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.8700e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 123/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8043e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 124/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7676e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 125/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7585e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7316e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 126/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7222e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6965e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.6880e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6620e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 128/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.6530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6286e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 129/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6206e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 130/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5868e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 131/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5547e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5317e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 132/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5233e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 133/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4918e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4695e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 134/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4613e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4392e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 135/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4310e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 136/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4010e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 137/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3508e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 138/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3220e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 139/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3148e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2940e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 140/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 141/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2586e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 142/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2313e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2126e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 143/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2048e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1859e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 144/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1779e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 145/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1519e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1333e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 146/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1074e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 147/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1011e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0820e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 148/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0758e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0575e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 149/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0512e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0334e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 150/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0274e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0098e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 151/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9865e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 152/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9803e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9637e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 153/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9578e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 154/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9352e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9190e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 155/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9130e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8969e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 156/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8751e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 157/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 158/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8478e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 159/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8258e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 161/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7849e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7692e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 162/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7639e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 163/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 164/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7242e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7090e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 165/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7039e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 166/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6847e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6704e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 167/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6515e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 168/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6471e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 169/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6272e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 170/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6094e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 171/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 172/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5719e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 173/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.5542e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5412e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 174/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 175/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5189e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5055e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 176/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5009e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4881e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 177/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.4838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4710e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 178/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4663e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4541e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 179/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4373e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 180/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.4331e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4207e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 181/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.4161e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4044e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 182/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3883e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 183/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 184/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3679e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3560e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 185/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.3522e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3401e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 186/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3244e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 187/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 188/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.3053e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2942e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 189/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 190/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2756e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2649e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 191/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2611e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2506e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 192/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.2468e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2363e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2330e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2221e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 194/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2185e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2082e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 195/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.2041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1944e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 196/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1805e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 197/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1773e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1668e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 198/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.1633e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 199/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1499e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1402e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 200/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1366e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 201/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1240e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 202/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1011e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 203/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.0976e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0886e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 204/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0854e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 205/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0730e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0638e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 206/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0605e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0516e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 207/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0485e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 208/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0359e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0274e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 209/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0248e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0152e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 210/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0033e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 211/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0000e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9916e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 212/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.9888e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 213/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9766e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9683e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 214/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9654e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 215/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9539e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9456e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 216/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9424e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 217/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9316e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 218/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.9204e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9122e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 219/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.9093e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9012e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 220/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.8982e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8903e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 221/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 222/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.8767e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 223/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.8658e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8581e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 224/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8552e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 225/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8447e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8372e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.8341e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8268e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 227/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 228/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 229/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8035e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 230/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7936e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7860e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 231/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 232/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7735e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 233/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7642e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 234/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7544e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7475e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 235/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7450e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 236/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7357e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 237/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7196e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 238/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7170e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7106e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 239/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7082e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 240/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6989e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6927e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 241/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6902e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 242/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6812e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6749e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 243/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6727e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6661e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 244/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6636e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6574e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 245/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6550e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6488e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 246/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6462e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6403e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 247/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6382e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 248/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6299e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 249/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6215e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 250/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6076e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 251/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6056e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5998e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 252/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5921e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 253/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5901e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5845e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 254/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5825e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5769e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 255/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5748e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 256/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5673e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5619e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 257/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5544e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 258/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5524e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5470e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5453e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5397e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 260/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5379e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 261/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.5306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5254e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 262/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5184e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 263/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5164e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5115e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 264/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5096e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5045e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 265/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5027e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4977e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 266/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4958e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4909e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 267/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4891e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4841e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 268/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4823e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4774e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 269/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4757e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4707e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 270/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4642e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 271/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4625e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4578e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 272/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4560e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4514e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 273/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4450e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 274/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4386e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 275/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 276/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4307e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4260e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 277/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.4243e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4199e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 278/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4183e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4137e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 279/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4120e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4075e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 280/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.4060e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4015e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 281/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 282/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 283/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3881e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 284/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3779e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 285/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3763e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 286/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3663e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 287/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3648e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3605e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 288/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3590e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3549e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 289/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3533e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3493e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 290/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3477e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3437e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 291/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3423e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3367e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 293/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3311e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 294/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3256e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3216e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 295/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3162e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 296/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3149e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 297/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3095e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3056e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 298/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3042e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 299/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2990e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2951e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 300/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2937e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 301/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2885e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2847e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 302/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2833e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2795e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 303/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2782e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 304/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2731e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 305/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2680e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2643e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 306/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 307/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2580e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2543e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 308/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2494e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 309/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2481e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2445e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 310/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2396e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 311/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2383e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2347e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 312/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2299e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 313/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2286e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2251e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 314/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2239e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2204e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 315/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 316/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2144e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 317/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2097e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 318/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2049e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 319/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2004e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1970e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 320/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1957e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1924e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 321/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1912e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1879e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 322/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1833e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 323/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1788e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 324/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1777e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1733e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1699e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 326/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1687e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1655e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 327/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1645e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1612e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 328/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.1600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 329/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1557e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1526e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 330/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1515e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1483e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 331/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1472e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1440e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 332/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1429e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1398e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 333/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1388e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1356e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 334/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 335/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1304e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1273e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 336/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1263e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 337/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1221e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1191e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 338/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1181e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1151e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 339/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1140e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1110e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 340/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1099e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1070e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 341/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1059e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1030e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 342/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1019e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0990e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 343/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0950e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 344/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0940e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0910e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 345/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0900e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0871e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 346/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0832e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 347/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0822e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0793e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 348/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0783e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0754e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 349/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0744e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0716e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 350/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0677e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 351/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0668e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0639e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 352/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0601e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 353/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0592e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0564e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 354/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0554e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0527e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 355/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0517e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0490e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 356/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0480e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0453e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 357/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0443e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0416e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0380e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 359/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0371e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 360/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0308e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 361/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0298e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0272e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 362/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 363/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0227e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0201e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 364/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 365/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0156e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0130e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 366/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 367/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0086e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0060e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 368/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0025e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 369/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0016e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 370/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.9817e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9563e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 371/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9471e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9222e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 372/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9135e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 373/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8544e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 374/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8455e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8209e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 375/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.8119e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7875e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 376/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7788e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 377/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7454e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7212e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 378/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6883e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 379/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6554e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 380/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6464e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6229e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 381/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.6143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5904e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 382/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 383/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5260e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 384/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5176e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 385/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4855e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4622e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 386/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4542e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4305e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 387/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 9.4226e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3992e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 388/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 389/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3603e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 390/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.3291e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3065e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2984e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2760e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 392/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.2677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 393/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2372e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2152e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 394/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.2073e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1848e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 395/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.1769e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1547e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 396/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.1468e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1248e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 397/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0951e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 398/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.0870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0654e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 399/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0575e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0278e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0064e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 401/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9983e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9770e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 402/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.9689e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9476e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 403/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 404/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.9108e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8895e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 405/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 406/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8533e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 407/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8249e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 408/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7959e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7752e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 409/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7471e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 410/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7394e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7190e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 411/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7117e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6910e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 412/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6835e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6633e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 413/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6561e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 414/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6284e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 415/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.6010e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5807e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 416/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5535e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 417/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5463e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5264e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 418/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5192e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4995e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 419/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4922e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 420/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.4655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4461e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 421/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4390e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 422/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3929e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 423/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3859e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.3593e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 425/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 426/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2879e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 427/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2807e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2618e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 428/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2546e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 429/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2293e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2101e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 430/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.2032e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 431/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1591e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 432/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1521e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1337e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 433/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1269e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 434/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.1019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0831e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 435/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 436/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0519e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0335e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 437/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0268e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0090e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 438/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 439/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.9778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 440/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9535e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9353e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9110e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9046e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8867e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.8799e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8626e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 444/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8385e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8146e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8083e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7841e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7607e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.7371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7199e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 450/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.7138e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6965e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 451/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6904e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6732e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 452/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.6674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6501e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6043e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5981e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5816e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5757e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5527e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5302e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4911e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.4852e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.4631e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4466e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.4408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4245e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.4186e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4025e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3966e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3806e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3746e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3370e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3313e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3153e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3095e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2937e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2722e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 471/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.2235e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1657e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1447e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1391e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1239e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1183e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.0772e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0620e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0364e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0161e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0012e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9958e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9811e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9758e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9610e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9410e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9210e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.9155e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.8960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8812e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8419e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.8369e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8223e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8169e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8028e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7641e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7589e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7398e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7257e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7205e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7066e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7015e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6876e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6633e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6496e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6443e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6307e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6118e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.6066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5930e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.5881e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 505/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5694e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5557e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.5507e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5189e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5006e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4957e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4775e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4462e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4414e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4282e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4236e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4055e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3925e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3748e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.3701e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3571e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3523e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3395e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.3348e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3219e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3174e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3044e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2998e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2870e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2697e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2652e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2525e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.2480e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2310e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2139e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2014e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1968e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1845e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1632e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1339e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1172e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1126e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1005e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0837e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0627e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0341e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.0298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0177e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0015e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9853e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 539/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9810e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9692e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9648e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9531e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9488e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9371e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9328e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9211e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9009e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8893e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.8851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8692e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8577e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8420e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8263e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8223e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7952e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7334e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7181e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.7140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7029e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6989e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6877e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6838e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6726e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6685e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6575e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6537e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6425e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6386e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6277e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6237e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6129e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6089e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5944e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.5796e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5503e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5397e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5213e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5069e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4963e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4926e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4819e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4677e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 573/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4640e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4393e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4355e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4214e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4112e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3971e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.3934e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3832e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3656e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3278e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3242e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3103e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2865e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2827e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2691e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2592e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2420e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2151e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2054e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2018e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1920e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1885e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1750e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1655e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1620e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1522e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1391e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1259e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1225e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1128e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1094e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0998e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0834e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0739e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0704e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0611e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0482e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 607/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0064e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9970e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.9937e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9686e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9593e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9560e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9469e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9435e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9345e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9312e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9220e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9187e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8973e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8941e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8851e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8818e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8607e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8574e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8485e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8452e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8331e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7971e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7762e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7731e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7644e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7612e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7494e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7408e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7376e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7290e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7259e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7173e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7026e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6909e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6709e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6679e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6594e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.6564e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6478e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6449e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6250e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6219e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 641/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.5992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5909e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5574e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5544e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5463e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5433e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5352e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5131e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5101e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4993e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4912e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4664e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.4448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4369e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4341e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4261e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4154e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4125e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3913e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3835e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3808e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3702e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3625e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3597e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3520e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3415e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3387e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3311e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3283e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3208e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3180e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3104e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3077e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2973e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2898e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2795e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2590e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2460e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2387e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 675/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2285e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.2157e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2056e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1856e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1783e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1684e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1658e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1559e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1487e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1461e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1389e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1363e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1292e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1267e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1072e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0903e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0808e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0687e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0521e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0426e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0331e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0306e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0237e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0142e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0118e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0023e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9955e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9931e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9862e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.9837e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9769e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9744e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9651e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9558e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9466e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9398e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9373e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9306e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9281e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9191e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 709/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.9098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9006e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8916e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8759e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8669e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8467e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8378e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8290e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8025e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7961e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7939e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7873e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7764e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7700e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7614e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7528e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7442e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7334e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7250e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7102e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7079e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7018e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6995e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6934e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6765e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6743e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6659e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6598e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6515e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6432e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6410e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6349e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6327e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6267e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6245e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6185e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 743/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6163e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6081e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6021e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5999e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5939e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5918e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5858e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5836e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5777e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5755e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5696e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5512e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5454e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5035e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4977e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4821e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4722e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4511e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4491e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4413e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4337e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4281e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4261e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4184e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4127e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4107e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4031e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3975e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3955e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3749e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3728e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3674e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3579e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3524e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 777/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3449e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3430e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3375e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3302e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3282e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3228e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3155e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3082e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3063e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3009e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2990e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2936e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2917e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2864e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2844e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2791e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2700e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2647e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2576e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2433e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2415e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2343e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2291e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2221e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2132e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2080e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2062e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1923e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1871e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1853e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1784e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1733e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1715e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1664e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.1645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1508e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1457e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1388e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1301e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1251e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1183e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1115e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 811/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1029e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0980e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0962e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0913e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0895e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0779e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0761e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0646e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0629e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0514e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0382e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0365e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0317e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0300e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0234e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0057e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0040e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9993e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9928e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9863e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9846e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9799e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9783e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9719e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9545e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9481e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9465e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9418e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9402e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9356e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9339e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9293e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9277e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9231e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9215e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9169e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9152e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.9090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9045e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8983e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8921e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 845/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8905e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8860e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8843e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8798e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8737e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8721e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8660e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8600e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8539e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8494e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8478e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8418e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8314e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8254e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8238e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8195e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8179e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8120e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8076e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8060e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8017e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8001e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7958e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7942e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7840e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7782e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.7767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7724e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7708e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7666e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7550e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7492e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7477e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7377e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7362e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7304e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7262e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7247e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7205e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7148e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7091e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7020e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6978e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6922e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 879/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6907e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6866e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6810e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6754e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6739e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6698e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6683e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6643e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6587e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6573e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6532e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6422e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6367e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6258e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6244e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6096e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6082e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6042e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5988e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5935e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5921e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5867e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5827e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5813e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5774e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5721e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(None,), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: Model Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must have preprocessing component ran, and saved the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fractions import Fraction\n",
    "from functools import reduce\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Random Seed\n",
    "seed = 15\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame:\n",
      "    numbers letters\n",
      "25       26       z\n",
      "24       25       y\n",
      "23       24       x\n",
      "22       23       w\n",
      "21       22       v\n",
      "20       21       u\n",
      "19       20       t\n",
      "18       19       s\n",
      "17       18       r\n",
      "16       17       q\n",
      "15       16       p\n",
      "14       15       o\n",
      "13       14       n\n",
      "12       13       m\n",
      "11       12       l\n",
      "10       11       k\n",
      "9        10       j\n",
      "8         9       i\n",
      "7         8       h\n",
      "6         7       g\n",
      "5         6       f\n",
      "4         5       e\n",
      "3         4       d\n",
      "2         3       c\n",
      "1         2       b\n",
      "0         1       a\n",
      "\n",
      "Time Series DataFrame with a window size of n_trail+1\n",
      "    numbers(t-5) letters(t-5)  numbers(t-4) letters(t-4)  numbers(t-3)  \\\n",
      "24          20.0            t          21.0            u          22.0   \n",
      "23          19.0            s          20.0            t          21.0   \n",
      "22          18.0            r          19.0            s          20.0   \n",
      "21          17.0            q          18.0            r          19.0   \n",
      "20          16.0            p          17.0            q          18.0   \n",
      "19          15.0            o          16.0            p          17.0   \n",
      "18          14.0            n          15.0            o          16.0   \n",
      "17          13.0            m          14.0            n          15.0   \n",
      "16          12.0            l          13.0            m          14.0   \n",
      "15          11.0            k          12.0            l          13.0   \n",
      "14          10.0            j          11.0            k          12.0   \n",
      "13           9.0            i          10.0            j          11.0   \n",
      "12           8.0            h           9.0            i          10.0   \n",
      "11           7.0            g           8.0            h           9.0   \n",
      "10           6.0            f           7.0            g           8.0   \n",
      "9            5.0            e           6.0            f           7.0   \n",
      "8            4.0            d           5.0            e           6.0   \n",
      "7            3.0            c           4.0            d           5.0   \n",
      "6            2.0            b           3.0            c           4.0   \n",
      "5            1.0            a           2.0            b           3.0   \n",
      "\n",
      "   letters(t-3)  numbers(t-2) letters(t-2)  numbers(t-1) letters(t-1)  \\\n",
      "24            v          23.0            w          24.0            x   \n",
      "23            u          22.0            v          23.0            w   \n",
      "22            t          21.0            u          22.0            v   \n",
      "21            s          20.0            t          21.0            u   \n",
      "20            r          19.0            s          20.0            t   \n",
      "19            q          18.0            r          19.0            s   \n",
      "18            p          17.0            q          18.0            r   \n",
      "17            o          16.0            p          17.0            q   \n",
      "16            n          15.0            o          16.0            p   \n",
      "15            m          14.0            n          15.0            o   \n",
      "14            l          13.0            m          14.0            n   \n",
      "13            k          12.0            l          13.0            m   \n",
      "12            j          11.0            k          12.0            l   \n",
      "11            i          10.0            j          11.0            k   \n",
      "10            h           9.0            i          10.0            j   \n",
      "9             g           8.0            h           9.0            i   \n",
      "8             f           7.0            g           8.0            h   \n",
      "7             e           6.0            f           7.0            g   \n",
      "6             d           5.0            e           6.0            f   \n",
      "5             c           4.0            d           5.0            e   \n",
      "\n",
      "    numbers(t+0) letters(t+0)  numbers(t+1) letters(t+1)  \n",
      "24            25            y          26.0            z  \n",
      "23            24            x          25.0            y  \n",
      "22            23            w          24.0            x  \n",
      "21            22            v          23.0            w  \n",
      "20            21            u          22.0            v  \n",
      "19            20            t          21.0            u  \n",
      "18            19            s          20.0            t  \n",
      "17            18            r          19.0            s  \n",
      "16            17            q          18.0            r  \n",
      "15            16            p          17.0            q  \n",
      "14            15            o          16.0            p  \n",
      "13            14            n          15.0            o  \n",
      "12            13            m          14.0            n  \n",
      "11            12            l          13.0            m  \n",
      "10            11            k          12.0            l  \n",
      "9             10            j          11.0            k  \n",
      "8              9            i          10.0            j  \n",
      "7              8            h           9.0            i  \n",
      "6              7            g           8.0            h  \n",
      "5              6            f           7.0            g  \n"
     ]
    }
   ],
   "source": [
    "def to_time_series(df, columns, n_trail=1, n_lead=1):\n",
    "    '''\n",
    "    :param df: DataFrame, dataframe object where the columns are the features and labels and the rows are days\n",
    "    :param columns: list of strings, names of the features and labels (columns of df) to be used in the time series\n",
    "    :param n_trail: int, number of days behind day 0 that will be used to predict days after day 0\n",
    "    :param n_lead: int, number of days ahead of day 0 that will be predicted\n",
    "    \n",
    "    ---> DataFrame, dataframe object structured like a time series where each row represents an element in the time\n",
    "                    series, and each column is a feature or label a certain amount of days in the future or past.\n",
    "    '''\n",
    "    df = df[columns]\n",
    "    dfs = []\n",
    "    col_names = []\n",
    "    \n",
    "    # Create trailing columns\n",
    "    for i in range(n_trail, 0, -1):\n",
    "        dfs.append(df.shift(-i))\n",
    "        col_names += [(col_name + '(t-{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    # Create leading columns\n",
    "    for i in range(0, n_lead+1):\n",
    "        dfs.append(df.shift(i))\n",
    "        col_names += [(col_name + '(t+{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    agg = pd.concat(dfs, axis=1)\n",
    "    agg.columns = col_names\n",
    "    \n",
    "    agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Testing Function\n",
    "test_df = pd.DataFrame([(1, 'a'), (2, 'b'), (3, 'c'),\n",
    "                        (4, 'd'), (5, 'e'), (6, 'f'),\n",
    "                        (7, 'g'), (8, 'h'), (9, 'i'),\n",
    "                        (10, 'j'), (11, 'k'), (12, 'l'),\n",
    "                        (13, 'm'), (14, 'n'), (15, 'o'),\n",
    "                        (16, 'p'), (17, 'q'), (18, 'r'),\n",
    "                        (19, 's'), (20, 't'), (21, 'u'),\n",
    "                        (22, 'v'), (23, 'w'), (24, 'x'),\n",
    "                        (25, 'y'), (26, 'z')], columns=['numbers', 'letters'])\n",
    "test_df = test_df.reindex(index=test_df.index[::-1])\n",
    "print('Test DataFrame:')\n",
    "print(test_df)\n",
    "df = to_time_series(test_df, columns=test_df.columns, n_trail=5)\n",
    "print()\n",
    "print('Time Series DataFrame with a window size of n_trail+1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only pricing data from one ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  log_adj_daily_returns_JPM  \\\n",
       "0 2019-10-22                   0.003166                   0.009986   \n",
       "1 2019-10-21                   0.009758                   0.024498   \n",
       "2 2019-10-18                   0.007230                   0.001743   \n",
       "3 2019-10-17                   0.000403                   0.005583   \n",
       "4 2019-10-16                  -0.010431                  -0.002337   \n",
       "5 2019-10-15                   0.016905                   0.029696   \n",
       "6 2019-10-14                   0.001219                   0.002666   \n",
       "7 2019-10-11                   0.011445                   0.016758   \n",
       "\n",
       "   log_adj_daily_returns_BAC  log_adj_daily_returns_C  \n",
       "0                   0.005786                 0.003475  \n",
       "1                   0.021836                 0.029250  \n",
       "2                   0.002970                 0.002009  \n",
       "3                   0.002979                 0.001438  \n",
       "4                   0.014691                -0.024447  \n",
       "5                   0.020045                 0.013856  \n",
       "6                   0.007924                 0.001995  \n",
       "7                   0.016039                 0.021339  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 1000\n",
    "batch_size = 1000\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-4)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_C(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+0)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_BAC(t-5)  \\\n",
       "1                        0.002666                        0.007924   \n",
       "2                        0.016758                        0.016039   \n",
       "3                        0.013931                        0.019880   \n",
       "4                        0.007218                        0.009366   \n",
       "5                       -0.022548                       -0.024313   \n",
       "\n",
       "   log_adj_daily_returns_C(t-5) timestamp(t-4)  \\\n",
       "1                      0.001995     2019-10-15   \n",
       "2                      0.021339     2019-10-14   \n",
       "3                      0.017494     2019-10-11   \n",
       "4                      0.015393     2019-10-10   \n",
       "5                     -0.026014     2019-10-09   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-4)  log_adj_daily_returns_JPM(t-4)  \\\n",
       "1                        0.016905                        0.029696   \n",
       "2                        0.001219                        0.002666   \n",
       "3                        0.011445                        0.016758   \n",
       "4                        0.010331                        0.013931   \n",
       "5                        0.006877                        0.007218   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-4)  log_adj_daily_returns_C(t-4)  ...  \\\n",
       "1                        0.020045                      0.013856  ...   \n",
       "2                        0.007924                      0.001995  ...   \n",
       "3                        0.016039                      0.021339  ...   \n",
       "4                        0.019880                      0.017494  ...   \n",
       "5                        0.009366                      0.015393  ...   \n",
       "\n",
       "  timestamp(t+0)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1     2019-10-21                        0.009758   \n",
       "2     2019-10-18                        0.007230   \n",
       "3     2019-10-17                        0.000403   \n",
       "4     2019-10-16                       -0.010431   \n",
       "5     2019-10-15                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+0)  log_adj_daily_returns_BAC(t+0)  \\\n",
       "1                        0.024498                        0.021836   \n",
       "2                        0.001743                        0.002970   \n",
       "3                        0.005583                        0.002979   \n",
       "4                       -0.002337                        0.014691   \n",
       "5                        0.029696                        0.020045   \n",
       "\n",
       "   log_adj_daily_returns_C(t+0) timestamp(t+1)  \\\n",
       "1                      0.029250     2019-10-22   \n",
       "2                      0.002009     2019-10-21   \n",
       "3                      0.001438     2019-10-18   \n",
       "4                     -0.024447     2019-10-17   \n",
       "5                      0.013856     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  log_adj_daily_returns_JPM(t+1)  \\\n",
       "1                        0.003166                        0.009986   \n",
       "2                        0.009758                        0.024498   \n",
       "3                        0.007230                        0.001743   \n",
       "4                        0.000403                        0.005583   \n",
       "5                       -0.010431                       -0.002337   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  log_adj_daily_returns_C(t+1)  \n",
       "1                        0.005786                      0.003475  \n",
       "2                        0.021836                      0.029250  \n",
       "3                        0.002970                      0.002009  \n",
       "4                        0.002979                      0.001438  \n",
       "5                        0.014691                     -0.024447  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)']]\n"
     ]
    }
   ],
   "source": [
    "column_names_by_ticker = [[name for name in df.columns if 'log_adj_daily_returns_' + t in name] for t in tickers]\n",
    "print(column_names_by_ticker)\n",
    "# Using only data from ticker WFC\n",
    "cols = column_names_by_ticker[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-3)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-2)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
       "1                        0.001219                        0.016905   \n",
       "2                        0.011445                        0.001219   \n",
       "3                        0.010331                        0.011445   \n",
       "4                        0.006877                        0.010331   \n",
       "5                       -0.020491                        0.006877   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
       "1                       -0.010431                        0.000403   \n",
       "2                        0.016905                       -0.010431   \n",
       "3                        0.001219                        0.016905   \n",
       "4                        0.011445                        0.001219   \n",
       "5                        0.010331                        0.011445   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1                        0.007230                        0.009758   \n",
       "2                        0.000403                        0.007230   \n",
       "3                       -0.010431                        0.000403   \n",
       "4                        0.016905                       -0.010431   \n",
       "5                        0.001219                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  \n",
       "1                        0.003166  \n",
       "2                        0.009758  \n",
       "3                        0.007230  \n",
       "4                        0.000403  \n",
       "5                       -0.010431  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if columns are still in the right order\n",
    "df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset: 5024\n"
     ]
    }
   ],
   "source": [
    "dataset = df[cols].values\n",
    "print('Length of Dataset: {}'.format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00121852  0.01690521 -0.01043139  0.00040323  0.0072304   0.00975812\n",
      "  0.00316581]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled Dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and Sampling Dataset\n",
    "shuffled_indices = np.random.choice(len(dataset), size=dataset_size, replace=False)\n",
    "assert (len(shuffled_indices) == dataset_size) and (shuffled_indices.dtype == np.int64)\n",
    "shuffled_dataset = dataset[shuffled_indices]\n",
    "print('Shuffled Dataset size: {}'.format(len(shuffled_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Dataset into Features and Labels\n",
    "X, y = shuffled_dataset[:, :-1], shuffled_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/900\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 5.5342e-04 - val_loss: 9.4334e-04\n",
      "Epoch 2/900\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 9.4334e-04 - val_loss: 5.6727e-04\n",
      "Epoch 3/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.6727e-04 - val_loss: 6.2682e-04\n",
      "Epoch 4/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 6.2682e-04 - val_loss: 7.2747e-04\n",
      "Epoch 5/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 7.2747e-04 - val_loss: 6.8187e-04\n",
      "Epoch 6/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 6.8187e-04 - val_loss: 5.9401e-04\n",
      "Epoch 7/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.9401e-04 - val_loss: 5.5202e-04\n",
      "Epoch 8/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5202e-04 - val_loss: 5.6980e-04\n",
      "Epoch 9/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.6980e-04 - val_loss: 6.0640e-04\n",
      "Epoch 10/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 6.0640e-04 - val_loss: 6.1700e-04\n",
      "Epoch 11/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 6.1700e-04 - val_loss: 5.9880e-04\n",
      "Epoch 12/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.9880e-04 - val_loss: 5.7252e-04\n",
      "Epoch 13/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.7252e-04 - val_loss: 5.5519e-04\n",
      "Epoch 14/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5519e-04 - val_loss: 5.5169e-04\n",
      "Epoch 15/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5169e-04 - val_loss: 5.5797e-04\n",
      "Epoch 16/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5797e-04 - val_loss: 5.6661e-04\n",
      "Epoch 17/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.6661e-04 - val_loss: 5.7150e-04\n",
      "Epoch 18/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.7150e-04 - val_loss: 5.7037e-04\n",
      "Epoch 19/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.7037e-04 - val_loss: 5.6462e-04\n",
      "Epoch 20/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.6462e-04 - val_loss: 5.5762e-04\n",
      "Epoch 21/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5762e-04 - val_loss: 5.5266e-04\n",
      "Epoch 22/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5266e-04 - val_loss: 5.5149e-04\n",
      "Epoch 23/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5149e-04 - val_loss: 5.5378e-04\n",
      "Epoch 24/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5378e-04 - val_loss: 5.5746e-04\n",
      "Epoch 25/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5746e-04 - val_loss: 5.6000e-04\n",
      "Epoch 26/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.6000e-04 - val_loss: 5.5993e-04\n",
      "Epoch 27/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5993e-04 - val_loss: 5.5757e-04\n",
      "Epoch 28/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5757e-04 - val_loss: 5.5442e-04\n",
      "Epoch 29/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5442e-04 - val_loss: 5.5210e-04\n",
      "Epoch 30/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5210e-04 - val_loss: 5.5142e-04\n",
      "Epoch 31/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5142e-04 - val_loss: 5.5222e-04\n",
      "Epoch 32/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5222e-04 - val_loss: 5.5366e-04\n",
      "Epoch 33/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5366e-04 - val_loss: 5.5480e-04\n",
      "Epoch 34/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5480e-04 - val_loss: 5.5506e-04\n",
      "Epoch 35/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5506e-04 - val_loss: 5.5437e-04\n",
      "Epoch 36/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5437e-04 - val_loss: 5.5316e-04\n",
      "Epoch 37/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5316e-04 - val_loss: 5.5202e-04\n",
      "Epoch 38/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5202e-04 - val_loss: 5.5144e-04\n",
      "Epoch 39/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5144e-04 - val_loss: 5.5154e-04\n",
      "Epoch 40/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5154e-04 - val_loss: 5.5210e-04\n",
      "Epoch 41/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5210e-04 - val_loss: 5.5269e-04\n",
      "Epoch 42/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5269e-04 - val_loss: 5.5297e-04\n",
      "Epoch 43/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5297e-04 - val_loss: 5.5279e-04\n",
      "Epoch 44/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5279e-04 - val_loss: 5.5230e-04\n",
      "Epoch 45/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5230e-04 - val_loss: 5.5177e-04\n",
      "Epoch 46/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5177e-04 - val_loss: 5.5144e-04\n",
      "Epoch 47/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5144e-04 - val_loss: 5.5143e-04\n",
      "Epoch 48/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5143e-04 - val_loss: 5.5165e-04\n",
      "Epoch 49/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5165e-04 - val_loss: 5.5192e-04\n",
      "Epoch 50/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5192e-04 - val_loss: 5.5207e-04\n",
      "Epoch 51/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5207e-04 - val_loss: 5.5202e-04\n",
      "Epoch 52/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.5202e-04 - val_loss: 5.5181e-04\n",
      "Epoch 53/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5181e-04 - val_loss: 5.5157e-04\n",
      "Epoch 54/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5157e-04 - val_loss: 5.5142e-04\n",
      "Epoch 55/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5142e-04 - val_loss: 5.5140e-04\n",
      "Epoch 56/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5140e-04 - val_loss: 5.5150e-04\n",
      "Epoch 57/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5150e-04 - val_loss: 5.5162e-04\n",
      "Epoch 58/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5162e-04 - val_loss: 5.5169e-04\n",
      "Epoch 59/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5169e-04 - val_loss: 5.5166e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5166e-04 - val_loss: 5.5156e-04\n",
      "Epoch 61/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 5.5156e-04 - val_loss: 5.5146e-04\n",
      "Epoch 62/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5146e-04 - val_loss: 5.5139e-04\n",
      "Epoch 63/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.5139e-04 - val_loss: 5.5140e-04\n",
      "Epoch 64/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5140e-04 - val_loss: 5.5145e-04\n",
      "Epoch 65/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5145e-04 - val_loss: 5.5150e-04\n",
      "Epoch 66/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5150e-04 - val_loss: 5.5152e-04\n",
      "Epoch 67/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5152e-04 - val_loss: 5.5150e-04\n",
      "Epoch 68/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5150e-04 - val_loss: 5.5145e-04\n",
      "Epoch 69/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5145e-04 - val_loss: 5.5140e-04\n",
      "Epoch 70/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.5140e-04 - val_loss: 5.5138e-04\n",
      "Epoch 71/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5138e-04 - val_loss: 5.5139e-04\n",
      "Epoch 72/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5139e-04 - val_loss: 5.5142e-04\n",
      "Epoch 73/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5142e-04 - val_loss: 5.5144e-04\n",
      "Epoch 74/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5144e-04 - val_loss: 5.5144e-04\n",
      "Epoch 75/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.5144e-04 - val_loss: 5.5142e-04\n",
      "Epoch 76/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5142e-04 - val_loss: 5.5139e-04\n",
      "Epoch 77/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5139e-04 - val_loss: 5.5137e-04\n",
      "Epoch 78/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 79/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5137e-04 - val_loss: 5.5138e-04\n",
      "Epoch 80/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5138e-04 - val_loss: 5.5140e-04\n",
      "Epoch 81/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 5.5140e-04 - val_loss: 5.5140e-04\n",
      "Epoch 82/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.5140e-04 - val_loss: 5.5139e-04\n",
      "Epoch 83/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5139e-04 - val_loss: 5.5138e-04\n",
      "Epoch 84/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5138e-04 - val_loss: 5.5137e-04\n",
      "Epoch 85/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5137e-04 - val_loss: 5.5136e-04\n",
      "Epoch 86/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5136e-04 - val_loss: 5.5137e-04\n",
      "Epoch 87/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 88/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5137e-04 - val_loss: 5.5138e-04\n",
      "Epoch 89/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5138e-04 - val_loss: 5.5137e-04\n",
      "Epoch 90/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 91/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 92/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 93/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 94/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 95/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 96/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 97/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5136e-04 - val_loss: 5.5135e-04\n",
      "Epoch 98/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 99/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 100/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 101/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 102/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 103/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 104/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5135e-04 - val_loss: 5.5134e-04\n",
      "Epoch 105/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 106/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 107/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 108/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 109/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 110/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5134e-04 - val_loss: 5.5133e-04\n",
      "Epoch 111/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 112/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 113/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 114/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 115/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 116/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5133e-04 - val_loss: 5.5132e-04\n",
      "Epoch 117/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 118/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 119/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 120/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 121/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 122/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5132e-04 - val_loss: 5.5131e-04\n",
      "Epoch 123/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 124/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 125/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 126/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 127/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5131e-04 - val_loss: 5.5130e-04\n",
      "Epoch 128/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 129/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 130/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 132/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5129e-04\n",
      "Epoch 133/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 134/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 135/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 136/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 137/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5129e-04 - val_loss: 5.5128e-04\n",
      "Epoch 138/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 139/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 140/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 141/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5128e-04 - val_loss: 5.5127e-04\n",
      "Epoch 142/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 143/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 144/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 145/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5127e-04 - val_loss: 5.5126e-04\n",
      "Epoch 146/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 147/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 148/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 149/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5126e-04 - val_loss: 5.5125e-04\n",
      "Epoch 150/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5125e-04 - val_loss: 5.5125e-04\n",
      "Epoch 151/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5125e-04 - val_loss: 5.5125e-04\n",
      "Epoch 152/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5125e-04 - val_loss: 5.5124e-04\n",
      "Epoch 153/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 154/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 155/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 156/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5124e-04 - val_loss: 5.5123e-04\n",
      "Epoch 157/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5123e-04 - val_loss: 5.5123e-04\n",
      "Epoch 158/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5123e-04 - val_loss: 5.5123e-04\n",
      "Epoch 159/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5123e-04 - val_loss: 5.5122e-04\n",
      "Epoch 160/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5122e-04 - val_loss: 5.5122e-04\n",
      "Epoch 161/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5122e-04 - val_loss: 5.5122e-04\n",
      "Epoch 162/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5122e-04 - val_loss: 5.5121e-04\n",
      "Epoch 163/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5121e-04 - val_loss: 5.5121e-04\n",
      "Epoch 164/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5121e-04 - val_loss: 5.5120e-04\n",
      "Epoch 165/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5120e-04 - val_loss: 5.5120e-04\n",
      "Epoch 166/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5120e-04 - val_loss: 5.5120e-04\n",
      "Epoch 167/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5120e-04 - val_loss: 5.5119e-04\n",
      "Epoch 168/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5119e-04 - val_loss: 5.5119e-04\n",
      "Epoch 169/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5119e-04 - val_loss: 5.5118e-04\n",
      "Epoch 170/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5118e-04 - val_loss: 5.5118e-04\n",
      "Epoch 171/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5118e-04 - val_loss: 5.5117e-04\n",
      "Epoch 172/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5117e-04 - val_loss: 5.5117e-04\n",
      "Epoch 173/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5117e-04 - val_loss: 5.5117e-04\n",
      "Epoch 174/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5117e-04 - val_loss: 5.5116e-04\n",
      "Epoch 175/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5116e-04 - val_loss: 5.5116e-04\n",
      "Epoch 176/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5116e-04 - val_loss: 5.5115e-04\n",
      "Epoch 177/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5115e-04 - val_loss: 5.5115e-04\n",
      "Epoch 178/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5115e-04 - val_loss: 5.5114e-04\n",
      "Epoch 179/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5114e-04 - val_loss: 5.5114e-04\n",
      "Epoch 180/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5114e-04 - val_loss: 5.5113e-04\n",
      "Epoch 181/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5113e-04 - val_loss: 5.5112e-04\n",
      "Epoch 182/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5112e-04 - val_loss: 5.5112e-04\n",
      "Epoch 183/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5112e-04 - val_loss: 5.5111e-04\n",
      "Epoch 184/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5111e-04 - val_loss: 5.5111e-04\n",
      "Epoch 185/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5111e-04 - val_loss: 5.5110e-04\n",
      "Epoch 186/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5110e-04 - val_loss: 5.5109e-04\n",
      "Epoch 187/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5109e-04 - val_loss: 5.5109e-04\n",
      "Epoch 188/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5109e-04 - val_loss: 5.5108e-04\n",
      "Epoch 189/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5108e-04 - val_loss: 5.5107e-04\n",
      "Epoch 190/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5107e-04 - val_loss: 5.5107e-04\n",
      "Epoch 191/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5107e-04 - val_loss: 5.5106e-04\n",
      "Epoch 192/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5106e-04 - val_loss: 5.5105e-04\n",
      "Epoch 193/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5105e-04 - val_loss: 5.5104e-04\n",
      "Epoch 194/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5104e-04 - val_loss: 5.5103e-04\n",
      "Epoch 195/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5103e-04 - val_loss: 5.5103e-04\n",
      "Epoch 196/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5103e-04 - val_loss: 5.5102e-04\n",
      "Epoch 197/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5102e-04 - val_loss: 5.5101e-04\n",
      "Epoch 198/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5101e-04 - val_loss: 5.5100e-04\n",
      "Epoch 199/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5100e-04 - val_loss: 5.5099e-04\n",
      "Epoch 200/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5099e-04 - val_loss: 5.5098e-04\n",
      "Epoch 201/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5098e-04 - val_loss: 5.5097e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5097e-04 - val_loss: 5.5096e-04\n",
      "Epoch 203/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5096e-04 - val_loss: 5.5095e-04\n",
      "Epoch 204/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5095e-04 - val_loss: 5.5094e-04\n",
      "Epoch 205/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5094e-04 - val_loss: 5.5093e-04\n",
      "Epoch 206/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5093e-04 - val_loss: 5.5092e-04\n",
      "Epoch 207/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5092e-04 - val_loss: 5.5091e-04\n",
      "Epoch 208/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5091e-04 - val_loss: 5.5089e-04\n",
      "Epoch 209/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5089e-04 - val_loss: 5.5088e-04\n",
      "Epoch 210/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5088e-04 - val_loss: 5.5087e-04\n",
      "Epoch 211/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5087e-04 - val_loss: 5.5086e-04\n",
      "Epoch 212/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5086e-04 - val_loss: 5.5084e-04\n",
      "Epoch 213/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5084e-04 - val_loss: 5.5083e-04\n",
      "Epoch 214/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5083e-04 - val_loss: 5.5081e-04\n",
      "Epoch 215/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5081e-04 - val_loss: 5.5080e-04\n",
      "Epoch 216/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5080e-04 - val_loss: 5.5078e-04\n",
      "Epoch 217/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5078e-04 - val_loss: 5.5076e-04\n",
      "Epoch 218/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5076e-04 - val_loss: 5.5075e-04\n",
      "Epoch 219/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5075e-04 - val_loss: 5.5073e-04\n",
      "Epoch 220/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5073e-04 - val_loss: 5.5071e-04\n",
      "Epoch 221/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5071e-04 - val_loss: 5.5069e-04\n",
      "Epoch 222/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5069e-04 - val_loss: 5.5067e-04\n",
      "Epoch 223/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5067e-04 - val_loss: 5.5065e-04\n",
      "Epoch 224/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5065e-04 - val_loss: 5.5063e-04\n",
      "Epoch 225/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5063e-04 - val_loss: 5.5061e-04\n",
      "Epoch 226/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5061e-04 - val_loss: 5.5059e-04\n",
      "Epoch 227/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 5.5059e-04 - val_loss: 5.5057e-04\n",
      "Epoch 228/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5057e-04 - val_loss: 5.5054e-04\n",
      "Epoch 229/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5054e-04 - val_loss: 5.5052e-04\n",
      "Epoch 230/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5052e-04 - val_loss: 5.5049e-04\n",
      "Epoch 231/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5049e-04 - val_loss: 5.5046e-04\n",
      "Epoch 232/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5046e-04 - val_loss: 5.5043e-04\n",
      "Epoch 233/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5043e-04 - val_loss: 5.5041e-04\n",
      "Epoch 234/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5041e-04 - val_loss: 5.5038e-04\n",
      "Epoch 235/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5038e-04 - val_loss: 5.5034e-04\n",
      "Epoch 236/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5034e-04 - val_loss: 5.5031e-04\n",
      "Epoch 237/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5031e-04 - val_loss: 5.5028e-04\n",
      "Epoch 238/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5028e-04 - val_loss: 5.5024e-04\n",
      "Epoch 239/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5024e-04 - val_loss: 5.5020e-04\n",
      "Epoch 240/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5020e-04 - val_loss: 5.5017e-04\n",
      "Epoch 241/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5017e-04 - val_loss: 5.5013e-04\n",
      "Epoch 242/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5013e-04 - val_loss: 5.5008e-04\n",
      "Epoch 243/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5008e-04 - val_loss: 5.5004e-04\n",
      "Epoch 244/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5004e-04 - val_loss: 5.5000e-04\n",
      "Epoch 245/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5000e-04 - val_loss: 5.4995e-04\n",
      "Epoch 246/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4995e-04 - val_loss: 5.4990e-04\n",
      "Epoch 247/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4990e-04 - val_loss: 5.4985e-04\n",
      "Epoch 248/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4985e-04 - val_loss: 5.4980e-04\n",
      "Epoch 249/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4980e-04 - val_loss: 5.4974e-04\n",
      "Epoch 250/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.4974e-04 - val_loss: 5.4968e-04\n",
      "Epoch 251/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4968e-04 - val_loss: 5.4962e-04\n",
      "Epoch 252/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4962e-04 - val_loss: 5.4956e-04\n",
      "Epoch 253/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4956e-04 - val_loss: 5.4950e-04\n",
      "Epoch 254/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4950e-04 - val_loss: 5.4943e-04\n",
      "Epoch 255/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4943e-04 - val_loss: 5.4936e-04\n",
      "Epoch 256/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4936e-04 - val_loss: 5.4928e-04\n",
      "Epoch 257/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4928e-04 - val_loss: 5.4921e-04\n",
      "Epoch 258/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4921e-04 - val_loss: 5.4913e-04\n",
      "Epoch 259/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4913e-04 - val_loss: 5.4905e-04\n",
      "Epoch 260/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4905e-04 - val_loss: 5.4896e-04\n",
      "Epoch 261/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4896e-04 - val_loss: 5.4888e-04\n",
      "Epoch 262/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4888e-04 - val_loss: 5.4879e-04\n",
      "Epoch 263/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4879e-04 - val_loss: 5.4869e-04\n",
      "Epoch 264/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4869e-04 - val_loss: 5.4860e-04\n",
      "Epoch 265/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4860e-04 - val_loss: 5.4850e-04\n",
      "Epoch 266/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4850e-04 - val_loss: 5.4840e-04\n",
      "Epoch 267/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4840e-04 - val_loss: 5.4829e-04\n",
      "Epoch 268/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4829e-04 - val_loss: 5.4819e-04\n",
      "Epoch 269/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4819e-04 - val_loss: 5.4808e-04\n",
      "Epoch 270/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4808e-04 - val_loss: 5.4797e-04\n",
      "Epoch 271/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4797e-04 - val_loss: 5.4786e-04\n",
      "Epoch 272/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4786e-04 - val_loss: 5.4776e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4776e-04 - val_loss: 5.4765e-04\n",
      "Epoch 274/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4765e-04 - val_loss: 5.4754e-04\n",
      "Epoch 275/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4754e-04 - val_loss: 5.4743e-04\n",
      "Epoch 276/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4743e-04 - val_loss: 5.4733e-04\n",
      "Epoch 277/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4733e-04 - val_loss: 5.4723e-04\n",
      "Epoch 278/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4723e-04 - val_loss: 5.4714e-04\n",
      "Epoch 279/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4714e-04 - val_loss: 5.4705e-04\n",
      "Epoch 280/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4705e-04 - val_loss: 5.4696e-04\n",
      "Epoch 281/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4696e-04 - val_loss: 5.4689e-04\n",
      "Epoch 282/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4689e-04 - val_loss: 5.4682e-04\n",
      "Epoch 283/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4682e-04 - val_loss: 5.4676e-04\n",
      "Epoch 284/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4676e-04 - val_loss: 5.4671e-04\n",
      "Epoch 285/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4671e-04 - val_loss: 5.4667e-04\n",
      "Epoch 286/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4667e-04 - val_loss: 5.4663e-04\n",
      "Epoch 287/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.4663e-04 - val_loss: 5.4661e-04\n",
      "Epoch 288/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4661e-04 - val_loss: 5.4665e-04\n",
      "Epoch 289/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4665e-04 - val_loss: 5.4748e-04\n",
      "Epoch 290/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4748e-04 - val_loss: 5.5622e-04\n",
      "Epoch 291/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5622e-04 - val_loss: 5.7902e-04\n",
      "Epoch 292/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.7902e-04 - val_loss: 5.5763e-04\n",
      "Epoch 293/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5763e-04 - val_loss: 5.5668e-04\n",
      "Epoch 294/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5668e-04 - val_loss: 5.5424e-04\n",
      "Epoch 295/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5424e-04 - val_loss: 5.5573e-04\n",
      "Epoch 296/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5573e-04 - val_loss: 5.4783e-04\n",
      "Epoch 297/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4783e-04 - val_loss: 5.5567e-04\n",
      "Epoch 298/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5567e-04 - val_loss: 5.4926e-04\n",
      "Epoch 299/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4926e-04 - val_loss: 5.4876e-04\n",
      "Epoch 300/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4876e-04 - val_loss: 5.5265e-04\n",
      "Epoch 301/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5265e-04 - val_loss: 5.4968e-04\n",
      "Epoch 302/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4968e-04 - val_loss: 5.4802e-04\n",
      "Epoch 303/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4802e-04 - val_loss: 5.5041e-04\n",
      "Epoch 304/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5041e-04 - val_loss: 5.5072e-04\n",
      "Epoch 305/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5072e-04 - val_loss: 5.4872e-04\n",
      "Epoch 306/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4872e-04 - val_loss: 5.4851e-04\n",
      "Epoch 307/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4851e-04 - val_loss: 5.4988e-04\n",
      "Epoch 308/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4988e-04 - val_loss: 5.4992e-04\n",
      "Epoch 309/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4992e-04 - val_loss: 5.4875e-04\n",
      "Epoch 310/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4875e-04 - val_loss: 5.4850e-04\n",
      "Epoch 311/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4850e-04 - val_loss: 5.4928e-04\n",
      "Epoch 312/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4928e-04 - val_loss: 5.4945e-04\n",
      "Epoch 313/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4945e-04 - val_loss: 5.4873e-04\n",
      "Epoch 314/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.4873e-04 - val_loss: 5.4834e-04\n",
      "Epoch 315/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4834e-04 - val_loss: 5.4873e-04\n",
      "Epoch 316/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4873e-04 - val_loss: 5.4895e-04\n",
      "Epoch 317/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4895e-04 - val_loss: 5.4849e-04\n",
      "Epoch 318/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4849e-04 - val_loss: 5.4810e-04\n",
      "Epoch 319/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4810e-04 - val_loss: 5.4826e-04\n",
      "Epoch 320/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4826e-04 - val_loss: 5.4842e-04\n",
      "Epoch 321/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4842e-04 - val_loss: 5.4809e-04\n",
      "Epoch 322/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4809e-04 - val_loss: 5.4774e-04\n",
      "Epoch 323/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4774e-04 - val_loss: 5.4781e-04\n",
      "Epoch 324/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4781e-04 - val_loss: 5.4787e-04\n",
      "Epoch 325/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4787e-04 - val_loss: 5.4756e-04\n",
      "Epoch 326/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4756e-04 - val_loss: 5.4730e-04\n",
      "Epoch 327/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4730e-04 - val_loss: 5.4736e-04\n",
      "Epoch 328/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4736e-04 - val_loss: 5.4730e-04\n",
      "Epoch 329/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4730e-04 - val_loss: 5.4699e-04\n",
      "Epoch 330/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4699e-04 - val_loss: 5.4689e-04\n",
      "Epoch 331/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4689e-04 - val_loss: 5.4692e-04\n",
      "Epoch 332/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4692e-04 - val_loss: 5.4671e-04\n",
      "Epoch 333/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4671e-04 - val_loss: 5.4654e-04\n",
      "Epoch 334/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4654e-04 - val_loss: 5.4657e-04\n",
      "Epoch 335/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4657e-04 - val_loss: 5.4643e-04\n",
      "Epoch 336/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4643e-04 - val_loss: 5.4628e-04\n",
      "Epoch 337/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4628e-04 - val_loss: 5.4631e-04\n",
      "Epoch 338/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4631e-04 - val_loss: 5.4621e-04\n",
      "Epoch 339/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4621e-04 - val_loss: 5.4611e-04\n",
      "Epoch 340/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4611e-04 - val_loss: 5.4615e-04\n",
      "Epoch 341/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4615e-04 - val_loss: 5.4605e-04\n",
      "Epoch 342/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4605e-04 - val_loss: 5.4604e-04\n",
      "Epoch 343/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4604e-04 - val_loss: 5.4606e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4606e-04 - val_loss: 5.4598e-04\n",
      "Epoch 345/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4598e-04 - val_loss: 5.4603e-04\n",
      "Epoch 346/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4603e-04 - val_loss: 5.4600e-04\n",
      "Epoch 347/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4600e-04 - val_loss: 5.4599e-04\n",
      "Epoch 348/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4599e-04 - val_loss: 5.4601e-04\n",
      "Epoch 349/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4601e-04 - val_loss: 5.4596e-04\n",
      "Epoch 350/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4596e-04 - val_loss: 5.4599e-04\n",
      "Epoch 351/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4599e-04 - val_loss: 5.4595e-04\n",
      "Epoch 352/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4595e-04 - val_loss: 5.4594e-04\n",
      "Epoch 353/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4594e-04 - val_loss: 5.4593e-04\n",
      "Epoch 354/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4593e-04 - val_loss: 5.4589e-04\n",
      "Epoch 355/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4589e-04 - val_loss: 5.4589e-04\n",
      "Epoch 356/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4589e-04 - val_loss: 5.4584e-04\n",
      "Epoch 357/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4584e-04 - val_loss: 5.4583e-04\n",
      "Epoch 358/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4583e-04 - val_loss: 5.4580e-04\n",
      "Epoch 359/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4580e-04 - val_loss: 5.4578e-04\n",
      "Epoch 360/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4578e-04 - val_loss: 5.4576e-04\n",
      "Epoch 361/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4576e-04 - val_loss: 5.4573e-04\n",
      "Epoch 362/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4573e-04 - val_loss: 5.4572e-04\n",
      "Epoch 363/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4572e-04 - val_loss: 5.4569e-04\n",
      "Epoch 364/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4569e-04 - val_loss: 5.4567e-04\n",
      "Epoch 365/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4567e-04 - val_loss: 5.4566e-04\n",
      "Epoch 366/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4566e-04 - val_loss: 5.4563e-04\n",
      "Epoch 367/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4563e-04 - val_loss: 5.4562e-04\n",
      "Epoch 368/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4562e-04 - val_loss: 5.4560e-04\n",
      "Epoch 369/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4560e-04 - val_loss: 5.4558e-04\n",
      "Epoch 370/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4558e-04 - val_loss: 5.4557e-04\n",
      "Epoch 371/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4557e-04 - val_loss: 5.4554e-04\n",
      "Epoch 372/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4554e-04 - val_loss: 5.4553e-04\n",
      "Epoch 373/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4553e-04 - val_loss: 5.4551e-04\n",
      "Epoch 374/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4551e-04 - val_loss: 5.4549e-04\n",
      "Epoch 375/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4549e-04 - val_loss: 5.4547e-04\n",
      "Epoch 376/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4547e-04 - val_loss: 5.4545e-04\n",
      "Epoch 377/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4545e-04 - val_loss: 5.4543e-04\n",
      "Epoch 378/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4543e-04 - val_loss: 5.4541e-04\n",
      "Epoch 379/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4541e-04 - val_loss: 5.4539e-04\n",
      "Epoch 380/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4539e-04 - val_loss: 5.4537e-04\n",
      "Epoch 381/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4537e-04 - val_loss: 5.4535e-04\n",
      "Epoch 382/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4535e-04 - val_loss: 5.4533e-04\n",
      "Epoch 383/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4533e-04 - val_loss: 5.4530e-04\n",
      "Epoch 384/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4530e-04 - val_loss: 5.4528e-04\n",
      "Epoch 385/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4528e-04 - val_loss: 5.4526e-04\n",
      "Epoch 386/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4526e-04 - val_loss: 5.4524e-04\n",
      "Epoch 387/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4524e-04 - val_loss: 5.4521e-04\n",
      "Epoch 388/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4521e-04 - val_loss: 5.4519e-04\n",
      "Epoch 389/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4519e-04 - val_loss: 5.4517e-04\n",
      "Epoch 390/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4517e-04 - val_loss: 5.4514e-04\n",
      "Epoch 391/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4514e-04 - val_loss: 5.4512e-04\n",
      "Epoch 392/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4512e-04 - val_loss: 5.4510e-04\n",
      "Epoch 393/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4510e-04 - val_loss: 5.4507e-04\n",
      "Epoch 394/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4507e-04 - val_loss: 5.4505e-04\n",
      "Epoch 395/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4505e-04 - val_loss: 5.4502e-04\n",
      "Epoch 396/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4502e-04 - val_loss: 5.4500e-04\n",
      "Epoch 397/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4500e-04 - val_loss: 5.4497e-04\n",
      "Epoch 398/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4497e-04 - val_loss: 5.4495e-04\n",
      "Epoch 399/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4494e-04 - val_loss: 5.4492e-04\n",
      "Epoch 400/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4492e-04 - val_loss: 5.4489e-04\n",
      "Epoch 401/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.4489e-04 - val_loss: 5.4487e-04\n",
      "Epoch 402/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.4487e-04 - val_loss: 5.4484e-04\n",
      "Epoch 403/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4484e-04 - val_loss: 5.4481e-04\n",
      "Epoch 404/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4481e-04 - val_loss: 5.4478e-04\n",
      "Epoch 405/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4478e-04 - val_loss: 5.4475e-04\n",
      "Epoch 406/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4475e-04 - val_loss: 5.4472e-04\n",
      "Epoch 407/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4472e-04 - val_loss: 5.4470e-04\n",
      "Epoch 408/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4470e-04 - val_loss: 5.4467e-04\n",
      "Epoch 409/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4467e-04 - val_loss: 5.4464e-04\n",
      "Epoch 410/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4464e-04 - val_loss: 5.4460e-04\n",
      "Epoch 411/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4460e-04 - val_loss: 5.4457e-04\n",
      "Epoch 412/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4457e-04 - val_loss: 5.4454e-04\n",
      "Epoch 413/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4454e-04 - val_loss: 5.4451e-04\n",
      "Epoch 414/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4451e-04 - val_loss: 5.4448e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4448e-04 - val_loss: 5.4445e-04\n",
      "Epoch 416/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4445e-04 - val_loss: 5.4441e-04\n",
      "Epoch 417/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4441e-04 - val_loss: 5.4438e-04\n",
      "Epoch 418/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4438e-04 - val_loss: 5.4434e-04\n",
      "Epoch 419/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4434e-04 - val_loss: 5.4431e-04\n",
      "Epoch 420/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4431e-04 - val_loss: 5.4428e-04\n",
      "Epoch 421/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4428e-04 - val_loss: 5.4424e-04\n",
      "Epoch 422/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4424e-04 - val_loss: 5.4420e-04\n",
      "Epoch 423/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4420e-04 - val_loss: 5.4417e-04\n",
      "Epoch 424/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4417e-04 - val_loss: 5.4413e-04\n",
      "Epoch 425/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4413e-04 - val_loss: 5.4409e-04\n",
      "Epoch 426/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4409e-04 - val_loss: 5.4405e-04\n",
      "Epoch 427/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4405e-04 - val_loss: 5.4401e-04\n",
      "Epoch 428/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4401e-04 - val_loss: 5.4397e-04\n",
      "Epoch 429/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4397e-04 - val_loss: 5.4393e-04\n",
      "Epoch 430/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4393e-04 - val_loss: 5.4389e-04\n",
      "Epoch 431/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4389e-04 - val_loss: 5.4385e-04\n",
      "Epoch 432/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4385e-04 - val_loss: 5.4381e-04\n",
      "Epoch 433/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4381e-04 - val_loss: 5.4377e-04\n",
      "Epoch 434/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4377e-04 - val_loss: 5.4372e-04\n",
      "Epoch 435/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4372e-04 - val_loss: 5.4368e-04\n",
      "Epoch 436/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4368e-04 - val_loss: 5.4364e-04\n",
      "Epoch 437/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4364e-04 - val_loss: 5.4359e-04\n",
      "Epoch 438/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4359e-04 - val_loss: 5.4354e-04\n",
      "Epoch 439/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4354e-04 - val_loss: 5.4350e-04\n",
      "Epoch 440/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4350e-04 - val_loss: 5.4345e-04\n",
      "Epoch 441/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.4345e-04 - val_loss: 5.4340e-04\n",
      "Epoch 442/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4340e-04 - val_loss: 5.4335e-04\n",
      "Epoch 443/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4335e-04 - val_loss: 5.4330e-04\n",
      "Epoch 444/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4330e-04 - val_loss: 5.4325e-04\n",
      "Epoch 445/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4325e-04 - val_loss: 5.4320e-04\n",
      "Epoch 446/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4320e-04 - val_loss: 5.4315e-04\n",
      "Epoch 447/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4315e-04 - val_loss: 5.4310e-04\n",
      "Epoch 448/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4310e-04 - val_loss: 5.4304e-04\n",
      "Epoch 449/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4304e-04 - val_loss: 5.4299e-04\n",
      "Epoch 450/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4299e-04 - val_loss: 5.4293e-04\n",
      "Epoch 451/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4293e-04 - val_loss: 5.4288e-04\n",
      "Epoch 452/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4288e-04 - val_loss: 5.4282e-04\n",
      "Epoch 453/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4282e-04 - val_loss: 5.4276e-04\n",
      "Epoch 454/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4276e-04 - val_loss: 5.4270e-04\n",
      "Epoch 455/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4270e-04 - val_loss: 5.4264e-04\n",
      "Epoch 456/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4264e-04 - val_loss: 5.4258e-04\n",
      "Epoch 457/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4258e-04 - val_loss: 5.4252e-04\n",
      "Epoch 458/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4252e-04 - val_loss: 5.4246e-04\n",
      "Epoch 459/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4246e-04 - val_loss: 5.4240e-04\n",
      "Epoch 460/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4240e-04 - val_loss: 5.4234e-04\n",
      "Epoch 461/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4234e-04 - val_loss: 5.4227e-04\n",
      "Epoch 462/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4227e-04 - val_loss: 5.4221e-04\n",
      "Epoch 463/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4221e-04 - val_loss: 5.4214e-04\n",
      "Epoch 464/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4214e-04 - val_loss: 5.4207e-04\n",
      "Epoch 465/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4207e-04 - val_loss: 5.4201e-04\n",
      "Epoch 466/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4201e-04 - val_loss: 5.4194e-04\n",
      "Epoch 467/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4194e-04 - val_loss: 5.4187e-04\n",
      "Epoch 468/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4187e-04 - val_loss: 5.4180e-04\n",
      "Epoch 469/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4180e-04 - val_loss: 5.4173e-04\n",
      "Epoch 470/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4173e-04 - val_loss: 5.4165e-04\n",
      "Epoch 471/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4165e-04 - val_loss: 5.4158e-04\n",
      "Epoch 472/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4158e-04 - val_loss: 5.4151e-04\n",
      "Epoch 473/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4151e-04 - val_loss: 5.4144e-04\n",
      "Epoch 474/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4144e-04 - val_loss: 5.4136e-04\n",
      "Epoch 475/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4136e-04 - val_loss: 5.4129e-04\n",
      "Epoch 476/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4129e-04 - val_loss: 5.4121e-04\n",
      "Epoch 477/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.4121e-04 - val_loss: 5.4113e-04\n",
      "Epoch 478/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4113e-04 - val_loss: 5.4106e-04\n",
      "Epoch 479/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4106e-04 - val_loss: 5.4098e-04\n",
      "Epoch 480/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4098e-04 - val_loss: 5.4090e-04\n",
      "Epoch 481/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4090e-04 - val_loss: 5.4082e-04\n",
      "Epoch 482/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4083e-04 - val_loss: 5.4075e-04\n",
      "Epoch 483/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4075e-04 - val_loss: 5.4067e-04\n",
      "Epoch 484/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4067e-04 - val_loss: 5.4059e-04\n",
      "Epoch 485/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4059e-04 - val_loss: 5.4051e-04\n",
      "Epoch 486/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4051e-04 - val_loss: 5.4043e-04\n",
      "Epoch 487/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4043e-04 - val_loss: 5.4035e-04\n",
      "Epoch 488/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4035e-04 - val_loss: 5.4027e-04\n",
      "Epoch 489/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4027e-04 - val_loss: 5.4019e-04\n",
      "Epoch 490/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4019e-04 - val_loss: 5.4011e-04\n",
      "Epoch 491/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4011e-04 - val_loss: 5.4002e-04\n",
      "Epoch 492/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4002e-04 - val_loss: 5.3994e-04\n",
      "Epoch 493/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3994e-04 - val_loss: 5.3986e-04\n",
      "Epoch 494/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3986e-04 - val_loss: 5.3978e-04\n",
      "Epoch 495/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3978e-04 - val_loss: 5.3970e-04\n",
      "Epoch 496/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3970e-04 - val_loss: 5.3962e-04\n",
      "Epoch 497/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3962e-04 - val_loss: 5.3954e-04\n",
      "Epoch 498/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3954e-04 - val_loss: 5.3945e-04\n",
      "Epoch 499/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.3945e-04 - val_loss: 5.3937e-04\n",
      "Epoch 500/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3937e-04 - val_loss: 5.3929e-04\n",
      "Epoch 501/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3929e-04 - val_loss: 5.3921e-04\n",
      "Epoch 502/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3921e-04 - val_loss: 5.3912e-04\n",
      "Epoch 503/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3912e-04 - val_loss: 5.3904e-04\n",
      "Epoch 504/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3904e-04 - val_loss: 5.3896e-04\n",
      "Epoch 505/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3896e-04 - val_loss: 5.3887e-04\n",
      "Epoch 506/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3887e-04 - val_loss: 5.3879e-04\n",
      "Epoch 507/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3879e-04 - val_loss: 5.3870e-04\n",
      "Epoch 508/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3870e-04 - val_loss: 5.3862e-04\n",
      "Epoch 509/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.3862e-04 - val_loss: 5.3853e-04\n",
      "Epoch 510/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3853e-04 - val_loss: 5.3844e-04\n",
      "Epoch 511/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3844e-04 - val_loss: 5.3835e-04\n",
      "Epoch 512/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.3835e-04 - val_loss: 5.3826e-04\n",
      "Epoch 513/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3826e-04 - val_loss: 5.3817e-04\n",
      "Epoch 514/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3817e-04 - val_loss: 5.3808e-04\n",
      "Epoch 515/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3808e-04 - val_loss: 5.3799e-04\n",
      "Epoch 516/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3799e-04 - val_loss: 5.3789e-04\n",
      "Epoch 517/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3789e-04 - val_loss: 5.3779e-04\n",
      "Epoch 518/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3779e-04 - val_loss: 5.3770e-04\n",
      "Epoch 519/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3770e-04 - val_loss: 5.3760e-04\n",
      "Epoch 520/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3760e-04 - val_loss: 5.3750e-04\n",
      "Epoch 521/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3750e-04 - val_loss: 5.3739e-04\n",
      "Epoch 522/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3739e-04 - val_loss: 5.3729e-04\n",
      "Epoch 523/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3729e-04 - val_loss: 5.3718e-04\n",
      "Epoch 524/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3718e-04 - val_loss: 5.3707e-04\n",
      "Epoch 525/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3707e-04 - val_loss: 5.3696e-04\n",
      "Epoch 526/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3696e-04 - val_loss: 5.3684e-04\n",
      "Epoch 527/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3684e-04 - val_loss: 5.3672e-04\n",
      "Epoch 528/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3672e-04 - val_loss: 5.3660e-04\n",
      "Epoch 529/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.3660e-04 - val_loss: 5.3648e-04\n",
      "Epoch 530/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3648e-04 - val_loss: 5.3635e-04\n",
      "Epoch 531/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3635e-04 - val_loss: 5.3623e-04\n",
      "Epoch 532/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.3623e-04 - val_loss: 5.3609e-04\n",
      "Epoch 533/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3609e-04 - val_loss: 5.3596e-04\n",
      "Epoch 534/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3596e-04 - val_loss: 5.3582e-04\n",
      "Epoch 535/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3582e-04 - val_loss: 5.3568e-04\n",
      "Epoch 536/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3568e-04 - val_loss: 5.3554e-04\n",
      "Epoch 537/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3554e-04 - val_loss: 5.3539e-04\n",
      "Epoch 538/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3539e-04 - val_loss: 5.3524e-04\n",
      "Epoch 539/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3524e-04 - val_loss: 5.3508e-04\n",
      "Epoch 540/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3508e-04 - val_loss: 5.3492e-04\n",
      "Epoch 541/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3492e-04 - val_loss: 5.3476e-04\n",
      "Epoch 542/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3476e-04 - val_loss: 5.3459e-04\n",
      "Epoch 543/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3459e-04 - val_loss: 5.3442e-04\n",
      "Epoch 544/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3442e-04 - val_loss: 5.3424e-04\n",
      "Epoch 545/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3424e-04 - val_loss: 5.3406e-04\n",
      "Epoch 546/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3406e-04 - val_loss: 5.3387e-04\n",
      "Epoch 547/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3387e-04 - val_loss: 5.3368e-04\n",
      "Epoch 548/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3368e-04 - val_loss: 5.3349e-04\n",
      "Epoch 549/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3349e-04 - val_loss: 5.3329e-04\n",
      "Epoch 550/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3329e-04 - val_loss: 5.3308e-04\n",
      "Epoch 551/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3308e-04 - val_loss: 5.3287e-04\n",
      "Epoch 552/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3287e-04 - val_loss: 5.3265e-04\n",
      "Epoch 553/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3265e-04 - val_loss: 5.3242e-04\n",
      "Epoch 554/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3242e-04 - val_loss: 5.3219e-04\n",
      "Epoch 555/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3219e-04 - val_loss: 5.3195e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3195e-04 - val_loss: 5.3171e-04\n",
      "Epoch 557/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3171e-04 - val_loss: 5.3146e-04\n",
      "Epoch 558/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3146e-04 - val_loss: 5.3120e-04\n",
      "Epoch 559/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3120e-04 - val_loss: 5.3093e-04\n",
      "Epoch 560/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3093e-04 - val_loss: 5.3066e-04\n",
      "Epoch 561/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3066e-04 - val_loss: 5.3037e-04\n",
      "Epoch 562/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3037e-04 - val_loss: 5.3008e-04\n",
      "Epoch 563/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3008e-04 - val_loss: 5.2978e-04\n",
      "Epoch 564/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2978e-04 - val_loss: 5.2947e-04\n",
      "Epoch 565/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2947e-04 - val_loss: 5.2915e-04\n",
      "Epoch 566/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2915e-04 - val_loss: 5.2882e-04\n",
      "Epoch 567/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.2882e-04 - val_loss: 5.2848e-04\n",
      "Epoch 568/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2848e-04 - val_loss: 5.2814e-04\n",
      "Epoch 569/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2814e-04 - val_loss: 5.2777e-04\n",
      "Epoch 570/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2777e-04 - val_loss: 5.2740e-04\n",
      "Epoch 571/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2740e-04 - val_loss: 5.2702e-04\n",
      "Epoch 572/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.2702e-04 - val_loss: 5.2662e-04\n",
      "Epoch 573/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.2662e-04 - val_loss: 5.2622e-04\n",
      "Epoch 574/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2622e-04 - val_loss: 5.2580e-04\n",
      "Epoch 575/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2580e-04 - val_loss: 5.2536e-04\n",
      "Epoch 576/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.2536e-04 - val_loss: 5.2492e-04\n",
      "Epoch 577/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2492e-04 - val_loss: 5.2446e-04\n",
      "Epoch 578/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2446e-04 - val_loss: 5.2398e-04\n",
      "Epoch 579/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.2398e-04 - val_loss: 5.2350e-04\n",
      "Epoch 580/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.2350e-04 - val_loss: 5.2299e-04\n",
      "Epoch 581/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2299e-04 - val_loss: 5.2248e-04\n",
      "Epoch 582/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2248e-04 - val_loss: 5.2195e-04\n",
      "Epoch 583/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2195e-04 - val_loss: 5.2140e-04\n",
      "Epoch 584/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2140e-04 - val_loss: 5.2085e-04\n",
      "Epoch 585/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2085e-04 - val_loss: 5.2027e-04\n",
      "Epoch 586/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2027e-04 - val_loss: 5.1969e-04\n",
      "Epoch 587/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1969e-04 - val_loss: 5.1909e-04\n",
      "Epoch 588/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1909e-04 - val_loss: 5.1848e-04\n",
      "Epoch 589/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.1848e-04 - val_loss: 5.1785e-04\n",
      "Epoch 590/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.1785e-04 - val_loss: 5.1722e-04\n",
      "Epoch 591/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.1722e-04 - val_loss: 5.1658e-04\n",
      "Epoch 592/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1658e-04 - val_loss: 5.1593e-04\n",
      "Epoch 593/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1593e-04 - val_loss: 5.1527e-04\n",
      "Epoch 594/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1527e-04 - val_loss: 5.1461e-04\n",
      "Epoch 595/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1461e-04 - val_loss: 5.1395e-04\n",
      "Epoch 596/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1395e-04 - val_loss: 5.1329e-04\n",
      "Epoch 597/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1329e-04 - val_loss: 5.1263e-04\n",
      "Epoch 598/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.1263e-04 - val_loss: 5.1199e-04\n",
      "Epoch 599/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1199e-04 - val_loss: 5.1135e-04\n",
      "Epoch 600/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1135e-04 - val_loss: 5.1072e-04\n",
      "Epoch 601/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1072e-04 - val_loss: 5.1012e-04\n",
      "Epoch 602/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1012e-04 - val_loss: 5.0953e-04\n",
      "Epoch 603/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0953e-04 - val_loss: 5.0898e-04\n",
      "Epoch 604/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0898e-04 - val_loss: 5.0845e-04\n",
      "Epoch 605/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0845e-04 - val_loss: 5.0796e-04\n",
      "Epoch 606/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0796e-04 - val_loss: 5.0751e-04\n",
      "Epoch 607/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0751e-04 - val_loss: 5.0710e-04\n",
      "Epoch 608/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0710e-04 - val_loss: 5.0673e-04\n",
      "Epoch 609/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0673e-04 - val_loss: 5.0641e-04\n",
      "Epoch 610/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0641e-04 - val_loss: 5.0613e-04\n",
      "Epoch 611/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0613e-04 - val_loss: 5.0590e-04\n",
      "Epoch 612/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0590e-04 - val_loss: 5.0572e-04\n",
      "Epoch 613/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0572e-04 - val_loss: 5.0558e-04\n",
      "Epoch 614/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0558e-04 - val_loss: 5.0548e-04\n",
      "Epoch 615/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0548e-04 - val_loss: 5.0541e-04\n",
      "Epoch 616/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0541e-04 - val_loss: 5.0537e-04\n",
      "Epoch 617/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0537e-04 - val_loss: 5.0535e-04\n",
      "Epoch 618/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0535e-04 - val_loss: 5.0536e-04\n",
      "Epoch 619/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0536e-04 - val_loss: 5.0537e-04\n",
      "Epoch 620/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0537e-04 - val_loss: 5.0539e-04\n",
      "Epoch 621/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0539e-04 - val_loss: 5.0542e-04\n",
      "Epoch 622/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0542e-04 - val_loss: 5.0544e-04\n",
      "Epoch 623/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0544e-04 - val_loss: 5.0545e-04\n",
      "Epoch 624/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0545e-04 - val_loss: 5.0546e-04\n",
      "Epoch 625/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0546e-04 - val_loss: 5.0545e-04\n",
      "Epoch 626/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0545e-04 - val_loss: 5.0544e-04\n",
      "Epoch 627/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0544e-04 - val_loss: 5.0541e-04\n",
      "Epoch 628/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0541e-04 - val_loss: 5.0538e-04\n",
      "Epoch 629/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0538e-04 - val_loss: 5.0536e-04\n",
      "Epoch 630/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0536e-04 - val_loss: 5.0540e-04\n",
      "Epoch 631/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0540e-04 - val_loss: 5.0580e-04\n",
      "Epoch 632/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0580e-04 - val_loss: 5.0785e-04\n",
      "Epoch 633/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0785e-04 - val_loss: 5.1600e-04\n",
      "Epoch 634/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1600e-04 - val_loss: 5.3276e-04\n",
      "Epoch 635/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3276e-04 - val_loss: 5.2725e-04\n",
      "Epoch 636/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2725e-04 - val_loss: 5.0600e-04\n",
      "Epoch 637/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0600e-04 - val_loss: 5.2096e-04\n",
      "Epoch 638/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.2096e-04 - val_loss: 5.0736e-04\n",
      "Epoch 639/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0736e-04 - val_loss: 5.1734e-04\n",
      "Epoch 640/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1734e-04 - val_loss: 5.0927e-04\n",
      "Epoch 641/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0927e-04 - val_loss: 5.1322e-04\n",
      "Epoch 642/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1322e-04 - val_loss: 5.1207e-04\n",
      "Epoch 643/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1207e-04 - val_loss: 5.0873e-04\n",
      "Epoch 644/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0873e-04 - val_loss: 5.1248e-04\n",
      "Epoch 645/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.1248e-04 - val_loss: 5.0710e-04\n",
      "Epoch 646/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0710e-04 - val_loss: 5.0975e-04\n",
      "Epoch 647/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0975e-04 - val_loss: 5.0737e-04\n",
      "Epoch 648/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0737e-04 - val_loss: 5.0715e-04\n",
      "Epoch 649/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0715e-04 - val_loss: 5.0767e-04\n",
      "Epoch 650/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0767e-04 - val_loss: 5.0618e-04\n",
      "Epoch 651/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0618e-04 - val_loss: 5.0764e-04\n",
      "Epoch 652/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0764e-04 - val_loss: 5.0627e-04\n",
      "Epoch 653/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0627e-04 - val_loss: 5.0723e-04\n",
      "Epoch 654/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0723e-04 - val_loss: 5.0641e-04\n",
      "Epoch 655/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0641e-04 - val_loss: 5.0653e-04\n",
      "Epoch 656/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0653e-04 - val_loss: 5.0611e-04\n",
      "Epoch 657/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0611e-04 - val_loss: 5.0595e-04\n",
      "Epoch 658/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0595e-04 - val_loss: 5.0556e-04\n",
      "Epoch 659/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0556e-04 - val_loss: 5.0574e-04\n",
      "Epoch 660/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0574e-04 - val_loss: 5.0514e-04\n",
      "Epoch 661/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0514e-04 - val_loss: 5.0576e-04\n",
      "Epoch 662/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0576e-04 - val_loss: 5.0495e-04\n",
      "Epoch 663/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0495e-04 - val_loss: 5.0570e-04\n",
      "Epoch 664/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0570e-04 - val_loss: 5.0496e-04\n",
      "Epoch 665/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0496e-04 - val_loss: 5.0540e-04\n",
      "Epoch 666/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0540e-04 - val_loss: 5.0501e-04\n",
      "Epoch 667/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0501e-04 - val_loss: 5.0500e-04\n",
      "Epoch 668/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0500e-04 - val_loss: 5.0500e-04\n",
      "Epoch 669/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0500e-04 - val_loss: 5.0470e-04\n",
      "Epoch 670/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0470e-04 - val_loss: 5.0493e-04\n",
      "Epoch 671/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0493e-04 - val_loss: 5.0458e-04\n",
      "Epoch 672/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0458e-04 - val_loss: 5.0488e-04\n",
      "Epoch 673/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.0488e-04 - val_loss: 5.0456e-04\n",
      "Epoch 674/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0456e-04 - val_loss: 5.0484e-04\n",
      "Epoch 675/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0484e-04 - val_loss: 5.0455e-04\n",
      "Epoch 676/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0455e-04 - val_loss: 5.0476e-04\n",
      "Epoch 677/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0476e-04 - val_loss: 5.0451e-04\n",
      "Epoch 678/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0451e-04 - val_loss: 5.0465e-04\n",
      "Epoch 679/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0465e-04 - val_loss: 5.0447e-04\n",
      "Epoch 680/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0447e-04 - val_loss: 5.0456e-04\n",
      "Epoch 681/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0456e-04 - val_loss: 5.0446e-04\n",
      "Epoch 682/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0446e-04 - val_loss: 5.0450e-04\n",
      "Epoch 683/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0450e-04 - val_loss: 5.0446e-04\n",
      "Epoch 684/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0446e-04 - val_loss: 5.0445e-04\n",
      "Epoch 685/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0445e-04 - val_loss: 5.0445e-04\n",
      "Epoch 686/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0445e-04 - val_loss: 5.0439e-04\n",
      "Epoch 687/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0439e-04 - val_loss: 5.0442e-04\n",
      "Epoch 688/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0442e-04 - val_loss: 5.0434e-04\n",
      "Epoch 689/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0434e-04 - val_loss: 5.0438e-04\n",
      "Epoch 690/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0438e-04 - val_loss: 5.0431e-04\n",
      "Epoch 691/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0431e-04 - val_loss: 5.0435e-04\n",
      "Epoch 692/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0435e-04 - val_loss: 5.0430e-04\n",
      "Epoch 693/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0430e-04 - val_loss: 5.0432e-04\n",
      "Epoch 694/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0432e-04 - val_loss: 5.0428e-04\n",
      "Epoch 695/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0428e-04 - val_loss: 5.0429e-04\n",
      "Epoch 696/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0429e-04 - val_loss: 5.0426e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0426e-04 - val_loss: 5.0426e-04\n",
      "Epoch 698/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0426e-04 - val_loss: 5.0424e-04\n",
      "Epoch 699/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0424e-04 - val_loss: 5.0424e-04\n",
      "Epoch 700/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0424e-04 - val_loss: 5.0423e-04\n",
      "Epoch 701/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0423e-04 - val_loss: 5.0422e-04\n",
      "Epoch 702/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0422e-04 - val_loss: 5.0421e-04\n",
      "Epoch 703/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0421e-04 - val_loss: 5.0420e-04\n",
      "Epoch 704/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0420e-04 - val_loss: 5.0420e-04\n",
      "Epoch 705/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0420e-04 - val_loss: 5.0418e-04\n",
      "Epoch 706/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0418e-04 - val_loss: 5.0418e-04\n",
      "Epoch 707/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0418e-04 - val_loss: 5.0417e-04\n",
      "Epoch 708/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0417e-04 - val_loss: 5.0417e-04\n",
      "Epoch 709/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0417e-04 - val_loss: 5.0415e-04\n",
      "Epoch 710/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0415e-04 - val_loss: 5.0415e-04\n",
      "Epoch 711/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0415e-04 - val_loss: 5.0414e-04\n",
      "Epoch 712/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0414e-04 - val_loss: 5.0414e-04\n",
      "Epoch 713/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0414e-04 - val_loss: 5.0413e-04\n",
      "Epoch 714/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0413e-04 - val_loss: 5.0412e-04\n",
      "Epoch 715/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0412e-04 - val_loss: 5.0412e-04\n",
      "Epoch 716/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0412e-04 - val_loss: 5.0411e-04\n",
      "Epoch 717/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0411e-04 - val_loss: 5.0410e-04\n",
      "Epoch 718/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0410e-04 - val_loss: 5.0410e-04\n",
      "Epoch 719/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0410e-04 - val_loss: 5.0409e-04\n",
      "Epoch 720/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0409e-04 - val_loss: 5.0409e-04\n",
      "Epoch 721/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0409e-04 - val_loss: 5.0408e-04\n",
      "Epoch 722/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0408e-04 - val_loss: 5.0408e-04\n",
      "Epoch 723/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0408e-04 - val_loss: 5.0407e-04\n",
      "Epoch 724/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0407e-04 - val_loss: 5.0406e-04\n",
      "Epoch 725/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0406e-04 - val_loss: 5.0406e-04\n",
      "Epoch 726/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0406e-04 - val_loss: 5.0405e-04\n",
      "Epoch 727/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0405e-04 - val_loss: 5.0405e-04\n",
      "Epoch 728/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0405e-04 - val_loss: 5.0404e-04\n",
      "Epoch 729/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0404e-04 - val_loss: 5.0404e-04\n",
      "Epoch 730/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0404e-04 - val_loss: 5.0403e-04\n",
      "Epoch 731/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0403e-04 - val_loss: 5.0403e-04\n",
      "Epoch 732/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0403e-04 - val_loss: 5.0402e-04\n",
      "Epoch 733/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0402e-04 - val_loss: 5.0402e-04\n",
      "Epoch 734/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0402e-04 - val_loss: 5.0401e-04\n",
      "Epoch 735/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0401e-04 - val_loss: 5.0401e-04\n",
      "Epoch 736/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0401e-04 - val_loss: 5.0400e-04\n",
      "Epoch 737/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0400e-04 - val_loss: 5.0400e-04\n",
      "Epoch 738/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0400e-04 - val_loss: 5.0399e-04\n",
      "Epoch 739/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0399e-04 - val_loss: 5.0399e-04\n",
      "Epoch 740/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0399e-04 - val_loss: 5.0398e-04\n",
      "Epoch 741/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0398e-04 - val_loss: 5.0398e-04\n",
      "Epoch 742/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0398e-04 - val_loss: 5.0397e-04\n",
      "Epoch 743/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0397e-04 - val_loss: 5.0397e-04\n",
      "Epoch 744/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0397e-04 - val_loss: 5.0396e-04\n",
      "Epoch 745/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0396e-04 - val_loss: 5.0396e-04\n",
      "Epoch 746/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0396e-04 - val_loss: 5.0395e-04\n",
      "Epoch 747/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0395e-04 - val_loss: 5.0395e-04\n",
      "Epoch 748/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0395e-04 - val_loss: 5.0394e-04\n",
      "Epoch 749/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0394e-04 - val_loss: 5.0394e-04\n",
      "Epoch 750/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0394e-04 - val_loss: 5.0393e-04\n",
      "Epoch 751/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0393e-04 - val_loss: 5.0393e-04\n",
      "Epoch 752/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0393e-04 - val_loss: 5.0392e-04\n",
      "Epoch 753/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0392e-04 - val_loss: 5.0392e-04\n",
      "Epoch 754/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0392e-04 - val_loss: 5.0391e-04\n",
      "Epoch 755/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0391e-04 - val_loss: 5.0391e-04\n",
      "Epoch 756/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0391e-04 - val_loss: 5.0390e-04\n",
      "Epoch 757/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0390e-04 - val_loss: 5.0390e-04\n",
      "Epoch 758/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0390e-04 - val_loss: 5.0389e-04\n",
      "Epoch 759/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0389e-04 - val_loss: 5.0389e-04\n",
      "Epoch 760/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0389e-04 - val_loss: 5.0388e-04\n",
      "Epoch 761/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0388e-04 - val_loss: 5.0388e-04\n",
      "Epoch 762/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0388e-04 - val_loss: 5.0387e-04\n",
      "Epoch 763/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0387e-04 - val_loss: 5.0387e-04\n",
      "Epoch 764/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0387e-04 - val_loss: 5.0386e-04\n",
      "Epoch 765/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0386e-04 - val_loss: 5.0386e-04\n",
      "Epoch 766/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0386e-04 - val_loss: 5.0385e-04\n",
      "Epoch 767/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0385e-04 - val_loss: 5.0385e-04\n",
      "Epoch 768/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0385e-04 - val_loss: 5.0384e-04\n",
      "Epoch 769/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0384e-04 - val_loss: 5.0384e-04\n",
      "Epoch 770/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0384e-04 - val_loss: 5.0383e-04\n",
      "Epoch 771/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0383e-04 - val_loss: 5.0383e-04\n",
      "Epoch 772/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0383e-04 - val_loss: 5.0382e-04\n",
      "Epoch 773/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0382e-04 - val_loss: 5.0382e-04\n",
      "Epoch 774/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0382e-04 - val_loss: 5.0381e-04\n",
      "Epoch 775/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0381e-04 - val_loss: 5.0381e-04\n",
      "Epoch 776/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0380e-04 - val_loss: 5.0380e-04\n",
      "Epoch 777/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0380e-04 - val_loss: 5.0379e-04\n",
      "Epoch 778/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0379e-04 - val_loss: 5.0379e-04\n",
      "Epoch 779/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0379e-04 - val_loss: 5.0378e-04\n",
      "Epoch 780/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0378e-04 - val_loss: 5.0378e-04\n",
      "Epoch 781/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0378e-04 - val_loss: 5.0377e-04\n",
      "Epoch 782/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0377e-04 - val_loss: 5.0377e-04\n",
      "Epoch 783/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0377e-04 - val_loss: 5.0376e-04\n",
      "Epoch 784/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0376e-04 - val_loss: 5.0375e-04\n",
      "Epoch 785/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0375e-04 - val_loss: 5.0375e-04\n",
      "Epoch 786/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0375e-04 - val_loss: 5.0374e-04\n",
      "Epoch 787/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0374e-04 - val_loss: 5.0374e-04\n",
      "Epoch 788/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0374e-04 - val_loss: 5.0373e-04\n",
      "Epoch 789/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0373e-04 - val_loss: 5.0373e-04\n",
      "Epoch 790/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0373e-04 - val_loss: 5.0372e-04\n",
      "Epoch 791/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0372e-04 - val_loss: 5.0371e-04\n",
      "Epoch 792/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0371e-04 - val_loss: 5.0371e-04\n",
      "Epoch 793/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0371e-04 - val_loss: 5.0370e-04\n",
      "Epoch 794/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0370e-04 - val_loss: 5.0370e-04\n",
      "Epoch 795/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0370e-04 - val_loss: 5.0369e-04\n",
      "Epoch 796/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0369e-04 - val_loss: 5.0368e-04\n",
      "Epoch 797/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0368e-04 - val_loss: 5.0368e-04\n",
      "Epoch 798/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0368e-04 - val_loss: 5.0367e-04\n",
      "Epoch 799/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0367e-04 - val_loss: 5.0366e-04\n",
      "Epoch 800/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0366e-04 - val_loss: 5.0366e-04\n",
      "Epoch 801/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0366e-04 - val_loss: 5.0365e-04\n",
      "Epoch 802/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0365e-04 - val_loss: 5.0365e-04\n",
      "Epoch 803/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0365e-04 - val_loss: 5.0364e-04\n",
      "Epoch 804/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0364e-04 - val_loss: 5.0363e-04\n",
      "Epoch 805/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0363e-04 - val_loss: 5.0363e-04\n",
      "Epoch 806/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0363e-04 - val_loss: 5.0362e-04\n",
      "Epoch 807/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0362e-04 - val_loss: 5.0361e-04\n",
      "Epoch 808/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0361e-04 - val_loss: 5.0361e-04\n",
      "Epoch 809/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0361e-04 - val_loss: 5.0360e-04\n",
      "Epoch 810/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0360e-04 - val_loss: 5.0359e-04\n",
      "Epoch 811/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0359e-04 - val_loss: 5.0359e-04\n",
      "Epoch 812/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0359e-04 - val_loss: 5.0358e-04\n",
      "Epoch 813/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0358e-04 - val_loss: 5.0357e-04\n",
      "Epoch 814/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0357e-04 - val_loss: 5.0357e-04\n",
      "Epoch 815/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0357e-04 - val_loss: 5.0356e-04\n",
      "Epoch 816/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0356e-04 - val_loss: 5.0355e-04\n",
      "Epoch 817/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0355e-04 - val_loss: 5.0354e-04\n",
      "Epoch 818/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0354e-04 - val_loss: 5.0354e-04\n",
      "Epoch 819/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0354e-04 - val_loss: 5.0353e-04\n",
      "Epoch 820/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0353e-04 - val_loss: 5.0352e-04\n",
      "Epoch 821/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0352e-04 - val_loss: 5.0352e-04\n",
      "Epoch 822/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0352e-04 - val_loss: 5.0351e-04\n",
      "Epoch 823/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0351e-04 - val_loss: 5.0350e-04\n",
      "Epoch 824/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0350e-04 - val_loss: 5.0349e-04\n",
      "Epoch 825/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0349e-04 - val_loss: 5.0348e-04\n",
      "Epoch 826/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0348e-04 - val_loss: 5.0348e-04\n",
      "Epoch 827/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0348e-04 - val_loss: 5.0347e-04\n",
      "Epoch 828/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0347e-04 - val_loss: 5.0346e-04\n",
      "Epoch 829/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0346e-04 - val_loss: 5.0345e-04\n",
      "Epoch 830/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0345e-04 - val_loss: 5.0345e-04\n",
      "Epoch 831/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0345e-04 - val_loss: 5.0344e-04\n",
      "Epoch 832/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0344e-04 - val_loss: 5.0343e-04\n",
      "Epoch 833/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0343e-04 - val_loss: 5.0342e-04\n",
      "Epoch 834/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0342e-04 - val_loss: 5.0341e-04\n",
      "Epoch 835/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0341e-04 - val_loss: 5.0340e-04\n",
      "Epoch 836/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 5.0340e-04 - val_loss: 5.0340e-04\n",
      "Epoch 837/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0340e-04 - val_loss: 5.0339e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0339e-04 - val_loss: 5.0338e-04\n",
      "Epoch 839/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0338e-04 - val_loss: 5.0337e-04\n",
      "Epoch 840/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0337e-04 - val_loss: 5.0336e-04\n",
      "Epoch 841/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0336e-04 - val_loss: 5.0335e-04\n",
      "Epoch 842/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0335e-04 - val_loss: 5.0334e-04\n",
      "Epoch 843/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0334e-04 - val_loss: 5.0333e-04\n",
      "Epoch 844/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 5.0333e-04 - val_loss: 5.0332e-04\n",
      "Epoch 845/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0332e-04 - val_loss: 5.0332e-04\n",
      "Epoch 846/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0332e-04 - val_loss: 5.0331e-04\n",
      "Epoch 847/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0331e-04 - val_loss: 5.0330e-04\n",
      "Epoch 848/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0330e-04 - val_loss: 5.0329e-04\n",
      "Epoch 849/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0329e-04 - val_loss: 5.0328e-04\n",
      "Epoch 850/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0328e-04 - val_loss: 5.0327e-04\n",
      "Epoch 851/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0327e-04 - val_loss: 5.0326e-04\n",
      "Epoch 852/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0326e-04 - val_loss: 5.0325e-04\n",
      "Epoch 853/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0325e-04 - val_loss: 5.0324e-04\n",
      "Epoch 854/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0324e-04 - val_loss: 5.0323e-04\n",
      "Epoch 855/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0323e-04 - val_loss: 5.0322e-04\n",
      "Epoch 856/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0322e-04 - val_loss: 5.0321e-04\n",
      "Epoch 857/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0321e-04 - val_loss: 5.0319e-04\n",
      "Epoch 858/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0319e-04 - val_loss: 5.0318e-04\n",
      "Epoch 859/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0318e-04 - val_loss: 5.0317e-04\n",
      "Epoch 860/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0317e-04 - val_loss: 5.0316e-04\n",
      "Epoch 861/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0316e-04 - val_loss: 5.0315e-04\n",
      "Epoch 862/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0315e-04 - val_loss: 5.0314e-04\n",
      "Epoch 863/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0314e-04 - val_loss: 5.0313e-04\n",
      "Epoch 864/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0313e-04 - val_loss: 5.0312e-04\n",
      "Epoch 865/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0312e-04 - val_loss: 5.0310e-04\n",
      "Epoch 866/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0310e-04 - val_loss: 5.0309e-04\n",
      "Epoch 867/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0309e-04 - val_loss: 5.0308e-04\n",
      "Epoch 868/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0308e-04 - val_loss: 5.0307e-04\n",
      "Epoch 869/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0307e-04 - val_loss: 5.0305e-04\n",
      "Epoch 870/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0305e-04 - val_loss: 5.0304e-04\n",
      "Epoch 871/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0304e-04 - val_loss: 5.0303e-04\n",
      "Epoch 872/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0303e-04 - val_loss: 5.0301e-04\n",
      "Epoch 873/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0301e-04 - val_loss: 5.0300e-04\n",
      "Epoch 874/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0300e-04 - val_loss: 5.0299e-04\n",
      "Epoch 875/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0299e-04 - val_loss: 5.0297e-04\n",
      "Epoch 876/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0297e-04 - val_loss: 5.0296e-04\n",
      "Epoch 877/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0296e-04 - val_loss: 5.0295e-04\n",
      "Epoch 878/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0295e-04 - val_loss: 5.0293e-04\n",
      "Epoch 879/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0293e-04 - val_loss: 5.0292e-04\n",
      "Epoch 880/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0292e-04 - val_loss: 5.0290e-04\n",
      "Epoch 881/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0290e-04 - val_loss: 5.0289e-04\n",
      "Epoch 882/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0289e-04 - val_loss: 5.0287e-04\n",
      "Epoch 883/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0287e-04 - val_loss: 5.0285e-04\n",
      "Epoch 884/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0285e-04 - val_loss: 5.0284e-04\n",
      "Epoch 885/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0284e-04 - val_loss: 5.0282e-04\n",
      "Epoch 886/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0282e-04 - val_loss: 5.0281e-04\n",
      "Epoch 887/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0281e-04 - val_loss: 5.0279e-04\n",
      "Epoch 888/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0279e-04 - val_loss: 5.0277e-04\n",
      "Epoch 889/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0277e-04 - val_loss: 5.0275e-04\n",
      "Epoch 890/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0275e-04 - val_loss: 5.0274e-04\n",
      "Epoch 891/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0274e-04 - val_loss: 5.0272e-04\n",
      "Epoch 892/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0272e-04 - val_loss: 5.0270e-04\n",
      "Epoch 893/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0270e-04 - val_loss: 5.0268e-04\n",
      "Epoch 894/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0268e-04 - val_loss: 5.0266e-04\n",
      "Epoch 895/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0266e-04 - val_loss: 5.0264e-04\n",
      "Epoch 896/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0264e-04 - val_loss: 5.0262e-04\n",
      "Epoch 897/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0262e-04 - val_loss: 5.0260e-04\n",
      "Epoch 898/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0260e-04 - val_loss: 5.0258e-04\n",
      "Epoch 899/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0258e-04 - val_loss: 5.0256e-04\n",
      "Epoch 900/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0256e-04 - val_loss: 5.0254e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_5)\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data=(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAALICAYAAABiqwZ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde7Skd13n+8+vdu29e/e9O+ncuiEJJEgCRIQAIqICitdZ0SNq0PEy4mVccjyj5ziDsxw9w8iMDnPkjCM6g4LjYVRgHJUocVAHL+CFEO4QIOncLyTdSfreva/1O39U7e6ndzrppqq6d/bD67VWr6791FO1n+pxMW9+fJ9flVprAACAvs5qXwAAADyZCGQAAGgQyAAA0CCQAQCgQSADAECDQAYAgAaBDMCqKKXUUsoVq30dACsJZIAVSil3lVK+drWvA4DVIZABvsiUUiZW+xoAnswEMsAXoJTyw6WU3aWUR0spN5RSLhkcL6WUN5VS9pRSDpZSPllKefbguW8qpdxSSjlUSrm/lPJ/Pc57d0opP1tKuXvwPv9fKWXL4Lk/LaW8dsX5Hy+l/G+Dx88spfz54Lo+V0r5zsZ5/7WU8uullBtLKUeSvOwUv3tLKeWtpZTPD67xF5ZDupTyA6WUvy2l/Gop5UAp5bOllFc0XnvJ4N/i0cG/zQ83npsopfzLUsrtg8//4VLKUxq/+mtLKbeVUvaXUt5cSimD111RSvnrwe97uJTyzi/0/60AhiWQAc5QKeXlSf5dku9McnGSu5O8Y/D0K5N8VZJnJNkyOOeRwXNvTfKjtdZNSZ6d5H2P8yt+YPDnZUmelmRjkl8dPPd7SV7duJark1ya5D2llA1J/jzJ7ya5IMn1SX5tcM6y707yhiSbknzgFL/7vyZZTHJFki8bfJ4fajz/oiS3Jzk/yc8n+YNSyvbBc+9Icl+SS5K8Ksm/HfxbJclPDa77m5JsTvKDSY423vdbkrwgyTXp/5t9/eD4v0nyZ0m2JdmV5D+d4poBzgqBDHDmvifJ22qtH6m1ziX5mSQvLqVclmQh/fh8ZpJSa/1MrfXzg9ctJLm6lLK51rqv1vqRJ3j/X6613lFrPTx4/+tLKd0kf5jkuaWUSxvn/sHgOr4lyV211t+qtS7WWj+a5H8k+Y7Ge7+71vq3tdZerXW2+UtLKRemH7D/rNZ6pNa6J8mb0g/tZXuS/L+11oVa6zuTfC7JNw9Wg1+S5F/UWmdrrR9L8ptJvm/wuh9K8rO11s/Vvo/XWh9pvO8v1lr311rvSfKXSZ7b+De7NMklg/c9VdQDnBUCGeDMXZL+qnGSZBCxjyTZWWt9X/qrvW9OsqeU8pZSyubBqd+efoDePRgbePGZvP/gcTfJhbXWQ0nekxPR+uokvzN4fGmSFw3GFPaXUvanH9AXNd7r3if4XJcmmUzy+cbr/0v6q9HL7q+11hXXdsngz6OD62s+t3Pw+Cnprzw/ngcbj4+mv2qeJP88SUlyUynl06WUH3yC9wAYK4EMcOYeSD8mkySD0YbzktyfJLXWX6m1Pj/J1emPWvz04PiHaq3XpR+cf5TkXWfy/kmemv7Yw0ODn38vyasHgb0u/RXXpB+/f11r3dr4s7HW+mON92rG7Ur3JplLcn7j9Ztrrc9qnLNzeT64cW0PDP5sL6VsWvHc/Y33fvoT/O5TqrU+WGv94VrrJUl+NP2REVvCAeeEQAY4tclSyrrGn276gfpPSinPLaVMJ/m3ST5Ya72rlPKCUsqLSimTSY4kmU3SK6VMlVK+p5Sypda6kORgkt7j/M7fS/KTpZTLSykbB+//zlrr4uD5G9MP6NcPji+/z58keUYp5XtLKZODPy8opVx1Jh90MAryZ0n+n1LK5sHNgk8vpXx147QLkvzE4L2/I8lVSW6std6b5O+S/LvBv9M1SV6T5L8NXvebSf5NKeXK/n2M5ZpSynmnu6ZSyneUUnYNftyXfuA/3r8bwFgJZIBTuzHJscaf/7vW+hdJ/lX6872fT39ldHnkYXOS30g/5u5Of/TijYPnvjfJXaWUg0n+afrjD6fytiRvT/I3Se5MP7L/9+UnB/PGf5Dka9O/IW/5+KH0b6q7Pv0V3QeT/FKS6S/g835fkqkktww+w++nfyPisg8muTLJw+nf7Peqxizxq5NcNvjdf5jk5wf/Vknyy+mvmP9Z+v/l4K1JZs7gel6Q5IOllMNJbkjyf9Ra7/gCPg/A0MrJI2UAcLJSyg8k+aFa61eu9rUAnAtWkAEAoEEgAwBAgxELAABosIIMAAAN3dW+gHE4//zz62WXXbbalwEAwBry4Q9/+OFa646Vx1sRyJdddlluvvnm1b4MAADWkFLK3ac6bsQCAAAaBDIAADQIZAAAaBDIAADQIJABAKBBIAMAQINABgCABoEMAAANAhkAABoEMgAANAhkAABoEMgAANAgkAEAoEEgAwBAg0AGAIAGgQwAAA0CGQAAGgQyAAA0CGQAAGgQyAAA0CCQAQCgQSADAECDQAYAgAaBDAAADQIZAAAaBDIAADQIZAAAaBDIQ+j1ah7cfyxHZhdW+1IAABgzgTyEA8cW8l/e+NPZ8IvnJ0cfXe3LAQBgjATykL5z4q/7Dw7ev7oXAgDAWAlkAABoEMhDKGW1rwAAgLNFIAMAQINABgCABoE8hBIzFgAAbSWQAQCgQSADAECDQB5Gc8Ki1lW7DAAAxk8gAwBAg0AelU2RAQBaRSAPoRixAABoLYEMAAANAnlURiwAAFpFII/KiAUAQKsI5CFYMwYAaC+BPCojFgAArSKQR2XEAgCgVQTyEIpVYwCA1hLIoxLLAACtIpBHZcQCAKBVBPIQrBkDALSXQB6VEQsAgFYRyKMyYgEA0CoCeQgWjQEA2ksgj0otAwC0ikAelRELAIBWEchDKPaxAABoLYE8KiMWAACtIpABAKBBIA/BojEAQHsJZAAAaBDIAADQIJBHZZs3AIBWEcgAANAgkEfljj0AgFYRyEM4qYmNWAAAtIpABgCABoE8KiMWAACtIpCHUNKIYiMWAACtIpABAKBBII/KiAUAQKsI5CHYxQIAoL0EMgAANAjkURmxAABoFYE8hJOS2IgFAECrCGQAAGgQyKMyYgEA0CoCeQil+KIQAIC2EsgAANAgkEdlxAIAoFUE8hDsYgEA0F4CGQAAGgTyqIxYAAC0ikAewklNbMQCAKBVBPKQaqwcAwC00RkFcinlG0opnyul7C6lvO4Uz0+XUt45eP6DpZTLGs/9zOD450opX3+69yylvLyU8pFSyqdKKb9dSumO9hHPjhIrxwAAbXTaQC6lTCR5c5JvTHJ1kleXUq5ecdprkuyrtV6R5E1Jfmnw2quTXJ/kWUm+IcmvlVImHu89SymdJL+d5Ppa67OT3J3k+0f/mONVzB0DALTWmawgvzDJ7lrrHbXW+STvSHLdinOuSz9sk+T3k7yi9CvyuiTvqLXO1VrvTLJ78H6P957nJZmvtd46eK8/T/Ltw3+8s8eIBQBAO51JIO9Mcm/j5/sGx055Tq11McmB9GP38V77eMcfTtItpVw7OP6qJE851UWVUn6klHJzKeXmvXv3nsHHGC8jFgAA7fSkukmv1lrTH8l4UynlpiSHkiw9zrlvqbVeW2u9dseOHefyMgEAaLEzuQHu/py8irtrcOxU59w3uKluS5JHTvPaUx6vtf59kpcmSSnllUmecSYf5FwzYgEA0E5nsoL8oSRXllIuL6VMpb/Ce8OKc27IiZvpXpXkfYPV4BuSXD/Y5eLyJFcmuemJ3rOUcsHg7+kk/yLJfx7lA54tRiwAANrptCvItdbFUsprk7w3yUSSt9VaP11KeX2Sm2utNyR5a5K3l1J2J3k0/eDN4Lx3JbklyWKSH6+1LiXJqd5z8Ct/upTyLenH+6/XWt83xs8LAABPqNQWfBPctddeW2+++eZz+jtv+blrcnXn7uRH359cfM05/d0AAIyulPLhWuu1K48/qW7SW0uMWAAAtJNABgCABoE8JLtYAAC0k0AekhELAIB2EsgAANAgkIdkxAIAoJ0E8pCMWAAAtJNABgCABoE8JCMWAADtJJCHZMQCAKCdBPKwji8gC2UAgDYRyEMzYgEA0EYCeWhWjgEA2kggD+nEhIVQBgBoE4E8JLtYAAC0k0AGAIAGgTwyIxYAAG0ikAEAoEEgAwBAg0AelV0sAABaRSADAECDQAYAgAaBPDIjFgAAbSKQAQCgQSADAECDQB6VCQsAgFYRyAAA0CCQAQCgQSAPqRx/ZMYCAKBNBDIAADQIZAAAaBDIo6pGLAAA2kQgAwBAg0AGAIAGgTwyIxYAAG0ikAEAoEEgAwBAg0AelV0sAABaRSADAECDQAYAgAaBPKyy/MCIBQBAmwhkAABoEMgAANAgkEdlFwsAgFYRyAAA0CCQAQCgQSCPzIgFAECbCGQAAGgQyAAA0CCQh1ROfwoAAGuQQB6Vbd4AAFpFIAMAQINABgCABoE8MiMWAABtIpABAKBBIA/NPhYAAG0kkEdlFwsAgFYRyAAA0CCQAQCgQSCPzIgFAECbCGQAAGgQyAAA0CCQR2UXCwCAVhHIAADQIJABAKBBII/MiAUAQJsIZAAAaBDIQyqrfQEAAJwVAnlUdrEAAGgVgQwAAA0CGQAAGgTyyIxYAAC0iUAGAIAGgTws21gAALSSQB6VXSwAAFpFIAMAQINABgCABoE8MiMWAABtIpABAKBBIAMAQINAHpUJCwCAVhHIAADQIJABAKBBII/MjAUAQJsI5KH5rmkAgDYSyEOzcgwA0EYCeUjH14+rUAYAaBOBPKRqxAIAoJUE8pCKEQsAgFYSyCMTygAAbSKQh2TEAgCgnQTykIxYAAC0k0AelV0sAABaRSAPyYgFAEA7CeQhGbEAAGgngTwyoQwA0CYCeUhGLAAA2kkgD8mIBQBAOwnkUdnFAgCgVQTykIxYAAC0k0AekhELAIB2EsjDOr6ALJQBANpEIA/NiAUAQBsJ5KFZOQYAaCOBPKQTExZCGQCgTQTykOxiAQDQTgJ5SHaxAABoJ4E8tOUVZKEMANAmAnlIshgAoJ0EMgAANAjkUdnFAgCgVQQyAAA0CGQAAGgQyCMzYgEA0CYCGQAAGgQyAAA0CORR2cUCAKBVBDIAADQIZAAAaBDIQyrHHxmxAABoE4EMAAANAhkAABoE8qjsYgEA0CoCGQAAGgQyAAA0COSRGbEAAGgTgQwAAA0CGQAAGs4okEsp31BK+VwpZXcp5XWneH66lPLOwfMfLKVc1njuZwbHP1dK+frTvWcp5RWllI+UUj5WSvlAKeWK0T7i2TL4qhC7WAAAtMppA7mUMpHkzUm+McnVSV5dSrl6xWmvSbKv1npFkjcl+aXBa69Ocn2SZyX5hiS/VkqZOM17/nqS76m1PjfJ7yb52dE+IgAAnLkzWUF+YZLdtdY7aq3zSd6R5LoV51yX5LcHj38/yStKKWVw/B211rla651Jdg/e74nesybZPHi8JckDw300AAD4wnXP4JydSe5t/Hxfkhc93jm11sVSyoEk5w2O/8OK1+4cPH689/yhJDeWUo4lOZjky091UaWUH0nyI0ny1Kc+9Qw+xpiVc/8rAQA4+56MN+n9ZJJvqrXuSvJbSX75VCfVWt9Sa7221nrtjh07zukFAgDQXmcSyPcneUrj512DY6c8p5TSTX804pEneO0pj5dSdiT50lrrBwfH35nkK87okwAAwBicSSB/KMmVpZTLSylT6d90d8OKc25I8v2Dx69K8r5aax0cv36wy8XlSa5MctMTvOe+JFtKKc8YvNfXJfnM8B8PAAC+MKedQR7MFL82yXuTTCR5W63106WU1ye5udZ6Q5K3Jnl7KWV3kkfTD94MzntXkluSLCb58VrrUpKc6j0Hx384yf8opfTSD+YfHOsnHjfbvAEAtMqZ3KSXWuuNSW5cceznGo9nk3zH47z2DUnecCbvOTj+h0n+8EyuCwAAxu3JeJPemmATCwCAdhLIIzNiAQDQJgIZAAAaBDIAADQI5FHZxQIAoFUEMgAANAhkAABoEMgjM2IBANAmAhkAABoEMgAANAjkUdnFAgCgVQQyAAA0CGQAAGgQyCMzYgEA0CYCGQAAGgTykMpqXwAAAGeFQB6VXSwAAFpFIAMAQINABgCABoE8MiMWAABtIpABAKBBIA/LNhYAAK0kkEdlFwsAgFYRyAAA0CCQAQCgQSCPzIgFAECbCGQAAGgQyAAA0CCQR2UXCwCAVhHIAADQIJABAKBBII/MiAUAQJsIZAAAaBDIAADQIJBHZRcLAIBWEcgAANAgkIdUVvsCAAA4KwTyyIxYAAC0iUAGAIAGgQwAAA0CeVR2sQAAaBWBPKTqNj0AgFYSyEOSxwAA7SSQR2bEAgCgTQTykGQxAEA7CeQhGbEAAGgngTwqu1gAALSKQB6SLAYAaCeBPCQjFgAA7SSQAQCgQSADAECDQAYAgAaBPCq7WAAAtIpAHpa79AAAWkkgD6lYOAYAaCWBPDKlDADQJgJ5SLWYsQAAaCOBPKRi5RgAoJUE8qjsYgEA0CoCeUjVNhYAAK0kkIdkxAIAoJ0E8siEMgBAmwjkIRmxAABoJ4E8JCMWAADtJJBHZRcLAIBWEchDM2IBANBGAhkAABoE8siMWAAAtIlABgCABoEMAAANAnlUdrEAAGgVgQwAAA0CGQAAGgTyyIxYAAC0iUAGAIAGgQwAAA0CeVR2sQAAaBWBDAAADQJ5WGW1LwAAgLNBII/MiAUAQJsIZAAAaBDIAADQIJCHVOxeAQDQSgJ5VEIZAKBVBPKwim0sAADaSCAPzcoxAEAbCeSRCWUAgDYRyEMzYgEA0EYCGQAAGgTyqOxiAQDQKgIZAAAaBDIAADQI5JEZsQAAaBOBPKKb//pPcuQ/fnmyOLfalwIAwBgI5BFdu/iRbNj3meSR21f7UgAAGAOBPC61t9pXAADAGAjksTGLDADQBgJ5XKwgAwC0gkAeF18YAgDQCgJ5bAQyAEAbCOQhlZUHjFgAALSCQB4XIxYAAK0gkMdFIAMAtIJAHhuBDADQBgJ5XMwgAwC0gkAeF4EMANAKAnlczCADALSCQB4bgQwA0AYCeVyMWAAAtIJAHtbKbwoRyAAArSCQx8UMMgBAKwjkcbGCDADQCgJ5XKwgAwC0gkAel7q02lcAAMAYCORx6QlkAIA2EMhDW7GNhRVkAIBWEMjj4iY9AIBWEMhDKiu/Oc+IBQBAKwjkcbGCDADQCgJ5XAQyAEArCOQhGbEAAGgngTwudrEAAGgFgTwuVpABAFpBIA9r5VdLm0EGAGgFgTykUnxRCABAGwnkcelZQQYAaAOBPCwjFgAArSSQx8WIBQBAK5xRIJdSvqGU8rlSyu5SyutO8fx0KeWdg+c/WEq5rPHczwyOf66U8vWne89SyvtLKR8b/HmglPJHo33Ec8QuFgAArdA93QmllIkkb07ydUnuS/KhUsoNtdZbGqe9Jsm+WusVpZTrk/xSku8qpVyd5Pokz0pySZK/KKU8Y/CaU75nrfWljd/9P5K8e+RPeRY85otCrCADALTCmawgvzDJ7lrrHbXW+STvSHLdinOuS/Lbg8e/n+QVpb/Nw3VJ3lFrnau13plk9+D9TvuepZTNSV6e5Mm5grxiEwszyAAA7XAmgbwzyb2Nn+8bHDvlObXWxSQHkpz3BK89k/f81iT/q9Z68AyucfXZxQIAoBWezDfpvTrJ7z3ek6WUHyml3FxKuXnv3r3n8LIGv/8xu1gYsQAAaIMzCeT7kzyl8fOuwbFTnlNK6SbZkuSRJ3jtE75nKeX89Mcw3vN4F1VrfUut9dpa67U7duw4g49xlrlJDwCgFc4kkD+U5MpSyuWllKn0b7q7YcU5NyT5/sHjVyV5X621Do5fP9jl4vIkVya56Qze81VJ/qTWOjvsBzvnzCADALTCaXexqLUullJem+S9SSaSvK3W+ulSyuuT3FxrvSHJW5O8vZSyO8mj6QdvBue9K8ktSRaT/Hit/VmEU71n49den+QXx/UhzwkjFgAArXDaQE6SWuuNSW5cceznGo9nk3zH47z2DUnecCbv2Xjua87kulbTyk0sjFgAALTDk/kmvbXFiAUAQCsI5HERyAAArSCQh7ZimzcjFgAArSCQx8VNegAArSCQx8WIBQBAKwjkIRUjFgAArSSQx8WIBQBAKwjkcan19OcAAPCkJ5CH5ItCAADaSSCPixELAIBWEMjjYgUZAKAVBPLQTp45rrZ5AwBoBYE8LlaQAQBaQSCPSRXIAACtIJCHtPKLQoxYAAC0g0AeFyvIAACtIJDHxIgFAEA7COQhPWbEQiADALSCQB4XM8gAAK0gkMfFCjIAQCsI5DGpK0YuAABYmwTyuBixAABoBYE8LtUKMgBAGwjkcbGCDADQCgJ5SCu3ebOCDADQDgJ5bAQyAEAbCOQxqUYsAABaQSAPaeWIRTFiAQDQCgJ5TKwgAwC0g0AeGyvIAABtIJCHtbKHjVgAALSCQB4XIxYAAK0gkIdVVvxsARkAoBUE8pAes2uFFWQAgFYQyGNjCRkAoA0E8tgIZACANhDIQzNiAQDQRgJ5XGzzBgDQCgJ5SCs3sbCCDADQDgJ5aI/5ppBVuQoAAMZLII+LEQsAgFYQyENbMWRhxAIAoBUE8pDKipGKx8wkAwCwJgnkcbGCDADQCgJ5XMwgAwC0gkAeGyvIAABtIJCHtvKb9KwgAwC0gUAeG4EMANAGAnlc3KQHANAKAnlIj9nmzQIyAEArCOSxsYIMANAGAnlc3KQHANAKAnlIj/3mPIEMANAGAnlMipv0AABaQSCPjRVkAIA2EMjDWjlzbAYZAKAVBPLYCGQAgDYQyGNSrCADALSCQB7Syi8KsQ8yAEA7CORxsYIMANAKAnlMjFgAALSDQB7ayiAWyAAAbSCQx0YgAwC0gUAeE9+kBwDQDgJ5SOUxP1tBBgBoA4E8Tm7UAwBY8wTyOAlkAIA1TyAP7RQxbA4ZAGDNE8hjZQUZAGCtE8jjZMQCAGDNE8jjZMQCAGDNE8hDOvW2blaQAQDWOoE8Bkt1sCuyFWQAgDVPII9Bb/mf0QwyAMCaJ5CHVBoxfDyQjVgAAKx5AnkMlo6vIBuxAABY6wTyGPSyPINsBRkAYK0TyGPQs4IMANAaAnkMlvwzAgC0hrIbAyMWAADtIZCHdopdLIxYAACseQJ5SKXx+PgKsm3eAADWPIE8BrZ5AwBoD4E8tFONWFhBBgBY6wTyGPTq8k16VpABANY6gTwGS75qGgCgNQTykIoRCwCAVhLIY+AmPQCA9hDIY9AzYgEA0BoCeWi+KAQAoI0E8hj4qmkAgPYQyGOw5J8RAKA1lN0YGLEAAGgPgTyk0pimMGIBANAeAnkMbPMGANAeAnkM6vIKsm3eAADWPIE8tBMxvJCJwSGBDACw1gnkMXCTHgBAewjkMVhaXkE2YgEAsOYJ5CEV36QHANBKAnkMemaQAQBaQyCPwYlv0hPIAABrnUAe2okYtg8yAEB7COQx6JXlEYvVvQ4AAEYnkMfATXoAAO0hkIdUGo9t8wYA0B4CeQx6xQoyAEBbCOQxWGps83b3nv1ZfPiO1b0gAACGJpCHVZu7WPQD+eHDs3n/r/xgur/6ZcmRR1brygAAGIFAHoPlm/T2HZ7Nyyc+2j+4cGQVrwgAgGEJ5DFY3uat16vpZjCH7Fv1AADWJIE8tBMBvLyCvLi0lG4W+weX5lfjogAAGJFAHoPlQF5YWspklvoHBTIAwJokkMdgaTBiMbewlO5yIC/OreIVAQAwLIE8pNIYsaiDfZDnFxZPBLIVZACANUkgj0FvsM3b3OJiJosVZACAtUwgj8HyDPLc/NKJg1aQAQDWJIE8BsvbvM0vLp44KJABANYkgTy0xjfpDQJ5dqGxgmzEAgBgTRLIY1AH/4xWkAEA1j6BPAbHRywWGoFsBRkAYE0SyEMqjW+SXhrsYtGbn20ctIIMALAWCeQxqIMV5LJw+MRBgQwAsCYJ5DFYGnxRyMRSYwXZiAUAwJokkIfW+Ca95X/Gnn2QAQDWOoE8Br3STZJMVDfpAQCsdQJ5DOpgxKL0bPMGALDWCeQhlcaIRW+wi8VJK8gCGQBgTRLIY7C8D3LHiAUAwJp3RoFcSvmGUsrnSim7SymvO8Xz06WUdw6e/2Ap5bLGcz8zOP65UsrXn+49S98bSim3llI+U0r5idE+4tl3fMSiukkPAGCt657uhFLKRJI3J/m6JPcl+VAp5YZa6y2N016TZF+t9YpSyvVJfinJd5VSrk5yfZJnJbkkyV+UUp4xeM3jvecPJHlKkmfWWnullAvG8UHH7aQRi/LYEYu6OJdyzq8KAIBRnckK8guT7K613lFrnU/yjiTXrTjnuiS/PXj8+0leUUopg+PvqLXO1VrvTLJ78H5P9J4/luT1tdZektRa9wz/8c6N5RXkzopABgBg7TmTQN6Z5N7Gz/cNjp3ynFrrYpIDSc57gtc+0Xs+Pf3V55tLKX9aSrnyVBdVSvmRwTk379279ww+xtlzqm3eegsCGQBgLXoy3qQ3nWS21nptkt9I8rZTnVRrfUut9dpa67U7duw4pxe40ql2sahmkAEA1qQzCeT7058JXrZrcOyU55RSukm2JHnkCV77RO95X5I/GDz+wyTXnME1rqrju1jkxE16dWlhtS4HAIARnEkgfyjJlaWUy0spU+nfdHfDinNuSPL9g8evSvK+WmsdHL9+sMvF5UmuTHLTad7zj5K8bPD4q5PcOtxHO3eWZ5CXV5DnajcRyAAAa9Jpd7GotS6WUl6b5L1JJpK8rdb66VLK65PcXGu9Iclbk7y9lLI7yaPpB28G570ryS1JFpP8eK39vdBO9Z6DX/mLSX6nlPKTSQ4n+aHxfdwxqfXkH5dHLAYryHOZzHTzW/UAAFgzThvISVJrvTHJjSuO/Vzj8WyS73ic174hyRvO5D0Hx/cn+eYzua4ni9rc5q0kc5nKtBVkAIA16cl4k96aUzvLIxYnVpCzZAUZAGAtEshj0Fs5YlEnkyqQAQDWIoE8jJUzyIMRi24GN+llyk16AABrlEAeg9qZTJJMHlK+o4YAACAASURBVA/kyRQ36QEArEkCeQzqRP9ex2Ygp2cFGQBgLRLIQ1k5YtFfQZ5KP4rn6mRKb+kxrwIA4MlPII/DYAV56qQRCyvIAABrkUAeg16ZSnJixGI2U2aQAQDWKIE8jBW7WBxfQS7LXzU9mWKbNwCANUkgj0Hp9Ld5s4sFAMDaJ5DHoNPppFdLI5CnUlITN+oBAKw5AnkoJ49YTHRKltLJdHObt8SXhQAArEECeQwmSkkvnRMryHUQyMYsAADWHIE8Bp3BCnKn9FeWj68g2+oNAGDNEcjDWLGLxUTpB/Ky2fS3fcuSFWQAgLVGII9Bp1PSSzn+83yMWAAArFUCeQwmOjm+glzTyUL6274ZsQAAWHsE8lAef8Siloks1kEg28UCAGDNEchj0B+xWA7kThaPryAbsQAAWGsE8hictILc6WapCGQAgLVKIA9j5S4WjRXklE5q8UUhAABrlUAeg1JKerW/i0XtdFM73f4TVpBpqV6v5ujRI/5LIACtJJDH4KRdLEonPYFMy73hxs9k/b+/JPU/PX+1LwUAxk4gj8HyV00nScpEshzIVtdoqXd96N4kSdl/9ypfCQCMn0AeyskzyMtfNd3/oZtalleQBTIAwFojkMfg5H2QO8nE8k16RiwAANYagTwGzX2Q0+mmdmzzRsuV058CAGuVQB7GKbZ5OzFiMZF0BivIRiwAANYcgTwGj71Jzz7ItJsFZADaTCCPQWflCvLE8k16S6t3UQAADEUgD2XFiEXJSYFcOnaxAABYqwTyGDS/arqUicYuFgKZdjJiAUCbCeQx6HRKluqJXSzKxHT/8dJ8Pnz3o/mj//iTWfibN63eBcKYdWN8CID2EsjDWLmLRTl5BrlMDgJ5cS6//le351v3vS2T7/u/k6OPntvrhLNEIAPQZgJ5DJr7IJdO90QgL81l+4apEyfe+j9X4epg/CZjj28A2ksgj8FJK8gT3Ux0B1G8OJcDB/afOPHQg+f+4uAsmCwCGYD2EshDeewXhSyvIHe605menMhcppLFuSwdbETxkYfP5UXCWTPZHLGwnSEALSOQx6C5D3LpTme628l8usnSfMrhE4Fcj+xdrUuEseo2Ryzs1gJAywjkMeiPWPQ3vupMTmdqopP5TKa3MJvp2X4UH67rsnRYINMOJ60gL82v3oUAwFkgkIcx2MXigcu+LfmnH8hEJye+anpiOlPdTuZqN3Nzs9mR/gzyZ+tTs3Roz2pdMYyVFWQA2kwgj+CSZ1ybXPScdE66SW8yU93+CvLi/LFsztEkyV31opSjZpBph8nSnEEWyAC0S3e1L6ANOuXETXrpTmdqYiJztZvFudlsKp3MT6zPnsWt6R57tL/6XHwPGWvbSdu8GbEAoGWsIA/l8XexyMTUYAW5m4X52WzMsSxNbswjdVM6dSGZPbAK1wvjdfIMshVkANpFII9isBJ80ldND3axmMtUeguz2ViOpazbnAPZ2H9+dv/jvBmsHV0ryAC0mEAeg4nmyMTgJr352k1vYS6bczRl3eYcKZv6zx8TyLRAc+5YIAPQMgJ5GPXkEYtOJ+ku37TUnTp+k15dnMvGciyddZuzOL2l//yxfef4YmH8OkvNFWTfqgdAuwjkkfRXjidKycTyTObEyV8UsinH0p3ZkrpuW/95gUwLFCvIALSYQB6DiU7JRHr9H7pTx78opCzNZVM5lrJuU8rM1v7zgxnkpV5NtfLGGlRrTaeaQQagvQTyGHSagbz8RSHpZmJpPpvKsWR6c7obTqwgP3J4Lj/7r3825d+cl6X3/uzqXTgMYWGprtjmzS4WALSLQB7Kim3eSkl3ecSiu3yT3mS6dS4bciyZ3pT1GzZlNlPJsf356D3784Lex5Iki5/+43N98TCSxV4vk8UKMgDtJZBHMdi94qQRi4mpTHcnMpfJbK0H+8emN2fLzGQO1A3JsX255fMHc3W5u//UwbvMJbOmLCzWk/dB9k16ALSMQB6DzqlWkDOZiTJYaZ7elK3rJ7Ovbkzv6L7cet+eXNm5Px/Plf3nH/jY6lw4DGGh1zt5H+SFY6t3MQBwFgjkYdTHfpPeiV0slm/Sa3yL9/rzsn3DVB6tm7J4aE9mH7otE+nlw1u+rv/8ns+cowuH0S0unVhBnquTmbv5v63yFQHAeAnkkSyPWCTdcmLEYnkG+bj123PBpunsydbUQw9m6uA9SZLZC56X/dmY+vCt5/rCYWgLS73jN+n9xtI3Zfre92fugU9lYWE+6S2d5tUA8OQnkMeg09wHudM9sQ/ysvXn5YLN67KnbsvEkT25pD6YJNl0yZW5vXdxFvf0A7nWms/e9UB6e3ef648AZ+zo/FJmylxqSj459WVJkum3vCSTb9iR+huvWOWrA4DRCeQxmOiUdJdv0ut0s3G6m8OZOXHC+vP6K8h1a7q92VzVuTuLk5uy6+KLc0fv4tSHb0uS/Mu3/0V2/NYLU3/thcl9H16FTwKnd3huIZtyLEuTG3Ln1JUnPVc+/9FVuioAGB+BPIrBLhYnryBPZOv6ydxbLzhx3rqtOX9jP5CT5Npya5a2XporLtiU3XVnpo7tyW133ZOLbv3dnFcOZaIuZe7G153rTwNn5NDsYjbmWHqTm3LVZTtX+3IAYOwE8hgs9epJK8illNzdDOSJbqa6ncyu25EkubSzJ90dV2bXtpnjK3A3feDP810Tf5VDT3l5fmHxezL9wE3Jg59KrTUfuu2B7P7r303df8+5/mjwGIfnFrOxHEud3pQ3fNtz8n0bfn21LwkAxkogD2NyJnnFzye7XpAkWezVk2aQk+TBcsFjXtbbcOLYxM7npZSSzs7nJUmedvvbc1F5NJte8N3Zc/m3ZzZTWbrpN/OmP745G9/+ylzxlz+WhV95QXLPPyRJ5hd7uff++7K4/4Gz+UnhMQ4PVpDL9KZsnO7msmdck/k6cfz5v/3XX5PejT+9ilcIAKPpnv4UHmNyJnnpTx3/cWZqIh+pu/IluS9ZtzlJsm7duiwvKi+79Mprko8Mfth1bZLkqst25XP37MqLOx9Nr3TT+ZJvyLdNH8sfv/3Lc91H3p5v7f1pLu3szR9c9BP50gf+e3b+9rfn7y57bY7d8ff5ut4H0i1LeWDTNTlw1atz75FOug99vD+mse3SdC68KkfrVOYO78vUwqFMTE6lMzWTian1SXc6KZ2UUlI63XS63ZTOREqnk1KW/y4rfu70/+5MpJROOsuPO510Bs/1/55IOiWdzkQ6nU7SmUhncH5n+fzOyT+X0jk+ssKT2+G5xWwqx9KZ6f8vIpvXTZ70/EvqR5ObPpp80xtX4/IAYGQCeQx2bp3JA//4NzM3cXemt+xKkvzm912bd7/7+/MtL3hmltfWXv3ll+dXbvrW/ET3j5KLvzRJ8n0vvjQ//4FX51fyxuTl/yqZ3pSvecbG/OwVr81L7/xkLuvsSf3mX851z/+BvPFdX5Vvu+Wf5eW3/2Jmy7rc8dRX5RMHN+YF+96Tq276mVyVZCHd7K8bsmPvgWSN7R7XqyW99P/UdAZ/l/TSSS1pHFvx3PKxUo4/rimppfH4+POdk4+XTjJ4r1pWHCud4+cnnf7Pg8cpJ16T5nmlM3i+k0xMpnank+66/n8h6c6kTK5LZ/nP1Ew6UzPpTq5Ld3p9pmfWZ2bjtqzfvC3rN21NmZx5wn+v1XJwdjGbcjQTM/3/Mrh55tT/MXLXnoPZdvAz2fK0FyQd/2MVAGtHqSu+9GItuvbaa+vNN9+82pdxRmbnFzOd+ZSp9cePHZxdyNSxvVm39eLjq6i11jz46L5cOLWYzqYToxl3PrQvM/tuzUWXPTNZtyVJcv++Izlw50eya+tMNj/1OVnqTOWeB/fmyH2fzvrJmo2bt6eu25L5ufnMzx7JwtyRZHEuqTW11iwtLaa3tJjSW0yv1tTeUlJ7qbWm1l7S6/X/rr3UXv/v5cfLx/vnD37u1ePHsuL5k471+r8jtZdSe0lO/boyOCfp9b+kpfb/Lhm8rvHz8fNz8nuW4+efeK6kDv5uvl9NcuJxJ43XHj+/+XM9OdXriYSfyGKm63yms5DJ8oXvDzyfbo5kfY51NmS2sz5z3Y1ZmNySxZnzkw07MrHpgkxtuSjrt1+UrefvzOYLLz3p/67Oltf/8S350Zu/KRc+71uS6341v3fTPXnVe577mM/4id7luaZzZ47+o/+S+zc8O1dcuCll26Vn/foA4EyVUj5ca7125XEryOfYuqluVv6zb143may75KRjpZRcfN72x7z+8gu3JRe+6KRjO7dtyM5tLz3+80SSyy+5ILnksXPQnHu9Xs3swnzmjh3L/NyRLMwey/zc0SzMzWZx7kgW52ezOH8sC8eOZPHYwfSOHUidO5gydyid+UOZWDicyYVDmVo8ko1zd2brwY9maw6nUx77X24fLVuzb+riHF2/M70tT83MRVfm/Mufm22XPSdletNYPs/huYVsLMeS6f4K8qZ1p/6PkWs6dyZJ7nnPG/PM3u4sdabyV1/7J9l614153le8MuWyl4zlegBg3AQynGWdTsm66emsm55OsnXk96u15uCR2Ty694EcfuTzObrv8zm274H09t2byUP3ZePsAznv0U/m4kf/MpN3LSX9+zrz0MRF2bfh6entuDpbrvzyXHz1V6az+aIv+PcfmZ3Lhswmg+Ce7k7kif53qGf2+l98M9Gbzyv+7JVJkmO7fzN/Nf2yPK/ekvP/0b/OwV1fk63rMraIB4BRCGRYY0op2bJxJls2Pj25/OmnPKfWmkcOHcs9t9+S/Xd9PIsP3pL1+2/NhQfuzNMP/EMmb/+N5H8meycuyCNbn5POrmuz45kvybanX5tMbXjC379w7HD/wSBma61Zvr3ydzZ8f55fPptnHv5gkuRN+e78ZH43d1/0ynzq/gP55okP5s9nvjEvOfq+fOOxP06S9P7792airstCZyl3POefpbfhglz1vK9K2fElo/9jAcAQBDK0UCkl529en/O/7Nrky06MVvV6NXc++HDu+fQ/5NidH8zGhz+Wpz388ex65H8lH0+W0snnJy/Nwe3PTvcpz8/2K16YbU+5OhPrtx6fj+8d2tN/s0EgP+PCTflvS1+bf9J9b77np345+2Z7+cW3/Gpeu/Vv82Pf8yvZu+9f5tJt2zNzrJOjR+/NS897Wv7mppvzlZsfyp8euyrb/u7fZmt3IYf33pOv+sS/T5Is/X0nt808NzM7Ls3ml/5YNl9yZSY2PHbkCADOBjfpwRe5Y/NL+eztu/PwZ/8+S/d9JFv3fypXLN6W88vB4+ccyUwe7l6Y/Z1tOX/unlzUOZCJ196UnNdfwT4yO58NncVkhJsE733kSObv/XBue3guCx/6rTxr/hPZ0Xs4m8qxJMldM8/K0W3PzORlL87GC5+W7Zc/J1Mzm1Mm1432DwDAF63Hu0lPIAOPcfDYfG697bM5cteHs/TInekcuC8bj92XDYv7s7Hby0Uv/7FMvug1Z/Ualno1f/uJzya3vjcP339Hrjnwl7mg7s3mQTAvezRbMlems1Cms9Dp/1la/jOxLr3udHoTM6nddf0t9yZnUrrrUqZm0pmcSWe6vzf4xNT6dKdnMrVufaZnNmZ6/abMbNyadRs2pXSnz+pnBWB1CGRgzbt/35HsvfWmHHjkwXT2fiaLxw5l3dzedBZnM7E0l4neXLq92XR7c5nszWWyzmeqzmUq85mu81mX+XRL7/S/aIX52s3Rsi6zZSazZSbzEzOZ76zPYrf/Z6m7IXVyQ+rUxnSmN2Zi3aZMrt+UqZlNWbdhS9Zt3JL1m7Znw9bz012/NelMnP6XAnDW2eYNWPN2btuQnS962dCvX+rVHJ2bzdyxo5mfPZL52f7fC7NHszh3NIvzR7M4eFznDqU3dyR1/nDK/JF0Fvp/uotHM7nU/7N+YV/W1WNZV49lfT2WdWXhtNfQqyVHykwOl405NrEpxyY2ZWFyc5amt6Su25qJ9dsysWFbpjedl3VbLsyG7Rdl03kXZ3rT+cIa4BwRyMAXjYlOyfqZmayfmUly3tjff3FhPkcOHciRQwdy+PCBzB4+kLmjBzN/9GB6Rx9NPbo/ZXZ/OnMH0104kKmFQ1m3eDBb5+/IhsOHs7keyfTjRPZSLdlftuTQxNYcndyehXXb01u/IxMbd2Ry60WZOe+p2XThU7P1wssyMbNl7J8N4IuJQAYYk+7kVLZs35Et23cM9fqFpV72HjiYg/v35vC+vZnd/1AWDu3p7xxy5OF0Zx/J1NyjmZl/NNtnP5Wt+w4cv4mx6Uhm8sjE+TkydUHm11+UbL4kU9ufkg0XXJbtu67Mxguf3v/6cwBOSSADPElMTnSyY/vW7Ni+NcmVpz1/frGX+/fvz/6H7suhvfdk/tF70zvwQCYOPZDpYw9m49yeXHj0zux4eF8m7jxxv0kvJY+U8/Lo9M7MbtyVbLs8Mxc+Peft+pJs3/WMlA3nH9/WD+CLkUAGWKOmup3sPH97dp6/Pck1pzyn1pqHDx7Nns/fk/2fvz1ze+5I9t2V6UP3ZPPs/blo79/lwoffk9x24jWHysbsnb40RzY9LfX8Z2T9JVflwsufk00XX5FM+P82gPbzn3QALVZKyY4tG7Jjy1XJM696zPO9Xs0Djzyaz999aw48cFsW9uzO5P7bs+3oXdm55/25YO8fJ5/pn7uQbh7qXpKDG5+W3nlXZP0lV2XH056bTbuelUzOnONPBnD2CGSAL2KdTsklO87LJTtenOTFJz03v9jLXQ9+Pnvu/HQO339L6t5bs/7QHblg36156r73Z/L2peT9/W9gfKh7SfZveFoWz78qMzufnQue/txs2XVVMjG5Oh8MYAQCGYBTmup2ctmunbls184krzx+vNereeDRg7n/9k/l4L2fTH3oM9l44LZctH93Lt3//kzcXpO/6a84f767Kwc3PT11x1XZ+JRrcvGVz8u6C55myzrgSc0XhQAwFrXWPPDI/jyw+xM5dM8nkz23ZOPB3bl47s48pew5ft5cpvLQ9KU5uuXKdC56drY+7fnZ8YwXpqzfvopXD3wx8k16AKyKXq/m3gf35v7dH8uhez6Rsvez2XJ4d566eHcuLo8eP++hzoV5ZPNVycVfmvOufGEueMYLUzZesIpXDrSdb9IDYFV0OiWXXnJBLr3klWmOahyeW8zH77k3D996U5bu/1g2PPKp7Nz32Vy2/6+O3xi4p3txHt7+vEw/7Suz60tflumLnmkLOuCss4IMwJPG4lIvt91zX+77zE2Zu/vmbH3ko3nmwi05vxxMkhzsbMme7ddm8ku+Njuf/83pbr90la8YWMuMWACwJh04Op9Pf+LDefgzf52ZBz6YZ81/LJcMRjMenLo0R5/61bnohd+e9Ve81M1/wBdEIAPQCo8cms0nP/7BHPjke3PBQ+/P8+pnMl0Wsr+zLQ8/5ZW55MXflfVXfrUvNQFOSyAD0DpLvZqP3X5f7vmHP8q2u27MixZvzkyZz8GJbdl35bdn58t+JN0Lv2S1LxN4khLIALRarTWfuOOBfOb9f5AL73p3Xlo/nG7p5YEtX5ZNX/GabHr+dybd6dW+TOBJRCAD8EVjYamXD3zs03nob34rL9r3J7m881AOdM/L3PN+OBe87J8mM9tW+xLH5v237c3WD/9qnvOy70ouvHq1LwfWFIEMwBel3Q8dyt//+bvy9Nv+a76ifCKzZV0OXfNPsuPr/3nSgi8nueJ1787udd+XTEwl/2rval8OrCmPF8id1bgYADhXrrhwU773H78mz/oX78vbn/s7eV99fs772H/Osf/w7Oz7019I5g6t9iWOZCqL/QdL86t7IdAiAhmALwpb1k/me7/1W/KVr3t3fvd5v5e/W7oq2z74xhz6D8/N0Y+8I1mj/4vqdIQxjJtABuCLyuZ1k/nH131jnvN/vie/+rRfz51zm7L+hh/Nw7/29cmez6725X3Bjq8gA2MjkAH4onTB5nV57fd9dzo//L68ecOPp7vnU1n8tZfk8P96Y9JbWu3LO2PTZWG1LwFaRyAD8EXt2U/Znh/9qV/IH7zk3fmL3vOy8f2/kH1v/trk0TtX+9LOyFQagbxGx0T+//buPUqOsk7j+PdXVd09F3IhJOSYBBFI1IOCCEFZdVGIIopr2F1WghcuBtGzIOJtAT0qihFdIei6yjELcnFZLkb3mF0VVwHPLqhAEEW5eBIDCQnBBAIzk7l1V9Vv/6iapGZym0lmusee53NOn6p6q7ret2beU/NM91tVIuONArKIiEx4URjw/pOOZe7532fpfh8nfPYx+r75BuLHftzopu3RpKjwaXdfR+MaItJEFJBFRERyc2dO5vyLPs21r7iJ1bXpRLedQc8dnx/XQy6mlgufGnc/27iGiDQRBWQREZGCShTysXedxNpT/5Pvp2+i7ddL6fr390Ktt9FN26mSF+5iEfc1riEiTUQBWUREZCdOOfpQ5p57A0uDc2hf8xM6l50CPVsa3awdWPH+x7oXssioUEAWERHZhVe9eH9Ov/AKlrR9ksqmh+m+5kTo3NjoZg0SFENxqlu+iYwGBWQREZHdmD21lQ9f8Ek+N+WLeOdGupe9FTqfbnSzAHB3glSfIIuMNgVkERGRPZjaVuZT/7iYL01bQtq1ie5lJ0PHhkY3i2qSDr7NmwKyyKhQQBYRERmGyS0lPv2hs1mSh+Se6/6m4WOS++N08INCEj00RGQ0KCCLiIgMU3sl4tIPnMll+32WsGMd3df/HVR7GtaeaqxPkEXGggKyiIjICExpK3HxB9/PFyofpWXzb+n9jzMhaczFcVlA3l73c7/5IWzd3JC2iDQTBWQREZEROnByC+eedxFXcC6tT/6M/h9f2pB29McplcInyAes+h58928b0haRZqKALCIishcOmd7Oie+7hO8kb6fy4DKSlTfWvQ3VOKVsQ8Ydb3687u0QaTYKyCIiInvpdYdNp+2UJfxvcgT86GOw7td1rb8ap1QYOrzDd7qtiAyfArKIiMg+WHTcodxz1D+zLjmA/pvfA13P1K3u/jihwpAL8zytW/0izUoBWUREZB99fOFrueqAy0j7Oum99f2QJnWpd+AivR6vbC/0FF/7y7rUL9KsFJBFRET2USUKueTMU7kiOJfWDfdSu+uKutTbnz8opMdaB5Xb9W+rS/0izUoBWUREZBTM2b+NExZ9lOXJ8YT3XAl/unvM6+yvZQ8K6bW2Ma9LZCJRQBYRERklJ7zsQDa87nJWp7Pou23xmI9H7q3FtNJPLWgZ03pEJhoFZBERkVF0wVtfxbdnfpa0fys9t5w9pg8R6eqLmWw9VKP9dlzZoIeXiDQDBWQREZFRFAbGxe87la+EH6Dt6V9Ru+tLY1ZXV1/MJHqJS5N2XNnfOWb1ijQ7BWQREZFRduDkFt58xkXcnryR8N6lsPrOMamns6/GZOuhtpOA3Put46Fny5jUK9LsFJBFRETGwF/Pm8HG113OqnQ2/bcvhs6nR72Ozt5siEVvuOMQi9atT/H7byzihW+fAtWeUa9bpJkpIIuIiIyR8086gm8f+Fni/h56x2A8cldvlXZ66Qvad7r+iN77mLrxHlh//6jWK9LsFJBFRETGSBQGXHzmQq4IPkjrxvuo3fnFUd1/rbeLkJTeXQTkbZLaqNYr0uwUkEVERMbQzMktnHTGhdyanEDpl1fjf7xj1Pad9nYA0GO7D8hp50ZwH7V6RZqdArKIiMgYO/6lM9j0+i/wSHowtdvPgWd+Pyr79b48IAe7f1BI8F8fhnu/Nip1ikwECsgiIiJ1cMFJR3DL3Ct5Nm6h94a/h44N+7xPy2/l1hPseJHeLfEJg5b9rtEd3iHSzBSQRURE6iAIjM+8ewFXTV9C0ttJ97+9bZ9DcljtAnYyxOJdNxG882ssT47fVmRpTMef17H5uWehT/dIFtkdBWQREZE6qUQhn/vAP7Bk2hLSrk1svWYBvvF3e7WvLd1Vpid/BuCFcP/BK8Myp7/mJdz18ssGFU+55ghmfOMw+PJBbPnx5RD371XdIs1OAVlERKSOJreU+PSHzuKqWUvp6u2ntuwtdN65dMR3mnjgyS0cG/yRattMngsP3Fa+5cjzYO5bADjtmDn8JDmWnqCdh9K5g94/7f4r6bzqaNIn7tn3gxJpMuZNcFXr/PnzfeXKlY1uhoiIyLClqXPDz+7n4HsvZUHwIC9EM9h82Gm0vexNtM48DI9aSdOUWrVKtdpHXO2DpEoUhASlErc98BRnrvoI01/xRj5T+gRf+t0bsh1f1rHT+p7p6GP5V8/jguiHO6x7sv1Itkw/lrBUpq9tFke+8khaDp6PVXYc2yzSTMzsQXefv0O5ArKIiEjjrH2um1/86GZe+qebeC1/ILDh/11OCAnffQvdBy/gF3f/D2+f14oddsIut3/86S3M7l+DTZ1D+5QZ/OTBVWz66ZWcHX9vp9s/dMAp0H4g0aQZ1PabRet+U5k0eSrtU2fQMm0OrW3tEJZGfMwi44UCsoiIyDhWS1IeW7OOrU/cDx3rCdMaZhCEZYJShaBUwcMySeJ4WqUlcA4/8ljC2UftU71J6vxm9QZW3fEtXvn8zzk0XUuJBDOny9uYShfhLkJ7n5eoWoXng6mAkVhEYmXioEQSlEmtRBqWSYMSaVDGw/wVlCGqQFjOXkEEYYRZCEGEhSFYiIURFoT5K4IgJBhYDiOCIMzKwoggCLD8vTZQFoYEQUQQRoRhti5bDgnCMC+LCIOIMMrWhVG0rQ7M9ulnK+OfArKIiIiMSGdfjVWPP8zzax+hvWM1pDFmRjVOCKtbieJO4lpMS9oNnmJpjTCtEnqNMK0Reo3Ia5S8SuQ1ImLKXqNETJkakaWNPsTdStxICEgJSC3I58NsuVC+fT7cNvVt60LcguxFSDowb2Fhmm3vQQj51C0EC8BCPMim2fzgqVkAQYQHogV5BAAACJ9JREFUUfbPRZT902FhRBCWsaiEhSXCqIRFFcKoRBCVCKIyYVQmKpUJwhJRuUIUlQlLWdnAq1QqY2EZgua8bG1XATlqRGNERERk/JvcUuKYo46Bo44Z9X27O/21GrVqH0kckyYxSVzD04Q4ifG4RpokJElWliYxaZLg6cA0IUliPE3wJCH1BJKENN1e5p7gSQyevYc0wdMUfGC+MM3LilNPU6ywnM2nGFmZeZqXp1gaZ1PyZR88Dcjn05gwnw9ICTzFSAk82R67vRjBEwLPYvlANB80HcGQnH0Re0BsITERVbJvDmpWJrYSNauQBOXsFbaQhJX824IWPKrgYQVKrVjUgpUqWNRKUGklrLQTVdoptU5i/9lzmT7r0Locy3AoIIuIiEjdmRmVcplKudzopvxFcndSh2qSkiQxSVwlqdWIa33ZNO4nrlVJ4lq+rkpaq5LEVdK4Rprk07hKmtTwuIontUEvkhqexFhShbQGSYylVSytEiT9BEl/9o1BPo3irbRUt1DyKiWvUqZK2WtUqFGx3d+l5VcHncf0xV+t009vz4YVkM3sZODrQAhc6+5fHrK+AtwEHAM8B5zu7k/m6y4FFgMJcKG7/3R3+zSzG4A3AgOX4Z7t7r/d+0MUERERaS5mRmgQBiGUQqDS6CbtUpo6fXFMf18f/X3d1Hp7qPZ3U+3dSrV3K3HfVmbNnrvnHdXRHgOymYXAN4G3AOuBB8xshbs/WthsMfC8u881s0XAV4DTzexwYBHwCmAW8HMze2n+nt3t85PuvnwUjk9EREREGigIjJZyiZZyCSZPanRzhmU4I65fA6x29zXuXgVuBRYO2WYhcGM+vxxYYGaWl9/q7v3u/gSwOt/fcPYpIiIiIlJ3wwnIs4GnCsvr87KdbuPuMdnwiAN289497XOJmT1sZlfnwzd2YGbnmdlKM1u5efPmYRyGiIiIiMiejcd7dlwKvBw4FpgGXLyzjdx9mbvPd/f5M2bMqGf7RERERKSJDScgbwAOKizPyct2uo2ZRcAUsov1dvXeXe7T3Td6ph+4nmw4hoiIiIhIXQwnID8AzDOzQ8ysTHbR3Yoh26wAzsrnTwPu8uwJJCuARWZWMbNDgHnA/bvbp5m9KJ8acCrwh305QBERERGRkdjjXSzcPTazC4Cfkt2S7Tvu/oiZfQFY6e4rgOuA75rZamALWeAl3+524FEgBs539wRgZ/vMq7zZzGYABvwW+NDoHa6IiIiIyO7pUdMiIiIiMiHt6lHT4/EiPRERERGRhlFAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESkwd290G/aZmW0G1jag6unAsw2oV8Yv9QkpUn+QodQnZCj1icY62N1nDC1sioDcKGa20t3nN7odMn6oT0iR+oMMpT4hQ6lPjE8aYiEiIiIiUqCALCIiIiJSoIC8b5Y1ugEy7qhPSJH6gwylPiFDqU+MQxqDLCIiIiJSoE+QRUREREQKFJBFRERERAoUkPeCmZ1sZn80s9Vmdkmj2yP1YWYHmdndZvaomT1iZh/Jy6eZ2c/MbFU+3T8vNzP7l7yfPGxmRzf2CGQsmFloZg+Z2X/ny4eY2X357/02Myvn5ZV8eXW+/iWNbLeMDTObambLzexxM3vMzP5K54iJzcw+mv/N+IOZ3WJmLTpPjH8KyCNkZiHwTeBtwOHAGWZ2eGNbJXUSAx9398OB44Dz89/9JcCd7j4PuDNfhqyPzMtf5wHX1L/JUgcfAR4rLH8FuNrd5wLPA4vz8sXA83n51fl20ny+Dtzh7i8HXkXWN3SOmKDMbDZwITDf3V8JhMAidJ4Y9xSQR+41wGp3X+PuVeBWYGGD2yR14O4b3f03+XwX2R++2WS//xvzzW4ETs3nFwI3eebXwFQze1Gdmy1jyMzmAKcA1+bLBpwILM83GdofBvrJcmBBvr00CTObAhwPXAfg7lV3fwGdIya6CGg1swhoAzai88S4p4A8crOBpwrL6/MymUDyr71eDdwHzHT3jfmqZ4CZ+bz6SvP7GvBPQJovHwC84O5xvlz8nW/rD/n6jnx7aR6HAJuB6/NhN9eaWTs6R0xY7r4BuBJYRxaMO4AH0Xli3FNAFhkhM9sP+D5wkbt3Ftd5dt9E3TtxAjCzdwCb3P3BRrdFxo0IOBq4xt1fDXSzfTgFoHPERJOPN19I9s/TLKAdOLmhjZJhUUAeuQ3AQYXlOXmZTABmViILxze7+w/y4j8PfC2aTzfl5eorze31wDvN7EmyoVYnko0/nZp/lQqDf+fb+kO+fgrwXD0bLGNuPbDe3e/Ll5eTBWadIyauNwNPuPtmd68BPyA7d+g8Mc4pII/cA8C8/ArUMtlg+xUNbpPUQT4O7DrgMXdfWli1Ajgrnz8L+GGh/Mz8SvXjgI7C16zyF87dL3X3Oe7+ErLzwF3u/h7gbuC0fLOh/WGgn5yWb69PEpuIuz8DPGVmL8uLFgCPonPERLYOOM7M2vK/IQN9QueJcU5P0tsLZvZ2srGHIfAdd1/S4CZJHZjZG4D/A37P9jGnnyIbh3w78GJgLfAud9+Snwz/lezrtB7gHHdfWfeGy5gzszcBn3D3d5jZoWSfKE8DHgLe6+79ZtYCfJds7PoWYJG7r2lUm2VsmNlRZBdtloE1wDlkH0bpHDFBmdnngdPJ7oT0EHAu2VhjnSfGMQVkEREREZECDbEQERERESlQQBYRERERKVBAFhEREREpUEAWERERESlQQBYRERERKVBAFhEREREpUEAWERERESn4f5316SEuZUZhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.506\n",
      "Probability of sampling a 0: 0.494\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/900\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 0.6931 - binary_accuracy: 0.4850 - precision: 0.4909 - recall: 0.4783 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 27/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9980\n",
      "Epoch 46/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9980 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9960\n",
      "Epoch 47/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9960 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9960\n",
      "Epoch 48/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9960 - val_loss: 0.6928 - val_binary_accuracy: 0.5110 - val_precision: 0.5086 - val_recall: 0.9960\n",
      "Epoch 49/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6928 - binary_accuracy: 0.5110 - precision: 0.5086 - recall: 0.9960 - val_loss: 0.6928 - val_binary_accuracy: 0.5090 - val_precision: 0.5079 - val_recall: 0.9565\n",
      "Epoch 50/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6928 - binary_accuracy: 0.5090 - precision: 0.5079 - recall: 0.9565 - val_loss: 0.6927 - val_binary_accuracy: 0.5110 - val_precision: 0.5086 - val_recall: 0.9960\n",
      "Epoch 51/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6927 - binary_accuracy: 0.5110 - precision: 0.5086 - recall: 0.9960 - val_loss: 0.6926 - val_binary_accuracy: 0.5160 - val_precision: 0.5166 - val_recall: 0.6759\n",
      "Epoch 52/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6926 - binary_accuracy: 0.5160 - precision: 0.5166 - recall: 0.6759 - val_loss: 0.6923 - val_binary_accuracy: 0.5150 - val_precision: 0.5118 - val_recall: 0.8972\n",
      "Epoch 53/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6923 - binary_accuracy: 0.5150 - precision: 0.5118 - recall: 0.8972 - val_loss: 0.6922 - val_binary_accuracy: 0.5120 - val_precision: 0.5096 - val_recall: 0.9466\n",
      "Epoch 54/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6922 - binary_accuracy: 0.5120 - precision: 0.5096 - recall: 0.9466 - val_loss: 0.6924 - val_binary_accuracy: 0.5130 - val_precision: 0.5772 - val_recall: 0.1403\n",
      "Epoch 55/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6924 - binary_accuracy: 0.5130 - precision: 0.5772 - recall: 0.1403 - val_loss: 0.6919 - val_binary_accuracy: 0.5130 - val_precision: 0.5106 - val_recall: 0.9032\n",
      "Epoch 56/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6919 - binary_accuracy: 0.5130 - precision: 0.5106 - recall: 0.9032 - val_loss: 0.6917 - val_binary_accuracy: 0.5170 - val_precision: 0.5135 - val_recall: 0.8617\n",
      "Epoch 57/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6917 - binary_accuracy: 0.5170 - precision: 0.5135 - recall: 0.8617 - val_loss: 0.6925 - val_binary_accuracy: 0.5050 - val_precision: 0.5311 - val_recall: 0.1858\n",
      "Epoch 58/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6925 - binary_accuracy: 0.5050 - precision: 0.5311 - recall: 0.1858 - val_loss: 0.6915 - val_binary_accuracy: 0.5070 - val_precision: 0.5083 - val_recall: 0.7866\n",
      "Epoch 59/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6915 - binary_accuracy: 0.5070 - precision: 0.5083 - recall: 0.7866 - val_loss: 0.6919 - val_binary_accuracy: 0.5130 - val_precision: 0.5106 - val_recall: 0.9051\n",
      "Epoch 60/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6919 - binary_accuracy: 0.5130 - precision: 0.5106 - recall: 0.9051 - val_loss: 0.6913 - val_binary_accuracy: 0.5080 - val_precision: 0.5102 - val_recall: 0.6897\n",
      "Epoch 61/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6913 - binary_accuracy: 0.5080 - precision: 0.5102 - recall: 0.6897 - val_loss: 0.6915 - val_binary_accuracy: 0.5020 - val_precision: 0.5132 - val_recall: 0.3063\n",
      "Epoch 62/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6915 - binary_accuracy: 0.5020 - precision: 0.5132 - recall: 0.3063 - val_loss: 0.6914 - val_binary_accuracy: 0.5050 - val_precision: 0.5169 - val_recall: 0.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6914 - binary_accuracy: 0.5050 - precision: 0.5169 - recall: 0.3320 - val_loss: 0.6911 - val_binary_accuracy: 0.5230 - val_precision: 0.5228 - val_recall: 0.6561\n",
      "Epoch 64/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6911 - binary_accuracy: 0.5230 - precision: 0.5228 - recall: 0.6561 - val_loss: 0.6911 - val_binary_accuracy: 0.5150 - val_precision: 0.5122 - val_recall: 0.8696\n",
      "Epoch 65/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6911 - binary_accuracy: 0.5150 - precision: 0.5122 - recall: 0.8696 - val_loss: 0.6911 - val_binary_accuracy: 0.5150 - val_precision: 0.5118 - val_recall: 0.8992\n",
      "Epoch 66/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6911 - binary_accuracy: 0.5150 - precision: 0.5118 - recall: 0.8992 - val_loss: 0.6907 - val_binary_accuracy: 0.5120 - val_precision: 0.5112 - val_recall: 0.8103\n",
      "Epoch 67/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6907 - binary_accuracy: 0.5120 - precision: 0.5112 - recall: 0.8103 - val_loss: 0.6905 - val_binary_accuracy: 0.5160 - val_precision: 0.5208 - val_recall: 0.5435\n",
      "Epoch 68/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6905 - binary_accuracy: 0.5160 - precision: 0.5208 - recall: 0.5435 - val_loss: 0.6904 - val_binary_accuracy: 0.5030 - val_precision: 0.5117 - val_recall: 0.3893\n",
      "Epoch 69/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6904 - binary_accuracy: 0.5030 - precision: 0.5117 - recall: 0.3893 - val_loss: 0.6900 - val_binary_accuracy: 0.5160 - val_precision: 0.5202 - val_recall: 0.5593\n",
      "Epoch 70/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6900 - binary_accuracy: 0.5160 - precision: 0.5202 - recall: 0.5593 - val_loss: 0.6899 - val_binary_accuracy: 0.5200 - val_precision: 0.5171 - val_recall: 0.7767\n",
      "Epoch 71/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6899 - binary_accuracy: 0.5200 - precision: 0.5171 - recall: 0.7767 - val_loss: 0.6895 - val_binary_accuracy: 0.5280 - val_precision: 0.5241 - val_recall: 0.7312\n",
      "Epoch 72/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6895 - binary_accuracy: 0.5280 - precision: 0.5241 - recall: 0.7312 - val_loss: 0.6892 - val_binary_accuracy: 0.5160 - val_precision: 0.5234 - val_recall: 0.4862\n",
      "Epoch 73/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6892 - binary_accuracy: 0.5160 - precision: 0.5234 - recall: 0.4862 - val_loss: 0.6888 - val_binary_accuracy: 0.5140 - val_precision: 0.5216 - val_recall: 0.4783\n",
      "Epoch 74/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6888 - binary_accuracy: 0.5140 - precision: 0.5216 - recall: 0.4783 - val_loss: 0.6883 - val_binary_accuracy: 0.5210 - val_precision: 0.5201 - val_recall: 0.6917\n",
      "Epoch 75/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6883 - binary_accuracy: 0.5210 - precision: 0.5201 - recall: 0.6917 - val_loss: 0.6880 - val_binary_accuracy: 0.5220 - val_precision: 0.5183 - val_recall: 0.7826\n",
      "Epoch 76/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6880 - binary_accuracy: 0.5220 - precision: 0.5183 - recall: 0.7826 - val_loss: 0.6874 - val_binary_accuracy: 0.5190 - val_precision: 0.5197 - val_recall: 0.6522\n",
      "Epoch 77/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6874 - binary_accuracy: 0.5190 - precision: 0.5197 - recall: 0.6522 - val_loss: 0.6870 - val_binary_accuracy: 0.5290 - val_precision: 0.5386 - val_recall: 0.4822\n",
      "Epoch 78/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6870 - binary_accuracy: 0.5290 - precision: 0.5386 - recall: 0.4822 - val_loss: 0.6864 - val_binary_accuracy: 0.5360 - val_precision: 0.5378 - val_recall: 0.5909\n",
      "Epoch 79/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6864 - binary_accuracy: 0.5360 - precision: 0.5378 - recall: 0.5909 - val_loss: 0.6861 - val_binary_accuracy: 0.5420 - val_precision: 0.5347 - val_recall: 0.7312\n",
      "Epoch 80/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6861 - binary_accuracy: 0.5420 - precision: 0.5347 - recall: 0.7312 - val_loss: 0.6856 - val_binary_accuracy: 0.5420 - val_precision: 0.5506 - val_recall: 0.5158\n",
      "Epoch 81/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6856 - binary_accuracy: 0.5420 - precision: 0.5506 - recall: 0.5158 - val_loss: 0.6852 - val_binary_accuracy: 0.5420 - val_precision: 0.5500 - val_recall: 0.5217\n",
      "Epoch 82/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6852 - binary_accuracy: 0.5420 - precision: 0.5500 - recall: 0.5217 - val_loss: 0.6848 - val_binary_accuracy: 0.5540 - val_precision: 0.5463 - val_recall: 0.6996\n",
      "Epoch 83/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6848 - binary_accuracy: 0.5540 - precision: 0.5463 - recall: 0.6996 - val_loss: 0.6841 - val_binary_accuracy: 0.5550 - val_precision: 0.5552 - val_recall: 0.6067\n",
      "Epoch 84/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6841 - binary_accuracy: 0.5550 - precision: 0.5552 - recall: 0.6067 - val_loss: 0.6835 - val_binary_accuracy: 0.5610 - val_precision: 0.5720 - val_recall: 0.5257\n",
      "Epoch 85/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6835 - binary_accuracy: 0.5610 - precision: 0.5720 - recall: 0.5257 - val_loss: 0.6826 - val_binary_accuracy: 0.5570 - val_precision: 0.5552 - val_recall: 0.6265\n",
      "Epoch 86/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6826 - binary_accuracy: 0.5570 - precision: 0.5552 - recall: 0.6265 - val_loss: 0.6818 - val_binary_accuracy: 0.5570 - val_precision: 0.5519 - val_recall: 0.6621\n",
      "Epoch 87/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6818 - binary_accuracy: 0.5570 - precision: 0.5519 - recall: 0.6621 - val_loss: 0.6810 - val_binary_accuracy: 0.5640 - val_precision: 0.5781 - val_recall: 0.5119\n",
      "Epoch 88/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6810 - binary_accuracy: 0.5640 - precision: 0.5781 - recall: 0.5119 - val_loss: 0.6801 - val_binary_accuracy: 0.5680 - val_precision: 0.5615 - val_recall: 0.6680\n",
      "Epoch 89/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6801 - binary_accuracy: 0.5680 - precision: 0.5615 - recall: 0.6680 - val_loss: 0.6793 - val_binary_accuracy: 0.5670 - val_precision: 0.5672 - val_recall: 0.6087\n",
      "Epoch 90/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6793 - binary_accuracy: 0.5670 - precision: 0.5672 - recall: 0.6087 - val_loss: 0.6788 - val_binary_accuracy: 0.5630 - val_precision: 0.5729 - val_recall: 0.5356\n",
      "Epoch 91/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6788 - binary_accuracy: 0.5630 - precision: 0.5729 - recall: 0.5356 - val_loss: 0.6789 - val_binary_accuracy: 0.5550 - val_precision: 0.5461 - val_recall: 0.7134\n",
      "Epoch 92/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6789 - binary_accuracy: 0.5550 - precision: 0.5461 - recall: 0.7134 - val_loss: 0.6810 - val_binary_accuracy: 0.5430 - val_precision: 0.5968 - val_recall: 0.2984\n",
      "Epoch 93/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6810 - binary_accuracy: 0.5430 - precision: 0.5968 - recall: 0.2984 - val_loss: 0.6799 - val_binary_accuracy: 0.5590 - val_precision: 0.5470 - val_recall: 0.7470\n",
      "Epoch 94/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6799 - binary_accuracy: 0.5590 - precision: 0.5470 - recall: 0.7470 - val_loss: 0.6796 - val_binary_accuracy: 0.5630 - val_precision: 0.5522 - val_recall: 0.7213\n",
      "Epoch 95/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6796 - binary_accuracy: 0.5630 - precision: 0.5522 - recall: 0.7213 - val_loss: 0.6796 - val_binary_accuracy: 0.5780 - val_precision: 0.6186 - val_recall: 0.4328\n",
      "Epoch 96/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6796 - binary_accuracy: 0.5780 - precision: 0.6186 - recall: 0.4328 - val_loss: 0.6782 - val_binary_accuracy: 0.5840 - val_precision: 0.5991 - val_recall: 0.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6782 - binary_accuracy: 0.5840 - precision: 0.5991 - recall: 0.5375 - val_loss: 0.6801 - val_binary_accuracy: 0.5470 - val_precision: 0.5381 - val_recall: 0.7391\n",
      "Epoch 98/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6801 - binary_accuracy: 0.5470 - precision: 0.5381 - recall: 0.7391 - val_loss: 0.6779 - val_binary_accuracy: 0.5770 - val_precision: 0.5870 - val_recall: 0.5534\n",
      "Epoch 99/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6779 - binary_accuracy: 0.5770 - precision: 0.5870 - recall: 0.5534 - val_loss: 0.6785 - val_binary_accuracy: 0.5910 - val_precision: 0.6228 - val_recall: 0.4862\n",
      "Epoch 100/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6785 - binary_accuracy: 0.5910 - precision: 0.6228 - recall: 0.4862 - val_loss: 0.6775 - val_binary_accuracy: 0.5730 - val_precision: 0.5727 - val_recall: 0.6146\n",
      "Epoch 101/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6775 - binary_accuracy: 0.5730 - precision: 0.5727 - recall: 0.6146 - val_loss: 0.6780 - val_binary_accuracy: 0.5550 - val_precision: 0.5455 - val_recall: 0.7233\n",
      "Epoch 102/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6780 - binary_accuracy: 0.5550 - precision: 0.5455 - recall: 0.7233 - val_loss: 0.6775 - val_binary_accuracy: 0.5620 - val_precision: 0.5531 - val_recall: 0.6996\n",
      "Epoch 103/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6775 - binary_accuracy: 0.5620 - precision: 0.5531 - recall: 0.6996 - val_loss: 0.6770 - val_binary_accuracy: 0.5800 - val_precision: 0.5843 - val_recall: 0.5889\n",
      "Epoch 104/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6770 - binary_accuracy: 0.5800 - precision: 0.5843 - recall: 0.5889 - val_loss: 0.6774 - val_binary_accuracy: 0.5760 - val_precision: 0.6030 - val_recall: 0.4743\n",
      "Epoch 105/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6774 - binary_accuracy: 0.5760 - precision: 0.6030 - recall: 0.4743 - val_loss: 0.6768 - val_binary_accuracy: 0.5620 - val_precision: 0.5620 - val_recall: 0.6087\n",
      "Epoch 106/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6768 - binary_accuracy: 0.5620 - precision: 0.5620 - recall: 0.6087 - val_loss: 0.6773 - val_binary_accuracy: 0.5600 - val_precision: 0.5502 - val_recall: 0.7154\n",
      "Epoch 107/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6773 - binary_accuracy: 0.5600 - precision: 0.5502 - recall: 0.7154 - val_loss: 0.6767 - val_binary_accuracy: 0.5670 - val_precision: 0.5599 - val_recall: 0.6739\n",
      "Epoch 108/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6767 - binary_accuracy: 0.5670 - precision: 0.5599 - recall: 0.6739 - val_loss: 0.6767 - val_binary_accuracy: 0.5750 - val_precision: 0.5835 - val_recall: 0.5593\n",
      "Epoch 109/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6767 - binary_accuracy: 0.5750 - precision: 0.5835 - recall: 0.5593 - val_loss: 0.6768 - val_binary_accuracy: 0.5760 - val_precision: 0.5899 - val_recall: 0.5316\n",
      "Epoch 110/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6768 - binary_accuracy: 0.5760 - precision: 0.5899 - recall: 0.5316 - val_loss: 0.6764 - val_binary_accuracy: 0.5700 - val_precision: 0.5679 - val_recall: 0.6285\n",
      "Epoch 111/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6764 - binary_accuracy: 0.5700 - precision: 0.5679 - recall: 0.6285 - val_loss: 0.6764 - val_binary_accuracy: 0.5590 - val_precision: 0.5513 - val_recall: 0.6897\n",
      "Epoch 112/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6764 - binary_accuracy: 0.5590 - precision: 0.5513 - recall: 0.6897 - val_loss: 0.6762 - val_binary_accuracy: 0.5580 - val_precision: 0.5508 - val_recall: 0.6858\n",
      "Epoch 113/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6762 - binary_accuracy: 0.5580 - precision: 0.5508 - recall: 0.6858 - val_loss: 0.6759 - val_binary_accuracy: 0.5740 - val_precision: 0.5725 - val_recall: 0.6245\n",
      "Epoch 114/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6759 - binary_accuracy: 0.5740 - precision: 0.5725 - recall: 0.6245 - val_loss: 0.6760 - val_binary_accuracy: 0.5670 - val_precision: 0.5746 - val_recall: 0.5553\n",
      "Epoch 115/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6760 - binary_accuracy: 0.5670 - precision: 0.5746 - recall: 0.5553 - val_loss: 0.6756 - val_binary_accuracy: 0.5750 - val_precision: 0.5719 - val_recall: 0.6364\n",
      "Epoch 116/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6756 - binary_accuracy: 0.5750 - precision: 0.5719 - recall: 0.6364 - val_loss: 0.6757 - val_binary_accuracy: 0.5610 - val_precision: 0.5534 - val_recall: 0.6858\n",
      "Epoch 117/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6757 - binary_accuracy: 0.5610 - precision: 0.5534 - recall: 0.6858 - val_loss: 0.6756 - val_binary_accuracy: 0.5610 - val_precision: 0.5543 - val_recall: 0.6759\n",
      "Epoch 118/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6756 - binary_accuracy: 0.5610 - precision: 0.5543 - recall: 0.6759 - val_loss: 0.6754 - val_binary_accuracy: 0.5790 - val_precision: 0.5766 - val_recall: 0.6324\n",
      "Epoch 119/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6754 - binary_accuracy: 0.5790 - precision: 0.5766 - recall: 0.6324 - val_loss: 0.6753 - val_binary_accuracy: 0.5720 - val_precision: 0.5747 - val_recall: 0.5929\n",
      "Epoch 120/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6753 - binary_accuracy: 0.5720 - precision: 0.5747 - recall: 0.5929 - val_loss: 0.6750 - val_binary_accuracy: 0.5690 - val_precision: 0.5650 - val_recall: 0.6443\n",
      "Epoch 121/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6750 - binary_accuracy: 0.5690 - precision: 0.5650 - recall: 0.6443 - val_loss: 0.6750 - val_binary_accuracy: 0.5690 - val_precision: 0.5608 - val_recall: 0.6838\n",
      "Epoch 122/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6750 - binary_accuracy: 0.5690 - precision: 0.5608 - recall: 0.6838 - val_loss: 0.6746 - val_binary_accuracy: 0.5690 - val_precision: 0.5635 - val_recall: 0.6581\n",
      "Epoch 123/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6746 - binary_accuracy: 0.5690 - precision: 0.5635 - recall: 0.6581 - val_loss: 0.6745 - val_binary_accuracy: 0.5730 - val_precision: 0.5738 - val_recall: 0.6067\n",
      "Epoch 124/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6745 - binary_accuracy: 0.5730 - precision: 0.5738 - recall: 0.6067 - val_loss: 0.6742 - val_binary_accuracy: 0.5680 - val_precision: 0.5680 - val_recall: 0.6107\n",
      "Epoch 125/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6742 - binary_accuracy: 0.5680 - precision: 0.5680 - recall: 0.6107 - val_loss: 0.6740 - val_binary_accuracy: 0.5710 - val_precision: 0.5641 - val_recall: 0.6700\n",
      "Epoch 126/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6740 - binary_accuracy: 0.5710 - precision: 0.5641 - recall: 0.6700 - val_loss: 0.6738 - val_binary_accuracy: 0.5680 - val_precision: 0.5611 - val_recall: 0.6719\n",
      "Epoch 127/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6738 - binary_accuracy: 0.5680 - precision: 0.5611 - recall: 0.6719 - val_loss: 0.6735 - val_binary_accuracy: 0.5640 - val_precision: 0.5648 - val_recall: 0.6028\n",
      "Epoch 128/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6735 - binary_accuracy: 0.5640 - precision: 0.5648 - recall: 0.6028 - val_loss: 0.6732 - val_binary_accuracy: 0.5650 - val_precision: 0.5637 - val_recall: 0.6206\n",
      "Epoch 129/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6732 - binary_accuracy: 0.5650 - precision: 0.5637 - recall: 0.6206 - val_loss: 0.6730 - val_binary_accuracy: 0.5710 - val_precision: 0.5632 - val_recall: 0.6779\n",
      "Epoch 130/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6730 - binary_accuracy: 0.5710 - precision: 0.5632 - recall: 0.6779 - val_loss: 0.6727 - val_binary_accuracy: 0.5680 - val_precision: 0.5636 - val_recall: 0.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6727 - binary_accuracy: 0.5680 - precision: 0.5636 - recall: 0.6482 - val_loss: 0.6725 - val_binary_accuracy: 0.5720 - val_precision: 0.5717 - val_recall: 0.6146\n",
      "Epoch 132/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6725 - binary_accuracy: 0.5720 - precision: 0.5717 - recall: 0.6146 - val_loss: 0.6722 - val_binary_accuracy: 0.5720 - val_precision: 0.5641 - val_recall: 0.6779\n",
      "Epoch 133/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6722 - binary_accuracy: 0.5720 - precision: 0.5641 - recall: 0.6779 - val_loss: 0.6720 - val_binary_accuracy: 0.5690 - val_precision: 0.5654 - val_recall: 0.6403\n",
      "Epoch 134/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6720 - binary_accuracy: 0.5690 - precision: 0.5654 - recall: 0.6403 - val_loss: 0.6719 - val_binary_accuracy: 0.5800 - val_precision: 0.5796 - val_recall: 0.6186\n",
      "Epoch 135/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6719 - binary_accuracy: 0.5800 - precision: 0.5796 - recall: 0.6186 - val_loss: 0.6718 - val_binary_accuracy: 0.5750 - val_precision: 0.5659 - val_recall: 0.6877\n",
      "Epoch 136/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6718 - binary_accuracy: 0.5750 - precision: 0.5659 - recall: 0.6877 - val_loss: 0.6717 - val_binary_accuracy: 0.5870 - val_precision: 0.5882 - val_recall: 0.6126\n",
      "Epoch 137/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6717 - binary_accuracy: 0.5870 - precision: 0.5882 - recall: 0.6126 - val_loss: 0.6716 - val_binary_accuracy: 0.5700 - val_precision: 0.5617 - val_recall: 0.6838\n",
      "Epoch 138/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6716 - binary_accuracy: 0.5700 - precision: 0.5617 - recall: 0.6838 - val_loss: 0.6712 - val_binary_accuracy: 0.5890 - val_precision: 0.5875 - val_recall: 0.6304\n",
      "Epoch 139/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6712 - binary_accuracy: 0.5890 - precision: 0.5875 - recall: 0.6304 - val_loss: 0.6709 - val_binary_accuracy: 0.5780 - val_precision: 0.5717 - val_recall: 0.6621\n",
      "Epoch 140/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6709 - binary_accuracy: 0.5780 - precision: 0.5717 - recall: 0.6621 - val_loss: 0.6707 - val_binary_accuracy: 0.5860 - val_precision: 0.5790 - val_recall: 0.6660\n",
      "Epoch 141/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6707 - binary_accuracy: 0.5860 - precision: 0.5790 - recall: 0.6660 - val_loss: 0.6705 - val_binary_accuracy: 0.5900 - val_precision: 0.5886 - val_recall: 0.6304\n",
      "Epoch 142/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6705 - binary_accuracy: 0.5900 - precision: 0.5886 - recall: 0.6304 - val_loss: 0.6702 - val_binary_accuracy: 0.5810 - val_precision: 0.5721 - val_recall: 0.6818\n",
      "Epoch 143/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6702 - binary_accuracy: 0.5810 - precision: 0.5721 - recall: 0.6818 - val_loss: 0.6699 - val_binary_accuracy: 0.5850 - val_precision: 0.5814 - val_recall: 0.6423\n",
      "Epoch 144/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6699 - binary_accuracy: 0.5850 - precision: 0.5814 - recall: 0.6423 - val_loss: 0.6695 - val_binary_accuracy: 0.5850 - val_precision: 0.5802 - val_recall: 0.6502\n",
      "Epoch 145/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6695 - binary_accuracy: 0.5850 - precision: 0.5802 - recall: 0.6502 - val_loss: 0.6692 - val_binary_accuracy: 0.5870 - val_precision: 0.5789 - val_recall: 0.6739\n",
      "Epoch 146/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6692 - binary_accuracy: 0.5870 - precision: 0.5789 - recall: 0.6739 - val_loss: 0.6689 - val_binary_accuracy: 0.5850 - val_precision: 0.5800 - val_recall: 0.6522\n",
      "Epoch 147/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6689 - binary_accuracy: 0.5850 - precision: 0.5800 - recall: 0.6522 - val_loss: 0.6686 - val_binary_accuracy: 0.5920 - val_precision: 0.5854 - val_recall: 0.6640\n",
      "Epoch 148/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6686 - binary_accuracy: 0.5920 - precision: 0.5854 - recall: 0.6640 - val_loss: 0.6682 - val_binary_accuracy: 0.5900 - val_precision: 0.5822 - val_recall: 0.6719\n",
      "Epoch 149/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6682 - binary_accuracy: 0.5900 - precision: 0.5822 - recall: 0.6719 - val_loss: 0.6679 - val_binary_accuracy: 0.5870 - val_precision: 0.5782 - val_recall: 0.6798\n",
      "Epoch 150/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6679 - binary_accuracy: 0.5870 - precision: 0.5782 - recall: 0.6798 - val_loss: 0.6673 - val_binary_accuracy: 0.5970 - val_precision: 0.5921 - val_recall: 0.6542\n",
      "Epoch 151/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6673 - binary_accuracy: 0.5970 - precision: 0.5921 - recall: 0.6542 - val_loss: 0.6668 - val_binary_accuracy: 0.5910 - val_precision: 0.5821 - val_recall: 0.6798\n",
      "Epoch 152/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6668 - binary_accuracy: 0.5910 - precision: 0.5821 - recall: 0.6798 - val_loss: 0.6662 - val_binary_accuracy: 0.5940 - val_precision: 0.5871 - val_recall: 0.6660\n",
      "Epoch 153/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6662 - binary_accuracy: 0.5940 - precision: 0.5871 - recall: 0.6660 - val_loss: 0.6657 - val_binary_accuracy: 0.5900 - val_precision: 0.5836 - val_recall: 0.6621\n",
      "Epoch 154/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.6657 - binary_accuracy: 0.5900 - precision: 0.5836 - recall: 0.6621 - val_loss: 0.6652 - val_binary_accuracy: 0.5860 - val_precision: 0.5790 - val_recall: 0.6660\n",
      "Epoch 155/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6652 - binary_accuracy: 0.5860 - precision: 0.5790 - recall: 0.6660 - val_loss: 0.6648 - val_binary_accuracy: 0.5910 - val_precision: 0.5849 - val_recall: 0.6601\n",
      "Epoch 156/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.6648 - binary_accuracy: 0.5910 - precision: 0.5849 - recall: 0.6601 - val_loss: 0.6645 - val_binary_accuracy: 0.5900 - val_precision: 0.5857 - val_recall: 0.6482\n",
      "Epoch 157/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6645 - binary_accuracy: 0.5900 - precision: 0.5857 - recall: 0.6482 - val_loss: 0.6652 - val_binary_accuracy: 0.5840 - val_precision: 0.5792 - val_recall: 0.6502\n",
      "Epoch 158/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6652 - binary_accuracy: 0.5840 - precision: 0.5792 - recall: 0.6502 - val_loss: 0.6632 - val_binary_accuracy: 0.5810 - val_precision: 0.5724 - val_recall: 0.6798\n",
      "Epoch 159/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6632 - binary_accuracy: 0.5810 - precision: 0.5724 - recall: 0.6798 - val_loss: 0.6631 - val_binary_accuracy: 0.6030 - val_precision: 0.6079 - val_recall: 0.6067\n",
      "Epoch 160/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6631 - binary_accuracy: 0.6030 - precision: 0.6079 - recall: 0.6067 - val_loss: 0.6638 - val_binary_accuracy: 0.5670 - val_precision: 0.5575 - val_recall: 0.6996\n",
      "Epoch 161/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.6638 - binary_accuracy: 0.5670 - precision: 0.5575 - recall: 0.6996 - val_loss: 0.6617 - val_binary_accuracy: 0.5740 - val_precision: 0.5660 - val_recall: 0.6779\n",
      "Epoch 162/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6617 - binary_accuracy: 0.5740 - precision: 0.5660 - recall: 0.6779 - val_loss: 0.6630 - val_binary_accuracy: 0.5990 - val_precision: 0.6048 - val_recall: 0.5988\n",
      "Epoch 163/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.6630 - binary_accuracy: 0.5990 - precision: 0.6048 - recall: 0.5988 - val_loss: 0.6614 - val_binary_accuracy: 0.5650 - val_precision: 0.5514 - val_recall: 0.7530\n",
      "Epoch 164/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6614 - binary_accuracy: 0.5650 - precision: 0.5514 - recall: 0.7530 - val_loss: 0.6624 - val_binary_accuracy: 0.5960 - val_precision: 0.6016 - val_recall: 0.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6624 - binary_accuracy: 0.5960 - precision: 0.6016 - recall: 0.5968 - val_loss: 0.6587 - val_binary_accuracy: 0.5890 - val_precision: 0.5832 - val_recall: 0.6581\n",
      "Epoch 166/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6587 - binary_accuracy: 0.5890 - precision: 0.5832 - recall: 0.6581 - val_loss: 0.6603 - val_binary_accuracy: 0.5850 - val_precision: 0.5740 - val_recall: 0.6976\n",
      "Epoch 167/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.6603 - binary_accuracy: 0.5850 - precision: 0.5740 - recall: 0.6976 - val_loss: 0.6582 - val_binary_accuracy: 0.6010 - val_precision: 0.6131 - val_recall: 0.5731\n",
      "Epoch 168/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6582 - binary_accuracy: 0.6010 - precision: 0.6131 - recall: 0.5731 - val_loss: 0.6582 - val_binary_accuracy: 0.5830 - val_precision: 0.5728 - val_recall: 0.6917\n",
      "Epoch 169/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6582 - binary_accuracy: 0.5830 - precision: 0.5728 - recall: 0.6917 - val_loss: 0.6575 - val_binary_accuracy: 0.5870 - val_precision: 0.5800 - val_recall: 0.6660\n",
      "Epoch 170/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6575 - binary_accuracy: 0.5870 - precision: 0.5800 - recall: 0.6660 - val_loss: 0.6556 - val_binary_accuracy: 0.6020 - val_precision: 0.6038 - val_recall: 0.6206\n",
      "Epoch 171/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6556 - binary_accuracy: 0.6020 - precision: 0.6038 - recall: 0.6206 - val_loss: 0.6562 - val_binary_accuracy: 0.5850 - val_precision: 0.5735 - val_recall: 0.7016\n",
      "Epoch 172/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6562 - binary_accuracy: 0.5850 - precision: 0.5735 - recall: 0.7016 - val_loss: 0.6538 - val_binary_accuracy: 0.6020 - val_precision: 0.5996 - val_recall: 0.6423\n",
      "Epoch 173/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6538 - binary_accuracy: 0.6020 - precision: 0.5996 - recall: 0.6423 - val_loss: 0.6535 - val_binary_accuracy: 0.6020 - val_precision: 0.5996 - val_recall: 0.6423\n",
      "Epoch 174/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6535 - binary_accuracy: 0.6020 - precision: 0.5996 - recall: 0.6423 - val_loss: 0.6530 - val_binary_accuracy: 0.5910 - val_precision: 0.5823 - val_recall: 0.6779\n",
      "Epoch 175/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6530 - binary_accuracy: 0.5910 - precision: 0.5823 - recall: 0.6779 - val_loss: 0.6512 - val_binary_accuracy: 0.6030 - val_precision: 0.6030 - val_recall: 0.6304\n",
      "Epoch 176/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6512 - binary_accuracy: 0.6030 - precision: 0.6030 - recall: 0.6304 - val_loss: 0.6510 - val_binary_accuracy: 0.6010 - val_precision: 0.5896 - val_recall: 0.6957\n",
      "Epoch 177/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6510 - binary_accuracy: 0.6010 - precision: 0.5896 - recall: 0.6957 - val_loss: 0.6492 - val_binary_accuracy: 0.6010 - val_precision: 0.5964 - val_recall: 0.6542\n",
      "Epoch 178/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6492 - binary_accuracy: 0.6010 - precision: 0.5964 - recall: 0.6542 - val_loss: 0.6489 - val_binary_accuracy: 0.5970 - val_precision: 0.5899 - val_recall: 0.6680\n",
      "Epoch 179/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6489 - binary_accuracy: 0.5970 - precision: 0.5899 - recall: 0.6680 - val_loss: 0.6473 - val_binary_accuracy: 0.5940 - val_precision: 0.5916 - val_recall: 0.6383\n",
      "Epoch 180/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6473 - binary_accuracy: 0.5940 - precision: 0.5916 - recall: 0.6383 - val_loss: 0.6471 - val_binary_accuracy: 0.5980 - val_precision: 0.5864 - val_recall: 0.6976\n",
      "Epoch 181/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6471 - binary_accuracy: 0.5980 - precision: 0.5864 - recall: 0.6976 - val_loss: 0.6464 - val_binary_accuracy: 0.6070 - val_precision: 0.6231 - val_recall: 0.5652\n",
      "Epoch 182/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6464 - binary_accuracy: 0.6070 - precision: 0.6231 - recall: 0.5652 - val_loss: 0.6547 - val_binary_accuracy: 0.5720 - val_precision: 0.5490 - val_recall: 0.8636\n",
      "Epoch 183/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6547 - binary_accuracy: 0.5720 - precision: 0.5490 - recall: 0.8636 - val_loss: 0.6558 - val_binary_accuracy: 0.5930 - val_precision: 0.6495 - val_recall: 0.4249\n",
      "Epoch 184/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6558 - binary_accuracy: 0.5930 - precision: 0.6495 - recall: 0.4249 - val_loss: 0.6486 - val_binary_accuracy: 0.6010 - val_precision: 0.6213 - val_recall: 0.5415\n",
      "Epoch 185/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6486 - binary_accuracy: 0.6010 - precision: 0.6213 - recall: 0.5415 - val_loss: 0.6465 - val_binary_accuracy: 0.5920 - val_precision: 0.5710 - val_recall: 0.7787\n",
      "Epoch 186/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.6465 - binary_accuracy: 0.5920 - precision: 0.5710 - recall: 0.7787 - val_loss: 0.6471 - val_binary_accuracy: 0.5850 - val_precision: 0.5633 - val_recall: 0.8004\n",
      "Epoch 187/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6471 - binary_accuracy: 0.5850 - precision: 0.5633 - recall: 0.8004 - val_loss: 0.6454 - val_binary_accuracy: 0.6070 - val_precision: 0.6151 - val_recall: 0.5968\n",
      "Epoch 188/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.6454 - binary_accuracy: 0.6070 - precision: 0.6151 - recall: 0.5968 - val_loss: 0.6463 - val_binary_accuracy: 0.5990 - val_precision: 0.5989 - val_recall: 0.6285\n",
      "Epoch 189/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6463 - binary_accuracy: 0.5990 - precision: 0.5989 - recall: 0.6285 - val_loss: 0.6442 - val_binary_accuracy: 0.5890 - val_precision: 0.5872 - val_recall: 0.6324\n",
      "Epoch 190/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6442 - binary_accuracy: 0.5890 - precision: 0.5872 - recall: 0.6324 - val_loss: 0.6430 - val_binary_accuracy: 0.5980 - val_precision: 0.5959 - val_recall: 0.6383\n",
      "Epoch 191/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6430 - binary_accuracy: 0.5980 - precision: 0.5959 - recall: 0.6383 - val_loss: 0.6426 - val_binary_accuracy: 0.6020 - val_precision: 0.5954 - val_recall: 0.6660\n",
      "Epoch 192/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6426 - binary_accuracy: 0.6020 - precision: 0.5954 - recall: 0.6660 - val_loss: 0.6417 - val_binary_accuracy: 0.5870 - val_precision: 0.5817 - val_recall: 0.6542\n",
      "Epoch 193/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6417 - binary_accuracy: 0.5870 - precision: 0.5817 - recall: 0.6542 - val_loss: 0.6401 - val_binary_accuracy: 0.6020 - val_precision: 0.6120 - val_recall: 0.5830\n",
      "Epoch 194/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6401 - binary_accuracy: 0.6020 - precision: 0.6120 - recall: 0.5830 - val_loss: 0.6396 - val_binary_accuracy: 0.6130 - val_precision: 0.6308 - val_recall: 0.5672\n",
      "Epoch 195/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6396 - binary_accuracy: 0.6130 - precision: 0.6308 - recall: 0.5672 - val_loss: 0.6385 - val_binary_accuracy: 0.6050 - val_precision: 0.6061 - val_recall: 0.6265\n",
      "Epoch 196/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.6385 - binary_accuracy: 0.6050 - precision: 0.6061 - recall: 0.6265 - val_loss: 0.6377 - val_binary_accuracy: 0.5980 - val_precision: 0.5884 - val_recall: 0.6838\n",
      "Epoch 197/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6377 - binary_accuracy: 0.5980 - precision: 0.5884 - recall: 0.6838 - val_loss: 0.6370 - val_binary_accuracy: 0.5940 - val_precision: 0.5820 - val_recall: 0.7016\n",
      "Epoch 198/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.6370 - binary_accuracy: 0.5940 - precision: 0.5820 - recall: 0.7016 - val_loss: 0.6353 - val_binary_accuracy: 0.6080 - val_precision: 0.5997 - val_recall: 0.6779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6353 - binary_accuracy: 0.6080 - precision: 0.5997 - recall: 0.6779 - val_loss: 0.6348 - val_binary_accuracy: 0.6050 - val_precision: 0.6126 - val_recall: 0.5968\n",
      "Epoch 200/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6348 - binary_accuracy: 0.6050 - precision: 0.6126 - recall: 0.5968 - val_loss: 0.6347 - val_binary_accuracy: 0.6050 - val_precision: 0.6188 - val_recall: 0.5711\n",
      "Epoch 201/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6347 - binary_accuracy: 0.6050 - precision: 0.6188 - recall: 0.5711 - val_loss: 0.6327 - val_binary_accuracy: 0.6070 - val_precision: 0.6119 - val_recall: 0.6107\n",
      "Epoch 202/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6327 - binary_accuracy: 0.6070 - precision: 0.6119 - recall: 0.6107 - val_loss: 0.6317 - val_binary_accuracy: 0.6080 - val_precision: 0.6022 - val_recall: 0.6640\n",
      "Epoch 203/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6317 - binary_accuracy: 0.6080 - precision: 0.6022 - recall: 0.6640 - val_loss: 0.6318 - val_binary_accuracy: 0.6060 - val_precision: 0.5949 - val_recall: 0.6937\n",
      "Epoch 204/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6318 - binary_accuracy: 0.6060 - precision: 0.5949 - recall: 0.6937 - val_loss: 0.6300 - val_binary_accuracy: 0.6110 - val_precision: 0.6085 - val_recall: 0.6482\n",
      "Epoch 205/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6300 - binary_accuracy: 0.6110 - precision: 0.6085 - recall: 0.6482 - val_loss: 0.6294 - val_binary_accuracy: 0.6100 - val_precision: 0.6169 - val_recall: 0.6047\n",
      "Epoch 206/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6294 - binary_accuracy: 0.6100 - precision: 0.6169 - recall: 0.6047 - val_loss: 0.6288 - val_binary_accuracy: 0.6120 - val_precision: 0.6239 - val_recall: 0.5870\n",
      "Epoch 207/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6288 - binary_accuracy: 0.6120 - precision: 0.6239 - recall: 0.5870 - val_loss: 0.6270 - val_binary_accuracy: 0.6130 - val_precision: 0.6192 - val_recall: 0.6107\n",
      "Epoch 208/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6270 - binary_accuracy: 0.6130 - precision: 0.6192 - recall: 0.6107 - val_loss: 0.6265 - val_binary_accuracy: 0.6200 - val_precision: 0.6113 - val_recall: 0.6838\n",
      "Epoch 209/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.6265 - binary_accuracy: 0.6200 - precision: 0.6113 - recall: 0.6838 - val_loss: 0.6258 - val_binary_accuracy: 0.6200 - val_precision: 0.6094 - val_recall: 0.6937\n",
      "Epoch 210/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6258 - binary_accuracy: 0.6200 - precision: 0.6094 - recall: 0.6937 - val_loss: 0.6241 - val_binary_accuracy: 0.6170 - val_precision: 0.6167 - val_recall: 0.6423\n",
      "Epoch 211/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6241 - binary_accuracy: 0.6170 - precision: 0.6167 - recall: 0.6423 - val_loss: 0.6235 - val_binary_accuracy: 0.6190 - val_precision: 0.6268 - val_recall: 0.6107\n",
      "Epoch 212/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6235 - binary_accuracy: 0.6190 - precision: 0.6268 - recall: 0.6107 - val_loss: 0.6223 - val_binary_accuracy: 0.6180 - val_precision: 0.6270 - val_recall: 0.6047\n",
      "Epoch 213/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6223 - binary_accuracy: 0.6180 - precision: 0.6270 - recall: 0.6047 - val_loss: 0.6210 - val_binary_accuracy: 0.6110 - val_precision: 0.6168 - val_recall: 0.6107\n",
      "Epoch 214/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6210 - binary_accuracy: 0.6110 - precision: 0.6168 - recall: 0.6107 - val_loss: 0.6203 - val_binary_accuracy: 0.6180 - val_precision: 0.6157 - val_recall: 0.6522\n",
      "Epoch 215/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6203 - binary_accuracy: 0.6180 - precision: 0.6157 - recall: 0.6522 - val_loss: 0.6188 - val_binary_accuracy: 0.6210 - val_precision: 0.6252 - val_recall: 0.6265\n",
      "Epoch 216/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6188 - binary_accuracy: 0.6210 - precision: 0.6252 - recall: 0.6265 - val_loss: 0.6177 - val_binary_accuracy: 0.6240 - val_precision: 0.6305 - val_recall: 0.6206\n",
      "Epoch 217/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6177 - binary_accuracy: 0.6240 - precision: 0.6305 - recall: 0.6206 - val_loss: 0.6166 - val_binary_accuracy: 0.6260 - val_precision: 0.6369 - val_recall: 0.6067\n",
      "Epoch 218/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6166 - binary_accuracy: 0.6260 - precision: 0.6369 - recall: 0.6067 - val_loss: 0.6150 - val_binary_accuracy: 0.6270 - val_precision: 0.6322 - val_recall: 0.6285\n",
      "Epoch 219/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6150 - binary_accuracy: 0.6270 - precision: 0.6322 - recall: 0.6285 - val_loss: 0.6140 - val_binary_accuracy: 0.6190 - val_precision: 0.6181 - val_recall: 0.6462\n",
      "Epoch 220/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6140 - binary_accuracy: 0.6190 - precision: 0.6181 - recall: 0.6462 - val_loss: 0.6125 - val_binary_accuracy: 0.6320 - val_precision: 0.6397 - val_recall: 0.6245\n",
      "Epoch 221/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6125 - binary_accuracy: 0.6320 - precision: 0.6397 - recall: 0.6245 - val_loss: 0.6113 - val_binary_accuracy: 0.6260 - val_precision: 0.6347 - val_recall: 0.6146\n",
      "Epoch 222/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6113 - binary_accuracy: 0.6260 - precision: 0.6347 - recall: 0.6146 - val_loss: 0.6104 - val_binary_accuracy: 0.6350 - val_precision: 0.6613 - val_recall: 0.5711\n",
      "Epoch 223/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6104 - binary_accuracy: 0.6350 - precision: 0.6613 - recall: 0.5711 - val_loss: 0.6113 - val_binary_accuracy: 0.6170 - val_precision: 0.6085 - val_recall: 0.6818\n",
      "Epoch 224/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6113 - binary_accuracy: 0.6170 - precision: 0.6085 - recall: 0.6818 - val_loss: 0.6148 - val_binary_accuracy: 0.6250 - val_precision: 0.6625 - val_recall: 0.5277\n",
      "Epoch 225/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6148 - binary_accuracy: 0.6250 - precision: 0.6625 - recall: 0.5277 - val_loss: 0.6238 - val_binary_accuracy: 0.6240 - val_precision: 0.6016 - val_recall: 0.7609\n",
      "Epoch 226/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6238 - binary_accuracy: 0.6240 - precision: 0.6016 - recall: 0.7609 - val_loss: 0.6112 - val_binary_accuracy: 0.6360 - val_precision: 0.6387 - val_recall: 0.6462\n",
      "Epoch 227/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6112 - binary_accuracy: 0.6360 - precision: 0.6387 - recall: 0.6462 - val_loss: 0.6219 - val_binary_accuracy: 0.6210 - val_precision: 0.6667 - val_recall: 0.5020\n",
      "Epoch 228/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6219 - binary_accuracy: 0.6210 - precision: 0.6667 - recall: 0.5020 - val_loss: 0.6057 - val_binary_accuracy: 0.6250 - val_precision: 0.6215 - val_recall: 0.6621\n",
      "Epoch 229/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6057 - binary_accuracy: 0.6250 - precision: 0.6215 - recall: 0.6621 - val_loss: 0.6146 - val_binary_accuracy: 0.6290 - val_precision: 0.6119 - val_recall: 0.7292\n",
      "Epoch 230/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6146 - binary_accuracy: 0.6290 - precision: 0.6119 - recall: 0.7292 - val_loss: 0.6043 - val_binary_accuracy: 0.6460 - val_precision: 0.6743 - val_recall: 0.5810\n",
      "Epoch 231/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.6043 - binary_accuracy: 0.6460 - precision: 0.6743 - recall: 0.5810 - val_loss: 0.6079 - val_binary_accuracy: 0.6520 - val_precision: 0.7124 - val_recall: 0.5237\n",
      "Epoch 232/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6079 - binary_accuracy: 0.6520 - precision: 0.7124 - recall: 0.5237 - val_loss: 0.6013 - val_binary_accuracy: 0.6500 - val_precision: 0.6773 - val_recall: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6013 - binary_accuracy: 0.6500 - precision: 0.6773 - recall: 0.5889 - val_loss: 0.6035 - val_binary_accuracy: 0.6460 - val_precision: 0.6234 - val_recall: 0.7589\n",
      "Epoch 234/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6035 - binary_accuracy: 0.6460 - precision: 0.6234 - recall: 0.7589 - val_loss: 0.5999 - val_binary_accuracy: 0.6370 - val_precision: 0.6288 - val_recall: 0.6897\n",
      "Epoch 235/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.5999 - binary_accuracy: 0.6370 - precision: 0.6288 - recall: 0.6897 - val_loss: 0.5980 - val_binary_accuracy: 0.6560 - val_precision: 0.7056 - val_recall: 0.5494\n",
      "Epoch 236/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5980 - binary_accuracy: 0.6560 - precision: 0.7056 - recall: 0.5494 - val_loss: 0.5985 - val_binary_accuracy: 0.6590 - val_precision: 0.7177 - val_recall: 0.5375\n",
      "Epoch 237/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.5985 - binary_accuracy: 0.6590 - precision: 0.7177 - recall: 0.5375 - val_loss: 0.5942 - val_binary_accuracy: 0.6370 - val_precision: 0.6505 - val_recall: 0.6107\n",
      "Epoch 238/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5942 - binary_accuracy: 0.6370 - precision: 0.6505 - recall: 0.6107 - val_loss: 0.5949 - val_binary_accuracy: 0.6430 - val_precision: 0.6244 - val_recall: 0.7391\n",
      "Epoch 239/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.5949 - binary_accuracy: 0.6430 - precision: 0.6244 - recall: 0.7391 - val_loss: 0.5916 - val_binary_accuracy: 0.6570 - val_precision: 0.6506 - val_recall: 0.6957\n",
      "Epoch 240/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.5916 - binary_accuracy: 0.6570 - precision: 0.6506 - recall: 0.6957 - val_loss: 0.5915 - val_binary_accuracy: 0.6490 - val_precision: 0.6815 - val_recall: 0.5751\n",
      "Epoch 241/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5915 - binary_accuracy: 0.6490 - precision: 0.6815 - recall: 0.5751 - val_loss: 0.5889 - val_binary_accuracy: 0.6560 - val_precision: 0.6884 - val_recall: 0.5850\n",
      "Epoch 242/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.5889 - binary_accuracy: 0.6560 - precision: 0.6884 - recall: 0.5850 - val_loss: 0.5884 - val_binary_accuracy: 0.6570 - val_precision: 0.6660 - val_recall: 0.6462\n",
      "Epoch 243/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.5884 - binary_accuracy: 0.6570 - precision: 0.6660 - recall: 0.6462 - val_loss: 0.5857 - val_binary_accuracy: 0.6530 - val_precision: 0.6492 - val_recall: 0.6838\n",
      "Epoch 244/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.5857 - binary_accuracy: 0.6530 - precision: 0.6492 - recall: 0.6838 - val_loss: 0.5851 - val_binary_accuracy: 0.6590 - val_precision: 0.6590 - val_recall: 0.6759\n",
      "Epoch 245/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.5851 - binary_accuracy: 0.6590 - precision: 0.6590 - recall: 0.6759 - val_loss: 0.5826 - val_binary_accuracy: 0.6750 - val_precision: 0.6828 - val_recall: 0.6680\n",
      "Epoch 246/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5826 - binary_accuracy: 0.6750 - precision: 0.6828 - recall: 0.6680 - val_loss: 0.5813 - val_binary_accuracy: 0.6550 - val_precision: 0.6777 - val_recall: 0.6067\n",
      "Epoch 247/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5813 - binary_accuracy: 0.6550 - precision: 0.6777 - recall: 0.6067 - val_loss: 0.5800 - val_binary_accuracy: 0.6590 - val_precision: 0.6837 - val_recall: 0.6067\n",
      "Epoch 248/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5800 - binary_accuracy: 0.6590 - precision: 0.6837 - recall: 0.6067 - val_loss: 0.5776 - val_binary_accuracy: 0.6630 - val_precision: 0.6749 - val_recall: 0.6443\n",
      "Epoch 249/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.5776 - binary_accuracy: 0.6630 - precision: 0.6749 - recall: 0.6443 - val_loss: 0.5770 - val_binary_accuracy: 0.6720 - val_precision: 0.6654 - val_recall: 0.7075\n",
      "Epoch 250/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.5770 - binary_accuracy: 0.6720 - precision: 0.6654 - recall: 0.7075 - val_loss: 0.5740 - val_binary_accuracy: 0.6780 - val_precision: 0.6870 - val_recall: 0.6680\n",
      "Epoch 251/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.5740 - binary_accuracy: 0.6780 - precision: 0.6870 - recall: 0.6680 - val_loss: 0.5732 - val_binary_accuracy: 0.6680 - val_precision: 0.6925 - val_recall: 0.6186\n",
      "Epoch 252/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.5732 - binary_accuracy: 0.6680 - precision: 0.6925 - recall: 0.6186 - val_loss: 0.5709 - val_binary_accuracy: 0.6770 - val_precision: 0.6943 - val_recall: 0.6462\n",
      "Epoch 253/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5709 - binary_accuracy: 0.6770 - precision: 0.6943 - recall: 0.6462 - val_loss: 0.5692 - val_binary_accuracy: 0.6810 - val_precision: 0.6728 - val_recall: 0.7194\n",
      "Epoch 254/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5692 - binary_accuracy: 0.6810 - precision: 0.6728 - recall: 0.7194 - val_loss: 0.5674 - val_binary_accuracy: 0.6730 - val_precision: 0.6679 - val_recall: 0.7036\n",
      "Epoch 255/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.5674 - binary_accuracy: 0.6730 - precision: 0.6679 - recall: 0.7036 - val_loss: 0.5648 - val_binary_accuracy: 0.6840 - val_precision: 0.6939 - val_recall: 0.6719\n",
      "Epoch 256/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.5648 - binary_accuracy: 0.6840 - precision: 0.6939 - recall: 0.6719 - val_loss: 0.5635 - val_binary_accuracy: 0.6860 - val_precision: 0.7051 - val_recall: 0.6522\n",
      "Epoch 257/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.5635 - binary_accuracy: 0.6860 - precision: 0.7051 - recall: 0.6522 - val_loss: 0.5606 - val_binary_accuracy: 0.6920 - val_precision: 0.7012 - val_recall: 0.6818\n",
      "Epoch 258/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5606 - binary_accuracy: 0.6920 - precision: 0.7012 - recall: 0.6818 - val_loss: 0.5590 - val_binary_accuracy: 0.6900 - val_precision: 0.6856 - val_recall: 0.7154\n",
      "Epoch 259/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5590 - binary_accuracy: 0.6900 - precision: 0.6856 - recall: 0.7154 - val_loss: 0.5563 - val_binary_accuracy: 0.6970 - val_precision: 0.7018 - val_recall: 0.6976\n",
      "Epoch 260/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.5563 - binary_accuracy: 0.6970 - precision: 0.7018 - recall: 0.6976 - val_loss: 0.5544 - val_binary_accuracy: 0.6920 - val_precision: 0.7152 - val_recall: 0.6502\n",
      "Epoch 261/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5544 - binary_accuracy: 0.6920 - precision: 0.7152 - recall: 0.6502 - val_loss: 0.5517 - val_binary_accuracy: 0.6990 - val_precision: 0.7071 - val_recall: 0.6917\n",
      "Epoch 262/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.5517 - binary_accuracy: 0.6990 - precision: 0.7071 - recall: 0.6917 - val_loss: 0.5490 - val_binary_accuracy: 0.7020 - val_precision: 0.7000 - val_recall: 0.7194\n",
      "Epoch 263/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5490 - binary_accuracy: 0.7020 - precision: 0.7000 - recall: 0.7194 - val_loss: 0.5461 - val_binary_accuracy: 0.7000 - val_precision: 0.7012 - val_recall: 0.7095\n",
      "Epoch 264/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5461 - binary_accuracy: 0.7000 - precision: 0.7012 - recall: 0.7095 - val_loss: 0.5434 - val_binary_accuracy: 0.7090 - val_precision: 0.7292 - val_recall: 0.6759\n",
      "Epoch 265/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5434 - binary_accuracy: 0.7090 - precision: 0.7292 - recall: 0.6759 - val_loss: 0.5401 - val_binary_accuracy: 0.7120 - val_precision: 0.7290 - val_recall: 0.6858\n",
      "Epoch 266/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5401 - binary_accuracy: 0.7120 - precision: 0.7290 - recall: 0.6858 - val_loss: 0.5371 - val_binary_accuracy: 0.7110 - val_precision: 0.7166 - val_recall: 0.7095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5371 - binary_accuracy: 0.7110 - precision: 0.7166 - recall: 0.7095 - val_loss: 0.5336 - val_binary_accuracy: 0.7170 - val_precision: 0.7290 - val_recall: 0.7016\n",
      "Epoch 268/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5336 - binary_accuracy: 0.7170 - precision: 0.7290 - recall: 0.7016 - val_loss: 0.5313 - val_binary_accuracy: 0.7130 - val_precision: 0.7386 - val_recall: 0.6700\n",
      "Epoch 269/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.5313 - binary_accuracy: 0.7130 - precision: 0.7386 - recall: 0.6700 - val_loss: 0.5339 - val_binary_accuracy: 0.7200 - val_precision: 0.7116 - val_recall: 0.7510\n",
      "Epoch 270/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.5339 - binary_accuracy: 0.7200 - precision: 0.7116 - recall: 0.7510 - val_loss: 0.5614 - val_binary_accuracy: 0.6730 - val_precision: 0.7254 - val_recall: 0.5692\n",
      "Epoch 271/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5614 - binary_accuracy: 0.6730 - precision: 0.7254 - recall: 0.5692 - val_loss: 0.5782 - val_binary_accuracy: 0.6620 - val_precision: 0.6391 - val_recall: 0.7628\n",
      "Epoch 272/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.5782 - binary_accuracy: 0.6620 - precision: 0.6391 - recall: 0.7628 - val_loss: 0.5545 - val_binary_accuracy: 0.6860 - val_precision: 0.6868 - val_recall: 0.6976\n",
      "Epoch 273/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.5545 - binary_accuracy: 0.6860 - precision: 0.6868 - recall: 0.6976 - val_loss: 0.5457 - val_binary_accuracy: 0.6980 - val_precision: 0.7073 - val_recall: 0.6877\n",
      "Epoch 274/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5457 - binary_accuracy: 0.6980 - precision: 0.7073 - recall: 0.6877 - val_loss: 0.5328 - val_binary_accuracy: 0.7030 - val_precision: 0.7370 - val_recall: 0.6423\n",
      "Epoch 275/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5328 - binary_accuracy: 0.7030 - precision: 0.7370 - recall: 0.6423 - val_loss: 0.5389 - val_binary_accuracy: 0.7120 - val_precision: 0.7163 - val_recall: 0.7134\n",
      "Epoch 276/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.5389 - binary_accuracy: 0.7120 - precision: 0.7163 - recall: 0.7134 - val_loss: 0.5336 - val_binary_accuracy: 0.6940 - val_precision: 0.7703 - val_recall: 0.5632\n",
      "Epoch 277/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5336 - binary_accuracy: 0.6940 - precision: 0.7703 - recall: 0.5632 - val_loss: 0.5191 - val_binary_accuracy: 0.7340 - val_precision: 0.7857 - val_recall: 0.6522\n",
      "Epoch 278/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5191 - binary_accuracy: 0.7340 - precision: 0.7857 - recall: 0.6522 - val_loss: 0.5224 - val_binary_accuracy: 0.7010 - val_precision: 0.6872 - val_recall: 0.7510\n",
      "Epoch 279/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5224 - binary_accuracy: 0.7010 - precision: 0.6872 - recall: 0.7510 - val_loss: 0.5169 - val_binary_accuracy: 0.7020 - val_precision: 0.6763 - val_recall: 0.7885\n",
      "Epoch 280/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5169 - binary_accuracy: 0.7020 - precision: 0.6763 - recall: 0.7885 - val_loss: 0.5067 - val_binary_accuracy: 0.7310 - val_precision: 0.7687 - val_recall: 0.6700\n",
      "Epoch 281/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5067 - binary_accuracy: 0.7310 - precision: 0.7687 - recall: 0.6700 - val_loss: 0.5045 - val_binary_accuracy: 0.7260 - val_precision: 0.7959 - val_recall: 0.6166\n",
      "Epoch 282/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5045 - binary_accuracy: 0.7260 - precision: 0.7959 - recall: 0.6166 - val_loss: 0.5000 - val_binary_accuracy: 0.7460 - val_precision: 0.7480 - val_recall: 0.7510\n",
      "Epoch 283/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5000 - binary_accuracy: 0.7460 - precision: 0.7480 - recall: 0.7510 - val_loss: 0.4966 - val_binary_accuracy: 0.7360 - val_precision: 0.7224 - val_recall: 0.7767\n",
      "Epoch 284/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.4966 - binary_accuracy: 0.7360 - precision: 0.7224 - recall: 0.7767 - val_loss: 0.4880 - val_binary_accuracy: 0.7570 - val_precision: 0.7929 - val_recall: 0.7036\n",
      "Epoch 285/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.4880 - binary_accuracy: 0.7570 - precision: 0.7929 - recall: 0.7036 - val_loss: 0.4912 - val_binary_accuracy: 0.7490 - val_precision: 0.7972 - val_recall: 0.6759\n",
      "Epoch 286/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4912 - binary_accuracy: 0.7490 - precision: 0.7972 - recall: 0.6759 - val_loss: 0.4800 - val_binary_accuracy: 0.7630 - val_precision: 0.7751 - val_recall: 0.7490\n",
      "Epoch 287/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4800 - binary_accuracy: 0.7630 - precision: 0.7751 - recall: 0.7490 - val_loss: 0.4777 - val_binary_accuracy: 0.7550 - val_precision: 0.7495 - val_recall: 0.7747\n",
      "Epoch 288/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.4777 - binary_accuracy: 0.7550 - precision: 0.7495 - recall: 0.7747 - val_loss: 0.4730 - val_binary_accuracy: 0.7670 - val_precision: 0.7714 - val_recall: 0.7668\n",
      "Epoch 289/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4730 - binary_accuracy: 0.7670 - precision: 0.7714 - recall: 0.7668 - val_loss: 0.4705 - val_binary_accuracy: 0.7570 - val_precision: 0.8009 - val_recall: 0.6917\n",
      "Epoch 290/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4705 - binary_accuracy: 0.7570 - precision: 0.8009 - recall: 0.6917 - val_loss: 0.4618 - val_binary_accuracy: 0.7640 - val_precision: 0.8013 - val_recall: 0.7095\n",
      "Epoch 291/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.4618 - binary_accuracy: 0.7640 - precision: 0.8013 - recall: 0.7095 - val_loss: 0.4611 - val_binary_accuracy: 0.7620 - val_precision: 0.7648 - val_recall: 0.7648\n",
      "Epoch 292/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4611 - binary_accuracy: 0.7620 - precision: 0.7648 - recall: 0.7648 - val_loss: 0.4553 - val_binary_accuracy: 0.7650 - val_precision: 0.7853 - val_recall: 0.7372\n",
      "Epoch 293/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.4553 - binary_accuracy: 0.7650 - precision: 0.7853 - recall: 0.7372 - val_loss: 0.4502 - val_binary_accuracy: 0.7770 - val_precision: 0.7979 - val_recall: 0.7490\n",
      "Epoch 294/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.4502 - binary_accuracy: 0.7770 - precision: 0.7979 - recall: 0.7490 - val_loss: 0.4439 - val_binary_accuracy: 0.7830 - val_precision: 0.7774 - val_recall: 0.8004\n",
      "Epoch 295/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.4439 - binary_accuracy: 0.7830 - precision: 0.7774 - recall: 0.8004 - val_loss: 0.4413 - val_binary_accuracy: 0.7830 - val_precision: 0.7873 - val_recall: 0.7826\n",
      "Epoch 296/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.4413 - binary_accuracy: 0.7830 - precision: 0.7873 - recall: 0.7826 - val_loss: 0.4372 - val_binary_accuracy: 0.7820 - val_precision: 0.8051 - val_recall: 0.7510\n",
      "Epoch 297/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.4372 - binary_accuracy: 0.7820 - precision: 0.8051 - recall: 0.7510 - val_loss: 0.4336 - val_binary_accuracy: 0.7940 - val_precision: 0.8151 - val_recall: 0.7668\n",
      "Epoch 298/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.4336 - binary_accuracy: 0.7940 - precision: 0.8151 - recall: 0.7668 - val_loss: 0.4347 - val_binary_accuracy: 0.7880 - val_precision: 0.7579 - val_recall: 0.8538\n",
      "Epoch 299/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4347 - binary_accuracy: 0.7880 - precision: 0.7579 - recall: 0.8538 - val_loss: 0.4365 - val_binary_accuracy: 0.7730 - val_precision: 0.8462 - val_recall: 0.6739\n",
      "Epoch 300/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.4365 - binary_accuracy: 0.7730 - precision: 0.8462 - recall: 0.6739 - val_loss: 0.4296 - val_binary_accuracy: 0.7850 - val_precision: 0.7437 - val_recall: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4296 - binary_accuracy: 0.7850 - precision: 0.7437 - recall: 0.8775 - val_loss: 0.4217 - val_binary_accuracy: 0.7990 - val_precision: 0.8144 - val_recall: 0.7806\n",
      "Epoch 302/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.4217 - binary_accuracy: 0.7990 - precision: 0.8144 - recall: 0.7806 - val_loss: 0.4225 - val_binary_accuracy: 0.8170 - val_precision: 0.8473 - val_recall: 0.7787\n",
      "Epoch 303/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.4225 - binary_accuracy: 0.8170 - precision: 0.8473 - recall: 0.7787 - val_loss: 0.4045 - val_binary_accuracy: 0.8160 - val_precision: 0.8061 - val_recall: 0.8379\n",
      "Epoch 304/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.4045 - binary_accuracy: 0.8160 - precision: 0.8061 - recall: 0.8379 - val_loss: 0.4077 - val_binary_accuracy: 0.8110 - val_precision: 0.8176 - val_recall: 0.8063\n",
      "Epoch 305/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4077 - binary_accuracy: 0.8110 - precision: 0.8176 - recall: 0.8063 - val_loss: 0.4178 - val_binary_accuracy: 0.7910 - val_precision: 0.7839 - val_recall: 0.8103\n",
      "Epoch 306/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4178 - binary_accuracy: 0.7910 - precision: 0.7839 - recall: 0.8103 - val_loss: 0.3974 - val_binary_accuracy: 0.8130 - val_precision: 0.8344 - val_recall: 0.7866\n",
      "Epoch 307/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3974 - binary_accuracy: 0.8130 - precision: 0.8344 - recall: 0.7866 - val_loss: 0.3979 - val_binary_accuracy: 0.8140 - val_precision: 0.7797 - val_recall: 0.8814\n",
      "Epoch 308/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.3979 - binary_accuracy: 0.8140 - precision: 0.7797 - recall: 0.8814 - val_loss: 0.3922 - val_binary_accuracy: 0.8200 - val_precision: 0.8368 - val_recall: 0.8004\n",
      "Epoch 309/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.3922 - binary_accuracy: 0.8200 - precision: 0.8368 - recall: 0.8004 - val_loss: 0.3854 - val_binary_accuracy: 0.8190 - val_precision: 0.8806 - val_recall: 0.7431\n",
      "Epoch 310/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.3854 - binary_accuracy: 0.8190 - precision: 0.8806 - recall: 0.7431 - val_loss: 0.3823 - val_binary_accuracy: 0.8230 - val_precision: 0.7774 - val_recall: 0.9111\n",
      "Epoch 311/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3823 - binary_accuracy: 0.8230 - precision: 0.7774 - recall: 0.9111 - val_loss: 0.3709 - val_binary_accuracy: 0.8340 - val_precision: 0.8220 - val_recall: 0.8577\n",
      "Epoch 312/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3709 - binary_accuracy: 0.8340 - precision: 0.8220 - recall: 0.8577 - val_loss: 0.3739 - val_binary_accuracy: 0.8250 - val_precision: 0.8913 - val_recall: 0.7451\n",
      "Epoch 313/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3739 - binary_accuracy: 0.8250 - precision: 0.8913 - recall: 0.7451 - val_loss: 0.3639 - val_binary_accuracy: 0.8470 - val_precision: 0.8227 - val_recall: 0.8893\n",
      "Epoch 314/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.3639 - binary_accuracy: 0.8470 - precision: 0.8227 - recall: 0.8893 - val_loss: 0.3594 - val_binary_accuracy: 0.8470 - val_precision: 0.8287 - val_recall: 0.8794\n",
      "Epoch 315/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.3594 - binary_accuracy: 0.8470 - precision: 0.8287 - recall: 0.8794 - val_loss: 0.3569 - val_binary_accuracy: 0.8370 - val_precision: 0.8924 - val_recall: 0.7708\n",
      "Epoch 316/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.3569 - binary_accuracy: 0.8370 - precision: 0.8924 - recall: 0.7708 - val_loss: 0.3470 - val_binary_accuracy: 0.8480 - val_precision: 0.8540 - val_recall: 0.8439\n",
      "Epoch 317/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3470 - binary_accuracy: 0.8480 - precision: 0.8540 - recall: 0.8439 - val_loss: 0.3527 - val_binary_accuracy: 0.8370 - val_precision: 0.7922 - val_recall: 0.9190\n",
      "Epoch 318/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.3527 - binary_accuracy: 0.8370 - precision: 0.7922 - recall: 0.9190 - val_loss: 0.3531 - val_binary_accuracy: 0.8480 - val_precision: 0.8703 - val_recall: 0.8221\n",
      "Epoch 319/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.3531 - binary_accuracy: 0.8480 - precision: 0.8703 - recall: 0.8221 - val_loss: 0.3771 - val_binary_accuracy: 0.8110 - val_precision: 0.8126 - val_recall: 0.8142\n",
      "Epoch 320/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3771 - binary_accuracy: 0.8110 - precision: 0.8126 - recall: 0.8142 - val_loss: 0.3794 - val_binary_accuracy: 0.8250 - val_precision: 0.8214 - val_recall: 0.8360\n",
      "Epoch 321/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3794 - binary_accuracy: 0.8250 - precision: 0.8214 - recall: 0.8360 - val_loss: 0.3526 - val_binary_accuracy: 0.8490 - val_precision: 0.8233 - val_recall: 0.8933\n",
      "Epoch 322/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3526 - binary_accuracy: 0.8490 - precision: 0.8233 - recall: 0.8933 - val_loss: 0.3410 - val_binary_accuracy: 0.8520 - val_precision: 0.8874 - val_recall: 0.8103\n",
      "Epoch 323/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.3410 - binary_accuracy: 0.8520 - precision: 0.8874 - recall: 0.8103 - val_loss: 0.3586 - val_binary_accuracy: 0.8340 - val_precision: 0.8498 - val_recall: 0.8162\n",
      "Epoch 324/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.3586 - binary_accuracy: 0.8340 - precision: 0.8498 - recall: 0.8162 - val_loss: 0.3297 - val_binary_accuracy: 0.8560 - val_precision: 0.8131 - val_recall: 0.9289\n",
      "Epoch 325/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.3297 - binary_accuracy: 0.8560 - precision: 0.8131 - recall: 0.9289 - val_loss: 0.3268 - val_binary_accuracy: 0.8620 - val_precision: 0.8651 - val_recall: 0.8617\n",
      "Epoch 326/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3268 - binary_accuracy: 0.8620 - precision: 0.8651 - recall: 0.8617 - val_loss: 0.3216 - val_binary_accuracy: 0.8610 - val_precision: 0.9069 - val_recall: 0.8083\n",
      "Epoch 327/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3216 - binary_accuracy: 0.8610 - precision: 0.9069 - recall: 0.8083 - val_loss: 0.3181 - val_binary_accuracy: 0.8700 - val_precision: 0.8469 - val_recall: 0.9071\n",
      "Epoch 328/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3181 - binary_accuracy: 0.8700 - precision: 0.8469 - recall: 0.9071 - val_loss: 0.3056 - val_binary_accuracy: 0.8720 - val_precision: 0.8677 - val_recall: 0.8814\n",
      "Epoch 329/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3056 - binary_accuracy: 0.8720 - precision: 0.8677 - recall: 0.8814 - val_loss: 0.3068 - val_binary_accuracy: 0.8780 - val_precision: 0.9120 - val_recall: 0.8399\n",
      "Epoch 330/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.3068 - binary_accuracy: 0.8780 - precision: 0.9120 - recall: 0.8399 - val_loss: 0.2955 - val_binary_accuracy: 0.8760 - val_precision: 0.8617 - val_recall: 0.8992\n",
      "Epoch 331/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.2955 - binary_accuracy: 0.8760 - precision: 0.8617 - recall: 0.8992 - val_loss: 0.2960 - val_binary_accuracy: 0.8810 - val_precision: 0.8486 - val_recall: 0.9308\n",
      "Epoch 332/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.2960 - binary_accuracy: 0.8810 - precision: 0.8486 - recall: 0.9308 - val_loss: 0.2834 - val_binary_accuracy: 0.8790 - val_precision: 0.8782 - val_recall: 0.8834\n",
      "Epoch 333/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.2834 - binary_accuracy: 0.8790 - precision: 0.8782 - recall: 0.8834 - val_loss: 0.2872 - val_binary_accuracy: 0.8800 - val_precision: 0.9055 - val_recall: 0.8518\n",
      "Epoch 334/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.2872 - binary_accuracy: 0.8800 - precision: 0.9055 - recall: 0.8518 - val_loss: 0.2788 - val_binary_accuracy: 0.8950 - val_precision: 0.8878 - val_recall: 0.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.2788 - binary_accuracy: 0.8950 - precision: 0.8878 - recall: 0.9071 - val_loss: 0.2793 - val_binary_accuracy: 0.8870 - val_precision: 0.8579 - val_recall: 0.9308\n",
      "Epoch 336/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.2793 - binary_accuracy: 0.8870 - precision: 0.8579 - recall: 0.9308 - val_loss: 0.2684 - val_binary_accuracy: 0.8900 - val_precision: 0.9125 - val_recall: 0.8656\n",
      "Epoch 337/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.2684 - binary_accuracy: 0.8900 - precision: 0.9125 - recall: 0.8656 - val_loss: 0.2628 - val_binary_accuracy: 0.9010 - val_precision: 0.9046 - val_recall: 0.8992\n",
      "Epoch 338/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.2628 - binary_accuracy: 0.9010 - precision: 0.9046 - recall: 0.8992 - val_loss: 0.2578 - val_binary_accuracy: 0.9050 - val_precision: 0.8813 - val_recall: 0.9387\n",
      "Epoch 339/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.2578 - binary_accuracy: 0.9050 - precision: 0.8813 - recall: 0.9387 - val_loss: 0.2528 - val_binary_accuracy: 0.9020 - val_precision: 0.8953 - val_recall: 0.9130\n",
      "Epoch 340/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.2528 - binary_accuracy: 0.9020 - precision: 0.8953 - recall: 0.9130 - val_loss: 0.2516 - val_binary_accuracy: 0.8970 - val_precision: 0.9155 - val_recall: 0.8775\n",
      "Epoch 341/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2516 - binary_accuracy: 0.8970 - precision: 0.9155 - recall: 0.8775 - val_loss: 0.2497 - val_binary_accuracy: 0.9050 - val_precision: 0.8944 - val_recall: 0.9209\n",
      "Epoch 342/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.2497 - binary_accuracy: 0.9050 - precision: 0.8944 - recall: 0.9209 - val_loss: 0.2568 - val_binary_accuracy: 0.8960 - val_precision: 0.8641 - val_recall: 0.9427\n",
      "Epoch 343/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.2568 - binary_accuracy: 0.8960 - precision: 0.8641 - recall: 0.9427 - val_loss: 0.2761 - val_binary_accuracy: 0.8760 - val_precision: 0.9099 - val_recall: 0.8379\n",
      "Epoch 344/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.2761 - binary_accuracy: 0.8760 - precision: 0.9099 - recall: 0.8379 - val_loss: 0.3024 - val_binary_accuracy: 0.8610 - val_precision: 0.8522 - val_recall: 0.8775\n",
      "Epoch 345/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.3024 - binary_accuracy: 0.8610 - precision: 0.8522 - recall: 0.8775 - val_loss: 0.2476 - val_binary_accuracy: 0.9140 - val_precision: 0.8875 - val_recall: 0.9506\n",
      "Epoch 346/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.2476 - binary_accuracy: 0.9140 - precision: 0.8875 - recall: 0.9506 - val_loss: 0.2971 - val_binary_accuracy: 0.8700 - val_precision: 0.9178 - val_recall: 0.8162\n",
      "Epoch 347/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2971 - binary_accuracy: 0.8700 - precision: 0.9178 - recall: 0.8162 - val_loss: 0.3423 - val_binary_accuracy: 0.8340 - val_precision: 0.8269 - val_recall: 0.8498\n",
      "Epoch 348/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.3423 - binary_accuracy: 0.8340 - precision: 0.8269 - recall: 0.8498 - val_loss: 0.2537 - val_binary_accuracy: 0.8920 - val_precision: 0.8685 - val_recall: 0.9269\n",
      "Epoch 349/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.2537 - binary_accuracy: 0.8920 - precision: 0.8685 - recall: 0.9269 - val_loss: 0.3255 - val_binary_accuracy: 0.8540 - val_precision: 0.8830 - val_recall: 0.8202\n",
      "Epoch 350/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.3255 - binary_accuracy: 0.8540 - precision: 0.8830 - recall: 0.8202 - val_loss: 0.2331 - val_binary_accuracy: 0.9220 - val_precision: 0.9084 - val_recall: 0.9407\n",
      "Epoch 351/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2331 - binary_accuracy: 0.9220 - precision: 0.9084 - recall: 0.9407 - val_loss: 0.2849 - val_binary_accuracy: 0.8690 - val_precision: 0.8641 - val_recall: 0.8794\n",
      "Epoch 352/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.2849 - binary_accuracy: 0.8690 - precision: 0.8641 - recall: 0.8794 - val_loss: 0.2255 - val_binary_accuracy: 0.9110 - val_precision: 0.9353 - val_recall: 0.8854\n",
      "Epoch 353/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.2255 - binary_accuracy: 0.9110 - precision: 0.9353 - recall: 0.8854 - val_loss: 0.2647 - val_binary_accuracy: 0.8930 - val_precision: 0.8950 - val_recall: 0.8933\n",
      "Epoch 354/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2647 - binary_accuracy: 0.8930 - precision: 0.8950 - recall: 0.8933 - val_loss: 0.2279 - val_binary_accuracy: 0.9200 - val_precision: 0.8859 - val_recall: 0.9664\n",
      "Epoch 355/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2279 - binary_accuracy: 0.9200 - precision: 0.8859 - recall: 0.9664 - val_loss: 0.2408 - val_binary_accuracy: 0.9100 - val_precision: 0.9160 - val_recall: 0.9051\n",
      "Epoch 356/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.2408 - binary_accuracy: 0.9100 - precision: 0.9160 - recall: 0.9051 - val_loss: 0.2103 - val_binary_accuracy: 0.9260 - val_precision: 0.9337 - val_recall: 0.9190\n",
      "Epoch 357/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.2103 - binary_accuracy: 0.9260 - precision: 0.9337 - recall: 0.9190 - val_loss: 0.2314 - val_binary_accuracy: 0.9050 - val_precision: 0.9022 - val_recall: 0.9111\n",
      "Epoch 358/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.2314 - binary_accuracy: 0.9050 - precision: 0.9022 - recall: 0.9111 - val_loss: 0.2099 - val_binary_accuracy: 0.9250 - val_precision: 0.9105 - val_recall: 0.9447\n",
      "Epoch 359/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.2099 - binary_accuracy: 0.9250 - precision: 0.9105 - recall: 0.9447 - val_loss: 0.2062 - val_binary_accuracy: 0.9300 - val_precision: 0.9431 - val_recall: 0.9170\n",
      "Epoch 360/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2062 - binary_accuracy: 0.9300 - precision: 0.9431 - recall: 0.9170 - val_loss: 0.1997 - val_binary_accuracy: 0.9350 - val_precision: 0.9401 - val_recall: 0.9308\n",
      "Epoch 361/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.1997 - binary_accuracy: 0.9350 - precision: 0.9401 - recall: 0.9308 - val_loss: 0.1952 - val_binary_accuracy: 0.9310 - val_precision: 0.9039 - val_recall: 0.9664\n",
      "Epoch 362/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1952 - binary_accuracy: 0.9310 - precision: 0.9039 - recall: 0.9664 - val_loss: 0.1885 - val_binary_accuracy: 0.9360 - val_precision: 0.9234 - val_recall: 0.9526\n",
      "Epoch 363/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1885 - binary_accuracy: 0.9360 - precision: 0.9234 - recall: 0.9526 - val_loss: 0.1870 - val_binary_accuracy: 0.9410 - val_precision: 0.9589 - val_recall: 0.9229\n",
      "Epoch 364/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.1870 - binary_accuracy: 0.9410 - precision: 0.9589 - recall: 0.9229 - val_loss: 0.1799 - val_binary_accuracy: 0.9400 - val_precision: 0.9390 - val_recall: 0.9427\n",
      "Epoch 365/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.1799 - binary_accuracy: 0.9400 - precision: 0.9390 - recall: 0.9427 - val_loss: 0.1774 - val_binary_accuracy: 0.9430 - val_precision: 0.9342 - val_recall: 0.9545\n",
      "Epoch 366/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1774 - binary_accuracy: 0.9430 - precision: 0.9342 - recall: 0.9545 - val_loss: 0.1676 - val_binary_accuracy: 0.9510 - val_precision: 0.9454 - val_recall: 0.9585\n",
      "Epoch 367/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1676 - binary_accuracy: 0.9510 - precision: 0.9454 - recall: 0.9585 - val_loss: 0.1684 - val_binary_accuracy: 0.9470 - val_precision: 0.9557 - val_recall: 0.9387\n",
      "Epoch 368/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.1684 - binary_accuracy: 0.9470 - precision: 0.9557 - recall: 0.9387 - val_loss: 0.1622 - val_binary_accuracy: 0.9550 - val_precision: 0.9493 - val_recall: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1622 - binary_accuracy: 0.9550 - precision: 0.9493 - recall: 0.9625 - val_loss: 0.1550 - val_binary_accuracy: 0.9570 - val_precision: 0.9513 - val_recall: 0.9644\n",
      "Epoch 370/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.1550 - binary_accuracy: 0.9570 - precision: 0.9513 - recall: 0.9644 - val_loss: 0.1548 - val_binary_accuracy: 0.9590 - val_precision: 0.9568 - val_recall: 0.9625\n",
      "Epoch 371/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.1548 - binary_accuracy: 0.9590 - precision: 0.9568 - recall: 0.9625 - val_loss: 0.1477 - val_binary_accuracy: 0.9620 - val_precision: 0.9625 - val_recall: 0.9625\n",
      "Epoch 372/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1477 - binary_accuracy: 0.9620 - precision: 0.9625 - recall: 0.9625 - val_loss: 0.1438 - val_binary_accuracy: 0.9590 - val_precision: 0.9586 - val_recall: 0.9605\n",
      "Epoch 373/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.1438 - binary_accuracy: 0.9590 - precision: 0.9586 - recall: 0.9605 - val_loss: 0.1417 - val_binary_accuracy: 0.9610 - val_precision: 0.9587 - val_recall: 0.9644\n",
      "Epoch 374/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1417 - binary_accuracy: 0.9610 - precision: 0.9587 - recall: 0.9644 - val_loss: 0.1368 - val_binary_accuracy: 0.9650 - val_precision: 0.9663 - val_recall: 0.9644\n",
      "Epoch 375/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1368 - binary_accuracy: 0.9650 - precision: 0.9663 - recall: 0.9644 - val_loss: 0.1335 - val_binary_accuracy: 0.9690 - val_precision: 0.9684 - val_recall: 0.9704\n",
      "Epoch 376/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1335 - binary_accuracy: 0.9690 - precision: 0.9684 - recall: 0.9704 - val_loss: 0.1274 - val_binary_accuracy: 0.9690 - val_precision: 0.9684 - val_recall: 0.9704\n",
      "Epoch 377/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.1274 - binary_accuracy: 0.9690 - precision: 0.9684 - recall: 0.9704 - val_loss: 0.1274 - val_binary_accuracy: 0.9730 - val_precision: 0.9724 - val_recall: 0.9743\n",
      "Epoch 378/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.1274 - binary_accuracy: 0.9730 - precision: 0.9724 - recall: 0.9743 - val_loss: 0.1202 - val_binary_accuracy: 0.9770 - val_precision: 0.9801 - val_recall: 0.9743\n",
      "Epoch 379/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1202 - binary_accuracy: 0.9770 - precision: 0.9801 - recall: 0.9743 - val_loss: 0.1191 - val_binary_accuracy: 0.9770 - val_precision: 0.9763 - val_recall: 0.9783\n",
      "Epoch 380/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.1191 - binary_accuracy: 0.9770 - precision: 0.9763 - recall: 0.9783 - val_loss: 0.1139 - val_binary_accuracy: 0.9790 - val_precision: 0.9783 - val_recall: 0.9802\n",
      "Epoch 381/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1139 - binary_accuracy: 0.9790 - precision: 0.9783 - recall: 0.9802 - val_loss: 0.1116 - val_binary_accuracy: 0.9790 - val_precision: 0.9764 - val_recall: 0.9822\n",
      "Epoch 382/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.1116 - binary_accuracy: 0.9790 - precision: 0.9764 - recall: 0.9822 - val_loss: 0.1077 - val_binary_accuracy: 0.9810 - val_precision: 0.9803 - val_recall: 0.9822\n",
      "Epoch 383/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.1077 - binary_accuracy: 0.9810 - precision: 0.9803 - recall: 0.9822 - val_loss: 0.1041 - val_binary_accuracy: 0.9820 - val_precision: 0.9822 - val_recall: 0.9822\n",
      "Epoch 384/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1041 - binary_accuracy: 0.9820 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.1016 - val_binary_accuracy: 0.9830 - val_precision: 0.9842 - val_recall: 0.9822\n",
      "Epoch 385/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1016 - binary_accuracy: 0.9830 - precision: 0.9842 - recall: 0.9822 - val_loss: 0.0970 - val_binary_accuracy: 0.9850 - val_precision: 0.9861 - val_recall: 0.9842\n",
      "Epoch 386/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0970 - binary_accuracy: 0.9850 - precision: 0.9861 - recall: 0.9842 - val_loss: 0.0953 - val_binary_accuracy: 0.9850 - val_precision: 0.9861 - val_recall: 0.9842\n",
      "Epoch 387/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0953 - binary_accuracy: 0.9850 - precision: 0.9861 - recall: 0.9842 - val_loss: 0.0912 - val_binary_accuracy: 0.9850 - val_precision: 0.9842 - val_recall: 0.9862\n",
      "Epoch 388/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0912 - binary_accuracy: 0.9850 - precision: 0.9842 - recall: 0.9862 - val_loss: 0.0888 - val_binary_accuracy: 0.9830 - val_precision: 0.9842 - val_recall: 0.9822\n",
      "Epoch 389/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0888 - binary_accuracy: 0.9830 - precision: 0.9842 - recall: 0.9822 - val_loss: 0.0854 - val_binary_accuracy: 0.9870 - val_precision: 0.9843 - val_recall: 0.9901\n",
      "Epoch 390/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0854 - binary_accuracy: 0.9870 - precision: 0.9843 - recall: 0.9901 - val_loss: 0.0827 - val_binary_accuracy: 0.9900 - val_precision: 0.9901 - val_recall: 0.9901\n",
      "Epoch 391/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0827 - binary_accuracy: 0.9900 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0798 - val_binary_accuracy: 0.9880 - val_precision: 0.9862 - val_recall: 0.9901\n",
      "Epoch 392/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0798 - binary_accuracy: 0.9880 - precision: 0.9862 - recall: 0.9901 - val_loss: 0.0767 - val_binary_accuracy: 0.9890 - val_precision: 0.9901 - val_recall: 0.9881\n",
      "Epoch 393/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0767 - binary_accuracy: 0.9890 - precision: 0.9901 - recall: 0.9881 - val_loss: 0.0745 - val_binary_accuracy: 0.9920 - val_precision: 0.9882 - val_recall: 0.9960\n",
      "Epoch 394/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0745 - binary_accuracy: 0.9920 - precision: 0.9882 - recall: 0.9960 - val_loss: 0.0714 - val_binary_accuracy: 0.9950 - val_precision: 0.9960 - val_recall: 0.9941\n",
      "Epoch 395/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0714 - binary_accuracy: 0.9950 - precision: 0.9960 - recall: 0.9941 - val_loss: 0.0695 - val_binary_accuracy: 0.9920 - val_precision: 0.9882 - val_recall: 0.9960\n",
      "Epoch 396/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0695 - binary_accuracy: 0.9920 - precision: 0.9882 - recall: 0.9960 - val_loss: 0.0675 - val_binary_accuracy: 0.9940 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 397/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0675 - binary_accuracy: 0.9940 - precision: 0.9960 - recall: 0.9921 - val_loss: 0.0679 - val_binary_accuracy: 0.9890 - val_precision: 0.9825 - val_recall: 0.9960\n",
      "Epoch 398/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0679 - binary_accuracy: 0.9890 - precision: 0.9825 - recall: 0.9960 - val_loss: 0.0732 - val_binary_accuracy: 0.9880 - val_precision: 1.0000 - val_recall: 0.9763\n",
      "Epoch 399/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0732 - binary_accuracy: 0.9880 - precision: 1.0000 - recall: 0.9763 - val_loss: 0.0892 - val_binary_accuracy: 0.9740 - val_precision: 0.9511 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0892 - binary_accuracy: 0.9740 - precision: 0.9511 - recall: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9510 - val_precision: 1.0000 - val_recall: 0.9032\n",
      "Epoch 401/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.1213 - binary_accuracy: 0.9510 - precision: 1.0000 - recall: 0.9032 - val_loss: 0.1359 - val_binary_accuracy: 0.9490 - val_precision: 0.9129 - val_recall: 0.9941\n",
      "Epoch 402/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.1359 - binary_accuracy: 0.9490 - precision: 0.9129 - recall: 0.9941 - val_loss: 0.1934 - val_binary_accuracy: 0.9230 - val_precision: 0.9351 - val_recall: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.1934 - binary_accuracy: 0.9230 - precision: 0.9351 - recall: 0.9111 - val_loss: 0.3141 - val_binary_accuracy: 0.8760 - val_precision: 0.9505 - val_recall: 0.7964\n",
      "Epoch 404/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.3141 - binary_accuracy: 0.8760 - precision: 0.9505 - recall: 0.7964 - val_loss: 0.3272 - val_binary_accuracy: 0.8710 - val_precision: 0.7997 - val_recall: 0.9941\n",
      "Epoch 405/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3272 - binary_accuracy: 0.8710 - precision: 0.7997 - recall: 0.9941 - val_loss: 0.2221 - val_binary_accuracy: 0.9080 - val_precision: 0.8935 - val_recall: 0.9289\n",
      "Epoch 406/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.2221 - binary_accuracy: 0.9080 - precision: 0.8935 - recall: 0.9289 - val_loss: 0.2248 - val_binary_accuracy: 0.9190 - val_precision: 0.9691 - val_recall: 0.8676\n",
      "Epoch 407/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.2248 - binary_accuracy: 0.9190 - precision: 0.9691 - recall: 0.8676 - val_loss: 0.2568 - val_binary_accuracy: 0.8980 - val_precision: 0.9509 - val_recall: 0.8419\n",
      "Epoch 408/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.2568 - binary_accuracy: 0.8980 - precision: 0.9509 - recall: 0.8419 - val_loss: 0.1391 - val_binary_accuracy: 0.9510 - val_precision: 0.9369 - val_recall: 0.9684\n",
      "Epoch 409/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1391 - binary_accuracy: 0.9510 - precision: 0.9369 - recall: 0.9684 - val_loss: 0.2502 - val_binary_accuracy: 0.8920 - val_precision: 0.8579 - val_recall: 0.9427\n",
      "Epoch 410/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.2502 - binary_accuracy: 0.8920 - precision: 0.8579 - recall: 0.9427 - val_loss: 0.1124 - val_binary_accuracy: 0.9660 - val_precision: 0.9487 - val_recall: 0.9862\n",
      "Epoch 411/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.1124 - binary_accuracy: 0.9660 - precision: 0.9487 - recall: 0.9862 - val_loss: 0.1784 - val_binary_accuracy: 0.9280 - val_precision: 0.9306 - val_recall: 0.9269\n",
      "Epoch 412/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.1784 - binary_accuracy: 0.9280 - precision: 0.9306 - recall: 0.9269 - val_loss: 0.1323 - val_binary_accuracy: 0.9590 - val_precision: 0.9895 - val_recall: 0.9289\n",
      "Epoch 413/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.1323 - binary_accuracy: 0.9590 - precision: 0.9895 - recall: 0.9289 - val_loss: 0.1205 - val_binary_accuracy: 0.9670 - val_precision: 0.9896 - val_recall: 0.9447\n",
      "Epoch 414/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1205 - binary_accuracy: 0.9670 - precision: 0.9896 - recall: 0.9447 - val_loss: 0.1398 - val_binary_accuracy: 0.9610 - val_precision: 0.9624 - val_recall: 0.9605\n",
      "Epoch 415/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1398 - binary_accuracy: 0.9610 - precision: 0.9624 - recall: 0.9605 - val_loss: 0.0951 - val_binary_accuracy: 0.9790 - val_precision: 0.9709 - val_recall: 0.9881\n",
      "Epoch 416/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0951 - binary_accuracy: 0.9790 - precision: 0.9709 - recall: 0.9881 - val_loss: 0.1213 - val_binary_accuracy: 0.9720 - val_precision: 0.9668 - val_recall: 0.9783\n",
      "Epoch 417/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1213 - binary_accuracy: 0.9720 - precision: 0.9668 - recall: 0.9783 - val_loss: 0.0926 - val_binary_accuracy: 0.9850 - val_precision: 0.9881 - val_recall: 0.9822\n",
      "Epoch 418/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0926 - binary_accuracy: 0.9850 - precision: 0.9881 - recall: 0.9822 - val_loss: 0.0848 - val_binary_accuracy: 0.9850 - val_precision: 0.9920 - val_recall: 0.9783\n",
      "Epoch 419/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0848 - binary_accuracy: 0.9850 - precision: 0.9920 - recall: 0.9783 - val_loss: 0.0853 - val_binary_accuracy: 0.9850 - val_precision: 0.9842 - val_recall: 0.9862\n",
      "Epoch 420/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0853 - binary_accuracy: 0.9850 - precision: 0.9842 - recall: 0.9862 - val_loss: 0.0805 - val_binary_accuracy: 0.9860 - val_precision: 0.9824 - val_recall: 0.9901\n",
      "Epoch 421/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0805 - binary_accuracy: 0.9860 - precision: 0.9824 - recall: 0.9901 - val_loss: 0.0739 - val_binary_accuracy: 0.9890 - val_precision: 0.9843 - val_recall: 0.9941\n",
      "Epoch 422/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0739 - binary_accuracy: 0.9890 - precision: 0.9843 - recall: 0.9941 - val_loss: 0.0716 - val_binary_accuracy: 0.9890 - val_precision: 0.9882 - val_recall: 0.9901\n",
      "Epoch 423/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0716 - binary_accuracy: 0.9890 - precision: 0.9882 - recall: 0.9901 - val_loss: 0.0687 - val_binary_accuracy: 0.9940 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 424/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0687 - binary_accuracy: 0.9940 - precision: 0.9960 - recall: 0.9921 - val_loss: 0.0627 - val_binary_accuracy: 0.9920 - val_precision: 0.9940 - val_recall: 0.9901\n",
      "Epoch 425/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0627 - binary_accuracy: 0.9920 - precision: 0.9940 - recall: 0.9901 - val_loss: 0.0601 - val_binary_accuracy: 0.9940 - val_precision: 0.9921 - val_recall: 0.9960\n",
      "Epoch 426/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0601 - binary_accuracy: 0.9940 - precision: 0.9921 - recall: 0.9960 - val_loss: 0.0626 - val_binary_accuracy: 0.9920 - val_precision: 0.9902 - val_recall: 0.9941\n",
      "Epoch 427/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0626 - binary_accuracy: 0.9920 - precision: 0.9902 - recall: 0.9941 - val_loss: 0.0610 - val_binary_accuracy: 0.9910 - val_precision: 0.9901 - val_recall: 0.9921\n",
      "Epoch 428/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0610 - binary_accuracy: 0.9910 - precision: 0.9901 - recall: 0.9921 - val_loss: 0.0518 - val_binary_accuracy: 0.9970 - val_precision: 1.0000 - val_recall: 0.9941\n",
      "Epoch 429/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0518 - binary_accuracy: 0.9970 - precision: 1.0000 - recall: 0.9941 - val_loss: 0.0494 - val_binary_accuracy: 0.9970 - val_precision: 1.0000 - val_recall: 0.9941\n",
      "Epoch 430/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0494 - binary_accuracy: 0.9970 - precision: 1.0000 - recall: 0.9941 - val_loss: 0.0519 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 431/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0519 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0488 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 432/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0488 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0471 - val_binary_accuracy: 0.9970 - val_precision: 0.9961 - val_recall: 0.9980\n",
      "Epoch 433/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0471 - binary_accuracy: 0.9970 - precision: 0.9961 - recall: 0.9980 - val_loss: 0.0440 - val_binary_accuracy: 0.9970 - val_precision: 0.9961 - val_recall: 0.9980\n",
      "Epoch 434/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0440 - binary_accuracy: 0.9970 - precision: 0.9961 - recall: 0.9980 - val_loss: 0.0419 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 435/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0419 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0428 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 436/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0428 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0406 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0406 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0383 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 438/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0383 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0367 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 439/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0367 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0358 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 440/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0358 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0354 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0354 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0341 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0341 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0330 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0330 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0326 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 444/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0326 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0315 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0315 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0301 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0301 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0295 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0295 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0288 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0288 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0277 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0277 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0273 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 450/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0273 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0269 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 451/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0269 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0260 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 452/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0260 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0252 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0252 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0247 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0241 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0241 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0235 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0235 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0231 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 457/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0231 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0227 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0227 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0221 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0221 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0216 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0216 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0211 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0211 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0208 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0208 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0204 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0204 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0199 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0199 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0196 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0196 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0192 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0192 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0188 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0188 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0184 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0181 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0181 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0178 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0178 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0174 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0174 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0171 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0171 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0169 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0169 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0166 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0166 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0163 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0163 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0160 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0160 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0157 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0157 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0155 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0155 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0152 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0152 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0150 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0150 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0147 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0147 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0145 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0145 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0143 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0143 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0141 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0139 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0139 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0136 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0136 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0134 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0134 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0132 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0132 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0130 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0130 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0129 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 490/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0129 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0127 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0127 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0125 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0125 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0123 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0123 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0122 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0122 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0120 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0120 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0118 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0118 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0117 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0117 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0115 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0115 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0114 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0114 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0112 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0112 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0111 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0111 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0109 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0109 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0108 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0108 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0106 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0106 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0105 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0105 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0104 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0104 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0102 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0101 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0101 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0100 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0100 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0099 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0098 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0098 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0096 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0096 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0095 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0094 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0093 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0092 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0092 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0089 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0088 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0088 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0087 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0086 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 523/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0085 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0084 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0083 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0082 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0081 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0081 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0080 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0078 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0076 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0075 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0074 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0074 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0073 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0072 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0070 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0068 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0066 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0066 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0065 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 556/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0060 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 589/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 622/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 655/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 675/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 688/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 721/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 754/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 787/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 820/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 853/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 886/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model for classification\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_5)\n",
    "\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "print(model.summary())\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only pricing data from all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  log_adj_daily_returns_JPM  \\\n",
       "0 2019-10-22                   0.003166                   0.009986   \n",
       "1 2019-10-21                   0.009758                   0.024498   \n",
       "2 2019-10-18                   0.007230                   0.001743   \n",
       "3 2019-10-17                   0.000403                   0.005583   \n",
       "4 2019-10-16                  -0.010431                  -0.002337   \n",
       "5 2019-10-15                   0.016905                   0.029696   \n",
       "6 2019-10-14                   0.001219                   0.002666   \n",
       "7 2019-10-11                   0.011445                   0.016758   \n",
       "\n",
       "   log_adj_daily_returns_BAC  log_adj_daily_returns_C  \n",
       "0                   0.005786                 0.003475  \n",
       "1                   0.021836                 0.029250  \n",
       "2                   0.002970                 0.002009  \n",
       "3                   0.002979                 0.001438  \n",
       "4                   0.014691                -0.024447  \n",
       "5                   0.020045                 0.013856  \n",
       "6                   0.007924                 0.001995  \n",
       "7                   0.016039                 0.021339  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size_by_ticker = [200, 100, 50, 300]\n",
    "batch_size = 650\n",
    "assert batch_size == sum(dataset_size_by_ticker)\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-4)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_C(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+0)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_BAC(t-5)  \\\n",
       "1                        0.002666                        0.007924   \n",
       "2                        0.016758                        0.016039   \n",
       "3                        0.013931                        0.019880   \n",
       "4                        0.007218                        0.009366   \n",
       "5                       -0.022548                       -0.024313   \n",
       "\n",
       "   log_adj_daily_returns_C(t-5) timestamp(t-4)  \\\n",
       "1                      0.001995     2019-10-15   \n",
       "2                      0.021339     2019-10-14   \n",
       "3                      0.017494     2019-10-11   \n",
       "4                      0.015393     2019-10-10   \n",
       "5                     -0.026014     2019-10-09   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-4)  log_adj_daily_returns_JPM(t-4)  \\\n",
       "1                        0.016905                        0.029696   \n",
       "2                        0.001219                        0.002666   \n",
       "3                        0.011445                        0.016758   \n",
       "4                        0.010331                        0.013931   \n",
       "5                        0.006877                        0.007218   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-4)  log_adj_daily_returns_C(t-4)  ...  \\\n",
       "1                        0.020045                      0.013856  ...   \n",
       "2                        0.007924                      0.001995  ...   \n",
       "3                        0.016039                      0.021339  ...   \n",
       "4                        0.019880                      0.017494  ...   \n",
       "5                        0.009366                      0.015393  ...   \n",
       "\n",
       "  timestamp(t+0)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1     2019-10-21                        0.009758   \n",
       "2     2019-10-18                        0.007230   \n",
       "3     2019-10-17                        0.000403   \n",
       "4     2019-10-16                       -0.010431   \n",
       "5     2019-10-15                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+0)  log_adj_daily_returns_BAC(t+0)  \\\n",
       "1                        0.024498                        0.021836   \n",
       "2                        0.001743                        0.002970   \n",
       "3                        0.005583                        0.002979   \n",
       "4                       -0.002337                        0.014691   \n",
       "5                        0.029696                        0.020045   \n",
       "\n",
       "   log_adj_daily_returns_C(t+0) timestamp(t+1)  \\\n",
       "1                      0.029250     2019-10-22   \n",
       "2                      0.002009     2019-10-21   \n",
       "3                      0.001438     2019-10-18   \n",
       "4                     -0.024447     2019-10-17   \n",
       "5                      0.013856     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  log_adj_daily_returns_JPM(t+1)  \\\n",
       "1                        0.003166                        0.009986   \n",
       "2                        0.009758                        0.024498   \n",
       "3                        0.007230                        0.001743   \n",
       "4                        0.000403                        0.005583   \n",
       "5                       -0.010431                       -0.002337   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  log_adj_daily_returns_C(t+1)  \n",
       "1                        0.005786                      0.003475  \n",
       "2                        0.021836                      0.029250  \n",
       "3                        0.002970                      0.002009  \n",
       "4                        0.002979                      0.001438  \n",
       "5                        0.014691                     -0.024447  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)']]\n"
     ]
    }
   ],
   "source": [
    "column_names_by_ticker = [[name for name in df.columns if 'log_adj_daily_returns_' + t in name] for t in tickers]\n",
    "print(column_names_by_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list(map(lambda cols: df[cols], column_names_by_ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
      "1                        0.001219                        0.016905   \n",
      "2                        0.011445                        0.001219   \n",
      "3                        0.010331                        0.011445   \n",
      "4                        0.006877                        0.010331   \n",
      "5                       -0.020491                        0.006877   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
      "1                       -0.010431                        0.000403   \n",
      "2                        0.016905                       -0.010431   \n",
      "3                        0.001219                        0.016905   \n",
      "4                        0.011445                        0.001219   \n",
      "5                        0.010331                        0.011445   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
      "1                        0.007230                        0.009758   \n",
      "2                        0.000403                        0.007230   \n",
      "3                       -0.010431                        0.000403   \n",
      "4                        0.016905                       -0.010431   \n",
      "5                        0.001219                        0.016905   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t+1)  \n",
      "1                        0.003166  \n",
      "2                        0.009758  \n",
      "3                        0.007230  \n",
      "4                        0.000403  \n",
      "5                       -0.010431  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_JPM(t-4)  \\\n",
      "1                        0.002666                        0.029696   \n",
      "2                        0.016758                        0.002666   \n",
      "3                        0.013931                        0.016758   \n",
      "4                        0.007218                        0.013931   \n",
      "5                       -0.022548                        0.007218   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-3)  log_adj_daily_returns_JPM(t-2)  \\\n",
      "1                       -0.002337                        0.005583   \n",
      "2                        0.029696                       -0.002337   \n",
      "3                        0.002666                        0.029696   \n",
      "4                        0.016758                        0.002666   \n",
      "5                        0.013931                        0.016758   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-1)  log_adj_daily_returns_JPM(t+0)  \\\n",
      "1                        0.001743                        0.024498   \n",
      "2                        0.005583                        0.001743   \n",
      "3                       -0.002337                        0.005583   \n",
      "4                        0.029696                       -0.002337   \n",
      "5                        0.002666                        0.029696   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t+1)  \n",
      "1                        0.009986  \n",
      "2                        0.024498  \n",
      "3                        0.001743  \n",
      "4                        0.005583  \n",
      "5                       -0.002337  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_BAC(t-5)  log_adj_daily_returns_BAC(t-4)  \\\n",
      "1                        0.007924                        0.020045   \n",
      "2                        0.016039                        0.007924   \n",
      "3                        0.019880                        0.016039   \n",
      "4                        0.009366                        0.019880   \n",
      "5                       -0.024313                        0.009366   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-3)  log_adj_daily_returns_BAC(t-2)  \\\n",
      "1                        0.014691                        0.002979   \n",
      "2                        0.020045                        0.014691   \n",
      "3                        0.007924                        0.020045   \n",
      "4                        0.016039                        0.007924   \n",
      "5                        0.019880                        0.016039   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-1)  log_adj_daily_returns_BAC(t+0)  \\\n",
      "1                        0.002970                        0.021836   \n",
      "2                        0.002979                        0.002970   \n",
      "3                        0.014691                        0.002979   \n",
      "4                        0.020045                        0.014691   \n",
      "5                        0.007924                        0.020045   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t+1)  \n",
      "1                        0.005786  \n",
      "2                        0.021836  \n",
      "3                        0.002970  \n",
      "4                        0.002979  \n",
      "5                        0.014691  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_C(t-5)  log_adj_daily_returns_C(t-4)  \\\n",
      "1                      0.001995                      0.013856   \n",
      "2                      0.021339                      0.001995   \n",
      "3                      0.017494                      0.021339   \n",
      "4                      0.015393                      0.017494   \n",
      "5                     -0.026014                      0.015393   \n",
      "\n",
      "   log_adj_daily_returns_C(t-3)  log_adj_daily_returns_C(t-2)  \\\n",
      "1                     -0.024447                      0.001438   \n",
      "2                      0.013856                     -0.024447   \n",
      "3                      0.001995                      0.013856   \n",
      "4                      0.021339                      0.001995   \n",
      "5                      0.017494                      0.021339   \n",
      "\n",
      "   log_adj_daily_returns_C(t-1)  log_adj_daily_returns_C(t+0)  \\\n",
      "1                      0.002009                      0.029250   \n",
      "2                      0.001438                      0.002009   \n",
      "3                     -0.024447                      0.001438   \n",
      "4                      0.013856                     -0.024447   \n",
      "5                      0.001995                      0.013856   \n",
      "\n",
      "   log_adj_daily_returns_C(t+1)  \n",
      "1                      0.003475  \n",
      "2                      0.029250  \n",
      "3                      0.002009  \n",
      "4                      0.001438  \n",
      "5                     -0.024447  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking dfs\n",
    "for el in dfs:\n",
    "    print(el.head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_by_ticker = list(map(lambda d: d.values, dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 4\n",
      "Shape of each dataset: [(5024, 7), (5024, 7), (5024, 7), (5024, 7)]\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets: {}'.format(len(datasets_by_ticker)))\n",
    "print('Shape of each dataset: {}'.format(list(map(lambda d: d.shape, datasets_by_ticker))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each ticker: [200, 100, 50, 300]\n",
      "Shape of each sampled dataset: [(200, 7), (100, 7), (50, 7), (300, 7)]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and Sampling Datasets\n",
    "shuffled_indices_per_ticker = [np.random.choice(len(datasets_by_ticker[i]),\n",
    "                                                size=dataset_size_by_ticker[i],\n",
    "                                                replace=False)\n",
    "                               for i in range(len(dataset_size_by_ticker))]\n",
    "print('Number of samples for each ticker: {}'.format(list(map(len, shuffled_indices_per_ticker))))\n",
    "sampled_datasets_by_ticker = [datasets_by_ticker[i][shuffled_indices_per_ticker[i]] for i in range(len(datasets_by_ticker))]\n",
    "print('Shape of each sampled dataset: {}'.format(list(map(lambda d: d.shape, sampled_datasets_by_ticker))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (650, 7)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating datasets\n",
    "dataset = np.concatenate(sampled_datasets_by_ticker, axis=0)\n",
    "print('Shape of dataset: {}'.format(dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161 521 569 584 609 256 218  17 513 207 584 503 547 157 253  21 565 589\n",
      " 107 533 490  32 189 399  22 104 197  23 491 255   5  91 435 105 323 198\n",
      " 607 406 383 591 329 255 514 497  30 624 575  41 573  66  36 279 630 261\n",
      " 373 618 574 129 504 531 524  68 363 100 145  95 166 156 525 585 459 162\n",
      " 346 194 173 157 353  55 357 478  96 521 395 131 222  94 514 437 433 104\n",
      " 306  90 602 560 175 347 151 644 152 455  97 634  92 194 231 495 529 557\n",
      " 166 189 286 311  58 290 238 549 430 599 509 171 216  73 601 541 600 106\n",
      " 542 310 466 232 479 279 300 305 635 263 383 389 555  70 250 350 424 121\n",
      " 391 111 495  98 147  18 173 454  64 148 553 584 626 423 555 431 141 362\n",
      "  42 239  79 282 123 592  17 632 321 334  87 562 327 337 569 329 116 158\n",
      " 517 258 381 624 597 151 450 487 546 113 406 542  13 261 138 350 301 379\n",
      " 521  60 410 368 595 123 212 577 485 367 378 505 500 548 112 544 614 446\n",
      " 520 112 375 297 249 596 483 186 616 194 243 534 583 216 240 496 363 572\n",
      " 527 624 278 151 423 649 354 281 635 511 131 583 452 193 234 534 111 569\n",
      " 578 120 508  92  89 451 458 282 605 303  35 306 543 116 241 278 369 321\n",
      " 244 146 540 529 424  62 463 424 597 281 406 339 530 445 625  53 303 246\n",
      "  96 377 286  33 505 431 317  81 516 236 109 175 571 451   0 588  95 111\n",
      " 248 405 180 404 635 207 295 147 396 351 642 362 272 322 110 649 515 642\n",
      " 420 406 345 231 379 437  38 318 171  56 396 591 279 476 354 626  46 143\n",
      " 567 507 505 641 324 129 608 516  37 534 485 534 555 608 210 507  39 168\n",
      " 443 208 420 282 368 274 524  58 424 366 183 142 137 630 293 102 452 243\n",
      " 300  13 220 407  29 482 331 358 288 553 486 109 628 618 486 217 281 244\n",
      " 270 347 300 354 149 470 174 613  54 289 638 223 230 593 345 508 187 250\n",
      " 401 268 558  34 242 443 544 486  95 352 241 342 640 168 144 519 496 291\n",
      "  82 272 510 645 617 620 495  84 580 566 261 273 364 542 498 102 239 611\n",
      " 612 320 456 373 170 103 610 545 576 370 557  32 641 398 582 256 170  71\n",
      " 245 300 402 485 546 347 497 149  28 544 554 219 234 590 155  65 460 226\n",
      " 244   0 143 451 200 471 583 372 280 360 568 424 377 457 499 126  59 122\n",
      " 450 395 391 174  99 599 594 128 345 649 447 507 418  86 290 492 265 499\n",
      " 370 273 511 116 362 630 289 642 124 311  63 242 449 603 220 457 102 438\n",
      " 478 399 426 582 101 495  64 211 347  76  59  43  26 176 228 494 435 107\n",
      " 164 464 543 343 368 420 214 335 209 592 290 382 310 369 499 528 120 611\n",
      "   9 477 218 518 368 634 148  98 438 415 165 303 584 216 432 629 372 447\n",
      " 219  60 543 151 570 280 198  47 244 209  60 619   7  80  61   8 101 462\n",
      " 265 451 441 421 540  99 167 400 587 599 197 624 166 618 317   3  18 500\n",
      " 344 158 464  65 140 399 631 190 239  43 123  80  58 187 508 462 224  18\n",
      "  80  22]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling merged dataset\n",
    "shuffle_indices = np.random.randint(len(dataset), size=len(dataset))\n",
    "assert len(shuffle_indices) == len(dataset)\n",
    "print(shuffle_indices)\n",
    "shuffled_dataset = dataset[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (650, 6)\n",
      "Shape of targets: (650,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting Dataset into Features and Labels\n",
    "X, y = shuffled_dataset[:, :-1], shuffled_dataset[:, -1]\n",
    "print('Shape of features: {}'.format(X.shape))\n",
    "print('Shape of targets: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 650 samples, validate on 650 samples\n",
      "Epoch 1/900\n",
      "650/650 [==============================] - 6s 9ms/sample - loss: 7.4908e-04 - val_loss: 0.0010\n",
      "Epoch 2/900\n",
      "650/650 [==============================] - 0s 75us/sample - loss: 0.0010 - val_loss: 7.5246e-04\n",
      "Epoch 3/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5246e-04 - val_loss: 8.4625e-04\n",
      "Epoch 4/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 8.4625e-04 - val_loss: 9.0363e-04\n",
      "Epoch 5/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 9.0363e-04 - val_loss: 8.3249e-04\n",
      "Epoch 6/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 8.3249e-04 - val_loss: 7.6318e-04\n",
      "Epoch 7/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.6318e-04 - val_loss: 7.5113e-04\n",
      "Epoch 8/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5113e-04 - val_loss: 7.7838e-04\n",
      "Epoch 9/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.7838e-04 - val_loss: 8.0174e-04\n",
      "Epoch 10/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 8.0174e-04 - val_loss: 7.9987e-04\n",
      "Epoch 11/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.9987e-04 - val_loss: 7.8066e-04\n",
      "Epoch 12/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.8066e-04 - val_loss: 7.6049e-04\n",
      "Epoch 13/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.6049e-04 - val_loss: 7.4984e-04\n",
      "Epoch 14/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4984e-04 - val_loss: 7.5042e-04\n",
      "Epoch 15/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.5042e-04 - val_loss: 7.5765e-04\n",
      "Epoch 16/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5765e-04 - val_loss: 7.6486e-04\n",
      "Epoch 17/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.6486e-04 - val_loss: 7.6728e-04\n",
      "Epoch 18/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.6728e-04 - val_loss: 7.6414e-04\n",
      "Epoch 19/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.6414e-04 - val_loss: 7.5789e-04\n",
      "Epoch 20/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5789e-04 - val_loss: 7.5201e-04\n",
      "Epoch 21/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5201e-04 - val_loss: 7.4908e-04\n",
      "Epoch 22/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4908e-04 - val_loss: 7.4975e-04\n",
      "Epoch 23/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4975e-04 - val_loss: 7.5272e-04\n",
      "Epoch 24/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.5272e-04 - val_loss: 7.5566e-04\n",
      "Epoch 25/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.5566e-04 - val_loss: 7.5667e-04\n",
      "Epoch 26/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5667e-04 - val_loss: 7.5532e-04\n",
      "Epoch 27/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.5532e-04 - val_loss: 7.5265e-04\n",
      "Epoch 28/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.5265e-04 - val_loss: 7.5018e-04\n",
      "Epoch 29/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.5018e-04 - val_loss: 7.4898e-04\n",
      "Epoch 30/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4898e-04 - val_loss: 7.4923e-04\n",
      "Epoch 31/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4923e-04 - val_loss: 7.5037e-04\n",
      "Epoch 32/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5037e-04 - val_loss: 7.5155e-04\n",
      "Epoch 33/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5155e-04 - val_loss: 7.5209e-04\n",
      "Epoch 34/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5209e-04 - val_loss: 7.5178e-04\n",
      "Epoch 35/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.5178e-04 - val_loss: 7.5084e-04\n",
      "Epoch 36/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5084e-04 - val_loss: 7.4977e-04\n",
      "Epoch 37/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4977e-04 - val_loss: 7.4905e-04\n",
      "Epoch 38/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4905e-04 - val_loss: 7.4891e-04\n",
      "Epoch 39/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4891e-04 - val_loss: 7.4925e-04\n",
      "Epoch 40/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4925e-04 - val_loss: 7.4979e-04\n",
      "Epoch 41/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4979e-04 - val_loss: 7.5016e-04\n",
      "Epoch 42/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5016e-04 - val_loss: 7.5017e-04\n",
      "Epoch 43/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.5017e-04 - val_loss: 7.4984e-04\n",
      "Epoch 44/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4984e-04 - val_loss: 7.4937e-04\n",
      "Epoch 45/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.4937e-04 - val_loss: 7.4899e-04\n",
      "Epoch 46/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.4899e-04 - val_loss: 7.4884e-04\n",
      "Epoch 47/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4884e-04 - val_loss: 7.4894e-04\n",
      "Epoch 48/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.4894e-04 - val_loss: 7.4916e-04\n",
      "Epoch 49/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4916e-04 - val_loss: 7.4935e-04\n",
      "Epoch 50/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.4935e-04 - val_loss: 7.4939e-04\n",
      "Epoch 51/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4939e-04 - val_loss: 7.4927e-04\n",
      "Epoch 52/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4927e-04 - val_loss: 7.4907e-04\n",
      "Epoch 53/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4907e-04 - val_loss: 7.4888e-04\n",
      "Epoch 54/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.4888e-04 - val_loss: 7.4879e-04\n",
      "Epoch 55/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4879e-04 - val_loss: 7.4882e-04\n",
      "Epoch 56/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.4882e-04 - val_loss: 7.4892e-04\n",
      "Epoch 57/900\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 7.4892e-04 - val_loss: 7.4900e-04\n",
      "Epoch 58/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4900e-04 - val_loss: 7.4902e-04\n",
      "Epoch 59/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4902e-04 - val_loss: 7.4896e-04\n",
      "Epoch 60/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4896e-04 - val_loss: 7.4886e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4886e-04 - val_loss: 7.4877e-04\n",
      "Epoch 62/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4877e-04 - val_loss: 7.4873e-04\n",
      "Epoch 63/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4873e-04 - val_loss: 7.4874e-04\n",
      "Epoch 64/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4874e-04 - val_loss: 7.4878e-04\n",
      "Epoch 65/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4878e-04 - val_loss: 7.4881e-04\n",
      "Epoch 66/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4881e-04 - val_loss: 7.4880e-04\n",
      "Epoch 67/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4880e-04 - val_loss: 7.4876e-04\n",
      "Epoch 68/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4876e-04 - val_loss: 7.4871e-04\n",
      "Epoch 69/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4871e-04 - val_loss: 7.4867e-04\n",
      "Epoch 70/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4865e-04\n",
      "Epoch 71/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4865e-04 - val_loss: 7.4866e-04\n",
      "Epoch 72/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4866e-04 - val_loss: 7.4867e-04\n",
      "Epoch 73/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4867e-04\n",
      "Epoch 74/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4865e-04\n",
      "Epoch 75/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4865e-04 - val_loss: 7.4861e-04\n",
      "Epoch 76/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.4861e-04 - val_loss: 7.4858e-04\n",
      "Epoch 77/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4858e-04 - val_loss: 7.4856e-04\n",
      "Epoch 78/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4856e-04 - val_loss: 7.4855e-04\n",
      "Epoch 79/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4855e-04 - val_loss: 7.4855e-04\n",
      "Epoch 80/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4855e-04 - val_loss: 7.4854e-04\n",
      "Epoch 81/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4854e-04 - val_loss: 7.4853e-04\n",
      "Epoch 82/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4853e-04 - val_loss: 7.4850e-04\n",
      "Epoch 83/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4850e-04 - val_loss: 7.4847e-04\n",
      "Epoch 84/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4847e-04 - val_loss: 7.4845e-04\n",
      "Epoch 85/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4845e-04 - val_loss: 7.4844e-04\n",
      "Epoch 86/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4844e-04 - val_loss: 7.4842e-04\n",
      "Epoch 87/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4842e-04 - val_loss: 7.4841e-04\n",
      "Epoch 88/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4841e-04 - val_loss: 7.4839e-04\n",
      "Epoch 89/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4839e-04 - val_loss: 7.4836e-04\n",
      "Epoch 90/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4836e-04 - val_loss: 7.4833e-04\n",
      "Epoch 91/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4833e-04 - val_loss: 7.4831e-04\n",
      "Epoch 92/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4831e-04 - val_loss: 7.4829e-04\n",
      "Epoch 93/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4829e-04 - val_loss: 7.4827e-04\n",
      "Epoch 94/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4827e-04 - val_loss: 7.4824e-04\n",
      "Epoch 95/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4824e-04 - val_loss: 7.4821e-04\n",
      "Epoch 96/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4821e-04 - val_loss: 7.4818e-04\n",
      "Epoch 97/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4818e-04 - val_loss: 7.4815e-04\n",
      "Epoch 98/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4815e-04 - val_loss: 7.4812e-04\n",
      "Epoch 99/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4812e-04 - val_loss: 7.4809e-04\n",
      "Epoch 100/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4809e-04 - val_loss: 7.4806e-04\n",
      "Epoch 101/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4806e-04 - val_loss: 7.4802e-04\n",
      "Epoch 102/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4802e-04 - val_loss: 7.4799e-04\n",
      "Epoch 103/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4799e-04 - val_loss: 7.4795e-04\n",
      "Epoch 104/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4795e-04 - val_loss: 7.4791e-04\n",
      "Epoch 105/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4791e-04 - val_loss: 7.4787e-04\n",
      "Epoch 106/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4787e-04 - val_loss: 7.4782e-04\n",
      "Epoch 107/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4782e-04 - val_loss: 7.4778e-04\n",
      "Epoch 108/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4778e-04 - val_loss: 7.4773e-04\n",
      "Epoch 109/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4773e-04 - val_loss: 7.4768e-04\n",
      "Epoch 110/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4768e-04 - val_loss: 7.4762e-04\n",
      "Epoch 111/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4762e-04 - val_loss: 7.4757e-04\n",
      "Epoch 112/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4757e-04 - val_loss: 7.4751e-04\n",
      "Epoch 113/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4751e-04 - val_loss: 7.4745e-04\n",
      "Epoch 114/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4745e-04 - val_loss: 7.4738e-04\n",
      "Epoch 115/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4738e-04 - val_loss: 7.4731e-04\n",
      "Epoch 116/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4731e-04 - val_loss: 7.4724e-04\n",
      "Epoch 117/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4724e-04 - val_loss: 7.4716e-04\n",
      "Epoch 118/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4716e-04 - val_loss: 7.4708e-04\n",
      "Epoch 119/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4708e-04 - val_loss: 7.4699e-04\n",
      "Epoch 120/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4699e-04 - val_loss: 7.4690e-04\n",
      "Epoch 121/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4690e-04 - val_loss: 7.4680e-04\n",
      "Epoch 122/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4680e-04 - val_loss: 7.4670e-04\n",
      "Epoch 123/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4670e-04 - val_loss: 7.4659e-04\n",
      "Epoch 124/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4659e-04 - val_loss: 7.4647e-04\n",
      "Epoch 125/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4647e-04 - val_loss: 7.4635e-04\n",
      "Epoch 126/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4635e-04 - val_loss: 7.4621e-04\n",
      "Epoch 127/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4621e-04 - val_loss: 7.4607e-04\n",
      "Epoch 128/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4607e-04 - val_loss: 7.4592e-04\n",
      "Epoch 129/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4592e-04 - val_loss: 7.4576e-04\n",
      "Epoch 130/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4576e-04 - val_loss: 7.4559e-04\n",
      "Epoch 131/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4559e-04 - val_loss: 7.4541e-04\n",
      "Epoch 132/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4541e-04 - val_loss: 7.4522e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4522e-04 - val_loss: 7.4501e-04\n",
      "Epoch 134/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4501e-04 - val_loss: 7.4479e-04\n",
      "Epoch 135/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4479e-04 - val_loss: 7.4455e-04\n",
      "Epoch 136/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4455e-04 - val_loss: 7.4430e-04\n",
      "Epoch 137/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4430e-04 - val_loss: 7.4403e-04\n",
      "Epoch 138/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4403e-04 - val_loss: 7.4375e-04\n",
      "Epoch 139/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4375e-04 - val_loss: 7.4344e-04\n",
      "Epoch 140/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4344e-04 - val_loss: 7.4311e-04\n",
      "Epoch 141/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4311e-04 - val_loss: 7.4277e-04\n",
      "Epoch 142/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4277e-04 - val_loss: 7.4240e-04\n",
      "Epoch 143/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4240e-04 - val_loss: 7.4201e-04\n",
      "Epoch 144/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4201e-04 - val_loss: 7.4160e-04\n",
      "Epoch 145/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4160e-04 - val_loss: 7.4117e-04\n",
      "Epoch 146/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4117e-04 - val_loss: 7.4072e-04\n",
      "Epoch 147/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4071e-04 - val_loss: 7.4025e-04\n",
      "Epoch 148/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4025e-04 - val_loss: 7.3976e-04\n",
      "Epoch 149/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3976e-04 - val_loss: 7.3927e-04\n",
      "Epoch 150/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3927e-04 - val_loss: 7.3877e-04\n",
      "Epoch 151/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3877e-04 - val_loss: 7.3828e-04\n",
      "Epoch 152/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3828e-04 - val_loss: 7.3780e-04\n",
      "Epoch 153/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3780e-04 - val_loss: 7.3734e-04\n",
      "Epoch 154/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3734e-04 - val_loss: 7.3692e-04\n",
      "Epoch 155/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3692e-04 - val_loss: 7.3654e-04\n",
      "Epoch 156/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3654e-04 - val_loss: 7.3623e-04\n",
      "Epoch 157/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3623e-04 - val_loss: 7.3598e-04\n",
      "Epoch 158/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3598e-04 - val_loss: 7.3580e-04\n",
      "Epoch 159/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3580e-04 - val_loss: 7.3569e-04\n",
      "Epoch 160/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3569e-04 - val_loss: 7.3566e-04\n",
      "Epoch 161/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.3566e-04 - val_loss: 7.3578e-04\n",
      "Epoch 162/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3578e-04 - val_loss: 7.3721e-04\n",
      "Epoch 163/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3721e-04 - val_loss: 7.4729e-04\n",
      "Epoch 164/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4729e-04 - val_loss: 7.5673e-04\n",
      "Epoch 165/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5673e-04 - val_loss: 7.3667e-04\n",
      "Epoch 166/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3667e-04 - val_loss: 7.4711e-04\n",
      "Epoch 167/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4711e-04 - val_loss: 7.3761e-04\n",
      "Epoch 168/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3761e-04 - val_loss: 7.4314e-04\n",
      "Epoch 169/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4314e-04 - val_loss: 7.3564e-04\n",
      "Epoch 170/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3564e-04 - val_loss: 7.4189e-04\n",
      "Epoch 171/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4189e-04 - val_loss: 7.3525e-04\n",
      "Epoch 172/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3525e-04 - val_loss: 7.3887e-04\n",
      "Epoch 173/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3887e-04 - val_loss: 7.3781e-04\n",
      "Epoch 174/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3781e-04 - val_loss: 7.3544e-04\n",
      "Epoch 175/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3544e-04 - val_loss: 7.3841e-04\n",
      "Epoch 176/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3841e-04 - val_loss: 7.3638e-04\n",
      "Epoch 177/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3638e-04 - val_loss: 7.3564e-04\n",
      "Epoch 178/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3564e-04 - val_loss: 7.3743e-04\n",
      "Epoch 179/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3743e-04 - val_loss: 7.3582e-04\n",
      "Epoch 180/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3582e-04 - val_loss: 7.3531e-04\n",
      "Epoch 181/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3531e-04 - val_loss: 7.3648e-04\n",
      "Epoch 182/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3648e-04 - val_loss: 7.3524e-04\n",
      "Epoch 183/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3524e-04 - val_loss: 7.3474e-04\n",
      "Epoch 184/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3474e-04 - val_loss: 7.3553e-04\n",
      "Epoch 185/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.3553e-04 - val_loss: 7.3450e-04\n",
      "Epoch 186/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3450e-04 - val_loss: 7.3412e-04\n",
      "Epoch 187/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.3412e-04 - val_loss: 7.3463e-04\n",
      "Epoch 188/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3463e-04 - val_loss: 7.3369e-04\n",
      "Epoch 189/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3369e-04 - val_loss: 7.3360e-04\n",
      "Epoch 190/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3360e-04 - val_loss: 7.3383e-04\n",
      "Epoch 191/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3383e-04 - val_loss: 7.3301e-04\n",
      "Epoch 192/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3301e-04 - val_loss: 7.3326e-04\n",
      "Epoch 193/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3326e-04 - val_loss: 7.3309e-04\n",
      "Epoch 194/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.3309e-04 - val_loss: 7.3264e-04\n",
      "Epoch 195/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3264e-04 - val_loss: 7.3297e-04\n",
      "Epoch 196/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.3297e-04 - val_loss: 7.3248e-04\n",
      "Epoch 197/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3248e-04 - val_loss: 7.3252e-04\n",
      "Epoch 198/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3252e-04 - val_loss: 7.3246e-04\n",
      "Epoch 199/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3246e-04 - val_loss: 7.3210e-04\n",
      "Epoch 200/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3210e-04 - val_loss: 7.3224e-04\n",
      "Epoch 201/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3224e-04 - val_loss: 7.3186e-04\n",
      "Epoch 202/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3186e-04 - val_loss: 7.3182e-04\n",
      "Epoch 203/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3182e-04 - val_loss: 7.3168e-04\n",
      "Epoch 204/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3168e-04 - val_loss: 7.3140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3140e-04 - val_loss: 7.3139e-04\n",
      "Epoch 206/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3139e-04 - val_loss: 7.3110e-04\n",
      "Epoch 207/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3110e-04 - val_loss: 7.3099e-04\n",
      "Epoch 208/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3099e-04 - val_loss: 7.3087e-04\n",
      "Epoch 209/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3087e-04 - val_loss: 7.3062e-04\n",
      "Epoch 210/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3062e-04 - val_loss: 7.3056e-04\n",
      "Epoch 211/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3056e-04 - val_loss: 7.3035e-04\n",
      "Epoch 212/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3035e-04 - val_loss: 7.3019e-04\n",
      "Epoch 213/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3019e-04 - val_loss: 7.3007e-04\n",
      "Epoch 214/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.3007e-04 - val_loss: 7.2985e-04\n",
      "Epoch 215/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.2985e-04 - val_loss: 7.2972e-04\n",
      "Epoch 216/900\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 7.2972e-04 - val_loss: 7.2954e-04\n",
      "Epoch 217/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2954e-04 - val_loss: 7.2933e-04\n",
      "Epoch 218/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2933e-04 - val_loss: 7.2919e-04\n",
      "Epoch 219/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2919e-04 - val_loss: 7.2897e-04\n",
      "Epoch 220/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2897e-04 - val_loss: 7.2878e-04\n",
      "Epoch 221/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2878e-04 - val_loss: 7.2859e-04\n",
      "Epoch 222/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2859e-04 - val_loss: 7.2836e-04\n",
      "Epoch 223/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2836e-04 - val_loss: 7.2818e-04\n",
      "Epoch 224/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2818e-04 - val_loss: 7.2795e-04\n",
      "Epoch 225/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2795e-04 - val_loss: 7.2773e-04\n",
      "Epoch 226/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2773e-04 - val_loss: 7.2752e-04\n",
      "Epoch 227/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2752e-04 - val_loss: 7.2728e-04\n",
      "Epoch 228/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2728e-04 - val_loss: 7.2706e-04\n",
      "Epoch 229/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2706e-04 - val_loss: 7.2682e-04\n",
      "Epoch 230/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.2682e-04 - val_loss: 7.2657e-04\n",
      "Epoch 231/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.2657e-04 - val_loss: 7.2632e-04\n",
      "Epoch 232/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.2632e-04 - val_loss: 7.2605e-04\n",
      "Epoch 233/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2605e-04 - val_loss: 7.2580e-04\n",
      "Epoch 234/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.2580e-04 - val_loss: 7.2552e-04\n",
      "Epoch 235/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2552e-04 - val_loss: 7.2524e-04\n",
      "Epoch 236/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2524e-04 - val_loss: 7.2496e-04\n",
      "Epoch 237/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2496e-04 - val_loss: 7.2466e-04\n",
      "Epoch 238/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2466e-04 - val_loss: 7.2437e-04\n",
      "Epoch 239/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.2437e-04 - val_loss: 7.2406e-04\n",
      "Epoch 240/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2405e-04 - val_loss: 7.2374e-04\n",
      "Epoch 241/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2374e-04 - val_loss: 7.2342e-04\n",
      "Epoch 242/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2342e-04 - val_loss: 7.2309e-04\n",
      "Epoch 243/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2309e-04 - val_loss: 7.2276e-04\n",
      "Epoch 244/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.2276e-04 - val_loss: 7.2241e-04\n",
      "Epoch 245/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2241e-04 - val_loss: 7.2206e-04\n",
      "Epoch 246/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2206e-04 - val_loss: 7.2171e-04\n",
      "Epoch 247/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2171e-04 - val_loss: 7.2134e-04\n",
      "Epoch 248/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2134e-04 - val_loss: 7.2098e-04\n",
      "Epoch 249/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2098e-04 - val_loss: 7.2060e-04\n",
      "Epoch 250/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2060e-04 - val_loss: 7.2023e-04\n",
      "Epoch 251/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2023e-04 - val_loss: 7.1985e-04\n",
      "Epoch 252/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1985e-04 - val_loss: 7.1948e-04\n",
      "Epoch 253/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1948e-04 - val_loss: 7.1911e-04\n",
      "Epoch 254/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1911e-04 - val_loss: 7.1874e-04\n",
      "Epoch 255/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1874e-04 - val_loss: 7.1837e-04\n",
      "Epoch 256/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1837e-04 - val_loss: 7.1802e-04\n",
      "Epoch 257/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.1802e-04 - val_loss: 7.1768e-04\n",
      "Epoch 258/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1768e-04 - val_loss: 7.1735e-04\n",
      "Epoch 259/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1735e-04 - val_loss: 7.1704e-04\n",
      "Epoch 260/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1704e-04 - val_loss: 7.1675e-04\n",
      "Epoch 261/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.1675e-04 - val_loss: 7.1648e-04\n",
      "Epoch 262/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1648e-04 - val_loss: 7.1624e-04\n",
      "Epoch 263/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1624e-04 - val_loss: 7.1603e-04\n",
      "Epoch 264/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1603e-04 - val_loss: 7.1585e-04\n",
      "Epoch 265/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1585e-04 - val_loss: 7.1570e-04\n",
      "Epoch 266/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1570e-04 - val_loss: 7.1557e-04\n",
      "Epoch 267/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1557e-04 - val_loss: 7.1548e-04\n",
      "Epoch 268/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1548e-04 - val_loss: 7.1542e-04\n",
      "Epoch 269/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1542e-04 - val_loss: 7.1539e-04\n",
      "Epoch 270/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1539e-04 - val_loss: 7.1537e-04\n",
      "Epoch 271/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1537e-04 - val_loss: 7.1538e-04\n",
      "Epoch 272/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1538e-04 - val_loss: 7.1540e-04\n",
      "Epoch 273/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1540e-04 - val_loss: 7.1542e-04\n",
      "Epoch 274/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1542e-04 - val_loss: 7.1546e-04\n",
      "Epoch 275/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1546e-04 - val_loss: 7.1549e-04\n",
      "Epoch 276/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1549e-04 - val_loss: 7.1551e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1551e-04 - val_loss: 7.1553e-04\n",
      "Epoch 278/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1553e-04 - val_loss: 7.1555e-04\n",
      "Epoch 279/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1555e-04 - val_loss: 7.1555e-04\n",
      "Epoch 280/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1555e-04 - val_loss: 7.1555e-04\n",
      "Epoch 281/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1555e-04 - val_loss: 7.1554e-04\n",
      "Epoch 282/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1554e-04 - val_loss: 7.1552e-04\n",
      "Epoch 283/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1552e-04 - val_loss: 7.1550e-04\n",
      "Epoch 284/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1550e-04 - val_loss: 7.1547e-04\n",
      "Epoch 285/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1547e-04 - val_loss: 7.1545e-04\n",
      "Epoch 286/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1545e-04 - val_loss: 7.1542e-04\n",
      "Epoch 287/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1542e-04 - val_loss: 7.1540e-04\n",
      "Epoch 288/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1540e-04 - val_loss: 7.1538e-04\n",
      "Epoch 289/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1538e-04 - val_loss: 7.1536e-04\n",
      "Epoch 290/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1536e-04 - val_loss: 7.1534e-04\n",
      "Epoch 291/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1534e-04 - val_loss: 7.1533e-04\n",
      "Epoch 292/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1533e-04 - val_loss: 7.1532e-04\n",
      "Epoch 293/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1532e-04 - val_loss: 7.1531e-04\n",
      "Epoch 294/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1531e-04 - val_loss: 7.1531e-04\n",
      "Epoch 295/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1531e-04 - val_loss: 7.1531e-04\n",
      "Epoch 296/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1531e-04 - val_loss: 7.1530e-04\n",
      "Epoch 297/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 298/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 299/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 300/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 301/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 302/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 303/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 304/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 305/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 306/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1529e-04\n",
      "Epoch 307/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1529e-04 - val_loss: 7.1529e-04\n",
      "Epoch 308/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1529e-04 - val_loss: 7.1529e-04\n",
      "Epoch 309/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1529e-04 - val_loss: 7.1528e-04\n",
      "Epoch 310/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1528e-04 - val_loss: 7.1528e-04\n",
      "Epoch 311/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1528e-04 - val_loss: 7.1528e-04\n",
      "Epoch 312/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1528e-04 - val_loss: 7.1527e-04\n",
      "Epoch 313/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1527e-04 - val_loss: 7.1527e-04\n",
      "Epoch 314/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1527e-04 - val_loss: 7.1526e-04\n",
      "Epoch 315/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1526e-04\n",
      "Epoch 316/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1526e-04\n",
      "Epoch 317/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1525e-04\n",
      "Epoch 318/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 319/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 320/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 321/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1525e-04 - val_loss: 7.1524e-04\n",
      "Epoch 322/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 323/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 324/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 325/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 7.1524e-04 - val_loss: 7.1523e-04\n",
      "Epoch 326/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 327/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 328/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 329/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1523e-04 - val_loss: 7.1522e-04\n",
      "Epoch 330/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 331/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 332/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 333/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 334/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1522e-04 - val_loss: 7.1521e-04\n",
      "Epoch 335/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 336/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 337/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 338/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1521e-04 - val_loss: 7.1520e-04\n",
      "Epoch 339/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 340/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 341/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 342/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.1520e-04 - val_loss: 7.1519e-04\n",
      "Epoch 343/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 344/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 345/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 346/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 7.1519e-04 - val_loss: 7.1518e-04\n",
      "Epoch 347/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n",
      "Epoch 348/900\n",
      "650/650 [==============================] - 0s 94us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n",
      "Epoch 350/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1518e-04 - val_loss: 7.1517e-04\n",
      "Epoch 351/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 352/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 353/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 354/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1517e-04 - val_loss: 7.1516e-04\n",
      "Epoch 355/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 356/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 357/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 358/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 7.1516e-04 - val_loss: 7.1515e-04\n",
      "Epoch 359/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 360/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 361/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 362/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1515e-04 - val_loss: 7.1514e-04\n",
      "Epoch 363/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 364/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 365/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 366/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1514e-04 - val_loss: 7.1513e-04\n",
      "Epoch 367/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 368/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 369/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 370/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1513e-04 - val_loss: 7.1512e-04\n",
      "Epoch 371/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 372/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 373/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 374/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1512e-04 - val_loss: 7.1511e-04\n",
      "Epoch 375/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 376/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 377/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 378/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1510e-04\n",
      "Epoch 379/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 380/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 381/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 382/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 383/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 384/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 385/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 386/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 387/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 7.1509e-04 - val_loss: 7.1508e-04\n",
      "Epoch 388/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 389/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 390/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 391/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1508e-04 - val_loss: 7.1507e-04\n",
      "Epoch 392/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 393/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 394/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 395/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1507e-04 - val_loss: 7.1506e-04\n",
      "Epoch 396/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 397/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 398/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 399/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1506e-04 - val_loss: 7.1505e-04\n",
      "Epoch 400/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 401/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 402/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 403/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1505e-04 - val_loss: 7.1504e-04\n",
      "Epoch 404/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 405/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 406/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 407/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1504e-04 - val_loss: 7.1503e-04\n",
      "Epoch 408/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 409/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 410/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 411/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1503e-04 - val_loss: 7.1502e-04\n",
      "Epoch 412/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1502e-04 - val_loss: 7.1502e-04\n",
      "Epoch 413/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1502e-04 - val_loss: 7.1502e-04\n",
      "Epoch 414/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1502e-04 - val_loss: 7.1501e-04\n",
      "Epoch 415/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1502e-04 - val_loss: 7.1501e-04\n",
      "Epoch 416/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1501e-04 - val_loss: 7.1501e-04\n",
      "Epoch 417/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1501e-04 - val_loss: 7.1501e-04\n",
      "Epoch 418/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1501e-04 - val_loss: 7.1500e-04\n",
      "Epoch 419/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n",
      "Epoch 420/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n",
      "Epoch 422/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1500e-04 - val_loss: 7.1499e-04\n",
      "Epoch 423/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 424/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 425/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 426/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1499e-04 - val_loss: 7.1498e-04\n",
      "Epoch 427/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 428/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 429/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 430/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1498e-04 - val_loss: 7.1497e-04\n",
      "Epoch 431/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 432/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 433/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 434/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1497e-04 - val_loss: 7.1496e-04\n",
      "Epoch 435/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 436/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 437/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 438/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1495e-04\n",
      "Epoch 439/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 440/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 441/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 442/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1495e-04 - val_loss: 7.1494e-04\n",
      "Epoch 443/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 444/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 445/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 446/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1493e-04\n",
      "Epoch 447/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1493e-04 - val_loss: 7.1493e-04\n",
      "Epoch 448/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1493e-04 - val_loss: 7.1493e-04\n",
      "Epoch 449/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1493e-04 - val_loss: 7.1492e-04\n",
      "Epoch 450/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 451/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 452/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 453/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1491e-04\n",
      "Epoch 454/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 455/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 456/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 457/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1491e-04 - val_loss: 7.1490e-04\n",
      "Epoch 458/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 459/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 460/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 461/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1490e-04 - val_loss: 7.1489e-04\n",
      "Epoch 462/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1489e-04 - val_loss: 7.1489e-04\n",
      "Epoch 463/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1489e-04 - val_loss: 7.1489e-04\n",
      "Epoch 464/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1489e-04 - val_loss: 7.1488e-04\n",
      "Epoch 465/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 466/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 467/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 468/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1487e-04\n",
      "Epoch 469/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 470/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 471/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 472/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1487e-04 - val_loss: 7.1486e-04\n",
      "Epoch 473/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1486e-04\n",
      "Epoch 474/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1486e-04\n",
      "Epoch 475/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1485e-04\n",
      "Epoch 476/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 477/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 478/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 479/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1485e-04 - val_loss: 7.1484e-04\n",
      "Epoch 480/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 481/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 482/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 483/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1484e-04 - val_loss: 7.1483e-04\n",
      "Epoch 484/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1483e-04 - val_loss: 7.1483e-04\n",
      "Epoch 485/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1483e-04 - val_loss: 7.1483e-04\n",
      "Epoch 486/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1483e-04 - val_loss: 7.1482e-04\n",
      "Epoch 487/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 488/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 489/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 490/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1482e-04 - val_loss: 7.1481e-04\n",
      "Epoch 491/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1481e-04 - val_loss: 7.1481e-04\n",
      "Epoch 492/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1481e-04 - val_loss: 7.1481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1481e-04 - val_loss: 7.1480e-04\n",
      "Epoch 494/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 495/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 496/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 497/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1480e-04 - val_loss: 7.1479e-04\n",
      "Epoch 498/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1479e-04 - val_loss: 7.1479e-04\n",
      "Epoch 499/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1479e-04 - val_loss: 7.1479e-04\n",
      "Epoch 500/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1479e-04 - val_loss: 7.1478e-04\n",
      "Epoch 501/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 502/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 503/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 504/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1478e-04 - val_loss: 7.1477e-04\n",
      "Epoch 505/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1477e-04 - val_loss: 7.1477e-04\n",
      "Epoch 506/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1477e-04 - val_loss: 7.1477e-04\n",
      "Epoch 507/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1477e-04 - val_loss: 7.1476e-04\n",
      "Epoch 508/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 509/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 510/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 511/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1476e-04 - val_loss: 7.1475e-04\n",
      "Epoch 512/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1475e-04 - val_loss: 7.1475e-04\n",
      "Epoch 513/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1475e-04 - val_loss: 7.1475e-04\n",
      "Epoch 514/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1475e-04 - val_loss: 7.1474e-04\n",
      "Epoch 515/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 516/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 517/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 518/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1474e-04 - val_loss: 7.1473e-04\n",
      "Epoch 519/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1473e-04 - val_loss: 7.1473e-04\n",
      "Epoch 520/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1473e-04 - val_loss: 7.1473e-04\n",
      "Epoch 521/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1473e-04 - val_loss: 7.1472e-04\n",
      "Epoch 522/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1472e-04 - val_loss: 7.1472e-04\n",
      "Epoch 523/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1472e-04 - val_loss: 7.1472e-04\n",
      "Epoch 524/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1472e-04 - val_loss: 7.1471e-04\n",
      "Epoch 525/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 526/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 527/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 528/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1471e-04 - val_loss: 7.1470e-04\n",
      "Epoch 529/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1470e-04 - val_loss: 7.1470e-04\n",
      "Epoch 530/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1470e-04 - val_loss: 7.1470e-04\n",
      "Epoch 531/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1470e-04 - val_loss: 7.1469e-04\n",
      "Epoch 532/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1469e-04 - val_loss: 7.1469e-04\n",
      "Epoch 533/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1469e-04 - val_loss: 7.1469e-04\n",
      "Epoch 534/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1469e-04 - val_loss: 7.1468e-04\n",
      "Epoch 535/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1468e-04 - val_loss: 7.1468e-04\n",
      "Epoch 536/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1468e-04 - val_loss: 7.1468e-04\n",
      "Epoch 537/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1468e-04 - val_loss: 7.1467e-04\n",
      "Epoch 538/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 539/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 540/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 541/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1467e-04 - val_loss: 7.1466e-04\n",
      "Epoch 542/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1466e-04 - val_loss: 7.1466e-04\n",
      "Epoch 543/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1466e-04 - val_loss: 7.1466e-04\n",
      "Epoch 544/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1466e-04 - val_loss: 7.1465e-04\n",
      "Epoch 545/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1465e-04 - val_loss: 7.1465e-04\n",
      "Epoch 546/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1465e-04 - val_loss: 7.1465e-04\n",
      "Epoch 547/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1465e-04 - val_loss: 7.1464e-04\n",
      "Epoch 548/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1464e-04 - val_loss: 7.1464e-04\n",
      "Epoch 549/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1464e-04 - val_loss: 7.1464e-04\n",
      "Epoch 550/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1464e-04 - val_loss: 7.1463e-04\n",
      "Epoch 551/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1463e-04 - val_loss: 7.1463e-04\n",
      "Epoch 552/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1463e-04 - val_loss: 7.1463e-04\n",
      "Epoch 553/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1463e-04 - val_loss: 7.1462e-04\n",
      "Epoch 554/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1462e-04 - val_loss: 7.1462e-04\n",
      "Epoch 555/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1462e-04 - val_loss: 7.1462e-04\n",
      "Epoch 556/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1462e-04 - val_loss: 7.1461e-04\n",
      "Epoch 557/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1461e-04 - val_loss: 7.1461e-04\n",
      "Epoch 558/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1461e-04 - val_loss: 7.1461e-04\n",
      "Epoch 559/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 7.1461e-04 - val_loss: 7.1460e-04\n",
      "Epoch 560/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 7.1460e-04 - val_loss: 7.1460e-04\n",
      "Epoch 561/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 7.1460e-04 - val_loss: 7.1460e-04\n",
      "Epoch 562/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1460e-04 - val_loss: 7.1459e-04\n",
      "Epoch 563/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 7.1459e-04 - val_loss: 7.1459e-04\n",
      "Epoch 564/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1459e-04 - val_loss: 7.1459e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1459e-04 - val_loss: 7.1458e-04\n",
      "Epoch 566/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1458e-04 - val_loss: 7.1458e-04\n",
      "Epoch 567/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1458e-04 - val_loss: 7.1458e-04\n",
      "Epoch 568/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1458e-04 - val_loss: 7.1457e-04\n",
      "Epoch 569/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1457e-04 - val_loss: 7.1457e-04\n",
      "Epoch 570/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1457e-04 - val_loss: 7.1457e-04\n",
      "Epoch 571/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1457e-04 - val_loss: 7.1456e-04\n",
      "Epoch 572/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1456e-04 - val_loss: 7.1456e-04\n",
      "Epoch 573/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1456e-04 - val_loss: 7.1456e-04\n",
      "Epoch 574/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1456e-04 - val_loss: 7.1455e-04\n",
      "Epoch 575/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1455e-04 - val_loss: 7.1455e-04\n",
      "Epoch 576/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1455e-04 - val_loss: 7.1455e-04\n",
      "Epoch 577/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1455e-04 - val_loss: 7.1454e-04\n",
      "Epoch 578/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1454e-04 - val_loss: 7.1454e-04\n",
      "Epoch 579/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1454e-04 - val_loss: 7.1454e-04\n",
      "Epoch 580/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1454e-04 - val_loss: 7.1453e-04\n",
      "Epoch 581/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1453e-04 - val_loss: 7.1453e-04\n",
      "Epoch 582/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1453e-04 - val_loss: 7.1453e-04\n",
      "Epoch 583/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1453e-04 - val_loss: 7.1452e-04\n",
      "Epoch 584/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1452e-04 - val_loss: 7.1452e-04\n",
      "Epoch 585/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1452e-04 - val_loss: 7.1451e-04\n",
      "Epoch 586/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1451e-04 - val_loss: 7.1451e-04\n",
      "Epoch 587/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1451e-04 - val_loss: 7.1451e-04\n",
      "Epoch 588/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 7.1451e-04 - val_loss: 7.1450e-04\n",
      "Epoch 589/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1450e-04 - val_loss: 7.1450e-04\n",
      "Epoch 590/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1450e-04 - val_loss: 7.1450e-04\n",
      "Epoch 591/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1450e-04 - val_loss: 7.1449e-04\n",
      "Epoch 592/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1449e-04 - val_loss: 7.1449e-04\n",
      "Epoch 593/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1449e-04 - val_loss: 7.1449e-04\n",
      "Epoch 594/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1449e-04 - val_loss: 7.1448e-04\n",
      "Epoch 595/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1448e-04 - val_loss: 7.1448e-04\n",
      "Epoch 596/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1448e-04 - val_loss: 7.1447e-04\n",
      "Epoch 597/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1447e-04 - val_loss: 7.1447e-04\n",
      "Epoch 598/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1447e-04 - val_loss: 7.1447e-04\n",
      "Epoch 599/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1447e-04 - val_loss: 7.1446e-04\n",
      "Epoch 600/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1446e-04 - val_loss: 7.1446e-04\n",
      "Epoch 601/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1446e-04 - val_loss: 7.1446e-04\n",
      "Epoch 602/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1446e-04 - val_loss: 7.1445e-04\n",
      "Epoch 603/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1445e-04 - val_loss: 7.1445e-04\n",
      "Epoch 604/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1445e-04 - val_loss: 7.1444e-04\n",
      "Epoch 605/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1444e-04 - val_loss: 7.1444e-04\n",
      "Epoch 606/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1444e-04 - val_loss: 7.1444e-04\n",
      "Epoch 607/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1444e-04 - val_loss: 7.1443e-04\n",
      "Epoch 608/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1443e-04 - val_loss: 7.1443e-04\n",
      "Epoch 609/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1443e-04 - val_loss: 7.1443e-04\n",
      "Epoch 610/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1443e-04 - val_loss: 7.1442e-04\n",
      "Epoch 611/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1442e-04 - val_loss: 7.1442e-04\n",
      "Epoch 612/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1442e-04 - val_loss: 7.1441e-04\n",
      "Epoch 613/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1441e-04 - val_loss: 7.1441e-04\n",
      "Epoch 614/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1441e-04 - val_loss: 7.1441e-04\n",
      "Epoch 615/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1441e-04 - val_loss: 7.1440e-04\n",
      "Epoch 616/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1440e-04 - val_loss: 7.1440e-04\n",
      "Epoch 617/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1440e-04 - val_loss: 7.1439e-04\n",
      "Epoch 618/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1439e-04 - val_loss: 7.1439e-04\n",
      "Epoch 619/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1439e-04 - val_loss: 7.1439e-04\n",
      "Epoch 620/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1439e-04 - val_loss: 7.1438e-04\n",
      "Epoch 621/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1438e-04 - val_loss: 7.1438e-04\n",
      "Epoch 622/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1438e-04 - val_loss: 7.1437e-04\n",
      "Epoch 623/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1437e-04 - val_loss: 7.1437e-04\n",
      "Epoch 624/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1437e-04 - val_loss: 7.1436e-04\n",
      "Epoch 625/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1436e-04 - val_loss: 7.1436e-04\n",
      "Epoch 626/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1436e-04 - val_loss: 7.1436e-04\n",
      "Epoch 627/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1436e-04 - val_loss: 7.1435e-04\n",
      "Epoch 628/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1435e-04 - val_loss: 7.1435e-04\n",
      "Epoch 629/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1435e-04 - val_loss: 7.1434e-04\n",
      "Epoch 630/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1434e-04 - val_loss: 7.1434e-04\n",
      "Epoch 631/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1434e-04 - val_loss: 7.1434e-04\n",
      "Epoch 632/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1434e-04 - val_loss: 7.1433e-04\n",
      "Epoch 633/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1433e-04 - val_loss: 7.1433e-04\n",
      "Epoch 634/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1433e-04 - val_loss: 7.1432e-04\n",
      "Epoch 635/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1432e-04 - val_loss: 7.1432e-04\n",
      "Epoch 636/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1432e-04 - val_loss: 7.1431e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 637/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1431e-04 - val_loss: 7.1431e-04\n",
      "Epoch 638/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1431e-04 - val_loss: 7.1431e-04\n",
      "Epoch 639/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1431e-04 - val_loss: 7.1430e-04\n",
      "Epoch 640/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1430e-04 - val_loss: 7.1430e-04\n",
      "Epoch 641/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1430e-04 - val_loss: 7.1429e-04\n",
      "Epoch 642/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1429e-04 - val_loss: 7.1429e-04\n",
      "Epoch 643/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1429e-04 - val_loss: 7.1428e-04\n",
      "Epoch 644/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1428e-04 - val_loss: 7.1428e-04\n",
      "Epoch 645/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1428e-04 - val_loss: 7.1427e-04\n",
      "Epoch 646/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1427e-04 - val_loss: 7.1427e-04\n",
      "Epoch 647/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1427e-04 - val_loss: 7.1426e-04\n",
      "Epoch 648/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1426e-04 - val_loss: 7.1426e-04\n",
      "Epoch 649/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1426e-04 - val_loss: 7.1426e-04\n",
      "Epoch 650/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1426e-04 - val_loss: 7.1425e-04\n",
      "Epoch 651/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1425e-04 - val_loss: 7.1425e-04\n",
      "Epoch 652/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1425e-04 - val_loss: 7.1424e-04\n",
      "Epoch 653/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1424e-04 - val_loss: 7.1424e-04\n",
      "Epoch 654/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1424e-04 - val_loss: 7.1423e-04\n",
      "Epoch 655/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 7.1423e-04 - val_loss: 7.1423e-04\n",
      "Epoch 656/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1423e-04 - val_loss: 7.1422e-04\n",
      "Epoch 657/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 7.1422e-04 - val_loss: 7.1422e-04\n",
      "Epoch 658/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1422e-04 - val_loss: 7.1421e-04\n",
      "Epoch 659/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1421e-04 - val_loss: 7.1421e-04\n",
      "Epoch 660/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1421e-04 - val_loss: 7.1420e-04\n",
      "Epoch 661/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1420e-04 - val_loss: 7.1420e-04\n",
      "Epoch 662/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1420e-04 - val_loss: 7.1419e-04\n",
      "Epoch 663/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1419e-04 - val_loss: 7.1419e-04\n",
      "Epoch 664/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1419e-04 - val_loss: 7.1418e-04\n",
      "Epoch 665/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1418e-04 - val_loss: 7.1418e-04\n",
      "Epoch 666/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1418e-04 - val_loss: 7.1417e-04\n",
      "Epoch 667/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1417e-04 - val_loss: 7.1417e-04\n",
      "Epoch 668/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1417e-04 - val_loss: 7.1416e-04\n",
      "Epoch 669/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1416e-04 - val_loss: 7.1416e-04\n",
      "Epoch 670/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1416e-04 - val_loss: 7.1415e-04\n",
      "Epoch 671/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1415e-04 - val_loss: 7.1415e-04\n",
      "Epoch 672/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1415e-04 - val_loss: 7.1414e-04\n",
      "Epoch 673/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1414e-04 - val_loss: 7.1414e-04\n",
      "Epoch 674/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1414e-04 - val_loss: 7.1413e-04\n",
      "Epoch 675/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1413e-04 - val_loss: 7.1413e-04\n",
      "Epoch 676/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1413e-04 - val_loss: 7.1412e-04\n",
      "Epoch 677/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1412e-04 - val_loss: 7.1412e-04\n",
      "Epoch 678/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1412e-04 - val_loss: 7.1411e-04\n",
      "Epoch 679/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1411e-04 - val_loss: 7.1411e-04\n",
      "Epoch 680/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1411e-04 - val_loss: 7.1410e-04\n",
      "Epoch 681/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1410e-04 - val_loss: 7.1409e-04\n",
      "Epoch 682/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1409e-04 - val_loss: 7.1409e-04\n",
      "Epoch 683/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1409e-04 - val_loss: 7.1408e-04\n",
      "Epoch 684/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1408e-04 - val_loss: 7.1408e-04\n",
      "Epoch 685/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1408e-04 - val_loss: 7.1407e-04\n",
      "Epoch 686/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1407e-04 - val_loss: 7.1407e-04\n",
      "Epoch 687/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1407e-04 - val_loss: 7.1406e-04\n",
      "Epoch 688/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1406e-04 - val_loss: 7.1405e-04\n",
      "Epoch 689/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1405e-04 - val_loss: 7.1405e-04\n",
      "Epoch 690/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1405e-04 - val_loss: 7.1404e-04\n",
      "Epoch 691/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1404e-04 - val_loss: 7.1404e-04\n",
      "Epoch 692/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1404e-04 - val_loss: 7.1403e-04\n",
      "Epoch 693/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1403e-04 - val_loss: 7.1403e-04\n",
      "Epoch 694/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1403e-04 - val_loss: 7.1402e-04\n",
      "Epoch 695/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1402e-04 - val_loss: 7.1401e-04\n",
      "Epoch 696/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1401e-04 - val_loss: 7.1401e-04\n",
      "Epoch 697/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1401e-04 - val_loss: 7.1400e-04\n",
      "Epoch 698/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1400e-04 - val_loss: 7.1400e-04\n",
      "Epoch 699/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1400e-04 - val_loss: 7.1399e-04\n",
      "Epoch 700/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1399e-04 - val_loss: 7.1398e-04\n",
      "Epoch 701/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1398e-04 - val_loss: 7.1398e-04\n",
      "Epoch 702/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1398e-04 - val_loss: 7.1397e-04\n",
      "Epoch 703/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1397e-04 - val_loss: 7.1396e-04\n",
      "Epoch 704/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1396e-04 - val_loss: 7.1396e-04\n",
      "Epoch 705/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1396e-04 - val_loss: 7.1395e-04\n",
      "Epoch 706/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1395e-04 - val_loss: 7.1395e-04\n",
      "Epoch 707/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1395e-04 - val_loss: 7.1394e-04\n",
      "Epoch 708/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1394e-04 - val_loss: 7.1393e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1393e-04 - val_loss: 7.1393e-04\n",
      "Epoch 710/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1393e-04 - val_loss: 7.1392e-04\n",
      "Epoch 711/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1392e-04 - val_loss: 7.1391e-04\n",
      "Epoch 712/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1391e-04 - val_loss: 7.1391e-04\n",
      "Epoch 713/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1391e-04 - val_loss: 7.1390e-04\n",
      "Epoch 714/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1390e-04 - val_loss: 7.1389e-04\n",
      "Epoch 715/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1389e-04 - val_loss: 7.1388e-04\n",
      "Epoch 716/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1388e-04 - val_loss: 7.1388e-04\n",
      "Epoch 717/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1388e-04 - val_loss: 7.1387e-04\n",
      "Epoch 718/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1387e-04 - val_loss: 7.1386e-04\n",
      "Epoch 719/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1386e-04 - val_loss: 7.1386e-04\n",
      "Epoch 720/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1386e-04 - val_loss: 7.1385e-04\n",
      "Epoch 721/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1385e-04 - val_loss: 7.1384e-04\n",
      "Epoch 722/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1384e-04 - val_loss: 7.1383e-04\n",
      "Epoch 723/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1383e-04 - val_loss: 7.1383e-04\n",
      "Epoch 724/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1383e-04 - val_loss: 7.1382e-04\n",
      "Epoch 725/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1382e-04 - val_loss: 7.1381e-04\n",
      "Epoch 726/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1381e-04 - val_loss: 7.1381e-04\n",
      "Epoch 727/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1381e-04 - val_loss: 7.1380e-04\n",
      "Epoch 728/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1380e-04 - val_loss: 7.1379e-04\n",
      "Epoch 729/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1379e-04 - val_loss: 7.1378e-04\n",
      "Epoch 730/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1378e-04 - val_loss: 7.1377e-04\n",
      "Epoch 731/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1377e-04 - val_loss: 7.1377e-04\n",
      "Epoch 732/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1377e-04 - val_loss: 7.1376e-04\n",
      "Epoch 733/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1376e-04 - val_loss: 7.1375e-04\n",
      "Epoch 734/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1375e-04 - val_loss: 7.1374e-04\n",
      "Epoch 735/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1374e-04 - val_loss: 7.1373e-04\n",
      "Epoch 736/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1373e-04 - val_loss: 7.1373e-04\n",
      "Epoch 737/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1373e-04 - val_loss: 7.1372e-04\n",
      "Epoch 738/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1372e-04 - val_loss: 7.1371e-04\n",
      "Epoch 739/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1371e-04 - val_loss: 7.1370e-04\n",
      "Epoch 740/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1370e-04 - val_loss: 7.1369e-04\n",
      "Epoch 741/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1369e-04 - val_loss: 7.1368e-04\n",
      "Epoch 742/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1368e-04 - val_loss: 7.1367e-04\n",
      "Epoch 743/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1367e-04 - val_loss: 7.1367e-04\n",
      "Epoch 744/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1367e-04 - val_loss: 7.1366e-04\n",
      "Epoch 745/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1366e-04 - val_loss: 7.1365e-04\n",
      "Epoch 746/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1365e-04 - val_loss: 7.1364e-04\n",
      "Epoch 747/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1364e-04 - val_loss: 7.1363e-04\n",
      "Epoch 748/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1363e-04 - val_loss: 7.1362e-04\n",
      "Epoch 749/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1362e-04 - val_loss: 7.1361e-04\n",
      "Epoch 750/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1361e-04 - val_loss: 7.1360e-04\n",
      "Epoch 751/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1360e-04 - val_loss: 7.1359e-04\n",
      "Epoch 752/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1359e-04 - val_loss: 7.1358e-04\n",
      "Epoch 753/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1358e-04 - val_loss: 7.1357e-04\n",
      "Epoch 754/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1357e-04 - val_loss: 7.1356e-04\n",
      "Epoch 755/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1356e-04 - val_loss: 7.1355e-04\n",
      "Epoch 756/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1355e-04 - val_loss: 7.1354e-04\n",
      "Epoch 757/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1354e-04 - val_loss: 7.1353e-04\n",
      "Epoch 758/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1353e-04 - val_loss: 7.1352e-04\n",
      "Epoch 759/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1352e-04 - val_loss: 7.1351e-04\n",
      "Epoch 760/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1351e-04 - val_loss: 7.1350e-04\n",
      "Epoch 761/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1350e-04 - val_loss: 7.1349e-04\n",
      "Epoch 762/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1349e-04 - val_loss: 7.1348e-04\n",
      "Epoch 763/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1348e-04 - val_loss: 7.1347e-04\n",
      "Epoch 764/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1347e-04 - val_loss: 7.1346e-04\n",
      "Epoch 765/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1346e-04 - val_loss: 7.1345e-04\n",
      "Epoch 766/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1345e-04 - val_loss: 7.1343e-04\n",
      "Epoch 767/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1343e-04 - val_loss: 7.1342e-04\n",
      "Epoch 768/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1342e-04 - val_loss: 7.1341e-04\n",
      "Epoch 769/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1341e-04 - val_loss: 7.1340e-04\n",
      "Epoch 770/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1340e-04 - val_loss: 7.1339e-04\n",
      "Epoch 771/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1339e-04 - val_loss: 7.1337e-04\n",
      "Epoch 772/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1337e-04 - val_loss: 7.1336e-04\n",
      "Epoch 773/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1336e-04 - val_loss: 7.1335e-04\n",
      "Epoch 774/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1335e-04 - val_loss: 7.1334e-04\n",
      "Epoch 775/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1334e-04 - val_loss: 7.1332e-04\n",
      "Epoch 776/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1332e-04 - val_loss: 7.1331e-04\n",
      "Epoch 777/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1331e-04 - val_loss: 7.1330e-04\n",
      "Epoch 778/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1330e-04 - val_loss: 7.1328e-04\n",
      "Epoch 779/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1328e-04 - val_loss: 7.1327e-04\n",
      "Epoch 780/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1327e-04 - val_loss: 7.1326e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1326e-04 - val_loss: 7.1324e-04\n",
      "Epoch 782/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1324e-04 - val_loss: 7.1323e-04\n",
      "Epoch 783/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1323e-04 - val_loss: 7.1321e-04\n",
      "Epoch 784/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1321e-04 - val_loss: 7.1320e-04\n",
      "Epoch 785/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1320e-04 - val_loss: 7.1318e-04\n",
      "Epoch 786/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1318e-04 - val_loss: 7.1317e-04\n",
      "Epoch 787/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1317e-04 - val_loss: 7.1315e-04\n",
      "Epoch 788/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1315e-04 - val_loss: 7.1313e-04\n",
      "Epoch 789/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1313e-04 - val_loss: 7.1312e-04\n",
      "Epoch 790/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1312e-04 - val_loss: 7.1310e-04\n",
      "Epoch 791/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1310e-04 - val_loss: 7.1308e-04\n",
      "Epoch 792/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1308e-04 - val_loss: 7.1307e-04\n",
      "Epoch 793/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1307e-04 - val_loss: 7.1305e-04\n",
      "Epoch 794/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1305e-04 - val_loss: 7.1303e-04\n",
      "Epoch 795/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1303e-04 - val_loss: 7.1301e-04\n",
      "Epoch 796/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1301e-04 - val_loss: 7.1299e-04\n",
      "Epoch 797/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1299e-04 - val_loss: 7.1297e-04\n",
      "Epoch 798/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1297e-04 - val_loss: 7.1295e-04\n",
      "Epoch 799/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1295e-04 - val_loss: 7.1293e-04\n",
      "Epoch 800/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1293e-04 - val_loss: 7.1291e-04\n",
      "Epoch 801/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 7.1291e-04 - val_loss: 7.1289e-04\n",
      "Epoch 802/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1289e-04 - val_loss: 7.1287e-04\n",
      "Epoch 803/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1287e-04 - val_loss: 7.1285e-04\n",
      "Epoch 804/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1285e-04 - val_loss: 7.1282e-04\n",
      "Epoch 805/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1282e-04 - val_loss: 7.1280e-04\n",
      "Epoch 806/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1280e-04 - val_loss: 7.1278e-04\n",
      "Epoch 807/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1278e-04 - val_loss: 7.1275e-04\n",
      "Epoch 808/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1275e-04 - val_loss: 7.1273e-04\n",
      "Epoch 809/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1273e-04 - val_loss: 7.1270e-04\n",
      "Epoch 810/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1270e-04 - val_loss: 7.1267e-04\n",
      "Epoch 811/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1267e-04 - val_loss: 7.1264e-04\n",
      "Epoch 812/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1264e-04 - val_loss: 7.1262e-04\n",
      "Epoch 813/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1262e-04 - val_loss: 7.1259e-04\n",
      "Epoch 814/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1259e-04 - val_loss: 7.1255e-04\n",
      "Epoch 815/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1255e-04 - val_loss: 7.1252e-04\n",
      "Epoch 816/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1252e-04 - val_loss: 7.1249e-04\n",
      "Epoch 817/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1249e-04 - val_loss: 7.1245e-04\n",
      "Epoch 818/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1245e-04 - val_loss: 7.1242e-04\n",
      "Epoch 819/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1242e-04 - val_loss: 7.1238e-04\n",
      "Epoch 820/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1238e-04 - val_loss: 7.1234e-04\n",
      "Epoch 821/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1234e-04 - val_loss: 7.1230e-04\n",
      "Epoch 822/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1230e-04 - val_loss: 7.1226e-04\n",
      "Epoch 823/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1226e-04 - val_loss: 7.1221e-04\n",
      "Epoch 824/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1221e-04 - val_loss: 7.1217e-04\n",
      "Epoch 825/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1217e-04 - val_loss: 7.1212e-04\n",
      "Epoch 826/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1212e-04 - val_loss: 7.1206e-04\n",
      "Epoch 827/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1206e-04 - val_loss: 7.1201e-04\n",
      "Epoch 828/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1201e-04 - val_loss: 7.1195e-04\n",
      "Epoch 829/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1195e-04 - val_loss: 7.1189e-04\n",
      "Epoch 830/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1189e-04 - val_loss: 7.1182e-04\n",
      "Epoch 831/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1182e-04 - val_loss: 7.1175e-04\n",
      "Epoch 832/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1175e-04 - val_loss: 7.1167e-04\n",
      "Epoch 833/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1167e-04 - val_loss: 7.1159e-04\n",
      "Epoch 834/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1159e-04 - val_loss: 7.1150e-04\n",
      "Epoch 835/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1150e-04 - val_loss: 7.1141e-04\n",
      "Epoch 836/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1141e-04 - val_loss: 7.1130e-04\n",
      "Epoch 837/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1130e-04 - val_loss: 7.1119e-04\n",
      "Epoch 838/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1119e-04 - val_loss: 7.1107e-04\n",
      "Epoch 839/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1107e-04 - val_loss: 7.1093e-04\n",
      "Epoch 840/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1093e-04 - val_loss: 7.1077e-04\n",
      "Epoch 841/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1077e-04 - val_loss: 7.1060e-04\n",
      "Epoch 842/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1060e-04 - val_loss: 7.1041e-04\n",
      "Epoch 843/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1041e-04 - val_loss: 7.1019e-04\n",
      "Epoch 844/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1019e-04 - val_loss: 7.0994e-04\n",
      "Epoch 845/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0994e-04 - val_loss: 7.0965e-04\n",
      "Epoch 846/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.0965e-04 - val_loss: 7.0931e-04\n",
      "Epoch 847/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0931e-04 - val_loss: 7.0892e-04\n",
      "Epoch 848/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.0892e-04 - val_loss: 7.0844e-04\n",
      "Epoch 849/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.0844e-04 - val_loss: 7.0787e-04\n",
      "Epoch 850/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0787e-04 - val_loss: 7.0718e-04\n",
      "Epoch 851/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0718e-04 - val_loss: 7.0632e-04\n",
      "Epoch 852/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0632e-04 - val_loss: 7.0525e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.0525e-04 - val_loss: 7.0390e-04\n",
      "Epoch 854/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.0390e-04 - val_loss: 7.0216e-04\n",
      "Epoch 855/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0216e-04 - val_loss: 6.9994e-04\n",
      "Epoch 856/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.9994e-04 - val_loss: 6.9707e-04\n",
      "Epoch 857/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 6.9707e-04 - val_loss: 6.9344e-04\n",
      "Epoch 858/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.9344e-04 - val_loss: 6.8894e-04\n",
      "Epoch 859/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.8894e-04 - val_loss: 6.8372e-04\n",
      "Epoch 860/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 6.8372e-04 - val_loss: 6.7852e-04\n",
      "Epoch 861/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 6.7852e-04 - val_loss: 6.7554e-04\n",
      "Epoch 862/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 6.7554e-04 - val_loss: 6.8865e-04\n",
      "Epoch 863/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 6.8865e-04 - val_loss: 0.0011\n",
      "Epoch 864/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 865/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 866/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 867/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.0010 - val_loss: 8.3454e-04\n",
      "Epoch 868/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 8.3454e-04 - val_loss: 7.7928e-04\n",
      "Epoch 869/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.7928e-04 - val_loss: 7.6302e-04\n",
      "Epoch 870/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.6302e-04 - val_loss: 7.5708e-04\n",
      "Epoch 871/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.5708e-04 - val_loss: 7.4853e-04\n",
      "Epoch 872/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4853e-04 - val_loss: 7.4984e-04\n",
      "Epoch 873/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4984e-04 - val_loss: 7.5138e-04\n",
      "Epoch 874/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.5138e-04 - val_loss: 7.4593e-04\n",
      "Epoch 875/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4593e-04 - val_loss: 7.4912e-04\n",
      "Epoch 876/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.4912e-04 - val_loss: 7.4807e-04\n",
      "Epoch 877/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.4807e-04 - val_loss: 7.4602e-04\n",
      "Epoch 878/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.4602e-04 - val_loss: 7.4916e-04\n",
      "Epoch 879/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.4916e-04 - val_loss: 7.4504e-04\n",
      "Epoch 880/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4504e-04 - val_loss: 7.4746e-04\n",
      "Epoch 881/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.4746e-04 - val_loss: 7.4512e-04\n",
      "Epoch 882/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.4512e-04 - val_loss: 7.4528e-04\n",
      "Epoch 883/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4528e-04 - val_loss: 7.4474e-04\n",
      "Epoch 884/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4474e-04 - val_loss: 7.4335e-04\n",
      "Epoch 885/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.4335e-04 - val_loss: 7.4365e-04\n",
      "Epoch 886/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.4365e-04 - val_loss: 7.4167e-04\n",
      "Epoch 887/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4167e-04 - val_loss: 7.4203e-04\n",
      "Epoch 888/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.4203e-04 - val_loss: 7.4015e-04\n",
      "Epoch 889/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4015e-04 - val_loss: 7.3993e-04\n",
      "Epoch 890/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.3993e-04 - val_loss: 7.3870e-04\n",
      "Epoch 891/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.3870e-04 - val_loss: 7.3733e-04\n",
      "Epoch 892/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3733e-04 - val_loss: 7.3738e-04\n",
      "Epoch 893/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3738e-04 - val_loss: 7.3485e-04\n",
      "Epoch 894/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3485e-04 - val_loss: 7.3503e-04\n",
      "Epoch 895/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.3503e-04 - val_loss: 7.3432e-04\n",
      "Epoch 896/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.3432e-04 - val_loss: 7.3202e-04\n",
      "Epoch 897/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.3202e-04 - val_loss: 7.3146e-04\n",
      "Epoch 898/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.3146e-04 - val_loss: 7.3247e-04\n",
      "Epoch 899/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.3247e-04 - val_loss: 7.3442e-04\n",
      "Epoch 900/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.3442e-04 - val_loss: 7.3996e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_5)\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.4553846153846154\n",
      "Probability of sampling a 0: 0.5446153846153846\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 650 samples, validate on 650 samples\n",
      "Epoch 1/900\n",
      "650/650 [==============================] - 6s 10ms/sample - loss: 0.6931 - binary_accuracy: 0.5077 - precision: 0.4615 - recall: 0.4865 - val_loss: 0.6922 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 0.6922 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6913 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6913 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6904 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6904 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6895 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6895 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6898 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 0.6898 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6900 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 0.6900 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6896 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6896 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6894 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6894 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6894 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6894 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 81/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 82/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 83/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 84/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 86/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 87/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 88/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 89/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 90/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 92/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 93/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 94/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 95/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 96/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 97/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 98/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 99/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 100/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 101/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 102/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 103/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 104/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 105/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 106/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 107/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 108/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 109/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 110/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 111/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 112/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 113/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 114/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 115/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 116/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 117/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 118/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 119/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 120/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 121/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 122/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 124/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 125/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 126/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 127/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5477 - val_precision: 1.0000 - val_recall: 0.0068\n",
      "Epoch 128/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6890 - binary_accuracy: 0.5477 - precision: 1.0000 - recall: 0.0068 - val_loss: 0.6890 - val_binary_accuracy: 0.5477 - val_precision: 1.0000 - val_recall: 0.0068\n",
      "Epoch 129/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6890 - binary_accuracy: 0.5477 - precision: 1.0000 - recall: 0.0068 - val_loss: 0.6890 - val_binary_accuracy: 0.5462 - val_precision: 0.6667 - val_recall: 0.0068\n",
      "Epoch 130/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6890 - binary_accuracy: 0.5462 - precision: 0.6667 - recall: 0.0068 - val_loss: 0.6889 - val_binary_accuracy: 0.5462 - val_precision: 0.6667 - val_recall: 0.0068\n",
      "Epoch 131/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6889 - binary_accuracy: 0.5462 - precision: 0.6667 - recall: 0.0068 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 132/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 133/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 134/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6888 - val_binary_accuracy: 0.5462 - val_precision: 0.5714 - val_recall: 0.0135\n",
      "Epoch 135/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6888 - binary_accuracy: 0.5462 - precision: 0.5714 - recall: 0.0135 - val_loss: 0.6888 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 136/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6888 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6888 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 137/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6888 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6887 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 138/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6887 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6887 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 139/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6887 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6886 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 140/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6886 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6886 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 141/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6886 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6885 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 142/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6885 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6884 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 143/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6884 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6883 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 144/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6883 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6882 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 145/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6882 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6881 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 146/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6881 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6879 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 147/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6879 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6877 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 148/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6877 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6875 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 149/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6875 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6872 - val_binary_accuracy: 0.5431 - val_precision: 0.4545 - val_recall: 0.0169\n",
      "Epoch 150/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6872 - binary_accuracy: 0.5431 - precision: 0.4545 - recall: 0.0169 - val_loss: 0.6869 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0236\n",
      "Epoch 151/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6869 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0236 - val_loss: 0.6866 - val_binary_accuracy: 0.5492 - val_precision: 0.5789 - val_recall: 0.0372\n",
      "Epoch 152/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6866 - binary_accuracy: 0.5492 - precision: 0.5789 - recall: 0.0372 - val_loss: 0.6867 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0270\n",
      "Epoch 153/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 0.6867 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0270 - val_loss: 0.6873 - val_binary_accuracy: 0.5292 - val_precision: 0.4324 - val_recall: 0.1081\n",
      "Epoch 154/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6873 - binary_accuracy: 0.5292 - precision: 0.4324 - recall: 0.1081 - val_loss: 0.6870 - val_binary_accuracy: 0.5538 - val_precision: 0.6154 - val_recall: 0.0541\n",
      "Epoch 155/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6870 - binary_accuracy: 0.5538 - precision: 0.6154 - recall: 0.0541 - val_loss: 0.6870 - val_binary_accuracy: 0.5508 - val_precision: 0.6000 - val_recall: 0.0405\n",
      "Epoch 156/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6870 - binary_accuracy: 0.5508 - precision: 0.6000 - recall: 0.0405 - val_loss: 0.6864 - val_binary_accuracy: 0.5600 - val_precision: 0.6667 - val_recall: 0.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6864 - binary_accuracy: 0.5600 - precision: 0.6667 - recall: 0.0676 - val_loss: 0.6863 - val_binary_accuracy: 0.5646 - val_precision: 0.7241 - val_recall: 0.0709\n",
      "Epoch 158/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6863 - binary_accuracy: 0.5646 - precision: 0.7241 - recall: 0.0709 - val_loss: 0.6862 - val_binary_accuracy: 0.5492 - val_precision: 0.5789 - val_recall: 0.0372\n",
      "Epoch 159/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6862 - binary_accuracy: 0.5492 - precision: 0.5789 - recall: 0.0372 - val_loss: 0.6861 - val_binary_accuracy: 0.5462 - val_precision: 0.5455 - val_recall: 0.0203\n",
      "Epoch 160/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6861 - binary_accuracy: 0.5462 - precision: 0.5455 - recall: 0.0203 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 161/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 162/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 163/900\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6860 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 164/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6860 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6859 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 165/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6859 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6859 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 166/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6859 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6857 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 167/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6857 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6856 - val_binary_accuracy: 0.5462 - val_precision: 0.5714 - val_recall: 0.0135\n",
      "Epoch 168/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6856 - binary_accuracy: 0.5462 - precision: 0.5714 - recall: 0.0135 - val_loss: 0.6855 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 169/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6855 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6853 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 170/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6853 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6851 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 171/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6851 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6850 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 172/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6850 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6849 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0135\n",
      "Epoch 173/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6849 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0135 - val_loss: 0.6847 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 174/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6847 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6844 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 175/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6844 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6842 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 176/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6842 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6840 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 177/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6840 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6838 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 178/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6838 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6836 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 179/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6836 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6833 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 180/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6833 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6831 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 181/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6831 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6829 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 182/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6829 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6827 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 183/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6827 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6827 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 184/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6827 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 185/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6822 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 186/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6822 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6820 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 187/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6820 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 188/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6818 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 189/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 190/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6814 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6875 - val_binary_accuracy: 0.5738 - val_precision: 0.7568 - val_recall: 0.0946\n",
      "Epoch 192/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6875 - binary_accuracy: 0.5738 - precision: 0.7568 - recall: 0.0946 - val_loss: 0.6830 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 193/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6830 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6889 - val_binary_accuracy: 0.5508 - val_precision: 0.8333 - val_recall: 0.0169\n",
      "Epoch 194/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6889 - binary_accuracy: 0.5508 - precision: 0.8333 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 195/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6814 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6845 - val_binary_accuracy: 0.5631 - val_precision: 0.7500 - val_recall: 0.0608\n",
      "Epoch 196/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6845 - binary_accuracy: 0.5631 - precision: 0.7500 - recall: 0.0608 - val_loss: 0.6830 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 197/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6830 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6815 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 198/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6815 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6823 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 199/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6823 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6833 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 200/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6833 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6828 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 201/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6828 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6819 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 202/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 0.6819 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 203/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6818 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 204/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6821 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 205/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6821 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 206/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6817 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 207/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 208/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 209/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6816 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 210/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6814 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 211/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 212/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6811 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 213/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6811 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6808 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 214/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6808 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 215/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 216/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 217/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 218/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 219/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6806 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 220/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6806 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 221/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6805 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 222/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 223/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 224/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 226/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 227/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 228/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 229/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 230/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 231/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 232/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 233/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 234/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 235/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 236/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6801 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 237/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 238/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 239/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 240/900\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 241/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 242/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 243/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 244/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6799 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 245/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6799 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5477 - val_precision: 0.6000 - val_recall: 0.0203\n",
      "Epoch 246/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6799 - binary_accuracy: 0.5477 - precision: 0.6000 - recall: 0.0203 - val_loss: 0.6798 - val_binary_accuracy: 0.5492 - val_precision: 0.6364 - val_recall: 0.0236\n",
      "Epoch 247/900\n",
      "650/650 [==============================] - 0s 92us/sample - loss: 0.6798 - binary_accuracy: 0.5492 - precision: 0.6364 - recall: 0.0236 - val_loss: 0.6798 - val_binary_accuracy: 0.5492 - val_precision: 0.6364 - val_recall: 0.0236\n",
      "Epoch 248/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6798 - binary_accuracy: 0.5492 - precision: 0.6364 - recall: 0.0236 - val_loss: 0.6797 - val_binary_accuracy: 0.5508 - val_precision: 0.6667 - val_recall: 0.0270\n",
      "Epoch 249/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 0.6797 - binary_accuracy: 0.5508 - precision: 0.6667 - recall: 0.0270 - val_loss: 0.6796 - val_binary_accuracy: 0.5508 - val_precision: 0.6667 - val_recall: 0.0270\n",
      "Epoch 250/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6796 - binary_accuracy: 0.5508 - precision: 0.6667 - recall: 0.0270 - val_loss: 0.6795 - val_binary_accuracy: 0.5554 - val_precision: 0.7333 - val_recall: 0.0372\n",
      "Epoch 251/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6795 - binary_accuracy: 0.5554 - precision: 0.7333 - recall: 0.0372 - val_loss: 0.6794 - val_binary_accuracy: 0.5585 - val_precision: 0.7647 - val_recall: 0.0439\n",
      "Epoch 252/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6794 - binary_accuracy: 0.5585 - precision: 0.7647 - recall: 0.0439 - val_loss: 0.6793 - val_binary_accuracy: 0.5569 - val_precision: 0.7222 - val_recall: 0.0439\n",
      "Epoch 253/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6793 - binary_accuracy: 0.5569 - precision: 0.7222 - recall: 0.0439 - val_loss: 0.6791 - val_binary_accuracy: 0.5569 - val_precision: 0.7222 - val_recall: 0.0439\n",
      "Epoch 254/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6791 - binary_accuracy: 0.5569 - precision: 0.7222 - recall: 0.0439 - val_loss: 0.6788 - val_binary_accuracy: 0.5554 - val_precision: 0.6842 - val_recall: 0.0439\n",
      "Epoch 255/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6788 - binary_accuracy: 0.5554 - precision: 0.6842 - recall: 0.0439 - val_loss: 0.6785 - val_binary_accuracy: 0.5569 - val_precision: 0.6538 - val_recall: 0.0574\n",
      "Epoch 256/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6785 - binary_accuracy: 0.5569 - precision: 0.6538 - recall: 0.0574 - val_loss: 0.6781 - val_binary_accuracy: 0.5600 - val_precision: 0.6786 - val_recall: 0.0642\n",
      "Epoch 257/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 0.6781 - binary_accuracy: 0.5600 - precision: 0.6786 - recall: 0.0642 - val_loss: 0.6776 - val_binary_accuracy: 0.5569 - val_precision: 0.6250 - val_recall: 0.0676\n",
      "Epoch 258/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6776 - binary_accuracy: 0.5569 - precision: 0.6250 - recall: 0.0676 - val_loss: 0.6769 - val_binary_accuracy: 0.5615 - val_precision: 0.6571 - val_recall: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6769 - binary_accuracy: 0.5615 - precision: 0.6571 - recall: 0.0777 - val_loss: 0.6763 - val_binary_accuracy: 0.5662 - val_precision: 0.6944 - val_recall: 0.0845\n",
      "Epoch 260/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6763 - binary_accuracy: 0.5662 - precision: 0.6944 - recall: 0.0845 - val_loss: 0.6769 - val_binary_accuracy: 0.5815 - val_precision: 0.7000 - val_recall: 0.1419\n",
      "Epoch 261/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6769 - binary_accuracy: 0.5815 - precision: 0.7000 - recall: 0.1419 - val_loss: 0.6769 - val_binary_accuracy: 0.5554 - val_precision: 0.5507 - val_recall: 0.1284\n",
      "Epoch 262/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6769 - binary_accuracy: 0.5554 - precision: 0.5507 - recall: 0.1284 - val_loss: 0.6829 - val_binary_accuracy: 0.5462 - val_precision: 0.5028 - val_recall: 0.3007\n",
      "Epoch 263/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6829 - binary_accuracy: 0.5462 - precision: 0.5028 - recall: 0.3007 - val_loss: 0.6788 - val_binary_accuracy: 0.5646 - val_precision: 0.7097 - val_recall: 0.0743\n",
      "Epoch 264/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6788 - binary_accuracy: 0.5646 - precision: 0.7097 - recall: 0.0743 - val_loss: 0.7089 - val_binary_accuracy: 0.4492 - val_precision: 0.4460 - val_recall: 0.8649\n",
      "Epoch 265/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.7089 - binary_accuracy: 0.4492 - precision: 0.4460 - recall: 0.8649 - val_loss: 0.6807 - val_binary_accuracy: 0.5415 - val_precision: 0.4889 - val_recall: 0.1486\n",
      "Epoch 266/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6807 - binary_accuracy: 0.5415 - precision: 0.4889 - recall: 0.1486 - val_loss: 0.6934 - val_binary_accuracy: 0.5677 - val_precision: 0.8947 - val_recall: 0.0574\n",
      "Epoch 267/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6934 - binary_accuracy: 0.5677 - precision: 0.8947 - recall: 0.0574 - val_loss: 0.6847 - val_binary_accuracy: 0.5738 - val_precision: 0.7436 - val_recall: 0.0980\n",
      "Epoch 268/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6847 - binary_accuracy: 0.5738 - precision: 0.7436 - recall: 0.0980 - val_loss: 0.6819 - val_binary_accuracy: 0.5631 - val_precision: 0.5938 - val_recall: 0.1284\n",
      "Epoch 269/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6819 - binary_accuracy: 0.5631 - precision: 0.5938 - recall: 0.1284 - val_loss: 0.6819 - val_binary_accuracy: 0.5662 - val_precision: 0.6167 - val_recall: 0.1250\n",
      "Epoch 270/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6819 - binary_accuracy: 0.5662 - precision: 0.6167 - recall: 0.1250 - val_loss: 0.6879 - val_binary_accuracy: 0.5677 - val_precision: 0.7419 - val_recall: 0.0777\n",
      "Epoch 271/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 0.6879 - binary_accuracy: 0.5677 - precision: 0.7419 - recall: 0.0777 - val_loss: 0.6825 - val_binary_accuracy: 0.5677 - val_precision: 0.8000 - val_recall: 0.0676\n",
      "Epoch 272/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6825 - binary_accuracy: 0.5677 - precision: 0.8000 - recall: 0.0676 - val_loss: 0.6804 - val_binary_accuracy: 0.5662 - val_precision: 0.7692 - val_recall: 0.0676\n",
      "Epoch 273/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5662 - precision: 0.7692 - recall: 0.0676 - val_loss: 0.6804 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 274/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6806 - val_binary_accuracy: 0.5538 - val_precision: 0.8000 - val_recall: 0.0270\n",
      "Epoch 275/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6806 - binary_accuracy: 0.5538 - precision: 0.8000 - recall: 0.0270 - val_loss: 0.6809 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 276/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6809 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6813 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 277/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6813 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 278/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 279/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 280/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 281/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 282/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6818 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 283/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6815 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 284/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6815 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6813 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 285/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6813 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 286/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6811 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6809 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 287/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6809 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6808 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 288/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6808 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6806 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 289/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6806 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 290/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6804 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 291/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 292/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6800 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6798 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/900\n",
      "650/650 [==============================] - 0s 95us/sample - loss: 0.6798 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6797 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 294/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 0.6797 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6796 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 295/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6796 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6795 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 296/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6795 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6794 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 297/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6794 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6793 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 298/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6793 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6792 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 299/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6792 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6792 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 300/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6792 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6791 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 301/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6791 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6788 - val_binary_accuracy: 0.5538 - val_precision: 0.8000 - val_recall: 0.0270\n",
      "Epoch 302/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6788 - binary_accuracy: 0.5538 - precision: 0.8000 - recall: 0.0270 - val_loss: 0.6787 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 303/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6787 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6785 - val_binary_accuracy: 0.5631 - val_precision: 0.8750 - val_recall: 0.0473\n",
      "Epoch 304/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6785 - binary_accuracy: 0.5631 - precision: 0.8750 - recall: 0.0473 - val_loss: 0.6783 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 305/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6783 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6781 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 306/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6781 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6779 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 307/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6779 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6775 - val_binary_accuracy: 0.5677 - val_precision: 0.8261 - val_recall: 0.0642\n",
      "Epoch 308/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6775 - binary_accuracy: 0.5677 - precision: 0.8261 - recall: 0.0642 - val_loss: 0.6771 - val_binary_accuracy: 0.5692 - val_precision: 0.7857 - val_recall: 0.0743\n",
      "Epoch 309/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6771 - binary_accuracy: 0.5692 - precision: 0.7857 - recall: 0.0743 - val_loss: 0.6769 - val_binary_accuracy: 0.5662 - val_precision: 0.6842 - val_recall: 0.0878\n",
      "Epoch 310/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6769 - binary_accuracy: 0.5662 - precision: 0.6842 - recall: 0.0878 - val_loss: 0.6762 - val_binary_accuracy: 0.5662 - val_precision: 0.7059 - val_recall: 0.0811\n",
      "Epoch 311/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6762 - binary_accuracy: 0.5662 - precision: 0.7059 - recall: 0.0811 - val_loss: 0.6757 - val_binary_accuracy: 0.5677 - val_precision: 0.7586 - val_recall: 0.0743\n",
      "Epoch 312/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6757 - binary_accuracy: 0.5677 - precision: 0.7586 - recall: 0.0743 - val_loss: 0.6753 - val_binary_accuracy: 0.5723 - val_precision: 0.8214 - val_recall: 0.0777\n",
      "Epoch 313/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6753 - binary_accuracy: 0.5723 - precision: 0.8214 - recall: 0.0777 - val_loss: 0.6747 - val_binary_accuracy: 0.5600 - val_precision: 0.6316 - val_recall: 0.0811\n",
      "Epoch 314/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 0.6747 - binary_accuracy: 0.5600 - precision: 0.6316 - recall: 0.0811 - val_loss: 0.6743 - val_binary_accuracy: 0.5754 - val_precision: 0.7083 - val_recall: 0.1149\n",
      "Epoch 315/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6743 - binary_accuracy: 0.5754 - precision: 0.7083 - recall: 0.1149 - val_loss: 0.6737 - val_binary_accuracy: 0.5677 - val_precision: 0.6744 - val_recall: 0.0980\n",
      "Epoch 316/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6737 - binary_accuracy: 0.5677 - precision: 0.6744 - recall: 0.0980 - val_loss: 0.6733 - val_binary_accuracy: 0.5646 - val_precision: 0.6585 - val_recall: 0.0912\n",
      "Epoch 317/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6733 - binary_accuracy: 0.5646 - precision: 0.6585 - recall: 0.0912 - val_loss: 0.6726 - val_binary_accuracy: 0.5692 - val_precision: 0.6818 - val_recall: 0.1014\n",
      "Epoch 318/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6726 - binary_accuracy: 0.5692 - precision: 0.6818 - recall: 0.1014 - val_loss: 0.6722 - val_binary_accuracy: 0.5846 - val_precision: 0.7031 - val_recall: 0.1520\n",
      "Epoch 319/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6722 - binary_accuracy: 0.5846 - precision: 0.7031 - recall: 0.1520 - val_loss: 0.6715 - val_binary_accuracy: 0.5862 - val_precision: 0.7368 - val_recall: 0.1419\n",
      "Epoch 320/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6715 - binary_accuracy: 0.5862 - precision: 0.7368 - recall: 0.1419 - val_loss: 0.6710 - val_binary_accuracy: 0.5831 - val_precision: 0.7358 - val_recall: 0.1318\n",
      "Epoch 321/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6710 - binary_accuracy: 0.5831 - precision: 0.7358 - recall: 0.1318 - val_loss: 0.6704 - val_binary_accuracy: 0.5908 - val_precision: 0.7206 - val_recall: 0.1655\n",
      "Epoch 322/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6704 - binary_accuracy: 0.5908 - precision: 0.7206 - recall: 0.1655 - val_loss: 0.6696 - val_binary_accuracy: 0.5862 - val_precision: 0.7077 - val_recall: 0.1554\n",
      "Epoch 323/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6696 - binary_accuracy: 0.5862 - precision: 0.7077 - recall: 0.1554 - val_loss: 0.6690 - val_binary_accuracy: 0.5846 - val_precision: 0.6912 - val_recall: 0.1588\n",
      "Epoch 324/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6690 - binary_accuracy: 0.5846 - precision: 0.6912 - recall: 0.1588 - val_loss: 0.6685 - val_binary_accuracy: 0.5785 - val_precision: 0.6410 - val_recall: 0.1689\n",
      "Epoch 325/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6685 - binary_accuracy: 0.5785 - precision: 0.6410 - recall: 0.1689 - val_loss: 0.6689 - val_binary_accuracy: 0.5662 - val_precision: 0.5946 - val_recall: 0.1486\n",
      "Epoch 326/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6689 - binary_accuracy: 0.5662 - precision: 0.5946 - recall: 0.1486 - val_loss: 0.6717 - val_binary_accuracy: 0.5646 - val_precision: 0.5644 - val_recall: 0.1926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6717 - binary_accuracy: 0.5646 - precision: 0.5644 - recall: 0.1926 - val_loss: 0.6794 - val_binary_accuracy: 0.5523 - val_precision: 0.5126 - val_recall: 0.3446\n",
      "Epoch 328/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6794 - binary_accuracy: 0.5523 - precision: 0.5126 - recall: 0.3446 - val_loss: 0.6763 - val_binary_accuracy: 0.5585 - val_precision: 0.5584 - val_recall: 0.1453\n",
      "Epoch 329/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6763 - binary_accuracy: 0.5585 - precision: 0.5584 - recall: 0.1453 - val_loss: 0.6715 - val_binary_accuracy: 0.5785 - val_precision: 0.6250 - val_recall: 0.1858\n",
      "Epoch 330/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6715 - binary_accuracy: 0.5785 - precision: 0.6250 - recall: 0.1858 - val_loss: 0.6685 - val_binary_accuracy: 0.5708 - val_precision: 0.5714 - val_recall: 0.2297\n",
      "Epoch 331/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6685 - binary_accuracy: 0.5708 - precision: 0.5714 - recall: 0.2297 - val_loss: 0.6747 - val_binary_accuracy: 0.5631 - val_precision: 0.5275 - val_recall: 0.3885\n",
      "Epoch 332/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6747 - binary_accuracy: 0.5631 - precision: 0.5275 - recall: 0.3885 - val_loss: 0.6708 - val_binary_accuracy: 0.5708 - val_precision: 0.6308 - val_recall: 0.1385\n",
      "Epoch 333/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6708 - binary_accuracy: 0.5708 - precision: 0.6308 - recall: 0.1385 - val_loss: 0.6690 - val_binary_accuracy: 0.5846 - val_precision: 0.6757 - val_recall: 0.1689\n",
      "Epoch 334/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6690 - binary_accuracy: 0.5846 - precision: 0.6757 - recall: 0.1689 - val_loss: 0.6734 - val_binary_accuracy: 0.5723 - val_precision: 0.5776 - val_recall: 0.2264\n",
      "Epoch 335/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6734 - binary_accuracy: 0.5723 - precision: 0.5776 - recall: 0.2264 - val_loss: 0.6701 - val_binary_accuracy: 0.5738 - val_precision: 0.6792 - val_recall: 0.1216\n",
      "Epoch 336/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6701 - binary_accuracy: 0.5738 - precision: 0.6792 - recall: 0.1216 - val_loss: 0.6757 - val_binary_accuracy: 0.5538 - val_precision: 0.5294 - val_recall: 0.1824\n",
      "Epoch 337/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6757 - binary_accuracy: 0.5538 - precision: 0.5294 - recall: 0.1824 - val_loss: 0.6728 - val_binary_accuracy: 0.5692 - val_precision: 0.6081 - val_recall: 0.1520\n",
      "Epoch 338/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6728 - binary_accuracy: 0.5692 - precision: 0.6081 - recall: 0.1520 - val_loss: 0.6665 - val_binary_accuracy: 0.5723 - val_precision: 0.6500 - val_recall: 0.1318\n",
      "Epoch 339/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6665 - binary_accuracy: 0.5723 - precision: 0.6500 - recall: 0.1318 - val_loss: 0.6735 - val_binary_accuracy: 0.5754 - val_precision: 0.5893 - val_recall: 0.2230\n",
      "Epoch 340/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6735 - binary_accuracy: 0.5754 - precision: 0.5893 - recall: 0.2230 - val_loss: 0.6674 - val_binary_accuracy: 0.5846 - val_precision: 0.7031 - val_recall: 0.1520\n",
      "Epoch 341/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6674 - binary_accuracy: 0.5846 - precision: 0.7031 - recall: 0.1520 - val_loss: 0.6685 - val_binary_accuracy: 0.5831 - val_precision: 0.8049 - val_recall: 0.1115\n",
      "Epoch 342/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6685 - binary_accuracy: 0.5831 - precision: 0.8049 - recall: 0.1115 - val_loss: 0.6699 - val_binary_accuracy: 0.5692 - val_precision: 0.6600 - val_recall: 0.1115\n",
      "Epoch 343/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6699 - binary_accuracy: 0.5692 - precision: 0.6600 - recall: 0.1115 - val_loss: 0.6692 - val_binary_accuracy: 0.5846 - val_precision: 0.6857 - val_recall: 0.1622\n",
      "Epoch 344/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6692 - binary_accuracy: 0.5846 - precision: 0.6857 - recall: 0.1622 - val_loss: 0.6679 - val_binary_accuracy: 0.5692 - val_precision: 0.5909 - val_recall: 0.1757\n",
      "Epoch 345/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6679 - binary_accuracy: 0.5692 - precision: 0.5909 - recall: 0.1757 - val_loss: 0.6682 - val_binary_accuracy: 0.5769 - val_precision: 0.6235 - val_recall: 0.1791\n",
      "Epoch 346/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6682 - binary_accuracy: 0.5769 - precision: 0.6235 - recall: 0.1791 - val_loss: 0.6667 - val_binary_accuracy: 0.5754 - val_precision: 0.6724 - val_recall: 0.1318\n",
      "Epoch 347/900\n",
      "650/650 [==============================] - 0s 165us/sample - loss: 0.6667 - binary_accuracy: 0.5754 - precision: 0.6724 - recall: 0.1318 - val_loss: 0.6670 - val_binary_accuracy: 0.5923 - val_precision: 0.8444 - val_recall: 0.1284\n",
      "Epoch 348/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6670 - binary_accuracy: 0.5923 - precision: 0.8444 - recall: 0.1284 - val_loss: 0.6651 - val_binary_accuracy: 0.5846 - val_precision: 0.7500 - val_recall: 0.1318\n",
      "Epoch 349/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6651 - binary_accuracy: 0.5846 - precision: 0.7500 - recall: 0.1318 - val_loss: 0.6644 - val_binary_accuracy: 0.5646 - val_precision: 0.5747 - val_recall: 0.1689\n",
      "Epoch 350/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6644 - binary_accuracy: 0.5646 - precision: 0.5747 - recall: 0.1689 - val_loss: 0.6647 - val_binary_accuracy: 0.5646 - val_precision: 0.5565 - val_recall: 0.2162\n",
      "Epoch 351/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6647 - binary_accuracy: 0.5646 - precision: 0.5565 - recall: 0.2162 - val_loss: 0.6633 - val_binary_accuracy: 0.5738 - val_precision: 0.6067 - val_recall: 0.1824\n",
      "Epoch 352/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6633 - binary_accuracy: 0.5738 - precision: 0.6067 - recall: 0.1824 - val_loss: 0.6625 - val_binary_accuracy: 0.5754 - val_precision: 0.6667 - val_recall: 0.1351\n",
      "Epoch 353/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6625 - binary_accuracy: 0.5754 - precision: 0.6667 - recall: 0.1351 - val_loss: 0.6633 - val_binary_accuracy: 0.5877 - val_precision: 0.7917 - val_recall: 0.1284\n",
      "Epoch 354/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6633 - binary_accuracy: 0.5877 - precision: 0.7917 - recall: 0.1284 - val_loss: 0.6622 - val_binary_accuracy: 0.5831 - val_precision: 0.7451 - val_recall: 0.1284\n",
      "Epoch 355/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6622 - binary_accuracy: 0.5831 - precision: 0.7451 - recall: 0.1284 - val_loss: 0.6610 - val_binary_accuracy: 0.5677 - val_precision: 0.6027 - val_recall: 0.1486\n",
      "Epoch 356/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6610 - binary_accuracy: 0.5677 - precision: 0.6027 - recall: 0.1486 - val_loss: 0.6613 - val_binary_accuracy: 0.5708 - val_precision: 0.5825 - val_recall: 0.2027\n",
      "Epoch 357/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6613 - binary_accuracy: 0.5708 - precision: 0.5825 - recall: 0.2027 - val_loss: 0.6610 - val_binary_accuracy: 0.5677 - val_precision: 0.5701 - val_recall: 0.2061\n",
      "Epoch 358/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6610 - binary_accuracy: 0.5677 - precision: 0.5701 - recall: 0.2061 - val_loss: 0.6602 - val_binary_accuracy: 0.5769 - val_precision: 0.6400 - val_recall: 0.1622\n",
      "Epoch 359/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6602 - binary_accuracy: 0.5769 - precision: 0.6400 - recall: 0.1622 - val_loss: 0.6599 - val_binary_accuracy: 0.5800 - val_precision: 0.7018 - val_recall: 0.1351\n",
      "Epoch 360/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6599 - binary_accuracy: 0.5800 - precision: 0.7018 - recall: 0.1351 - val_loss: 0.6601 - val_binary_accuracy: 0.5738 - val_precision: 0.6610 - val_recall: 0.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.6601 - binary_accuracy: 0.5738 - precision: 0.6610 - recall: 0.1318 - val_loss: 0.6592 - val_binary_accuracy: 0.5754 - val_precision: 0.6515 - val_recall: 0.1453\n",
      "Epoch 362/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6592 - binary_accuracy: 0.5754 - precision: 0.6515 - recall: 0.1453 - val_loss: 0.6589 - val_binary_accuracy: 0.5723 - val_precision: 0.6098 - val_recall: 0.1689\n",
      "Epoch 363/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6589 - binary_accuracy: 0.5723 - precision: 0.6098 - recall: 0.1689 - val_loss: 0.6588 - val_binary_accuracy: 0.5723 - val_precision: 0.5918 - val_recall: 0.1959\n",
      "Epoch 364/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.6588 - binary_accuracy: 0.5723 - precision: 0.5918 - recall: 0.1959 - val_loss: 0.6584 - val_binary_accuracy: 0.5677 - val_precision: 0.5862 - val_recall: 0.1723\n",
      "Epoch 365/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6584 - binary_accuracy: 0.5677 - precision: 0.5862 - recall: 0.1723 - val_loss: 0.6578 - val_binary_accuracy: 0.5785 - val_precision: 0.6719 - val_recall: 0.1453\n",
      "Epoch 366/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6578 - binary_accuracy: 0.5785 - precision: 0.6719 - recall: 0.1453 - val_loss: 0.6578 - val_binary_accuracy: 0.5800 - val_precision: 0.6825 - val_recall: 0.1453\n",
      "Epoch 367/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6578 - binary_accuracy: 0.5800 - precision: 0.6825 - recall: 0.1453 - val_loss: 0.6573 - val_binary_accuracy: 0.5785 - val_precision: 0.6719 - val_recall: 0.1453\n",
      "Epoch 368/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6573 - binary_accuracy: 0.5785 - precision: 0.6719 - recall: 0.1453 - val_loss: 0.6569 - val_binary_accuracy: 0.5708 - val_precision: 0.6232 - val_recall: 0.1453\n",
      "Epoch 369/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6569 - binary_accuracy: 0.5708 - precision: 0.6232 - recall: 0.1453 - val_loss: 0.6567 - val_binary_accuracy: 0.5754 - val_precision: 0.6163 - val_recall: 0.1791\n",
      "Epoch 370/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6567 - binary_accuracy: 0.5754 - precision: 0.6163 - recall: 0.1791 - val_loss: 0.6562 - val_binary_accuracy: 0.5785 - val_precision: 0.6250 - val_recall: 0.1858\n",
      "Epoch 371/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6562 - binary_accuracy: 0.5785 - precision: 0.6250 - recall: 0.1858 - val_loss: 0.6557 - val_binary_accuracy: 0.5785 - val_precision: 0.6486 - val_recall: 0.1622\n",
      "Epoch 372/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6557 - binary_accuracy: 0.5785 - precision: 0.6486 - recall: 0.1622 - val_loss: 0.6554 - val_binary_accuracy: 0.5785 - val_precision: 0.6667 - val_recall: 0.1486\n",
      "Epoch 373/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6554 - binary_accuracy: 0.5785 - precision: 0.6667 - recall: 0.1486 - val_loss: 0.6551 - val_binary_accuracy: 0.5785 - val_precision: 0.6486 - val_recall: 0.1622\n",
      "Epoch 374/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6551 - binary_accuracy: 0.5785 - precision: 0.6486 - recall: 0.1622 - val_loss: 0.6546 - val_binary_accuracy: 0.5785 - val_precision: 0.6375 - val_recall: 0.1723\n",
      "Epoch 375/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6546 - binary_accuracy: 0.5785 - precision: 0.6375 - recall: 0.1723 - val_loss: 0.6543 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 376/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6543 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6540 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 377/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6540 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6537 - val_binary_accuracy: 0.5800 - val_precision: 0.6533 - val_recall: 0.1655\n",
      "Epoch 378/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6537 - binary_accuracy: 0.5800 - precision: 0.6533 - recall: 0.1655 - val_loss: 0.6533 - val_binary_accuracy: 0.5738 - val_precision: 0.6338 - val_recall: 0.1520\n",
      "Epoch 379/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6533 - binary_accuracy: 0.5738 - precision: 0.6338 - recall: 0.1520 - val_loss: 0.6530 - val_binary_accuracy: 0.5815 - val_precision: 0.6463 - val_recall: 0.1791\n",
      "Epoch 380/900\n",
      "650/650 [==============================] - 0s 149us/sample - loss: 0.6530 - binary_accuracy: 0.5815 - precision: 0.6463 - recall: 0.1791 - val_loss: 0.6528 - val_binary_accuracy: 0.5800 - val_precision: 0.6353 - val_recall: 0.1824\n",
      "Epoch 381/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6528 - binary_accuracy: 0.5800 - precision: 0.6353 - recall: 0.1824 - val_loss: 0.6525 - val_binary_accuracy: 0.5769 - val_precision: 0.6207 - val_recall: 0.1824\n",
      "Epoch 382/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6525 - binary_accuracy: 0.5769 - precision: 0.6207 - recall: 0.1824 - val_loss: 0.6522 - val_binary_accuracy: 0.5723 - val_precision: 0.6286 - val_recall: 0.1486\n",
      "Epoch 383/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6522 - binary_accuracy: 0.5723 - precision: 0.6286 - recall: 0.1486 - val_loss: 0.6519 - val_binary_accuracy: 0.5723 - val_precision: 0.6286 - val_recall: 0.1486\n",
      "Epoch 384/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6519 - binary_accuracy: 0.5723 - precision: 0.6286 - recall: 0.1486 - val_loss: 0.6515 - val_binary_accuracy: 0.5769 - val_precision: 0.6207 - val_recall: 0.1824\n",
      "Epoch 385/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6515 - binary_accuracy: 0.5769 - precision: 0.6207 - recall: 0.1824 - val_loss: 0.6513 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 386/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6513 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6511 - val_binary_accuracy: 0.5846 - val_precision: 0.6300 - val_recall: 0.2128\n",
      "Epoch 387/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6511 - binary_accuracy: 0.5846 - precision: 0.6300 - recall: 0.2128 - val_loss: 0.6511 - val_binary_accuracy: 0.5815 - val_precision: 0.6622 - val_recall: 0.1655\n",
      "Epoch 388/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6511 - binary_accuracy: 0.5815 - precision: 0.6622 - recall: 0.1655 - val_loss: 0.6529 - val_binary_accuracy: 0.5769 - val_precision: 0.5981 - val_recall: 0.2162\n",
      "Epoch 389/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6529 - binary_accuracy: 0.5769 - precision: 0.5981 - recall: 0.2162 - val_loss: 0.6619 - val_binary_accuracy: 0.5646 - val_precision: 0.5783 - val_recall: 0.1622\n",
      "Epoch 390/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6619 - binary_accuracy: 0.5646 - precision: 0.5783 - recall: 0.1622 - val_loss: 0.6787 - val_binary_accuracy: 0.5462 - val_precision: 0.5021 - val_recall: 0.4122\n",
      "Epoch 391/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6787 - binary_accuracy: 0.5462 - precision: 0.5021 - recall: 0.4122 - val_loss: 0.6927 - val_binary_accuracy: 0.5415 - val_precision: 0.4762 - val_recall: 0.0676\n",
      "Epoch 392/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6927 - binary_accuracy: 0.5415 - precision: 0.4762 - recall: 0.0676 - val_loss: 0.6963 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 393/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6963 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6831 - val_binary_accuracy: 0.5800 - val_precision: 0.7949 - val_recall: 0.1047\n",
      "Epoch 394/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6831 - binary_accuracy: 0.5800 - precision: 0.7949 - recall: 0.1047 - val_loss: 0.6784 - val_binary_accuracy: 0.5569 - val_precision: 0.5217 - val_recall: 0.3243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6784 - binary_accuracy: 0.5569 - precision: 0.5217 - recall: 0.3243 - val_loss: 0.6788 - val_binary_accuracy: 0.5738 - val_precision: 0.5503 - val_recall: 0.3514\n",
      "Epoch 396/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6788 - binary_accuracy: 0.5738 - precision: 0.5503 - recall: 0.3514 - val_loss: 0.6749 - val_binary_accuracy: 0.5877 - val_precision: 0.7333 - val_recall: 0.1486\n",
      "Epoch 397/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6749 - binary_accuracy: 0.5877 - precision: 0.7333 - recall: 0.1486 - val_loss: 0.6740 - val_binary_accuracy: 0.5785 - val_precision: 0.6833 - val_recall: 0.1385\n",
      "Epoch 398/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6740 - binary_accuracy: 0.5785 - precision: 0.6833 - recall: 0.1385 - val_loss: 0.6740 - val_binary_accuracy: 0.5754 - val_precision: 0.6562 - val_recall: 0.1419\n",
      "Epoch 399/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6740 - binary_accuracy: 0.5754 - precision: 0.6562 - recall: 0.1419 - val_loss: 0.6725 - val_binary_accuracy: 0.5785 - val_precision: 0.6833 - val_recall: 0.1385\n",
      "Epoch 400/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6725 - binary_accuracy: 0.5785 - precision: 0.6833 - recall: 0.1385 - val_loss: 0.6701 - val_binary_accuracy: 0.5831 - val_precision: 0.7119 - val_recall: 0.1419\n",
      "Epoch 401/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6701 - binary_accuracy: 0.5831 - precision: 0.7119 - recall: 0.1419 - val_loss: 0.6686 - val_binary_accuracy: 0.5831 - val_precision: 0.6667 - val_recall: 0.1689\n",
      "Epoch 402/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6686 - binary_accuracy: 0.5831 - precision: 0.6667 - recall: 0.1689 - val_loss: 0.6680 - val_binary_accuracy: 0.5708 - val_precision: 0.5876 - val_recall: 0.1926\n",
      "Epoch 403/900\n",
      "650/650 [==============================] - 0s 165us/sample - loss: 0.6680 - binary_accuracy: 0.5708 - precision: 0.5876 - recall: 0.1926 - val_loss: 0.6683 - val_binary_accuracy: 0.5785 - val_precision: 0.6078 - val_recall: 0.2095\n",
      "Epoch 404/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.6683 - binary_accuracy: 0.5785 - precision: 0.6078 - recall: 0.2095 - val_loss: 0.6670 - val_binary_accuracy: 0.5615 - val_precision: 0.5679 - val_recall: 0.1554\n",
      "Epoch 405/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6670 - binary_accuracy: 0.5615 - precision: 0.5679 - recall: 0.1554 - val_loss: 0.6653 - val_binary_accuracy: 0.5815 - val_precision: 0.6818 - val_recall: 0.1520\n",
      "Epoch 406/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6653 - binary_accuracy: 0.5815 - precision: 0.6818 - recall: 0.1520 - val_loss: 0.6679 - val_binary_accuracy: 0.5831 - val_precision: 0.6623 - val_recall: 0.1723\n",
      "Epoch 407/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6679 - binary_accuracy: 0.5831 - precision: 0.6623 - recall: 0.1723 - val_loss: 0.6659 - val_binary_accuracy: 0.5785 - val_precision: 0.6571 - val_recall: 0.1554\n",
      "Epoch 408/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6659 - binary_accuracy: 0.5785 - precision: 0.6571 - recall: 0.1554 - val_loss: 0.6667 - val_binary_accuracy: 0.5615 - val_precision: 0.5632 - val_recall: 0.1655\n",
      "Epoch 409/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6667 - binary_accuracy: 0.5615 - precision: 0.5632 - recall: 0.1655 - val_loss: 0.6649 - val_binary_accuracy: 0.5662 - val_precision: 0.5686 - val_recall: 0.1959\n",
      "Epoch 410/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6649 - binary_accuracy: 0.5662 - precision: 0.5686 - recall: 0.1959 - val_loss: 0.6649 - val_binary_accuracy: 0.5677 - val_precision: 0.5610 - val_recall: 0.2331\n",
      "Epoch 411/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6649 - binary_accuracy: 0.5677 - precision: 0.5610 - recall: 0.2331 - val_loss: 0.6651 - val_binary_accuracy: 0.5954 - val_precision: 0.5873 - val_recall: 0.3750\n",
      "Epoch 412/900\n",
      "650/650 [==============================] - 0s 149us/sample - loss: 0.6651 - binary_accuracy: 0.5954 - precision: 0.5873 - recall: 0.3750 - val_loss: 0.6627 - val_binary_accuracy: 0.5754 - val_precision: 0.5909 - val_recall: 0.2196\n",
      "Epoch 413/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6627 - binary_accuracy: 0.5754 - precision: 0.5909 - recall: 0.2196 - val_loss: 0.6627 - val_binary_accuracy: 0.5769 - val_precision: 0.6105 - val_recall: 0.1959\n",
      "Epoch 414/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6627 - binary_accuracy: 0.5769 - precision: 0.6105 - recall: 0.1959 - val_loss: 0.6629 - val_binary_accuracy: 0.5585 - val_precision: 0.5366 - val_recall: 0.2230\n",
      "Epoch 415/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6629 - binary_accuracy: 0.5585 - precision: 0.5366 - recall: 0.2230 - val_loss: 0.6616 - val_binary_accuracy: 0.5738 - val_precision: 0.6044 - val_recall: 0.1858\n",
      "Epoch 416/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6616 - binary_accuracy: 0.5738 - precision: 0.6044 - recall: 0.1858 - val_loss: 0.6631 - val_binary_accuracy: 0.5815 - val_precision: 0.6395 - val_recall: 0.1858\n",
      "Epoch 417/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6631 - binary_accuracy: 0.5815 - precision: 0.6395 - recall: 0.1858 - val_loss: 0.6617 - val_binary_accuracy: 0.5862 - val_precision: 0.5860 - val_recall: 0.3108\n",
      "Epoch 418/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6617 - binary_accuracy: 0.5862 - precision: 0.5860 - recall: 0.3108 - val_loss: 0.6601 - val_binary_accuracy: 0.5738 - val_precision: 0.5922 - val_recall: 0.2061\n",
      "Epoch 419/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6601 - binary_accuracy: 0.5738 - precision: 0.5922 - recall: 0.2061 - val_loss: 0.6608 - val_binary_accuracy: 0.5785 - val_precision: 0.6100 - val_recall: 0.2061\n",
      "Epoch 420/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.6608 - binary_accuracy: 0.5785 - precision: 0.6100 - recall: 0.2061 - val_loss: 0.6605 - val_binary_accuracy: 0.5892 - val_precision: 0.5819 - val_recall: 0.3480\n",
      "Epoch 421/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6605 - binary_accuracy: 0.5892 - precision: 0.5819 - recall: 0.3480 - val_loss: 0.6582 - val_binary_accuracy: 0.5662 - val_precision: 0.5714 - val_recall: 0.1892\n",
      "Epoch 422/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6582 - binary_accuracy: 0.5662 - precision: 0.5714 - recall: 0.1892 - val_loss: 0.6580 - val_binary_accuracy: 0.5754 - val_precision: 0.6163 - val_recall: 0.1791\n",
      "Epoch 423/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6580 - binary_accuracy: 0.5754 - precision: 0.6163 - recall: 0.1791 - val_loss: 0.6581 - val_binary_accuracy: 0.5646 - val_precision: 0.5489 - val_recall: 0.2466\n",
      "Epoch 424/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6581 - binary_accuracy: 0.5646 - precision: 0.5489 - recall: 0.2466 - val_loss: 0.6569 - val_binary_accuracy: 0.5662 - val_precision: 0.5875 - val_recall: 0.1588\n",
      "Epoch 425/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6569 - binary_accuracy: 0.5662 - precision: 0.5875 - recall: 0.1588 - val_loss: 0.6560 - val_binary_accuracy: 0.5723 - val_precision: 0.6098 - val_recall: 0.1689\n",
      "Epoch 426/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6560 - binary_accuracy: 0.5723 - precision: 0.6098 - recall: 0.1689 - val_loss: 0.6558 - val_binary_accuracy: 0.5754 - val_precision: 0.5746 - val_recall: 0.2601\n",
      "Epoch 427/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6558 - binary_accuracy: 0.5754 - precision: 0.5746 - recall: 0.2601 - val_loss: 0.6563 - val_binary_accuracy: 0.5692 - val_precision: 0.5889 - val_recall: 0.1791\n",
      "Epoch 428/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6563 - binary_accuracy: 0.5692 - precision: 0.5889 - recall: 0.1791 - val_loss: 0.6549 - val_binary_accuracy: 0.5862 - val_precision: 0.5860 - val_recall: 0.3108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6549 - binary_accuracy: 0.5862 - precision: 0.5860 - recall: 0.3108 - val_loss: 0.6545 - val_binary_accuracy: 0.5708 - val_precision: 0.5934 - val_recall: 0.1824\n",
      "Epoch 430/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6545 - binary_accuracy: 0.5708 - precision: 0.5934 - recall: 0.1824 - val_loss: 0.6536 - val_binary_accuracy: 0.5800 - val_precision: 0.5935 - val_recall: 0.2466\n",
      "Epoch 431/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6536 - binary_accuracy: 0.5800 - precision: 0.5935 - recall: 0.2466 - val_loss: 0.6532 - val_binary_accuracy: 0.5800 - val_precision: 0.5891 - val_recall: 0.2568\n",
      "Epoch 432/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6532 - binary_accuracy: 0.5800 - precision: 0.5891 - recall: 0.2568 - val_loss: 0.6532 - val_binary_accuracy: 0.5708 - val_precision: 0.5914 - val_recall: 0.1858\n",
      "Epoch 433/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6532 - binary_accuracy: 0.5708 - precision: 0.5914 - recall: 0.1858 - val_loss: 0.6531 - val_binary_accuracy: 0.5985 - val_precision: 0.6115 - val_recall: 0.3243\n",
      "Epoch 434/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6531 - binary_accuracy: 0.5985 - precision: 0.6115 - recall: 0.3243 - val_loss: 0.6533 - val_binary_accuracy: 0.5754 - val_precision: 0.6190 - val_recall: 0.1757\n",
      "Epoch 435/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6533 - binary_accuracy: 0.5754 - precision: 0.6190 - recall: 0.1757 - val_loss: 0.6527 - val_binary_accuracy: 0.6046 - val_precision: 0.6383 - val_recall: 0.3041\n",
      "Epoch 436/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6527 - binary_accuracy: 0.6046 - precision: 0.6383 - recall: 0.3041 - val_loss: 0.6518 - val_binary_accuracy: 0.5800 - val_precision: 0.6667 - val_recall: 0.1554\n",
      "Epoch 437/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6518 - binary_accuracy: 0.5800 - precision: 0.6667 - recall: 0.1554 - val_loss: 0.6510 - val_binary_accuracy: 0.5785 - val_precision: 0.6310 - val_recall: 0.1791\n",
      "Epoch 438/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6510 - binary_accuracy: 0.5785 - precision: 0.6310 - recall: 0.1791 - val_loss: 0.6514 - val_binary_accuracy: 0.5985 - val_precision: 0.6207 - val_recall: 0.3041\n",
      "Epoch 439/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6514 - binary_accuracy: 0.5985 - precision: 0.6207 - recall: 0.3041 - val_loss: 0.6520 - val_binary_accuracy: 0.5738 - val_precision: 0.6173 - val_recall: 0.1689\n",
      "Epoch 440/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6520 - binary_accuracy: 0.5738 - precision: 0.6173 - recall: 0.1689 - val_loss: 0.6516 - val_binary_accuracy: 0.6062 - val_precision: 0.6333 - val_recall: 0.3209\n",
      "Epoch 441/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6516 - binary_accuracy: 0.6062 - precision: 0.6333 - recall: 0.3209 - val_loss: 0.6510 - val_binary_accuracy: 0.5815 - val_precision: 0.6714 - val_recall: 0.1588\n",
      "Epoch 442/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6510 - binary_accuracy: 0.5815 - precision: 0.6714 - recall: 0.1588 - val_loss: 0.6501 - val_binary_accuracy: 0.5846 - val_precision: 0.6548 - val_recall: 0.1858\n",
      "Epoch 443/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6501 - binary_accuracy: 0.5846 - precision: 0.6548 - recall: 0.1858 - val_loss: 0.6508 - val_binary_accuracy: 0.6062 - val_precision: 0.6266 - val_recall: 0.3345\n",
      "Epoch 444/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6508 - binary_accuracy: 0.6062 - precision: 0.6266 - recall: 0.3345 - val_loss: 0.6536 - val_binary_accuracy: 0.5754 - val_precision: 0.6282 - val_recall: 0.1655\n",
      "Epoch 445/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6536 - binary_accuracy: 0.5754 - precision: 0.6282 - recall: 0.1655 - val_loss: 0.6563 - val_binary_accuracy: 0.5723 - val_precision: 0.5385 - val_recall: 0.4257\n",
      "Epoch 446/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6563 - binary_accuracy: 0.5723 - precision: 0.5385 - recall: 0.4257 - val_loss: 0.6547 - val_binary_accuracy: 0.5862 - val_precision: 0.7547 - val_recall: 0.1351\n",
      "Epoch 447/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6547 - binary_accuracy: 0.5862 - precision: 0.7547 - recall: 0.1351 - val_loss: 0.6507 - val_binary_accuracy: 0.5846 - val_precision: 0.7407 - val_recall: 0.1351\n",
      "Epoch 448/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6507 - binary_accuracy: 0.5846 - precision: 0.7407 - recall: 0.1351 - val_loss: 0.6570 - val_binary_accuracy: 0.5708 - val_precision: 0.5365 - val_recall: 0.4223\n",
      "Epoch 449/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6570 - binary_accuracy: 0.5708 - precision: 0.5365 - recall: 0.4223 - val_loss: 0.6507 - val_binary_accuracy: 0.5800 - val_precision: 0.6667 - val_recall: 0.1554\n",
      "Epoch 450/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6507 - binary_accuracy: 0.5800 - precision: 0.6667 - recall: 0.1554 - val_loss: 0.6512 - val_binary_accuracy: 0.5800 - val_precision: 0.6620 - val_recall: 0.1588\n",
      "Epoch 451/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6512 - binary_accuracy: 0.5800 - precision: 0.6620 - recall: 0.1588 - val_loss: 0.6530 - val_binary_accuracy: 0.6000 - val_precision: 0.6023 - val_recall: 0.3581\n",
      "Epoch 452/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6530 - binary_accuracy: 0.6000 - precision: 0.6023 - recall: 0.3581 - val_loss: 0.6489 - val_binary_accuracy: 0.5831 - val_precision: 0.6506 - val_recall: 0.1824\n",
      "Epoch 453/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6489 - binary_accuracy: 0.5831 - precision: 0.6506 - recall: 0.1824 - val_loss: 0.6526 - val_binary_accuracy: 0.5892 - val_precision: 0.7544 - val_recall: 0.1453\n",
      "Epoch 454/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6526 - binary_accuracy: 0.5892 - precision: 0.7544 - recall: 0.1453 - val_loss: 0.6481 - val_binary_accuracy: 0.5800 - val_precision: 0.6575 - val_recall: 0.1622\n",
      "Epoch 455/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6481 - binary_accuracy: 0.5800 - precision: 0.6575 - recall: 0.1622 - val_loss: 0.6514 - val_binary_accuracy: 0.6000 - val_precision: 0.6071 - val_recall: 0.3446\n",
      "Epoch 456/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6514 - binary_accuracy: 0.6000 - precision: 0.6071 - recall: 0.3446 - val_loss: 0.6481 - val_binary_accuracy: 0.5754 - val_precision: 0.6316 - val_recall: 0.1622\n",
      "Epoch 457/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6481 - binary_accuracy: 0.5754 - precision: 0.6316 - recall: 0.1622 - val_loss: 0.6489 - val_binary_accuracy: 0.5862 - val_precision: 0.6800 - val_recall: 0.1723\n",
      "Epoch 458/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6489 - binary_accuracy: 0.5862 - precision: 0.6800 - recall: 0.1723 - val_loss: 0.6495 - val_binary_accuracy: 0.5969 - val_precision: 0.5977 - val_recall: 0.3514\n",
      "Epoch 459/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6495 - binary_accuracy: 0.5969 - precision: 0.5977 - recall: 0.3514 - val_loss: 0.6464 - val_binary_accuracy: 0.5877 - val_precision: 0.6667 - val_recall: 0.1892\n",
      "Epoch 460/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6464 - binary_accuracy: 0.5877 - precision: 0.6667 - recall: 0.1892 - val_loss: 0.6482 - val_binary_accuracy: 0.5908 - val_precision: 0.7344 - val_recall: 0.1588\n",
      "Epoch 461/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6482 - binary_accuracy: 0.5908 - precision: 0.7344 - recall: 0.1588 - val_loss: 0.6470 - val_binary_accuracy: 0.6062 - val_precision: 0.6266 - val_recall: 0.3345\n",
      "Epoch 462/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6470 - binary_accuracy: 0.6062 - precision: 0.6266 - recall: 0.3345 - val_loss: 0.6450 - val_binary_accuracy: 0.5954 - val_precision: 0.6514 - val_recall: 0.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6450 - binary_accuracy: 0.5954 - precision: 0.6514 - recall: 0.2399 - val_loss: 0.6462 - val_binary_accuracy: 0.5862 - val_precision: 0.6667 - val_recall: 0.1824\n",
      "Epoch 464/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6462 - binary_accuracy: 0.5862 - precision: 0.6667 - recall: 0.1824 - val_loss: 0.6479 - val_binary_accuracy: 0.5908 - val_precision: 0.5758 - val_recall: 0.3851\n",
      "Epoch 465/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6479 - binary_accuracy: 0.5908 - precision: 0.5758 - recall: 0.3851 - val_loss: 0.6493 - val_binary_accuracy: 0.5908 - val_precision: 0.7500 - val_recall: 0.1520\n",
      "Epoch 466/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6493 - binary_accuracy: 0.5908 - precision: 0.7500 - recall: 0.1520 - val_loss: 0.6441 - val_binary_accuracy: 0.5985 - val_precision: 0.6259 - val_recall: 0.2939\n",
      "Epoch 467/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6441 - binary_accuracy: 0.5985 - precision: 0.6259 - recall: 0.2939 - val_loss: 0.6433 - val_binary_accuracy: 0.6031 - val_precision: 0.6418 - val_recall: 0.2905\n",
      "Epoch 468/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6433 - binary_accuracy: 0.6031 - precision: 0.6418 - recall: 0.2905 - val_loss: 0.6464 - val_binary_accuracy: 0.5923 - val_precision: 0.7246 - val_recall: 0.1689\n",
      "Epoch 469/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.6464 - binary_accuracy: 0.5923 - precision: 0.7246 - recall: 0.1689 - val_loss: 0.6455 - val_binary_accuracy: 0.5985 - val_precision: 0.5862 - val_recall: 0.4020\n",
      "Epoch 470/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6455 - binary_accuracy: 0.5985 - precision: 0.5862 - recall: 0.4020 - val_loss: 0.6450 - val_binary_accuracy: 0.5908 - val_precision: 0.7273 - val_recall: 0.1622\n",
      "Epoch 471/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6450 - binary_accuracy: 0.5908 - precision: 0.7273 - recall: 0.1622 - val_loss: 0.6413 - val_binary_accuracy: 0.6077 - val_precision: 0.6589 - val_recall: 0.2872\n",
      "Epoch 472/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6413 - binary_accuracy: 0.6077 - precision: 0.6589 - recall: 0.2872 - val_loss: 0.6404 - val_binary_accuracy: 0.6031 - val_precision: 0.6557 - val_recall: 0.2703\n",
      "Epoch 473/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6404 - binary_accuracy: 0.6031 - precision: 0.6557 - recall: 0.2703 - val_loss: 0.6422 - val_binary_accuracy: 0.5954 - val_precision: 0.7324 - val_recall: 0.1757\n",
      "Epoch 474/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6422 - binary_accuracy: 0.5954 - precision: 0.7324 - recall: 0.1757 - val_loss: 0.6505 - val_binary_accuracy: 0.5877 - val_precision: 0.5515 - val_recall: 0.5068\n",
      "Epoch 475/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6505 - binary_accuracy: 0.5877 - precision: 0.5515 - recall: 0.5068 - val_loss: 0.6707 - val_binary_accuracy: 0.5738 - val_precision: 0.6203 - val_recall: 0.1655\n",
      "Epoch 476/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6707 - binary_accuracy: 0.5738 - precision: 0.6203 - recall: 0.1655 - val_loss: 0.6576 - val_binary_accuracy: 0.5892 - val_precision: 0.8718 - val_recall: 0.1149\n",
      "Epoch 477/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6576 - binary_accuracy: 0.5892 - precision: 0.8718 - recall: 0.1149 - val_loss: 0.6564 - val_binary_accuracy: 0.5954 - val_precision: 0.9459 - val_recall: 0.1182\n",
      "Epoch 478/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6564 - binary_accuracy: 0.5954 - precision: 0.9459 - recall: 0.1182 - val_loss: 0.6623 - val_binary_accuracy: 0.5677 - val_precision: 0.5330 - val_recall: 0.4088\n",
      "Epoch 479/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6623 - binary_accuracy: 0.5677 - precision: 0.5330 - recall: 0.4088 - val_loss: 0.6628 - val_binary_accuracy: 0.5677 - val_precision: 0.5342 - val_recall: 0.3953\n",
      "Epoch 480/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6628 - binary_accuracy: 0.5677 - precision: 0.5342 - recall: 0.3953 - val_loss: 0.6581 - val_binary_accuracy: 0.5831 - val_precision: 0.7907 - val_recall: 0.1149\n",
      "Epoch 481/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6581 - binary_accuracy: 0.5831 - precision: 0.7907 - recall: 0.1149 - val_loss: 0.6558 - val_binary_accuracy: 0.5892 - val_precision: 0.9143 - val_recall: 0.1081\n",
      "Epoch 482/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6558 - binary_accuracy: 0.5892 - precision: 0.9143 - recall: 0.1081 - val_loss: 0.6506 - val_binary_accuracy: 0.5908 - val_precision: 0.8750 - val_recall: 0.1182\n",
      "Epoch 483/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6506 - binary_accuracy: 0.5908 - precision: 0.8750 - recall: 0.1182 - val_loss: 0.6472 - val_binary_accuracy: 0.5938 - val_precision: 0.8077 - val_recall: 0.1419\n",
      "Epoch 484/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6472 - binary_accuracy: 0.5938 - precision: 0.8077 - recall: 0.1419 - val_loss: 0.6642 - val_binary_accuracy: 0.5785 - val_precision: 0.5948 - val_recall: 0.2331\n",
      "Epoch 485/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6642 - binary_accuracy: 0.5785 - precision: 0.5948 - recall: 0.2331 - val_loss: 0.6742 - val_binary_accuracy: 0.5569 - val_precision: 0.5123 - val_recall: 0.5642\n",
      "Epoch 486/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6742 - binary_accuracy: 0.5569 - precision: 0.5123 - recall: 0.5642 - val_loss: 0.6479 - val_binary_accuracy: 0.6062 - val_precision: 0.6471 - val_recall: 0.2973\n",
      "Epoch 487/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6479 - binary_accuracy: 0.6062 - precision: 0.6471 - recall: 0.2973 - val_loss: 0.6554 - val_binary_accuracy: 0.5892 - val_precision: 0.7959 - val_recall: 0.1318\n",
      "Epoch 488/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6554 - binary_accuracy: 0.5892 - precision: 0.7959 - recall: 0.1318 - val_loss: 0.6572 - val_binary_accuracy: 0.5815 - val_precision: 0.7609 - val_recall: 0.1182\n",
      "Epoch 489/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6572 - binary_accuracy: 0.5815 - precision: 0.7609 - recall: 0.1182 - val_loss: 0.6515 - val_binary_accuracy: 0.5923 - val_precision: 0.8444 - val_recall: 0.1284\n",
      "Epoch 490/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6515 - binary_accuracy: 0.5923 - precision: 0.8444 - recall: 0.1284 - val_loss: 0.6503 - val_binary_accuracy: 0.6000 - val_precision: 0.7432 - val_recall: 0.1858\n",
      "Epoch 491/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6503 - binary_accuracy: 0.6000 - precision: 0.7432 - recall: 0.1858 - val_loss: 0.6506 - val_binary_accuracy: 0.6015 - val_precision: 0.6135 - val_recall: 0.3378\n",
      "Epoch 492/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6506 - binary_accuracy: 0.6015 - precision: 0.6135 - recall: 0.3378 - val_loss: 0.6518 - val_binary_accuracy: 0.5908 - val_precision: 0.5758 - val_recall: 0.3851\n",
      "Epoch 493/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6518 - binary_accuracy: 0.5908 - precision: 0.5758 - recall: 0.3851 - val_loss: 0.6508 - val_binary_accuracy: 0.6031 - val_precision: 0.5913 - val_recall: 0.4155\n",
      "Epoch 494/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6508 - binary_accuracy: 0.6031 - precision: 0.5913 - recall: 0.4155 - val_loss: 0.6479 - val_binary_accuracy: 0.5908 - val_precision: 0.5652 - val_recall: 0.4392\n",
      "Epoch 495/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6479 - binary_accuracy: 0.5908 - precision: 0.5652 - recall: 0.4392 - val_loss: 0.6449 - val_binary_accuracy: 0.6169 - val_precision: 0.6391 - val_recall: 0.3649\n",
      "Epoch 496/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6449 - binary_accuracy: 0.6169 - precision: 0.6391 - recall: 0.3649 - val_loss: 0.6437 - val_binary_accuracy: 0.5862 - val_precision: 0.6627 - val_recall: 0.1858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6437 - binary_accuracy: 0.5862 - precision: 0.6627 - recall: 0.1858 - val_loss: 0.6440 - val_binary_accuracy: 0.5985 - val_precision: 0.7869 - val_recall: 0.1622\n",
      "Epoch 498/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6440 - binary_accuracy: 0.5985 - precision: 0.7869 - recall: 0.1622 - val_loss: 0.6440 - val_binary_accuracy: 0.6031 - val_precision: 0.7375 - val_recall: 0.1993\n",
      "Epoch 499/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6440 - binary_accuracy: 0.6031 - precision: 0.7375 - recall: 0.1993 - val_loss: 0.6432 - val_binary_accuracy: 0.6123 - val_precision: 0.7157 - val_recall: 0.2466\n",
      "Epoch 500/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6432 - binary_accuracy: 0.6123 - precision: 0.7157 - recall: 0.2466 - val_loss: 0.6412 - val_binary_accuracy: 0.6077 - val_precision: 0.7253 - val_recall: 0.2230\n",
      "Epoch 501/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6412 - binary_accuracy: 0.6077 - precision: 0.7253 - recall: 0.2230 - val_loss: 0.6404 - val_binary_accuracy: 0.6077 - val_precision: 0.6990 - val_recall: 0.2432\n",
      "Epoch 502/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6404 - binary_accuracy: 0.6077 - precision: 0.6990 - recall: 0.2432 - val_loss: 0.6394 - val_binary_accuracy: 0.6262 - val_precision: 0.6587 - val_recall: 0.3716\n",
      "Epoch 503/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6394 - binary_accuracy: 0.6262 - precision: 0.6587 - recall: 0.3716 - val_loss: 0.6372 - val_binary_accuracy: 0.6046 - val_precision: 0.6585 - val_recall: 0.2736\n",
      "Epoch 504/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6372 - binary_accuracy: 0.6046 - precision: 0.6585 - recall: 0.2736 - val_loss: 0.6357 - val_binary_accuracy: 0.6108 - val_precision: 0.6807 - val_recall: 0.2736\n",
      "Epoch 505/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6357 - binary_accuracy: 0.6108 - precision: 0.6807 - recall: 0.2736 - val_loss: 0.6352 - val_binary_accuracy: 0.6092 - val_precision: 0.6479 - val_recall: 0.3108\n",
      "Epoch 506/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6352 - binary_accuracy: 0.6092 - precision: 0.6479 - recall: 0.3108 - val_loss: 0.6346 - val_binary_accuracy: 0.6092 - val_precision: 0.6641 - val_recall: 0.2872\n",
      "Epoch 507/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6346 - binary_accuracy: 0.6092 - precision: 0.6641 - recall: 0.2872 - val_loss: 0.6337 - val_binary_accuracy: 0.6138 - val_precision: 0.6667 - val_recall: 0.3041\n",
      "Epoch 508/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6337 - binary_accuracy: 0.6138 - precision: 0.6667 - recall: 0.3041 - val_loss: 0.6328 - val_binary_accuracy: 0.6092 - val_precision: 0.6346 - val_recall: 0.3345\n",
      "Epoch 509/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6328 - binary_accuracy: 0.6092 - precision: 0.6346 - recall: 0.3345 - val_loss: 0.6330 - val_binary_accuracy: 0.6169 - val_precision: 0.6850 - val_recall: 0.2939\n",
      "Epoch 510/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6330 - binary_accuracy: 0.6169 - precision: 0.6850 - recall: 0.2939 - val_loss: 0.6312 - val_binary_accuracy: 0.6138 - val_precision: 0.6301 - val_recall: 0.3682\n",
      "Epoch 511/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6312 - binary_accuracy: 0.6138 - precision: 0.6301 - recall: 0.3682 - val_loss: 0.6354 - val_binary_accuracy: 0.6031 - val_precision: 0.6979 - val_recall: 0.2264\n",
      "Epoch 512/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6354 - binary_accuracy: 0.6031 - precision: 0.6979 - recall: 0.2264 - val_loss: 0.6527 - val_binary_accuracy: 0.5754 - val_precision: 0.5355 - val_recall: 0.5101\n",
      "Epoch 513/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6527 - binary_accuracy: 0.5754 - precision: 0.5355 - recall: 0.5101 - val_loss: 0.6929 - val_binary_accuracy: 0.5692 - val_precision: 0.5816 - val_recall: 0.1926\n",
      "Epoch 514/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6929 - binary_accuracy: 0.5692 - precision: 0.5816 - recall: 0.1926 - val_loss: 0.6658 - val_binary_accuracy: 0.5800 - val_precision: 0.6949 - val_recall: 0.1385\n",
      "Epoch 515/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6658 - binary_accuracy: 0.5800 - precision: 0.6949 - recall: 0.1385 - val_loss: 0.6633 - val_binary_accuracy: 0.5892 - val_precision: 0.9394 - val_recall: 0.1047\n",
      "Epoch 516/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6633 - binary_accuracy: 0.5892 - precision: 0.9394 - recall: 0.1047 - val_loss: 0.6661 - val_binary_accuracy: 0.5862 - val_precision: 0.9091 - val_recall: 0.1014\n",
      "Epoch 517/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6661 - binary_accuracy: 0.5862 - precision: 0.9091 - recall: 0.1014 - val_loss: 0.6623 - val_binary_accuracy: 0.5862 - val_precision: 0.9355 - val_recall: 0.0980\n",
      "Epoch 518/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6623 - binary_accuracy: 0.5862 - precision: 0.9355 - recall: 0.0980 - val_loss: 0.6591 - val_binary_accuracy: 0.5954 - val_precision: 0.9459 - val_recall: 0.1182\n",
      "Epoch 519/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6591 - binary_accuracy: 0.5954 - precision: 0.9459 - recall: 0.1182 - val_loss: 0.6549 - val_binary_accuracy: 0.5985 - val_precision: 0.7108 - val_recall: 0.1993\n",
      "Epoch 520/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6549 - binary_accuracy: 0.5985 - precision: 0.7108 - recall: 0.1993 - val_loss: 0.6506 - val_binary_accuracy: 0.5954 - val_precision: 0.5912 - val_recall: 0.3615\n",
      "Epoch 521/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6506 - binary_accuracy: 0.5954 - precision: 0.5912 - recall: 0.3615 - val_loss: 0.6546 - val_binary_accuracy: 0.6092 - val_precision: 0.6082 - val_recall: 0.3986\n",
      "Epoch 522/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6546 - binary_accuracy: 0.6092 - precision: 0.6082 - recall: 0.3986 - val_loss: 0.6462 - val_binary_accuracy: 0.5954 - val_precision: 0.5721 - val_recall: 0.4426\n",
      "Epoch 523/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6462 - binary_accuracy: 0.5954 - precision: 0.5721 - recall: 0.4426 - val_loss: 0.6439 - val_binary_accuracy: 0.5938 - val_precision: 0.5714 - val_recall: 0.4324\n",
      "Epoch 524/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6439 - binary_accuracy: 0.5938 - precision: 0.5714 - recall: 0.4324 - val_loss: 0.6384 - val_binary_accuracy: 0.6154 - val_precision: 0.7396 - val_recall: 0.2399\n",
      "Epoch 525/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6384 - binary_accuracy: 0.6154 - precision: 0.7396 - recall: 0.2399 - val_loss: 0.6426 - val_binary_accuracy: 0.6046 - val_precision: 0.8545 - val_recall: 0.1588\n",
      "Epoch 526/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6426 - binary_accuracy: 0.6046 - precision: 0.8545 - recall: 0.1588 - val_loss: 0.6429 - val_binary_accuracy: 0.6031 - val_precision: 0.8519 - val_recall: 0.1554\n",
      "Epoch 527/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6429 - binary_accuracy: 0.6031 - precision: 0.8519 - recall: 0.1554 - val_loss: 0.6375 - val_binary_accuracy: 0.6108 - val_precision: 0.7945 - val_recall: 0.1959\n",
      "Epoch 528/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6375 - binary_accuracy: 0.6108 - precision: 0.7945 - recall: 0.1959 - val_loss: 0.6369 - val_binary_accuracy: 0.6169 - val_precision: 0.6621 - val_recall: 0.3243\n",
      "Epoch 529/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6369 - binary_accuracy: 0.6169 - precision: 0.6621 - recall: 0.3243 - val_loss: 0.6332 - val_binary_accuracy: 0.6200 - val_precision: 0.6788 - val_recall: 0.3142\n",
      "Epoch 530/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6332 - binary_accuracy: 0.6200 - precision: 0.6788 - recall: 0.3142 - val_loss: 0.6352 - val_binary_accuracy: 0.6185 - val_precision: 0.6935 - val_recall: 0.2905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6352 - binary_accuracy: 0.6185 - precision: 0.6935 - recall: 0.2905 - val_loss: 0.6337 - val_binary_accuracy: 0.6215 - val_precision: 0.6603 - val_recall: 0.3480\n",
      "Epoch 532/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6337 - binary_accuracy: 0.6215 - precision: 0.6603 - recall: 0.3480 - val_loss: 0.6344 - val_binary_accuracy: 0.6231 - val_precision: 0.6409 - val_recall: 0.3919\n",
      "Epoch 533/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6344 - binary_accuracy: 0.6231 - precision: 0.6409 - recall: 0.3919 - val_loss: 0.6319 - val_binary_accuracy: 0.6246 - val_precision: 0.6912 - val_recall: 0.3176\n",
      "Epoch 534/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6319 - binary_accuracy: 0.6246 - precision: 0.6912 - recall: 0.3176 - val_loss: 0.6326 - val_binary_accuracy: 0.6231 - val_precision: 0.7297 - val_recall: 0.2736\n",
      "Epoch 535/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6326 - binary_accuracy: 0.6231 - precision: 0.7297 - recall: 0.2736 - val_loss: 0.6308 - val_binary_accuracy: 0.6185 - val_precision: 0.7000 - val_recall: 0.2838\n",
      "Epoch 536/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6308 - binary_accuracy: 0.6185 - precision: 0.7000 - recall: 0.2838 - val_loss: 0.6319 - val_binary_accuracy: 0.6308 - val_precision: 0.6818 - val_recall: 0.3547\n",
      "Epoch 537/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6319 - binary_accuracy: 0.6308 - precision: 0.6818 - recall: 0.3547 - val_loss: 0.6291 - val_binary_accuracy: 0.6231 - val_precision: 0.7040 - val_recall: 0.2973\n",
      "Epoch 538/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6291 - binary_accuracy: 0.6231 - precision: 0.7040 - recall: 0.2973 - val_loss: 0.6292 - val_binary_accuracy: 0.6231 - val_precision: 0.7073 - val_recall: 0.2939\n",
      "Epoch 539/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6292 - binary_accuracy: 0.6231 - precision: 0.7073 - recall: 0.2939 - val_loss: 0.6279 - val_binary_accuracy: 0.6323 - val_precision: 0.6629 - val_recall: 0.3919\n",
      "Epoch 540/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6279 - binary_accuracy: 0.6323 - precision: 0.6629 - recall: 0.3919 - val_loss: 0.6262 - val_binary_accuracy: 0.6246 - val_precision: 0.6605 - val_recall: 0.3615\n",
      "Epoch 541/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6262 - binary_accuracy: 0.6246 - precision: 0.6605 - recall: 0.3615 - val_loss: 0.6255 - val_binary_accuracy: 0.6338 - val_precision: 0.7231 - val_recall: 0.3176\n",
      "Epoch 542/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6255 - binary_accuracy: 0.6338 - precision: 0.7231 - recall: 0.3176 - val_loss: 0.6238 - val_binary_accuracy: 0.6354 - val_precision: 0.7185 - val_recall: 0.3277\n",
      "Epoch 543/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6238 - binary_accuracy: 0.6354 - precision: 0.7185 - recall: 0.3277 - val_loss: 0.6239 - val_binary_accuracy: 0.6277 - val_precision: 0.6667 - val_recall: 0.3649\n",
      "Epoch 544/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6239 - binary_accuracy: 0.6277 - precision: 0.6667 - recall: 0.3649 - val_loss: 0.6221 - val_binary_accuracy: 0.6292 - val_precision: 0.7099 - val_recall: 0.3142\n",
      "Epoch 545/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6221 - binary_accuracy: 0.6292 - precision: 0.7099 - recall: 0.3142 - val_loss: 0.6211 - val_binary_accuracy: 0.6323 - val_precision: 0.7317 - val_recall: 0.3041\n",
      "Epoch 546/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6211 - binary_accuracy: 0.6323 - precision: 0.7317 - recall: 0.3041 - val_loss: 0.6200 - val_binary_accuracy: 0.6354 - val_precision: 0.6903 - val_recall: 0.3615\n",
      "Epoch 547/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6200 - binary_accuracy: 0.6354 - precision: 0.6903 - recall: 0.3615 - val_loss: 0.6189 - val_binary_accuracy: 0.6446 - val_precision: 0.7559 - val_recall: 0.3243\n",
      "Epoch 548/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6189 - binary_accuracy: 0.6446 - precision: 0.7559 - recall: 0.3243 - val_loss: 0.6174 - val_binary_accuracy: 0.6308 - val_precision: 0.6918 - val_recall: 0.3412\n",
      "Epoch 549/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6174 - binary_accuracy: 0.6308 - precision: 0.6918 - recall: 0.3412 - val_loss: 0.6160 - val_binary_accuracy: 0.6323 - val_precision: 0.6913 - val_recall: 0.3480\n",
      "Epoch 550/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6160 - binary_accuracy: 0.6323 - precision: 0.6913 - recall: 0.3480 - val_loss: 0.6158 - val_binary_accuracy: 0.6385 - val_precision: 0.7607 - val_recall: 0.3007\n",
      "Epoch 551/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6158 - binary_accuracy: 0.6385 - precision: 0.7607 - recall: 0.3007 - val_loss: 0.6152 - val_binary_accuracy: 0.6369 - val_precision: 0.6899 - val_recall: 0.3682\n",
      "Epoch 552/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6152 - binary_accuracy: 0.6369 - precision: 0.6899 - recall: 0.3682 - val_loss: 0.6151 - val_binary_accuracy: 0.6415 - val_precision: 0.7788 - val_recall: 0.2973\n",
      "Epoch 553/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6151 - binary_accuracy: 0.6415 - precision: 0.7788 - recall: 0.2973 - val_loss: 0.6138 - val_binary_accuracy: 0.6246 - val_precision: 0.6461 - val_recall: 0.3885\n",
      "Epoch 554/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6138 - binary_accuracy: 0.6246 - precision: 0.6461 - recall: 0.3885 - val_loss: 0.6177 - val_binary_accuracy: 0.6338 - val_precision: 0.7636 - val_recall: 0.2838\n",
      "Epoch 555/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6177 - binary_accuracy: 0.6338 - precision: 0.7636 - recall: 0.2838 - val_loss: 0.6190 - val_binary_accuracy: 0.6262 - val_precision: 0.6293 - val_recall: 0.4358\n",
      "Epoch 556/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6190 - binary_accuracy: 0.6262 - precision: 0.6293 - recall: 0.4358 - val_loss: 0.6492 - val_binary_accuracy: 0.6000 - val_precision: 0.7093 - val_recall: 0.2061\n",
      "Epoch 557/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6492 - binary_accuracy: 0.6000 - precision: 0.7093 - recall: 0.2061 - val_loss: 0.6429 - val_binary_accuracy: 0.6092 - val_precision: 0.7917 - val_recall: 0.1926\n",
      "Epoch 558/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6429 - binary_accuracy: 0.6092 - precision: 0.7917 - recall: 0.1926 - val_loss: 0.6288 - val_binary_accuracy: 0.6246 - val_precision: 0.7407 - val_recall: 0.2703\n",
      "Epoch 559/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6288 - binary_accuracy: 0.6246 - precision: 0.7407 - recall: 0.2703 - val_loss: 0.6522 - val_binary_accuracy: 0.5538 - val_precision: 0.5110 - val_recall: 0.4696\n",
      "Epoch 560/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6522 - binary_accuracy: 0.5538 - precision: 0.5110 - recall: 0.4696 - val_loss: 0.6255 - val_binary_accuracy: 0.6123 - val_precision: 0.7895 - val_recall: 0.2027\n",
      "Epoch 561/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6255 - binary_accuracy: 0.6123 - precision: 0.7895 - recall: 0.2027 - val_loss: 0.6374 - val_binary_accuracy: 0.6169 - val_precision: 0.7374 - val_recall: 0.2466\n",
      "Epoch 562/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6374 - binary_accuracy: 0.6169 - precision: 0.7374 - recall: 0.2466 - val_loss: 0.6290 - val_binary_accuracy: 0.6154 - val_precision: 0.7674 - val_recall: 0.2230\n",
      "Epoch 563/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6290 - binary_accuracy: 0.6154 - precision: 0.7674 - recall: 0.2230 - val_loss: 0.6102 - val_binary_accuracy: 0.6262 - val_precision: 0.7431 - val_recall: 0.2736\n",
      "Epoch 564/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6102 - binary_accuracy: 0.6262 - precision: 0.7431 - recall: 0.2736 - val_loss: 0.6484 - val_binary_accuracy: 0.5877 - val_precision: 0.5680 - val_recall: 0.3953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6484 - binary_accuracy: 0.5877 - precision: 0.5680 - recall: 0.3953 - val_loss: 0.6289 - val_binary_accuracy: 0.6138 - val_precision: 0.7103 - val_recall: 0.2568\n",
      "Epoch 566/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6289 - binary_accuracy: 0.6138 - precision: 0.7103 - recall: 0.2568 - val_loss: 0.6136 - val_binary_accuracy: 0.6431 - val_precision: 0.9324 - val_recall: 0.2331\n",
      "Epoch 567/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6136 - binary_accuracy: 0.6431 - precision: 0.9324 - recall: 0.2331 - val_loss: 0.6166 - val_binary_accuracy: 0.6292 - val_precision: 0.8986 - val_recall: 0.2095\n",
      "Epoch 568/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6166 - binary_accuracy: 0.6292 - precision: 0.8986 - recall: 0.2095 - val_loss: 0.6249 - val_binary_accuracy: 0.6231 - val_precision: 0.8923 - val_recall: 0.1959\n",
      "Epoch 569/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6249 - binary_accuracy: 0.6231 - precision: 0.8923 - recall: 0.1959 - val_loss: 0.6117 - val_binary_accuracy: 0.6292 - val_precision: 0.8767 - val_recall: 0.2162\n",
      "Epoch 570/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6117 - binary_accuracy: 0.6292 - precision: 0.8767 - recall: 0.2162 - val_loss: 0.6072 - val_binary_accuracy: 0.6431 - val_precision: 0.8333 - val_recall: 0.2703\n",
      "Epoch 571/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6072 - binary_accuracy: 0.6431 - precision: 0.8333 - recall: 0.2703 - val_loss: 0.6077 - val_binary_accuracy: 0.6215 - val_precision: 0.6736 - val_recall: 0.3277\n",
      "Epoch 572/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6077 - binary_accuracy: 0.6215 - precision: 0.6736 - recall: 0.3277 - val_loss: 0.6097 - val_binary_accuracy: 0.6369 - val_precision: 0.6485 - val_recall: 0.4426\n",
      "Epoch 573/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6097 - binary_accuracy: 0.6369 - precision: 0.6485 - recall: 0.4426 - val_loss: 0.5999 - val_binary_accuracy: 0.6354 - val_precision: 0.6595 - val_recall: 0.4122\n",
      "Epoch 574/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5999 - binary_accuracy: 0.6354 - precision: 0.6595 - recall: 0.4122 - val_loss: 0.5994 - val_binary_accuracy: 0.6569 - val_precision: 0.7355 - val_recall: 0.3851\n",
      "Epoch 575/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.5994 - binary_accuracy: 0.6569 - precision: 0.7355 - recall: 0.3851 - val_loss: 0.5935 - val_binary_accuracy: 0.6431 - val_precision: 0.7222 - val_recall: 0.3514\n",
      "Epoch 576/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.5935 - binary_accuracy: 0.6431 - precision: 0.7222 - recall: 0.3514 - val_loss: 0.5938 - val_binary_accuracy: 0.6446 - val_precision: 0.7372 - val_recall: 0.3412\n",
      "Epoch 577/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.5938 - binary_accuracy: 0.6446 - precision: 0.7372 - recall: 0.3412 - val_loss: 0.5916 - val_binary_accuracy: 0.6431 - val_precision: 0.7424 - val_recall: 0.3311\n",
      "Epoch 578/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5916 - binary_accuracy: 0.6431 - precision: 0.7424 - recall: 0.3311 - val_loss: 0.5893 - val_binary_accuracy: 0.6385 - val_precision: 0.7480 - val_recall: 0.3108\n",
      "Epoch 579/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.5893 - binary_accuracy: 0.6385 - precision: 0.7480 - recall: 0.3108 - val_loss: 0.5875 - val_binary_accuracy: 0.6492 - val_precision: 0.7073 - val_recall: 0.3919\n",
      "Epoch 580/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5875 - binary_accuracy: 0.6492 - precision: 0.7073 - recall: 0.3919 - val_loss: 0.5886 - val_binary_accuracy: 0.6523 - val_precision: 0.6768 - val_recall: 0.4527\n",
      "Epoch 581/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5886 - binary_accuracy: 0.6523 - precision: 0.6768 - recall: 0.4527 - val_loss: 0.5824 - val_binary_accuracy: 0.6354 - val_precision: 0.6311 - val_recall: 0.4797\n",
      "Epoch 582/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.5824 - binary_accuracy: 0.6354 - precision: 0.6311 - recall: 0.4797 - val_loss: 0.5858 - val_binary_accuracy: 0.6400 - val_precision: 0.6615 - val_recall: 0.4291\n",
      "Epoch 583/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.5858 - binary_accuracy: 0.6400 - precision: 0.6615 - recall: 0.4291 - val_loss: 0.5790 - val_binary_accuracy: 0.6554 - val_precision: 0.6714 - val_recall: 0.4764\n",
      "Epoch 584/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5790 - binary_accuracy: 0.6554 - precision: 0.6714 - recall: 0.4764 - val_loss: 0.5803 - val_binary_accuracy: 0.6431 - val_precision: 0.6280 - val_recall: 0.5304\n",
      "Epoch 585/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5803 - binary_accuracy: 0.6431 - precision: 0.6280 - recall: 0.5304 - val_loss: 0.5814 - val_binary_accuracy: 0.6600 - val_precision: 0.7419 - val_recall: 0.3885\n",
      "Epoch 586/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5814 - binary_accuracy: 0.6600 - precision: 0.7419 - recall: 0.3885 - val_loss: 0.5723 - val_binary_accuracy: 0.6400 - val_precision: 0.6598 - val_recall: 0.4324\n",
      "Epoch 587/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5723 - binary_accuracy: 0.6400 - precision: 0.6598 - recall: 0.4324 - val_loss: 0.5772 - val_binary_accuracy: 0.6600 - val_precision: 0.6271 - val_recall: 0.6250\n",
      "Epoch 588/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5772 - binary_accuracy: 0.6600 - precision: 0.6271 - recall: 0.6250 - val_loss: 0.5670 - val_binary_accuracy: 0.6462 - val_precision: 0.6241 - val_recall: 0.5608\n",
      "Epoch 589/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5670 - binary_accuracy: 0.6462 - precision: 0.6241 - recall: 0.5608 - val_loss: 0.5812 - val_binary_accuracy: 0.6369 - val_precision: 0.6786 - val_recall: 0.3851\n",
      "Epoch 590/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5812 - binary_accuracy: 0.6369 - precision: 0.6786 - recall: 0.3851 - val_loss: 0.5897 - val_binary_accuracy: 0.6446 - val_precision: 0.6836 - val_recall: 0.4088\n",
      "Epoch 591/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5897 - binary_accuracy: 0.6446 - precision: 0.6836 - recall: 0.4088 - val_loss: 0.6308 - val_binary_accuracy: 0.6277 - val_precision: 0.5860 - val_recall: 0.6216\n",
      "Epoch 592/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6308 - binary_accuracy: 0.6277 - precision: 0.5860 - recall: 0.6216 - val_loss: 0.6527 - val_binary_accuracy: 0.6015 - val_precision: 0.6947 - val_recall: 0.2230\n",
      "Epoch 593/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6527 - binary_accuracy: 0.6015 - precision: 0.6947 - recall: 0.2230 - val_loss: 0.6344 - val_binary_accuracy: 0.6077 - val_precision: 0.7253 - val_recall: 0.2230\n",
      "Epoch 594/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6344 - binary_accuracy: 0.6077 - precision: 0.7253 - recall: 0.2230 - val_loss: 0.6242 - val_binary_accuracy: 0.6354 - val_precision: 0.6497 - val_recall: 0.4324\n",
      "Epoch 595/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6242 - binary_accuracy: 0.6354 - precision: 0.6497 - recall: 0.4324 - val_loss: 0.6326 - val_binary_accuracy: 0.6369 - val_precision: 0.6079 - val_recall: 0.5709\n",
      "Epoch 596/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6326 - binary_accuracy: 0.6369 - precision: 0.6079 - recall: 0.5709 - val_loss: 0.6207 - val_binary_accuracy: 0.6569 - val_precision: 0.6229 - val_recall: 0.6250\n",
      "Epoch 597/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6207 - binary_accuracy: 0.6569 - precision: 0.6229 - recall: 0.6250 - val_loss: 0.6202 - val_binary_accuracy: 0.6492 - val_precision: 0.6241 - val_recall: 0.5777\n",
      "Epoch 598/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6202 - binary_accuracy: 0.6492 - precision: 0.6241 - recall: 0.5777 - val_loss: 0.6201 - val_binary_accuracy: 0.6400 - val_precision: 0.6115 - val_recall: 0.5743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6201 - binary_accuracy: 0.6400 - precision: 0.6115 - recall: 0.5743 - val_loss: 0.6068 - val_binary_accuracy: 0.6492 - val_precision: 0.6269 - val_recall: 0.5676\n",
      "Epoch 600/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.6068 - binary_accuracy: 0.6492 - precision: 0.6269 - recall: 0.5676 - val_loss: 0.6077 - val_binary_accuracy: 0.6338 - val_precision: 0.6074 - val_recall: 0.5541\n",
      "Epoch 601/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6077 - binary_accuracy: 0.6338 - precision: 0.6074 - recall: 0.5541 - val_loss: 0.6060 - val_binary_accuracy: 0.6508 - val_precision: 0.6273 - val_recall: 0.5743\n",
      "Epoch 602/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6060 - binary_accuracy: 0.6508 - precision: 0.6273 - recall: 0.5743 - val_loss: 0.6008 - val_binary_accuracy: 0.6323 - val_precision: 0.6135 - val_recall: 0.5203\n",
      "Epoch 603/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6008 - binary_accuracy: 0.6323 - precision: 0.6135 - recall: 0.5203 - val_loss: 0.6001 - val_binary_accuracy: 0.6123 - val_precision: 0.6000 - val_recall: 0.4459\n",
      "Epoch 604/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6001 - binary_accuracy: 0.6123 - precision: 0.6000 - recall: 0.4459 - val_loss: 0.5981 - val_binary_accuracy: 0.6046 - val_precision: 0.6242 - val_recall: 0.3311\n",
      "Epoch 605/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5981 - binary_accuracy: 0.6046 - precision: 0.6242 - recall: 0.3311 - val_loss: 0.5945 - val_binary_accuracy: 0.5985 - val_precision: 0.6159 - val_recall: 0.3142\n",
      "Epoch 606/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5945 - binary_accuracy: 0.5985 - precision: 0.6159 - recall: 0.3142 - val_loss: 0.5896 - val_binary_accuracy: 0.6415 - val_precision: 0.6493 - val_recall: 0.4628\n",
      "Epoch 607/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5896 - binary_accuracy: 0.6415 - precision: 0.6493 - recall: 0.4628 - val_loss: 0.5872 - val_binary_accuracy: 0.6446 - val_precision: 0.6360 - val_recall: 0.5135\n",
      "Epoch 608/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.5872 - binary_accuracy: 0.6446 - precision: 0.6360 - recall: 0.5135 - val_loss: 0.5835 - val_binary_accuracy: 0.6600 - val_precision: 0.6448 - val_recall: 0.5642\n",
      "Epoch 609/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5835 - binary_accuracy: 0.6600 - precision: 0.6448 - recall: 0.5642 - val_loss: 0.5773 - val_binary_accuracy: 0.6492 - val_precision: 0.6269 - val_recall: 0.5676\n",
      "Epoch 610/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5773 - binary_accuracy: 0.6492 - precision: 0.6269 - recall: 0.5676 - val_loss: 0.5742 - val_binary_accuracy: 0.6415 - val_precision: 0.6226 - val_recall: 0.5405\n",
      "Epoch 611/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5742 - binary_accuracy: 0.6415 - precision: 0.6226 - recall: 0.5405 - val_loss: 0.5705 - val_binary_accuracy: 0.6385 - val_precision: 0.6151 - val_recall: 0.5507\n",
      "Epoch 612/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5705 - binary_accuracy: 0.6385 - precision: 0.6151 - recall: 0.5507 - val_loss: 0.5687 - val_binary_accuracy: 0.6569 - val_precision: 0.6263 - val_recall: 0.6115\n",
      "Epoch 613/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5687 - binary_accuracy: 0.6569 - precision: 0.6263 - recall: 0.6115 - val_loss: 0.5638 - val_binary_accuracy: 0.6585 - val_precision: 0.6225 - val_recall: 0.6351\n",
      "Epoch 614/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5638 - binary_accuracy: 0.6585 - precision: 0.6225 - recall: 0.6351 - val_loss: 0.5623 - val_binary_accuracy: 0.6815 - val_precision: 0.6488 - val_recall: 0.6554\n",
      "Epoch 615/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5623 - binary_accuracy: 0.6815 - precision: 0.6488 - recall: 0.6554 - val_loss: 0.5571 - val_binary_accuracy: 0.6646 - val_precision: 0.6309 - val_recall: 0.6351\n",
      "Epoch 616/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5571 - binary_accuracy: 0.6646 - precision: 0.6309 - recall: 0.6351 - val_loss: 0.5551 - val_binary_accuracy: 0.6692 - val_precision: 0.6392 - val_recall: 0.6284\n",
      "Epoch 617/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5551 - binary_accuracy: 0.6692 - precision: 0.6392 - recall: 0.6284 - val_loss: 0.5527 - val_binary_accuracy: 0.6908 - val_precision: 0.6599 - val_recall: 0.6622\n",
      "Epoch 618/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5527 - binary_accuracy: 0.6908 - precision: 0.6599 - recall: 0.6622 - val_loss: 0.5483 - val_binary_accuracy: 0.6769 - val_precision: 0.6424 - val_recall: 0.6554\n",
      "Epoch 619/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5483 - binary_accuracy: 0.6769 - precision: 0.6424 - recall: 0.6554 - val_loss: 0.5467 - val_binary_accuracy: 0.6815 - val_precision: 0.6584 - val_recall: 0.6250\n",
      "Epoch 620/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5467 - binary_accuracy: 0.6815 - precision: 0.6584 - recall: 0.6250 - val_loss: 0.5432 - val_binary_accuracy: 0.6831 - val_precision: 0.6596 - val_recall: 0.6284\n",
      "Epoch 621/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5432 - binary_accuracy: 0.6831 - precision: 0.6596 - recall: 0.6284 - val_loss: 0.5384 - val_binary_accuracy: 0.6846 - val_precision: 0.6522 - val_recall: 0.6588\n",
      "Epoch 622/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5384 - binary_accuracy: 0.6846 - precision: 0.6522 - recall: 0.6588 - val_loss: 0.5360 - val_binary_accuracy: 0.6877 - val_precision: 0.6620 - val_recall: 0.6419\n",
      "Epoch 623/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5360 - binary_accuracy: 0.6877 - precision: 0.6620 - recall: 0.6419 - val_loss: 0.5320 - val_binary_accuracy: 0.7015 - val_precision: 0.6747 - val_recall: 0.6655\n",
      "Epoch 624/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5320 - binary_accuracy: 0.7015 - precision: 0.6747 - recall: 0.6655 - val_loss: 0.5279 - val_binary_accuracy: 0.6985 - val_precision: 0.6603 - val_recall: 0.6959\n",
      "Epoch 625/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5279 - binary_accuracy: 0.6985 - precision: 0.6603 - recall: 0.6959 - val_loss: 0.5252 - val_binary_accuracy: 0.6985 - val_precision: 0.6773 - val_recall: 0.6453\n",
      "Epoch 626/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5252 - binary_accuracy: 0.6985 - precision: 0.6773 - recall: 0.6453 - val_loss: 0.5223 - val_binary_accuracy: 0.7015 - val_precision: 0.6614 - val_recall: 0.7061\n",
      "Epoch 627/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5223 - binary_accuracy: 0.7015 - precision: 0.6614 - recall: 0.7061 - val_loss: 0.5181 - val_binary_accuracy: 0.7138 - val_precision: 0.7200 - val_recall: 0.6081\n",
      "Epoch 628/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5181 - binary_accuracy: 0.7138 - precision: 0.7200 - recall: 0.6081 - val_loss: 0.5141 - val_binary_accuracy: 0.7169 - val_precision: 0.6830 - val_recall: 0.7061\n",
      "Epoch 629/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5141 - binary_accuracy: 0.7169 - precision: 0.6830 - recall: 0.7061 - val_loss: 0.5095 - val_binary_accuracy: 0.7138 - val_precision: 0.7099 - val_recall: 0.6284\n",
      "Epoch 630/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.5095 - binary_accuracy: 0.7138 - precision: 0.7099 - recall: 0.6284 - val_loss: 0.5074 - val_binary_accuracy: 0.7108 - val_precision: 0.6667 - val_recall: 0.7297\n",
      "Epoch 631/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5074 - binary_accuracy: 0.7108 - precision: 0.6667 - recall: 0.7297 - val_loss: 0.5103 - val_binary_accuracy: 0.7154 - val_precision: 0.7817 - val_recall: 0.5203\n",
      "Epoch 632/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5103 - binary_accuracy: 0.7154 - precision: 0.7817 - recall: 0.5203 - val_loss: 0.5588 - val_binary_accuracy: 0.6769 - val_precision: 0.5964 - val_recall: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5588 - binary_accuracy: 0.6769 - precision: 0.5964 - recall: 0.8986 - val_loss: 0.6146 - val_binary_accuracy: 0.6600 - val_precision: 0.6923 - val_recall: 0.4561\n",
      "Epoch 634/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6146 - binary_accuracy: 0.6600 - precision: 0.6923 - recall: 0.4561 - val_loss: 0.6028 - val_binary_accuracy: 0.6369 - val_precision: 0.6648 - val_recall: 0.4088\n",
      "Epoch 635/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6028 - binary_accuracy: 0.6369 - precision: 0.6648 - recall: 0.4088 - val_loss: 0.5909 - val_binary_accuracy: 0.6262 - val_precision: 0.5917 - val_recall: 0.5777\n",
      "Epoch 636/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5909 - binary_accuracy: 0.6262 - precision: 0.5917 - recall: 0.5777 - val_loss: 0.6125 - val_binary_accuracy: 0.6323 - val_precision: 0.6014 - val_recall: 0.5709\n",
      "Epoch 637/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6125 - binary_accuracy: 0.6323 - precision: 0.6014 - recall: 0.5709 - val_loss: 0.5634 - val_binary_accuracy: 0.6708 - val_precision: 0.6952 - val_recall: 0.4932\n",
      "Epoch 638/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5634 - binary_accuracy: 0.6708 - precision: 0.6952 - recall: 0.4932 - val_loss: 0.5784 - val_binary_accuracy: 0.6600 - val_precision: 0.7095 - val_recall: 0.4291\n",
      "Epoch 639/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5784 - binary_accuracy: 0.6600 - precision: 0.7095 - recall: 0.4291 - val_loss: 0.5600 - val_binary_accuracy: 0.7015 - val_precision: 0.7161 - val_recall: 0.5709\n",
      "Epoch 640/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5600 - binary_accuracy: 0.7015 - precision: 0.7161 - recall: 0.5709 - val_loss: 0.5860 - val_binary_accuracy: 0.6969 - val_precision: 0.7089 - val_recall: 0.5676\n",
      "Epoch 641/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.5860 - binary_accuracy: 0.6969 - precision: 0.7089 - recall: 0.5676 - val_loss: 0.5525 - val_binary_accuracy: 0.6938 - val_precision: 0.7046 - val_recall: 0.5642\n",
      "Epoch 642/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5525 - binary_accuracy: 0.6938 - precision: 0.7046 - recall: 0.5642 - val_loss: 0.5266 - val_binary_accuracy: 0.7277 - val_precision: 0.7820 - val_recall: 0.5574\n",
      "Epoch 643/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.5266 - binary_accuracy: 0.7277 - precision: 0.7820 - recall: 0.5574 - val_loss: 0.5414 - val_binary_accuracy: 0.7308 - val_precision: 0.7763 - val_recall: 0.5743\n",
      "Epoch 644/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.5414 - binary_accuracy: 0.7308 - precision: 0.7763 - recall: 0.5743 - val_loss: 0.5383 - val_binary_accuracy: 0.7031 - val_precision: 0.6988 - val_recall: 0.6115\n",
      "Epoch 645/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5383 - binary_accuracy: 0.7031 - precision: 0.6988 - recall: 0.6115 - val_loss: 0.5228 - val_binary_accuracy: 0.7215 - val_precision: 0.6936 - val_recall: 0.6959\n",
      "Epoch 646/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5228 - binary_accuracy: 0.7215 - precision: 0.6936 - recall: 0.6959 - val_loss: 0.5157 - val_binary_accuracy: 0.7215 - val_precision: 0.7309 - val_recall: 0.6149\n",
      "Epoch 647/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5157 - binary_accuracy: 0.7215 - precision: 0.7309 - recall: 0.6149 - val_loss: 0.5084 - val_binary_accuracy: 0.7277 - val_precision: 0.7390 - val_recall: 0.6216\n",
      "Epoch 648/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.5084 - binary_accuracy: 0.7277 - precision: 0.7390 - recall: 0.6216 - val_loss: 0.5050 - val_binary_accuracy: 0.7277 - val_precision: 0.7228 - val_recall: 0.6520\n",
      "Epoch 649/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5050 - binary_accuracy: 0.7277 - precision: 0.7228 - recall: 0.6520 - val_loss: 0.5032 - val_binary_accuracy: 0.7323 - val_precision: 0.6943 - val_recall: 0.7365\n",
      "Epoch 650/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5032 - binary_accuracy: 0.7323 - precision: 0.6943 - recall: 0.7365 - val_loss: 0.4888 - val_binary_accuracy: 0.7585 - val_precision: 0.7324 - val_recall: 0.7399\n",
      "Epoch 651/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4888 - binary_accuracy: 0.7585 - precision: 0.7324 - recall: 0.7399 - val_loss: 0.4956 - val_binary_accuracy: 0.7462 - val_precision: 0.7631 - val_recall: 0.6419\n",
      "Epoch 652/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.4956 - binary_accuracy: 0.7462 - precision: 0.7631 - recall: 0.6419 - val_loss: 0.4843 - val_binary_accuracy: 0.7662 - val_precision: 0.7590 - val_recall: 0.7128\n",
      "Epoch 653/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.4843 - binary_accuracy: 0.7662 - precision: 0.7590 - recall: 0.7128 - val_loss: 0.4812 - val_binary_accuracy: 0.7538 - val_precision: 0.7615 - val_recall: 0.6689\n",
      "Epoch 654/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4812 - binary_accuracy: 0.7538 - precision: 0.7615 - recall: 0.6689 - val_loss: 0.4849 - val_binary_accuracy: 0.7600 - val_precision: 0.7632 - val_recall: 0.6858\n",
      "Epoch 655/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4849 - binary_accuracy: 0.7600 - precision: 0.7632 - recall: 0.6858 - val_loss: 0.4726 - val_binary_accuracy: 0.7508 - val_precision: 0.7376 - val_recall: 0.7027\n",
      "Epoch 656/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4726 - binary_accuracy: 0.7508 - precision: 0.7376 - recall: 0.7027 - val_loss: 0.4709 - val_binary_accuracy: 0.7708 - val_precision: 0.8155 - val_recall: 0.6419\n",
      "Epoch 657/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4709 - binary_accuracy: 0.7708 - precision: 0.8155 - recall: 0.6419 - val_loss: 0.4853 - val_binary_accuracy: 0.7400 - val_precision: 0.7343 - val_recall: 0.6723\n",
      "Epoch 658/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4853 - binary_accuracy: 0.7400 - precision: 0.7343 - recall: 0.6723 - val_loss: 0.4643 - val_binary_accuracy: 0.7831 - val_precision: 0.7627 - val_recall: 0.7601\n",
      "Epoch 659/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4643 - binary_accuracy: 0.7831 - precision: 0.7627 - recall: 0.7601 - val_loss: 0.4649 - val_binary_accuracy: 0.7585 - val_precision: 0.7791 - val_recall: 0.6554\n",
      "Epoch 660/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4649 - binary_accuracy: 0.7585 - precision: 0.7791 - recall: 0.6554 - val_loss: 0.4861 - val_binary_accuracy: 0.7431 - val_precision: 0.7768 - val_recall: 0.6115\n",
      "Epoch 661/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.4861 - binary_accuracy: 0.7431 - precision: 0.7768 - recall: 0.6115 - val_loss: 0.4740 - val_binary_accuracy: 0.7600 - val_precision: 0.7482 - val_recall: 0.7128\n",
      "Epoch 662/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.4740 - binary_accuracy: 0.7600 - precision: 0.7482 - recall: 0.7128 - val_loss: 0.4813 - val_binary_accuracy: 0.7354 - val_precision: 0.6802 - val_recall: 0.7905\n",
      "Epoch 663/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4813 - binary_accuracy: 0.7354 - precision: 0.6802 - recall: 0.7905 - val_loss: 0.5091 - val_binary_accuracy: 0.7092 - val_precision: 0.9213 - val_recall: 0.3953\n",
      "Epoch 664/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.5091 - binary_accuracy: 0.7092 - precision: 0.9213 - recall: 0.3953 - val_loss: 0.5221 - val_binary_accuracy: 0.7108 - val_precision: 0.6607 - val_recall: 0.7500\n",
      "Epoch 665/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.5221 - binary_accuracy: 0.7108 - precision: 0.6607 - recall: 0.7500 - val_loss: 0.5204 - val_binary_accuracy: 0.7123 - val_precision: 0.6677 - val_recall: 0.7331\n",
      "Epoch 666/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.5204 - binary_accuracy: 0.7123 - precision: 0.6677 - recall: 0.7331 - val_loss: 0.4654 - val_binary_accuracy: 0.7585 - val_precision: 0.7491 - val_recall: 0.7061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4654 - binary_accuracy: 0.7585 - precision: 0.7491 - recall: 0.7061 - val_loss: 0.4732 - val_binary_accuracy: 0.7615 - val_precision: 0.8190 - val_recall: 0.6115\n",
      "Epoch 668/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4732 - binary_accuracy: 0.7615 - precision: 0.8190 - recall: 0.6115 - val_loss: 0.4837 - val_binary_accuracy: 0.7262 - val_precision: 0.8598 - val_recall: 0.4764\n",
      "Epoch 669/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.4837 - binary_accuracy: 0.7262 - precision: 0.8598 - recall: 0.4764 - val_loss: 0.4464 - val_binary_accuracy: 0.7662 - val_precision: 0.7400 - val_recall: 0.7500\n",
      "Epoch 670/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4464 - binary_accuracy: 0.7662 - precision: 0.7400 - recall: 0.7500 - val_loss: 0.4539 - val_binary_accuracy: 0.7492 - val_precision: 0.6873 - val_recall: 0.8243\n",
      "Epoch 671/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4539 - binary_accuracy: 0.7492 - precision: 0.6873 - recall: 0.8243 - val_loss: 0.4595 - val_binary_accuracy: 0.7769 - val_precision: 0.7397 - val_recall: 0.7872\n",
      "Epoch 672/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4595 - binary_accuracy: 0.7769 - precision: 0.7397 - recall: 0.7872 - val_loss: 0.4375 - val_binary_accuracy: 0.7938 - val_precision: 0.8045 - val_recall: 0.7230\n",
      "Epoch 673/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.4375 - binary_accuracy: 0.7938 - precision: 0.8045 - recall: 0.7230 - val_loss: 0.4775 - val_binary_accuracy: 0.7492 - val_precision: 0.8446 - val_recall: 0.5507\n",
      "Epoch 674/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4775 - binary_accuracy: 0.7492 - precision: 0.8446 - recall: 0.5507 - val_loss: 0.4418 - val_binary_accuracy: 0.8015 - val_precision: 0.8249 - val_recall: 0.7162\n",
      "Epoch 675/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.4418 - binary_accuracy: 0.8015 - precision: 0.8249 - recall: 0.7162 - val_loss: 0.4471 - val_binary_accuracy: 0.7662 - val_precision: 0.7483 - val_recall: 0.7331\n",
      "Epoch 676/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.4471 - binary_accuracy: 0.7662 - precision: 0.7483 - recall: 0.7331 - val_loss: 0.4454 - val_binary_accuracy: 0.7785 - val_precision: 0.7436 - val_recall: 0.7838\n",
      "Epoch 677/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4454 - binary_accuracy: 0.7785 - precision: 0.7436 - recall: 0.7838 - val_loss: 0.4206 - val_binary_accuracy: 0.7985 - val_precision: 0.7570 - val_recall: 0.8209\n",
      "Epoch 678/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4206 - binary_accuracy: 0.7985 - precision: 0.7570 - recall: 0.8209 - val_loss: 0.4355 - val_binary_accuracy: 0.7646 - val_precision: 0.8265 - val_recall: 0.6115\n",
      "Epoch 679/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4355 - binary_accuracy: 0.7646 - precision: 0.8265 - recall: 0.6115 - val_loss: 0.4165 - val_binary_accuracy: 0.7908 - val_precision: 0.8125 - val_recall: 0.7027\n",
      "Epoch 680/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4165 - binary_accuracy: 0.7908 - precision: 0.8125 - recall: 0.7027 - val_loss: 0.4110 - val_binary_accuracy: 0.8046 - val_precision: 0.8051 - val_recall: 0.7534\n",
      "Epoch 681/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4110 - binary_accuracy: 0.8046 - precision: 0.8051 - recall: 0.7534 - val_loss: 0.4113 - val_binary_accuracy: 0.7969 - val_precision: 0.7789 - val_recall: 0.7736\n",
      "Epoch 682/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4113 - binary_accuracy: 0.7969 - precision: 0.7789 - recall: 0.7736 - val_loss: 0.4027 - val_binary_accuracy: 0.7862 - val_precision: 0.7524 - val_recall: 0.7905\n",
      "Epoch 683/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4027 - binary_accuracy: 0.7862 - precision: 0.7524 - recall: 0.7905 - val_loss: 0.3972 - val_binary_accuracy: 0.8077 - val_precision: 0.8251 - val_recall: 0.7331\n",
      "Epoch 684/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3972 - binary_accuracy: 0.8077 - precision: 0.8251 - recall: 0.7331 - val_loss: 0.4000 - val_binary_accuracy: 0.8000 - val_precision: 0.8487 - val_recall: 0.6824\n",
      "Epoch 685/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.4000 - binary_accuracy: 0.8000 - precision: 0.8487 - recall: 0.6824 - val_loss: 0.3953 - val_binary_accuracy: 0.8185 - val_precision: 0.8371 - val_recall: 0.7466\n",
      "Epoch 686/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3953 - binary_accuracy: 0.8185 - precision: 0.8371 - recall: 0.7466 - val_loss: 0.3805 - val_binary_accuracy: 0.8046 - val_precision: 0.7717 - val_recall: 0.8108\n",
      "Epoch 687/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.3805 - binary_accuracy: 0.8046 - precision: 0.7717 - recall: 0.8108 - val_loss: 0.3778 - val_binary_accuracy: 0.8169 - val_precision: 0.8062 - val_recall: 0.7872\n",
      "Epoch 688/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3778 - binary_accuracy: 0.8169 - precision: 0.8062 - recall: 0.7872 - val_loss: 0.3931 - val_binary_accuracy: 0.8185 - val_precision: 0.8870 - val_recall: 0.6892\n",
      "Epoch 689/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.3931 - binary_accuracy: 0.8185 - precision: 0.8870 - recall: 0.6892 - val_loss: 0.4121 - val_binary_accuracy: 0.7908 - val_precision: 0.8175 - val_recall: 0.6959\n",
      "Epoch 690/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.4121 - binary_accuracy: 0.7908 - precision: 0.8175 - recall: 0.6959 - val_loss: 0.4912 - val_binary_accuracy: 0.7585 - val_precision: 0.7235 - val_recall: 0.7601\n",
      "Epoch 691/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.4912 - binary_accuracy: 0.7585 - precision: 0.7235 - recall: 0.7601 - val_loss: 0.5503 - val_binary_accuracy: 0.7123 - val_precision: 0.6430 - val_recall: 0.8277\n",
      "Epoch 692/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5503 - binary_accuracy: 0.7123 - precision: 0.6430 - recall: 0.8277 - val_loss: 0.6911 - val_binary_accuracy: 0.6492 - val_precision: 0.7152 - val_recall: 0.3818\n",
      "Epoch 693/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6911 - binary_accuracy: 0.6492 - precision: 0.7152 - recall: 0.3818 - val_loss: 0.4595 - val_binary_accuracy: 0.7554 - val_precision: 0.8374 - val_recall: 0.5743\n",
      "Epoch 694/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.4595 - binary_accuracy: 0.7554 - precision: 0.8374 - recall: 0.5743 - val_loss: 0.5756 - val_binary_accuracy: 0.6862 - val_precision: 0.6369 - val_recall: 0.7230\n",
      "Epoch 695/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5756 - binary_accuracy: 0.6862 - precision: 0.6369 - recall: 0.7230 - val_loss: 0.5512 - val_binary_accuracy: 0.6862 - val_precision: 0.6292 - val_recall: 0.7568\n",
      "Epoch 696/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5512 - binary_accuracy: 0.6862 - precision: 0.6292 - recall: 0.7568 - val_loss: 0.4608 - val_binary_accuracy: 0.7862 - val_precision: 0.7985 - val_recall: 0.7095\n",
      "Epoch 697/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4608 - binary_accuracy: 0.7862 - precision: 0.7985 - recall: 0.7095 - val_loss: 0.5338 - val_binary_accuracy: 0.7369 - val_precision: 0.7753 - val_recall: 0.5946\n",
      "Epoch 698/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5338 - binary_accuracy: 0.7369 - precision: 0.7753 - recall: 0.5946 - val_loss: 0.5298 - val_binary_accuracy: 0.7123 - val_precision: 0.8759 - val_recall: 0.4291\n",
      "Epoch 699/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5298 - binary_accuracy: 0.7123 - precision: 0.8759 - recall: 0.4291 - val_loss: 0.4626 - val_binary_accuracy: 0.7631 - val_precision: 0.8515 - val_recall: 0.5811\n",
      "Epoch 700/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.4626 - binary_accuracy: 0.7631 - precision: 0.8515 - recall: 0.5811 - val_loss: 0.4761 - val_binary_accuracy: 0.7431 - val_precision: 0.6949 - val_recall: 0.7770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4761 - binary_accuracy: 0.7431 - precision: 0.6949 - recall: 0.7770 - val_loss: 0.5093 - val_binary_accuracy: 0.7215 - val_precision: 0.6567 - val_recall: 0.8142\n",
      "Epoch 702/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5093 - binary_accuracy: 0.7215 - precision: 0.6567 - recall: 0.8142 - val_loss: 0.4473 - val_binary_accuracy: 0.7677 - val_precision: 0.7231 - val_recall: 0.7939\n",
      "Epoch 703/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4473 - binary_accuracy: 0.7677 - precision: 0.7231 - recall: 0.7939 - val_loss: 0.4368 - val_binary_accuracy: 0.7677 - val_precision: 0.7778 - val_recall: 0.6858\n",
      "Epoch 704/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4368 - binary_accuracy: 0.7677 - precision: 0.7778 - recall: 0.6858 - val_loss: 0.4617 - val_binary_accuracy: 0.7477 - val_precision: 0.8511 - val_recall: 0.5405\n",
      "Epoch 705/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.4617 - binary_accuracy: 0.7477 - precision: 0.8511 - recall: 0.5405 - val_loss: 0.4263 - val_binary_accuracy: 0.7754 - val_precision: 0.8989 - val_recall: 0.5709\n",
      "Epoch 706/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4263 - binary_accuracy: 0.7754 - precision: 0.8989 - recall: 0.5709 - val_loss: 0.4347 - val_binary_accuracy: 0.7877 - val_precision: 0.8591 - val_recall: 0.6385\n",
      "Epoch 707/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4347 - binary_accuracy: 0.7877 - precision: 0.8591 - recall: 0.6385 - val_loss: 0.4339 - val_binary_accuracy: 0.7738 - val_precision: 0.7614 - val_recall: 0.7331\n",
      "Epoch 708/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4339 - binary_accuracy: 0.7738 - precision: 0.7614 - recall: 0.7331 - val_loss: 0.4140 - val_binary_accuracy: 0.7769 - val_precision: 0.7214 - val_recall: 0.8311\n",
      "Epoch 709/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.4140 - binary_accuracy: 0.7769 - precision: 0.7214 - recall: 0.8311 - val_loss: 0.4105 - val_binary_accuracy: 0.7969 - val_precision: 0.7515 - val_recall: 0.8277\n",
      "Epoch 710/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.4105 - binary_accuracy: 0.7969 - precision: 0.7515 - recall: 0.8277 - val_loss: 0.4074 - val_binary_accuracy: 0.7800 - val_precision: 0.7802 - val_recall: 0.7196\n",
      "Epoch 711/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4074 - binary_accuracy: 0.7800 - precision: 0.7802 - recall: 0.7196 - val_loss: 0.3898 - val_binary_accuracy: 0.8031 - val_precision: 0.8784 - val_recall: 0.6588\n",
      "Epoch 712/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3898 - binary_accuracy: 0.8031 - precision: 0.8784 - recall: 0.6588 - val_loss: 0.4013 - val_binary_accuracy: 0.7908 - val_precision: 0.8846 - val_recall: 0.6216\n",
      "Epoch 713/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4013 - binary_accuracy: 0.7908 - precision: 0.8846 - recall: 0.6216 - val_loss: 0.3840 - val_binary_accuracy: 0.8231 - val_precision: 0.8787 - val_recall: 0.7095\n",
      "Epoch 714/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3840 - binary_accuracy: 0.8231 - precision: 0.8787 - recall: 0.7095 - val_loss: 0.3697 - val_binary_accuracy: 0.8277 - val_precision: 0.8194 - val_recall: 0.7973\n",
      "Epoch 715/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3697 - binary_accuracy: 0.8277 - precision: 0.8194 - recall: 0.7973 - val_loss: 0.3840 - val_binary_accuracy: 0.8000 - val_precision: 0.7712 - val_recall: 0.7973\n",
      "Epoch 716/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3840 - binary_accuracy: 0.8000 - precision: 0.7712 - recall: 0.7973 - val_loss: 0.3680 - val_binary_accuracy: 0.8046 - val_precision: 0.7864 - val_recall: 0.7838\n",
      "Epoch 717/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3680 - binary_accuracy: 0.8046 - precision: 0.7864 - recall: 0.7838 - val_loss: 0.3573 - val_binary_accuracy: 0.8338 - val_precision: 0.8672 - val_recall: 0.7500\n",
      "Epoch 718/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3573 - binary_accuracy: 0.8338 - precision: 0.8672 - recall: 0.7500 - val_loss: 0.3661 - val_binary_accuracy: 0.8215 - val_precision: 0.9091 - val_recall: 0.6757\n",
      "Epoch 719/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3661 - binary_accuracy: 0.8215 - precision: 0.9091 - recall: 0.6757 - val_loss: 0.3451 - val_binary_accuracy: 0.8415 - val_precision: 0.9142 - val_recall: 0.7196\n",
      "Epoch 720/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3451 - binary_accuracy: 0.8415 - precision: 0.9142 - recall: 0.7196 - val_loss: 0.3519 - val_binary_accuracy: 0.8308 - val_precision: 0.8444 - val_recall: 0.7703\n",
      "Epoch 721/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3519 - binary_accuracy: 0.8308 - precision: 0.8444 - recall: 0.7703 - val_loss: 0.3406 - val_binary_accuracy: 0.8523 - val_precision: 0.8497 - val_recall: 0.8209\n",
      "Epoch 722/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3406 - binary_accuracy: 0.8523 - precision: 0.8497 - recall: 0.8209 - val_loss: 0.3465 - val_binary_accuracy: 0.8323 - val_precision: 0.8351 - val_recall: 0.7872\n",
      "Epoch 723/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3465 - binary_accuracy: 0.8323 - precision: 0.8351 - recall: 0.7872 - val_loss: 0.3342 - val_binary_accuracy: 0.8292 - val_precision: 0.8339 - val_recall: 0.7804\n",
      "Epoch 724/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3342 - binary_accuracy: 0.8292 - precision: 0.8339 - recall: 0.7804 - val_loss: 0.3336 - val_binary_accuracy: 0.8369 - val_precision: 0.8958 - val_recall: 0.7264\n",
      "Epoch 725/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3336 - binary_accuracy: 0.8369 - precision: 0.8958 - recall: 0.7264 - val_loss: 0.3198 - val_binary_accuracy: 0.8462 - val_precision: 0.8952 - val_recall: 0.7500\n",
      "Epoch 726/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3198 - binary_accuracy: 0.8462 - precision: 0.8952 - recall: 0.7500 - val_loss: 0.3250 - val_binary_accuracy: 0.8400 - val_precision: 0.8453 - val_recall: 0.7939\n",
      "Epoch 727/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3250 - binary_accuracy: 0.8400 - precision: 0.8453 - recall: 0.7939 - val_loss: 0.3295 - val_binary_accuracy: 0.8415 - val_precision: 0.8434 - val_recall: 0.8007\n",
      "Epoch 728/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3295 - binary_accuracy: 0.8415 - precision: 0.8434 - recall: 0.8007 - val_loss: 0.3056 - val_binary_accuracy: 0.8538 - val_precision: 0.8681 - val_recall: 0.8007\n",
      "Epoch 729/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3056 - binary_accuracy: 0.8538 - precision: 0.8681 - recall: 0.8007 - val_loss: 0.3083 - val_binary_accuracy: 0.8538 - val_precision: 0.8972 - val_recall: 0.7669\n",
      "Epoch 730/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3083 - binary_accuracy: 0.8538 - precision: 0.8972 - recall: 0.7669 - val_loss: 0.3017 - val_binary_accuracy: 0.8646 - val_precision: 0.9228 - val_recall: 0.7669\n",
      "Epoch 731/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3017 - binary_accuracy: 0.8646 - precision: 0.9228 - recall: 0.7669 - val_loss: 0.2926 - val_binary_accuracy: 0.8723 - val_precision: 0.9019 - val_recall: 0.8074\n",
      "Epoch 732/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2926 - binary_accuracy: 0.8723 - precision: 0.9019 - recall: 0.8074 - val_loss: 0.2954 - val_binary_accuracy: 0.8677 - val_precision: 0.8671 - val_recall: 0.8378\n",
      "Epoch 733/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2954 - binary_accuracy: 0.8677 - precision: 0.8671 - recall: 0.8378 - val_loss: 0.2809 - val_binary_accuracy: 0.8831 - val_precision: 0.9297 - val_recall: 0.8041\n",
      "Epoch 734/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2809 - binary_accuracy: 0.8831 - precision: 0.9297 - recall: 0.8041 - val_loss: 0.2795 - val_binary_accuracy: 0.8769 - val_precision: 0.9463 - val_recall: 0.7736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2795 - binary_accuracy: 0.8769 - precision: 0.9463 - recall: 0.7736 - val_loss: 0.2817 - val_binary_accuracy: 0.8692 - val_precision: 0.8809 - val_recall: 0.8243\n",
      "Epoch 736/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2817 - binary_accuracy: 0.8692 - precision: 0.8809 - recall: 0.8243 - val_loss: 0.2889 - val_binary_accuracy: 0.8692 - val_precision: 0.9042 - val_recall: 0.7973\n",
      "Epoch 737/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2889 - binary_accuracy: 0.8692 - precision: 0.9042 - recall: 0.7973 - val_loss: 0.3103 - val_binary_accuracy: 0.8323 - val_precision: 0.8400 - val_recall: 0.7804\n",
      "Epoch 738/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.3103 - binary_accuracy: 0.8323 - precision: 0.8400 - recall: 0.7804 - val_loss: 0.3910 - val_binary_accuracy: 0.8154 - val_precision: 0.8761 - val_recall: 0.6926\n",
      "Epoch 739/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.3910 - binary_accuracy: 0.8154 - precision: 0.8761 - recall: 0.6926 - val_loss: 0.3113 - val_binary_accuracy: 0.8523 - val_precision: 0.8378 - val_recall: 0.8378\n",
      "Epoch 740/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.3113 - binary_accuracy: 0.8523 - precision: 0.8378 - recall: 0.8378 - val_loss: 0.3985 - val_binary_accuracy: 0.7969 - val_precision: 0.7808 - val_recall: 0.7703\n",
      "Epoch 741/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.3985 - binary_accuracy: 0.7969 - precision: 0.7808 - recall: 0.7703 - val_loss: 0.4236 - val_binary_accuracy: 0.7985 - val_precision: 0.9188 - val_recall: 0.6115\n",
      "Epoch 742/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4236 - binary_accuracy: 0.7985 - precision: 0.9188 - recall: 0.6115 - val_loss: 0.4225 - val_binary_accuracy: 0.7831 - val_precision: 0.7719 - val_recall: 0.7432\n",
      "Epoch 743/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4225 - binary_accuracy: 0.7831 - precision: 0.7719 - recall: 0.7432 - val_loss: 0.3405 - val_binary_accuracy: 0.8231 - val_precision: 0.7768 - val_recall: 0.8581\n",
      "Epoch 744/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.3405 - binary_accuracy: 0.8231 - precision: 0.7768 - recall: 0.8581 - val_loss: 0.3594 - val_binary_accuracy: 0.7985 - val_precision: 0.8767 - val_recall: 0.6486\n",
      "Epoch 745/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.3594 - binary_accuracy: 0.7985 - precision: 0.8767 - recall: 0.6486 - val_loss: 0.3806 - val_binary_accuracy: 0.7969 - val_precision: 0.9059 - val_recall: 0.6182\n",
      "Epoch 746/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.3806 - binary_accuracy: 0.7969 - precision: 0.9059 - recall: 0.6182 - val_loss: 0.3004 - val_binary_accuracy: 0.8662 - val_precision: 0.9130 - val_recall: 0.7804\n",
      "Epoch 747/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3004 - binary_accuracy: 0.8662 - precision: 0.9130 - recall: 0.7804 - val_loss: 0.3394 - val_binary_accuracy: 0.8154 - val_precision: 0.7514 - val_recall: 0.8885\n",
      "Epoch 748/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.3394 - binary_accuracy: 0.8154 - precision: 0.7514 - recall: 0.8885 - val_loss: 0.3263 - val_binary_accuracy: 0.8492 - val_precision: 0.8694 - val_recall: 0.7872\n",
      "Epoch 749/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3263 - binary_accuracy: 0.8492 - precision: 0.8694 - recall: 0.7872 - val_loss: 0.2858 - val_binary_accuracy: 0.8615 - val_precision: 0.9087 - val_recall: 0.7736\n",
      "Epoch 750/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2858 - binary_accuracy: 0.8615 - precision: 0.9087 - recall: 0.7736 - val_loss: 0.3176 - val_binary_accuracy: 0.8338 - val_precision: 0.8701 - val_recall: 0.7466\n",
      "Epoch 751/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3176 - binary_accuracy: 0.8338 - precision: 0.8701 - recall: 0.7466 - val_loss: 0.2791 - val_binary_accuracy: 0.8785 - val_precision: 0.9189 - val_recall: 0.8041\n",
      "Epoch 752/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2791 - binary_accuracy: 0.8785 - precision: 0.9189 - recall: 0.8041 - val_loss: 0.2898 - val_binary_accuracy: 0.8662 - val_precision: 0.8746 - val_recall: 0.8243\n",
      "Epoch 753/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2898 - binary_accuracy: 0.8662 - precision: 0.8746 - recall: 0.8243 - val_loss: 0.2811 - val_binary_accuracy: 0.8738 - val_precision: 0.8963 - val_recall: 0.8176\n",
      "Epoch 754/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.2811 - binary_accuracy: 0.8738 - precision: 0.8963 - recall: 0.8176 - val_loss: 0.2642 - val_binary_accuracy: 0.8754 - val_precision: 0.8938 - val_recall: 0.8243\n",
      "Epoch 755/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2642 - binary_accuracy: 0.8754 - precision: 0.8938 - recall: 0.8243 - val_loss: 0.2701 - val_binary_accuracy: 0.8677 - val_precision: 0.8889 - val_recall: 0.8108\n",
      "Epoch 756/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2701 - binary_accuracy: 0.8677 - precision: 0.8889 - recall: 0.8108 - val_loss: 0.2603 - val_binary_accuracy: 0.8800 - val_precision: 0.9160 - val_recall: 0.8108\n",
      "Epoch 757/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2603 - binary_accuracy: 0.8800 - precision: 0.9160 - recall: 0.8108 - val_loss: 0.2588 - val_binary_accuracy: 0.8754 - val_precision: 0.8938 - val_recall: 0.8243\n",
      "Epoch 758/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2588 - binary_accuracy: 0.8754 - precision: 0.8938 - recall: 0.8243 - val_loss: 0.2411 - val_binary_accuracy: 0.9169 - val_precision: 0.9416 - val_recall: 0.8716\n",
      "Epoch 759/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2411 - binary_accuracy: 0.9169 - precision: 0.9416 - recall: 0.8716 - val_loss: 0.2530 - val_binary_accuracy: 0.8862 - val_precision: 0.9173 - val_recall: 0.8243\n",
      "Epoch 760/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2530 - binary_accuracy: 0.8862 - precision: 0.9173 - recall: 0.8243 - val_loss: 0.2345 - val_binary_accuracy: 0.9062 - val_precision: 0.9401 - val_recall: 0.8480\n",
      "Epoch 761/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2345 - binary_accuracy: 0.9062 - precision: 0.9401 - recall: 0.8480 - val_loss: 0.2484 - val_binary_accuracy: 0.8908 - val_precision: 0.8893 - val_recall: 0.8682\n",
      "Epoch 762/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2484 - binary_accuracy: 0.8908 - precision: 0.8893 - recall: 0.8682 - val_loss: 0.2196 - val_binary_accuracy: 0.9154 - val_precision: 0.9382 - val_recall: 0.8716\n",
      "Epoch 763/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2196 - binary_accuracy: 0.9154 - precision: 0.9382 - recall: 0.8716 - val_loss: 0.2360 - val_binary_accuracy: 0.8938 - val_precision: 0.9283 - val_recall: 0.8311\n",
      "Epoch 764/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2360 - binary_accuracy: 0.8938 - precision: 0.9283 - recall: 0.8311 - val_loss: 0.2228 - val_binary_accuracy: 0.9046 - val_precision: 0.9366 - val_recall: 0.8480\n",
      "Epoch 765/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2228 - binary_accuracy: 0.9046 - precision: 0.9366 - recall: 0.8480 - val_loss: 0.2498 - val_binary_accuracy: 0.8954 - val_precision: 0.9014 - val_recall: 0.8649\n",
      "Epoch 766/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2498 - binary_accuracy: 0.8954 - precision: 0.9014 - recall: 0.8649 - val_loss: 0.3387 - val_binary_accuracy: 0.8477 - val_precision: 0.8689 - val_recall: 0.7838\n",
      "Epoch 767/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3387 - binary_accuracy: 0.8477 - precision: 0.8689 - recall: 0.7838 - val_loss: 0.3251 - val_binary_accuracy: 0.8385 - val_precision: 0.8215 - val_recall: 0.8243\n",
      "Epoch 768/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3251 - binary_accuracy: 0.8385 - precision: 0.8215 - recall: 0.8243 - val_loss: 0.3006 - val_binary_accuracy: 0.8600 - val_precision: 0.9253 - val_recall: 0.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.3006 - binary_accuracy: 0.8600 - precision: 0.9253 - recall: 0.7534 - val_loss: 0.2953 - val_binary_accuracy: 0.8785 - val_precision: 0.8511 - val_recall: 0.8885\n",
      "Epoch 770/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2953 - binary_accuracy: 0.8785 - precision: 0.8511 - recall: 0.8885 - val_loss: 0.2828 - val_binary_accuracy: 0.8677 - val_precision: 0.8918 - val_recall: 0.8074\n",
      "Epoch 771/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2828 - binary_accuracy: 0.8677 - precision: 0.8918 - recall: 0.8074 - val_loss: 0.2745 - val_binary_accuracy: 0.8708 - val_precision: 0.9649 - val_recall: 0.7432\n",
      "Epoch 772/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2745 - binary_accuracy: 0.8708 - precision: 0.9649 - recall: 0.7432 - val_loss: 0.2868 - val_binary_accuracy: 0.8631 - val_precision: 0.8462 - val_recall: 0.8547\n",
      "Epoch 773/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2868 - binary_accuracy: 0.8631 - precision: 0.8462 - recall: 0.8547 - val_loss: 0.2392 - val_binary_accuracy: 0.8708 - val_precision: 0.8354 - val_recall: 0.8919\n",
      "Epoch 774/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2392 - binary_accuracy: 0.8708 - precision: 0.8354 - recall: 0.8919 - val_loss: 0.2467 - val_binary_accuracy: 0.8862 - val_precision: 0.9336 - val_recall: 0.8074\n",
      "Epoch 775/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2467 - binary_accuracy: 0.8862 - precision: 0.9336 - recall: 0.8074 - val_loss: 0.2441 - val_binary_accuracy: 0.8877 - val_precision: 0.9514 - val_recall: 0.7939\n",
      "Epoch 776/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2441 - binary_accuracy: 0.8877 - precision: 0.9514 - recall: 0.7939 - val_loss: 0.2403 - val_binary_accuracy: 0.8862 - val_precision: 0.8964 - val_recall: 0.8480\n",
      "Epoch 777/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2403 - binary_accuracy: 0.8862 - precision: 0.8964 - recall: 0.8480 - val_loss: 0.2333 - val_binary_accuracy: 0.8892 - val_precision: 0.8613 - val_recall: 0.9020\n",
      "Epoch 778/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2333 - binary_accuracy: 0.8892 - precision: 0.8613 - recall: 0.9020 - val_loss: 0.2175 - val_binary_accuracy: 0.9092 - val_precision: 0.9341 - val_recall: 0.8615\n",
      "Epoch 779/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2175 - binary_accuracy: 0.9092 - precision: 0.9341 - recall: 0.8615 - val_loss: 0.2283 - val_binary_accuracy: 0.9046 - val_precision: 0.9795 - val_recall: 0.8074\n",
      "Epoch 780/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2283 - binary_accuracy: 0.9046 - precision: 0.9795 - recall: 0.8074 - val_loss: 0.2025 - val_binary_accuracy: 0.9092 - val_precision: 0.9405 - val_recall: 0.8547\n",
      "Epoch 781/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2025 - binary_accuracy: 0.9092 - precision: 0.9405 - recall: 0.8547 - val_loss: 0.2189 - val_binary_accuracy: 0.8923 - val_precision: 0.8717 - val_recall: 0.8953\n",
      "Epoch 782/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2189 - binary_accuracy: 0.8923 - precision: 0.8717 - recall: 0.8953 - val_loss: 0.1928 - val_binary_accuracy: 0.9231 - val_precision: 0.9590 - val_recall: 0.8682\n",
      "Epoch 783/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1928 - binary_accuracy: 0.9231 - precision: 0.9590 - recall: 0.8682 - val_loss: 0.1981 - val_binary_accuracy: 0.9185 - val_precision: 0.9728 - val_recall: 0.8446\n",
      "Epoch 784/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1981 - binary_accuracy: 0.9185 - precision: 0.9728 - recall: 0.8446 - val_loss: 0.1934 - val_binary_accuracy: 0.9123 - val_precision: 0.9509 - val_recall: 0.8514\n",
      "Epoch 785/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1934 - binary_accuracy: 0.9123 - precision: 0.9509 - recall: 0.8514 - val_loss: 0.1876 - val_binary_accuracy: 0.9200 - val_precision: 0.8910 - val_recall: 0.9392\n",
      "Epoch 786/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1876 - binary_accuracy: 0.9200 - precision: 0.8910 - recall: 0.9392 - val_loss: 0.1842 - val_binary_accuracy: 0.9200 - val_precision: 0.9388 - val_recall: 0.8818\n",
      "Epoch 787/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1842 - binary_accuracy: 0.9200 - precision: 0.9388 - recall: 0.8818 - val_loss: 0.1852 - val_binary_accuracy: 0.9262 - val_precision: 0.9844 - val_recall: 0.8514\n",
      "Epoch 788/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1852 - binary_accuracy: 0.9262 - precision: 0.9844 - recall: 0.8514 - val_loss: 0.1797 - val_binary_accuracy: 0.9308 - val_precision: 0.9631 - val_recall: 0.8818\n",
      "Epoch 789/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1797 - binary_accuracy: 0.9308 - precision: 0.9631 - recall: 0.8818 - val_loss: 0.1743 - val_binary_accuracy: 0.9200 - val_precision: 0.8935 - val_recall: 0.9358\n",
      "Epoch 790/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1743 - binary_accuracy: 0.9200 - precision: 0.8935 - recall: 0.9358 - val_loss: 0.1689 - val_binary_accuracy: 0.9277 - val_precision: 0.9278 - val_recall: 0.9122\n",
      "Epoch 791/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1689 - binary_accuracy: 0.9277 - precision: 0.9278 - recall: 0.9122 - val_loss: 0.1686 - val_binary_accuracy: 0.9308 - val_precision: 0.9846 - val_recall: 0.8615\n",
      "Epoch 792/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1686 - binary_accuracy: 0.9308 - precision: 0.9846 - recall: 0.8615 - val_loss: 0.1643 - val_binary_accuracy: 0.9308 - val_precision: 0.9564 - val_recall: 0.8885\n",
      "Epoch 793/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1643 - binary_accuracy: 0.9308 - precision: 0.9564 - recall: 0.8885 - val_loss: 0.1572 - val_binary_accuracy: 0.9446 - val_precision: 0.9514 - val_recall: 0.9257\n",
      "Epoch 794/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1572 - binary_accuracy: 0.9446 - precision: 0.9514 - recall: 0.9257 - val_loss: 0.1649 - val_binary_accuracy: 0.9308 - val_precision: 0.9254 - val_recall: 0.9223\n",
      "Epoch 795/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1649 - binary_accuracy: 0.9308 - precision: 0.9254 - recall: 0.9223 - val_loss: 0.1589 - val_binary_accuracy: 0.9323 - val_precision: 0.9701 - val_recall: 0.8784\n",
      "Epoch 796/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1589 - binary_accuracy: 0.9323 - precision: 0.9701 - recall: 0.8784 - val_loss: 0.1565 - val_binary_accuracy: 0.9400 - val_precision: 0.9606 - val_recall: 0.9054\n",
      "Epoch 797/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1565 - binary_accuracy: 0.9400 - precision: 0.9606 - recall: 0.9054 - val_loss: 0.1640 - val_binary_accuracy: 0.9292 - val_precision: 0.9195 - val_recall: 0.9257\n",
      "Epoch 798/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1640 - binary_accuracy: 0.9292 - precision: 0.9195 - recall: 0.9257 - val_loss: 0.1558 - val_binary_accuracy: 0.9385 - val_precision: 0.9672 - val_recall: 0.8953\n",
      "Epoch 799/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1558 - binary_accuracy: 0.9385 - precision: 0.9672 - recall: 0.8953 - val_loss: 0.1357 - val_binary_accuracy: 0.9492 - val_precision: 0.9550 - val_recall: 0.9324\n",
      "Epoch 800/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1357 - binary_accuracy: 0.9492 - precision: 0.9550 - recall: 0.9324 - val_loss: 0.1338 - val_binary_accuracy: 0.9554 - val_precision: 0.9890 - val_recall: 0.9122\n",
      "Epoch 801/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1338 - binary_accuracy: 0.9554 - precision: 0.9890 - recall: 0.9122 - val_loss: 0.1425 - val_binary_accuracy: 0.9415 - val_precision: 0.9574 - val_recall: 0.9122\n",
      "Epoch 802/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1425 - binary_accuracy: 0.9415 - precision: 0.9574 - recall: 0.9122 - val_loss: 0.2056 - val_binary_accuracy: 0.8923 - val_precision: 0.8951 - val_recall: 0.8649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2056 - binary_accuracy: 0.8923 - precision: 0.8951 - recall: 0.8649 - val_loss: 0.5463 - val_binary_accuracy: 0.7908 - val_precision: 0.7837 - val_recall: 0.7466\n",
      "Epoch 804/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5463 - binary_accuracy: 0.7908 - precision: 0.7837 - recall: 0.7466 - val_loss: 0.3425 - val_binary_accuracy: 0.8508 - val_precision: 0.8373 - val_recall: 0.8345\n",
      "Epoch 805/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3425 - binary_accuracy: 0.8508 - precision: 0.8373 - recall: 0.8345 - val_loss: 0.4688 - val_binary_accuracy: 0.7969 - val_precision: 0.7908 - val_recall: 0.7534\n",
      "Epoch 806/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4688 - binary_accuracy: 0.7969 - precision: 0.7908 - recall: 0.7534 - val_loss: 0.2704 - val_binary_accuracy: 0.8662 - val_precision: 0.9197 - val_recall: 0.7736\n",
      "Epoch 807/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.2704 - binary_accuracy: 0.8662 - precision: 0.9197 - recall: 0.7736 - val_loss: 0.4423 - val_binary_accuracy: 0.7600 - val_precision: 0.6741 - val_recall: 0.9155\n",
      "Epoch 808/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4423 - binary_accuracy: 0.7600 - precision: 0.6741 - recall: 0.9155 - val_loss: 0.2874 - val_binary_accuracy: 0.8754 - val_precision: 0.9909 - val_recall: 0.7331\n",
      "Epoch 809/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2874 - binary_accuracy: 0.8754 - precision: 0.9909 - recall: 0.7331 - val_loss: 0.3856 - val_binary_accuracy: 0.8262 - val_precision: 0.8327 - val_recall: 0.7736\n",
      "Epoch 810/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3856 - binary_accuracy: 0.8262 - precision: 0.8327 - recall: 0.7736 - val_loss: 0.2278 - val_binary_accuracy: 0.8938 - val_precision: 0.8348 - val_recall: 0.9561\n",
      "Epoch 811/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2278 - binary_accuracy: 0.8938 - precision: 0.8348 - recall: 0.9561 - val_loss: 0.3366 - val_binary_accuracy: 0.8292 - val_precision: 0.8715 - val_recall: 0.7331\n",
      "Epoch 812/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.3366 - binary_accuracy: 0.8292 - precision: 0.8715 - recall: 0.7331 - val_loss: 0.1978 - val_binary_accuracy: 0.9123 - val_precision: 0.9314 - val_recall: 0.8716\n",
      "Epoch 813/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1978 - binary_accuracy: 0.9123 - precision: 0.9314 - recall: 0.8716 - val_loss: 0.2760 - val_binary_accuracy: 0.8585 - val_precision: 0.8493 - val_recall: 0.8378\n",
      "Epoch 814/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.2760 - binary_accuracy: 0.8585 - precision: 0.8493 - recall: 0.8378 - val_loss: 0.2028 - val_binary_accuracy: 0.9123 - val_precision: 0.9314 - val_recall: 0.8716\n",
      "Epoch 815/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2028 - binary_accuracy: 0.9123 - precision: 0.9314 - recall: 0.8716 - val_loss: 0.2031 - val_binary_accuracy: 0.9108 - val_precision: 0.9440 - val_recall: 0.8547\n",
      "Epoch 816/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2031 - binary_accuracy: 0.9108 - precision: 0.9440 - recall: 0.8547 - val_loss: 0.2281 - val_binary_accuracy: 0.8954 - val_precision: 0.9014 - val_recall: 0.8649\n",
      "Epoch 817/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2281 - binary_accuracy: 0.8954 - precision: 0.9014 - recall: 0.8649 - val_loss: 0.1821 - val_binary_accuracy: 0.9246 - val_precision: 0.9103 - val_recall: 0.9257\n",
      "Epoch 818/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.1821 - binary_accuracy: 0.9246 - precision: 0.9103 - recall: 0.9257 - val_loss: 0.1921 - val_binary_accuracy: 0.9246 - val_precision: 0.9427 - val_recall: 0.8885\n",
      "Epoch 819/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.1921 - binary_accuracy: 0.9246 - precision: 0.9427 - recall: 0.8885 - val_loss: 0.1996 - val_binary_accuracy: 0.9108 - val_precision: 0.9648 - val_recall: 0.8345\n",
      "Epoch 820/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1996 - binary_accuracy: 0.9108 - precision: 0.9648 - recall: 0.8345 - val_loss: 0.1823 - val_binary_accuracy: 0.9231 - val_precision: 0.9393 - val_recall: 0.8885\n",
      "Epoch 821/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1823 - binary_accuracy: 0.9231 - precision: 0.9393 - recall: 0.8885 - val_loss: 0.1768 - val_binary_accuracy: 0.9292 - val_precision: 0.9371 - val_recall: 0.9054\n",
      "Epoch 822/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1768 - binary_accuracy: 0.9292 - precision: 0.9371 - recall: 0.9054 - val_loss: 0.1602 - val_binary_accuracy: 0.9415 - val_precision: 0.9674 - val_recall: 0.9020\n",
      "Epoch 823/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1602 - binary_accuracy: 0.9415 - precision: 0.9674 - recall: 0.9020 - val_loss: 0.1577 - val_binary_accuracy: 0.9385 - val_precision: 0.9604 - val_recall: 0.9020\n",
      "Epoch 824/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1577 - binary_accuracy: 0.9385 - precision: 0.9604 - recall: 0.9020 - val_loss: 0.1519 - val_binary_accuracy: 0.9354 - val_precision: 0.9504 - val_recall: 0.9054\n",
      "Epoch 825/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1519 - binary_accuracy: 0.9354 - precision: 0.9504 - recall: 0.9054 - val_loss: 0.1429 - val_binary_accuracy: 0.9554 - val_precision: 0.9751 - val_recall: 0.9257\n",
      "Epoch 826/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.1429 - binary_accuracy: 0.9554 - precision: 0.9751 - recall: 0.9257 - val_loss: 0.1488 - val_binary_accuracy: 0.9400 - val_precision: 0.9573 - val_recall: 0.9088\n",
      "Epoch 827/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1488 - binary_accuracy: 0.9400 - precision: 0.9573 - recall: 0.9088 - val_loss: 0.1364 - val_binary_accuracy: 0.9569 - val_precision: 0.9786 - val_recall: 0.9257\n",
      "Epoch 828/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1364 - binary_accuracy: 0.9569 - precision: 0.9786 - recall: 0.9257 - val_loss: 0.1292 - val_binary_accuracy: 0.9538 - val_precision: 0.9854 - val_recall: 0.9122\n",
      "Epoch 829/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1292 - binary_accuracy: 0.9538 - precision: 0.9854 - recall: 0.9122 - val_loss: 0.1367 - val_binary_accuracy: 0.9523 - val_precision: 0.9492 - val_recall: 0.9459\n",
      "Epoch 830/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1367 - binary_accuracy: 0.9523 - precision: 0.9492 - recall: 0.9459 - val_loss: 0.1238 - val_binary_accuracy: 0.9538 - val_precision: 0.9586 - val_recall: 0.9392\n",
      "Epoch 831/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1238 - binary_accuracy: 0.9538 - precision: 0.9586 - recall: 0.9392 - val_loss: 0.1256 - val_binary_accuracy: 0.9523 - val_precision: 0.9749 - val_recall: 0.9189\n",
      "Epoch 832/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.1256 - binary_accuracy: 0.9523 - precision: 0.9749 - recall: 0.9189 - val_loss: 0.1217 - val_binary_accuracy: 0.9585 - val_precision: 0.9821 - val_recall: 0.9257\n",
      "Epoch 833/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1217 - binary_accuracy: 0.9585 - precision: 0.9821 - recall: 0.9257 - val_loss: 0.1130 - val_binary_accuracy: 0.9600 - val_precision: 0.9754 - val_recall: 0.9358\n",
      "Epoch 834/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.1130 - binary_accuracy: 0.9600 - precision: 0.9754 - recall: 0.9358 - val_loss: 0.1175 - val_binary_accuracy: 0.9585 - val_precision: 0.9686 - val_recall: 0.9392\n",
      "Epoch 835/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1175 - binary_accuracy: 0.9585 - precision: 0.9686 - recall: 0.9392 - val_loss: 0.1064 - val_binary_accuracy: 0.9692 - val_precision: 0.9894 - val_recall: 0.9426\n",
      "Epoch 836/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1064 - binary_accuracy: 0.9692 - precision: 0.9894 - recall: 0.9426 - val_loss: 0.1080 - val_binary_accuracy: 0.9692 - val_precision: 0.9894 - val_recall: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1080 - binary_accuracy: 0.9692 - precision: 0.9894 - recall: 0.9426 - val_loss: 0.1044 - val_binary_accuracy: 0.9677 - val_precision: 0.9758 - val_recall: 0.9527\n",
      "Epoch 838/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1044 - binary_accuracy: 0.9677 - precision: 0.9758 - recall: 0.9527 - val_loss: 0.0976 - val_binary_accuracy: 0.9692 - val_precision: 0.9726 - val_recall: 0.9595\n",
      "Epoch 839/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0976 - binary_accuracy: 0.9692 - precision: 0.9726 - recall: 0.9595 - val_loss: 0.1002 - val_binary_accuracy: 0.9723 - val_precision: 0.9860 - val_recall: 0.9527\n",
      "Epoch 840/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1002 - binary_accuracy: 0.9723 - precision: 0.9860 - recall: 0.9527 - val_loss: 0.0951 - val_binary_accuracy: 0.9615 - val_precision: 0.9927 - val_recall: 0.9223\n",
      "Epoch 841/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.0951 - binary_accuracy: 0.9615 - precision: 0.9927 - recall: 0.9223 - val_loss: 0.0933 - val_binary_accuracy: 0.9769 - val_precision: 0.9828 - val_recall: 0.9662\n",
      "Epoch 842/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.0933 - binary_accuracy: 0.9769 - precision: 0.9828 - recall: 0.9662 - val_loss: 0.0915 - val_binary_accuracy: 0.9815 - val_precision: 0.9931 - val_recall: 0.9662\n",
      "Epoch 843/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.0915 - binary_accuracy: 0.9815 - precision: 0.9931 - recall: 0.9662 - val_loss: 0.0871 - val_binary_accuracy: 0.9723 - val_precision: 0.9894 - val_recall: 0.9493\n",
      "Epoch 844/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.0871 - binary_accuracy: 0.9723 - precision: 0.9894 - recall: 0.9493 - val_loss: 0.0832 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 845/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.0832 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0823 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 846/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.0823 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0837 - val_binary_accuracy: 0.9738 - val_precision: 0.9861 - val_recall: 0.9561\n",
      "Epoch 847/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0837 - binary_accuracy: 0.9738 - precision: 0.9861 - recall: 0.9561 - val_loss: 0.0784 - val_binary_accuracy: 0.9800 - val_precision: 0.9930 - val_recall: 0.9628\n",
      "Epoch 848/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0784 - binary_accuracy: 0.9800 - precision: 0.9930 - recall: 0.9628 - val_loss: 0.0774 - val_binary_accuracy: 0.9862 - val_precision: 0.9832 - val_recall: 0.9865\n",
      "Epoch 849/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0774 - binary_accuracy: 0.9862 - precision: 0.9832 - recall: 0.9865 - val_loss: 0.0829 - val_binary_accuracy: 0.9723 - val_precision: 0.9964 - val_recall: 0.9426\n",
      "Epoch 850/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0829 - binary_accuracy: 0.9723 - precision: 0.9964 - recall: 0.9426 - val_loss: 0.0857 - val_binary_accuracy: 0.9738 - val_precision: 0.9574 - val_recall: 0.9865\n",
      "Epoch 851/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.0857 - binary_accuracy: 0.9738 - precision: 0.9574 - recall: 0.9865 - val_loss: 0.1015 - val_binary_accuracy: 0.9569 - val_precision: 0.9855 - val_recall: 0.9189\n",
      "Epoch 852/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1015 - binary_accuracy: 0.9569 - precision: 0.9855 - recall: 0.9189 - val_loss: 0.1187 - val_binary_accuracy: 0.9492 - val_precision: 0.9071 - val_recall: 0.9899\n",
      "Epoch 853/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1187 - binary_accuracy: 0.9492 - precision: 0.9071 - recall: 0.9899 - val_loss: 0.1656 - val_binary_accuracy: 0.9200 - val_precision: 0.9552 - val_recall: 0.8649\n",
      "Epoch 854/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1656 - binary_accuracy: 0.9200 - precision: 0.9552 - recall: 0.8649 - val_loss: 0.3733 - val_binary_accuracy: 0.8508 - val_precision: 0.8241 - val_recall: 0.8547\n",
      "Epoch 855/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3733 - binary_accuracy: 0.8508 - precision: 0.8241 - recall: 0.8547 - val_loss: 0.7544 - val_binary_accuracy: 0.7369 - val_precision: 0.6972 - val_recall: 0.7466\n",
      "Epoch 856/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.7544 - binary_accuracy: 0.7369 - precision: 0.6972 - recall: 0.7466 - val_loss: 0.2921 - val_binary_accuracy: 0.8754 - val_precision: 0.9249 - val_recall: 0.7905\n",
      "Epoch 857/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2921 - binary_accuracy: 0.8754 - precision: 0.9249 - recall: 0.7905 - val_loss: 0.6249 - val_binary_accuracy: 0.7477 - val_precision: 0.6813 - val_recall: 0.8378\n",
      "Epoch 858/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.6249 - binary_accuracy: 0.7477 - precision: 0.6813 - recall: 0.8378 - val_loss: 0.4036 - val_binary_accuracy: 0.8492 - val_precision: 0.8837 - val_recall: 0.7703\n",
      "Epoch 859/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4036 - binary_accuracy: 0.8492 - precision: 0.8837 - recall: 0.7703 - val_loss: 0.3974 - val_binary_accuracy: 0.8385 - val_precision: 0.8259 - val_recall: 0.8176\n",
      "Epoch 860/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3974 - binary_accuracy: 0.8385 - precision: 0.8259 - recall: 0.8176 - val_loss: 0.3430 - val_binary_accuracy: 0.8646 - val_precision: 0.8562 - val_recall: 0.8446\n",
      "Epoch 861/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.3430 - binary_accuracy: 0.8646 - precision: 0.8562 - recall: 0.8446 - val_loss: 0.2538 - val_binary_accuracy: 0.8969 - val_precision: 0.9288 - val_recall: 0.8378\n",
      "Epoch 862/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2538 - binary_accuracy: 0.8969 - precision: 0.9288 - recall: 0.8378 - val_loss: 0.3044 - val_binary_accuracy: 0.8415 - val_precision: 0.8249 - val_recall: 0.8277\n",
      "Epoch 863/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3044 - binary_accuracy: 0.8415 - precision: 0.8249 - recall: 0.8277 - val_loss: 0.2697 - val_binary_accuracy: 0.8769 - val_precision: 0.8750 - val_recall: 0.8514\n",
      "Epoch 864/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2697 - binary_accuracy: 0.8769 - precision: 0.8750 - recall: 0.8514 - val_loss: 0.1848 - val_binary_accuracy: 0.9169 - val_precision: 0.9231 - val_recall: 0.8919\n",
      "Epoch 865/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1848 - binary_accuracy: 0.9169 - precision: 0.9231 - recall: 0.8919 - val_loss: 0.2501 - val_binary_accuracy: 0.8923 - val_precision: 0.9065 - val_recall: 0.8514\n",
      "Epoch 866/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2501 - binary_accuracy: 0.8923 - precision: 0.9065 - recall: 0.8514 - val_loss: 0.2155 - val_binary_accuracy: 0.9108 - val_precision: 0.8993 - val_recall: 0.9054\n",
      "Epoch 867/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2155 - binary_accuracy: 0.9108 - precision: 0.8993 - recall: 0.9054 - val_loss: 0.1688 - val_binary_accuracy: 0.9323 - val_precision: 0.9375 - val_recall: 0.9122\n",
      "Epoch 868/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1688 - binary_accuracy: 0.9323 - precision: 0.9375 - recall: 0.9122 - val_loss: 0.2072 - val_binary_accuracy: 0.9062 - val_precision: 0.9502 - val_recall: 0.8378\n",
      "Epoch 869/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.2072 - binary_accuracy: 0.9062 - precision: 0.9502 - recall: 0.8378 - val_loss: 0.1704 - val_binary_accuracy: 0.9262 - val_precision: 0.9493 - val_recall: 0.8851\n",
      "Epoch 870/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.1704 - binary_accuracy: 0.9262 - precision: 0.9493 - recall: 0.8851 - val_loss: 0.1501 - val_binary_accuracy: 0.9431 - val_precision: 0.9246 - val_recall: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1501 - binary_accuracy: 0.9431 - precision: 0.9246 - recall: 0.9527 - val_loss: 0.1620 - val_binary_accuracy: 0.9415 - val_precision: 0.9607 - val_recall: 0.9088\n",
      "Epoch 872/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1620 - binary_accuracy: 0.9415 - precision: 0.9607 - recall: 0.9088 - val_loss: 0.1567 - val_binary_accuracy: 0.9323 - val_precision: 0.9737 - val_recall: 0.8750\n",
      "Epoch 873/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1567 - binary_accuracy: 0.9323 - precision: 0.9737 - recall: 0.8750 - val_loss: 0.1443 - val_binary_accuracy: 0.9400 - val_precision: 0.9477 - val_recall: 0.9189\n",
      "Epoch 874/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1443 - binary_accuracy: 0.9400 - precision: 0.9477 - recall: 0.9189 - val_loss: 0.1457 - val_binary_accuracy: 0.9400 - val_precision: 0.9241 - val_recall: 0.9459\n",
      "Epoch 875/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 0.1457 - binary_accuracy: 0.9400 - precision: 0.9241 - recall: 0.9459 - val_loss: 0.1216 - val_binary_accuracy: 0.9569 - val_precision: 0.9558 - val_recall: 0.9493\n",
      "Epoch 876/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1216 - binary_accuracy: 0.9569 - precision: 0.9558 - recall: 0.9493 - val_loss: 0.1284 - val_binary_accuracy: 0.9492 - val_precision: 0.9817 - val_recall: 0.9054\n",
      "Epoch 877/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1284 - binary_accuracy: 0.9492 - precision: 0.9817 - recall: 0.9054 - val_loss: 0.1293 - val_binary_accuracy: 0.9446 - val_precision: 0.9610 - val_recall: 0.9155\n",
      "Epoch 878/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.1293 - binary_accuracy: 0.9446 - precision: 0.9610 - recall: 0.9155 - val_loss: 0.1105 - val_binary_accuracy: 0.9585 - val_precision: 0.9529 - val_recall: 0.9561\n",
      "Epoch 879/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1105 - binary_accuracy: 0.9585 - precision: 0.9529 - recall: 0.9561 - val_loss: 0.1087 - val_binary_accuracy: 0.9631 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 880/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1087 - binary_accuracy: 0.9631 - precision: 0.9595 - recall: 0.9595 - val_loss: 0.1101 - val_binary_accuracy: 0.9585 - val_precision: 0.9786 - val_recall: 0.9291\n",
      "Epoch 881/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1101 - binary_accuracy: 0.9585 - precision: 0.9786 - recall: 0.9291 - val_loss: 0.1022 - val_binary_accuracy: 0.9631 - val_precision: 0.9857 - val_recall: 0.9324\n",
      "Epoch 882/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1022 - binary_accuracy: 0.9631 - precision: 0.9857 - recall: 0.9324 - val_loss: 0.0972 - val_binary_accuracy: 0.9738 - val_precision: 0.9761 - val_recall: 0.9662\n",
      "Epoch 883/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0972 - binary_accuracy: 0.9738 - precision: 0.9761 - recall: 0.9662 - val_loss: 0.0991 - val_binary_accuracy: 0.9615 - val_precision: 0.9472 - val_recall: 0.9696\n",
      "Epoch 884/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0991 - binary_accuracy: 0.9615 - precision: 0.9472 - recall: 0.9696 - val_loss: 0.0906 - val_binary_accuracy: 0.9800 - val_precision: 0.9930 - val_recall: 0.9628\n",
      "Epoch 885/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.0906 - binary_accuracy: 0.9800 - precision: 0.9930 - recall: 0.9628 - val_loss: 0.0928 - val_binary_accuracy: 0.9662 - val_precision: 0.9928 - val_recall: 0.9324\n",
      "Epoch 886/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0928 - binary_accuracy: 0.9662 - precision: 0.9928 - recall: 0.9324 - val_loss: 0.0864 - val_binary_accuracy: 0.9723 - val_precision: 0.9860 - val_recall: 0.9527\n",
      "Epoch 887/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.0864 - binary_accuracy: 0.9723 - precision: 0.9860 - recall: 0.9527 - val_loss: 0.0846 - val_binary_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9797\n",
      "Epoch 888/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0846 - binary_accuracy: 0.9831 - precision: 0.9831 - recall: 0.9797 - val_loss: 0.0826 - val_binary_accuracy: 0.9800 - val_precision: 0.9863 - val_recall: 0.9696\n",
      "Epoch 889/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0826 - binary_accuracy: 0.9800 - precision: 0.9863 - recall: 0.9696 - val_loss: 0.0791 - val_binary_accuracy: 0.9785 - val_precision: 0.9930 - val_recall: 0.9595\n",
      "Epoch 890/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0791 - binary_accuracy: 0.9785 - precision: 0.9930 - recall: 0.9595 - val_loss: 0.0757 - val_binary_accuracy: 0.9815 - val_precision: 0.9863 - val_recall: 0.9730\n",
      "Epoch 891/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0757 - binary_accuracy: 0.9815 - precision: 0.9863 - recall: 0.9730 - val_loss: 0.0745 - val_binary_accuracy: 0.9800 - val_precision: 0.9764 - val_recall: 0.9797\n",
      "Epoch 892/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0745 - binary_accuracy: 0.9800 - precision: 0.9764 - recall: 0.9797 - val_loss: 0.0713 - val_binary_accuracy: 0.9831 - val_precision: 0.9897 - val_recall: 0.9730\n",
      "Epoch 893/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.0713 - binary_accuracy: 0.9831 - precision: 0.9897 - recall: 0.9730 - val_loss: 0.0681 - val_binary_accuracy: 0.9815 - val_precision: 0.9965 - val_recall: 0.9628\n",
      "Epoch 894/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.0681 - binary_accuracy: 0.9815 - precision: 0.9965 - recall: 0.9628 - val_loss: 0.0673 - val_binary_accuracy: 0.9800 - val_precision: 0.9896 - val_recall: 0.9662\n",
      "Epoch 895/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0673 - binary_accuracy: 0.9800 - precision: 0.9896 - recall: 0.9662 - val_loss: 0.0658 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 896/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0658 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0615 - val_binary_accuracy: 0.9877 - val_precision: 0.9966 - val_recall: 0.9764\n",
      "Epoch 897/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0615 - binary_accuracy: 0.9877 - precision: 0.9966 - recall: 0.9764 - val_loss: 0.0608 - val_binary_accuracy: 0.9862 - val_precision: 0.9965 - val_recall: 0.9730\n",
      "Epoch 898/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0608 - binary_accuracy: 0.9862 - precision: 0.9965 - recall: 0.9730 - val_loss: 0.0586 - val_binary_accuracy: 0.9892 - val_precision: 0.9932 - val_recall: 0.9831\n",
      "Epoch 899/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.0586 - binary_accuracy: 0.9892 - precision: 0.9932 - recall: 0.9831 - val_loss: 0.0577 - val_binary_accuracy: 0.9877 - val_precision: 0.9898 - val_recall: 0.9831\n",
      "Epoch 900/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.0577 - binary_accuracy: 0.9877 - precision: 0.9898 - recall: 0.9831 - val_loss: 0.0546 - val_binary_accuracy: 0.9877 - val_precision: 0.9932 - val_recall: 0.9797\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model for classification\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_5)\n",
    "\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "print(model.summary())\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  \\\n",
       "0 2019-10-22                   0.003166   \n",
       "1 2019-10-21                   0.009758   \n",
       "2 2019-10-18                   0.007230   \n",
       "3 2019-10-17                   0.000403   \n",
       "4 2019-10-16                  -0.010431   \n",
       "5 2019-10-15                   0.016905   \n",
       "6 2019-10-14                   0.001219   \n",
       "7 2019-10-11                   0.011445   \n",
       "\n",
       "                                            docs_WFC  \\\n",
       "0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "   log_adj_daily_returns_JPM  \\\n",
       "0                   0.009986   \n",
       "1                   0.024498   \n",
       "2                   0.001743   \n",
       "3                   0.005583   \n",
       "4                  -0.002337   \n",
       "5                   0.029696   \n",
       "6                   0.002666   \n",
       "7                   0.016758   \n",
       "\n",
       "                                            docs_JPM  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "\n",
       "   log_adj_daily_returns_BAC  \\\n",
       "0                   0.005786   \n",
       "1                   0.021836   \n",
       "2                   0.002970   \n",
       "3                   0.002979   \n",
       "4                   0.014691   \n",
       "5                   0.020045   \n",
       "6                   0.007924   \n",
       "7                   0.016039   \n",
       "\n",
       "                                            docs_BAC  log_adj_daily_returns_C  \\\n",
       "0                                                 []                 0.003475   \n",
       "1                                                 []                 0.029250   \n",
       "2                                                 []                 0.002009   \n",
       "3                                                 []                 0.001438   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...                -0.024447   \n",
       "5                                                 []                 0.013856   \n",
       "6                                                 []                 0.001995   \n",
       "7                                                 []                 0.021339   \n",
       "\n",
       "                                              docs_C  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "6                                                 []  \n",
       "7                                                 []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 1000\n",
    "batch_size = 2\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns', 'docs']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>docs_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>docs_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>docs_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>docs_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>docs_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>docs_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>docs_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>docs_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "      <th>docs_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "                                       docs_WFC(t-5)  \\\n",
       "1                                                 []   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5) docs_JPM(t-5)  \\\n",
       "1                        0.002666            []   \n",
       "2                        0.016758            []   \n",
       "3                        0.013931            []   \n",
       "4                        0.007218            []   \n",
       "5                       -0.022548            []   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-5) docs_BAC(t-5)  log_adj_daily_returns_C(t-5)  \\\n",
       "1                        0.007924            []                      0.001995   \n",
       "2                        0.016039            []                      0.021339   \n",
       "3                        0.019880            []                      0.017494   \n",
       "4                        0.009366            []                      0.015393   \n",
       "5                       -0.024313            []                     -0.026014   \n",
       "\n",
       "  docs_C(t-5) timestamp(t-4)  ...  \\\n",
       "1          []     2019-10-15  ...   \n",
       "2          []     2019-10-14  ...   \n",
       "3          []     2019-10-11  ...   \n",
       "4          []     2019-10-10  ...   \n",
       "5          []     2019-10-09  ...   \n",
       "\n",
       "                                         docs_C(t+0) timestamp(t+1)  \\\n",
       "1                                                 []     2019-10-22   \n",
       "2                                                 []     2019-10-21   \n",
       "3                                                 []     2019-10-18   \n",
       "4                                                 []     2019-10-17   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  \\\n",
       "1                        0.003166   \n",
       "2                        0.009758   \n",
       "3                        0.007230   \n",
       "4                        0.000403   \n",
       "5                       -0.010431   \n",
       "\n",
       "                                       docs_WFC(t+1)  \\\n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "5                                                 []   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+1) docs_JPM(t+1)  \\\n",
       "1                        0.009986            []   \n",
       "2                        0.024498            []   \n",
       "3                        0.001743            []   \n",
       "4                        0.005583            []   \n",
       "5                       -0.002337            []   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  \\\n",
       "1                        0.005786   \n",
       "2                        0.021836   \n",
       "3                        0.002970   \n",
       "4                        0.002979   \n",
       "5                        0.014691   \n",
       "\n",
       "                                       docs_BAC(t+1)  \\\n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "  log_adj_daily_returns_C(t+1)  docs_C(t+1)  \n",
       "1                     0.003475           []  \n",
       "2                     0.029250           []  \n",
       "3                     0.002009           []  \n",
       "4                     0.001438           []  \n",
       "5                    -0.024447           []  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'log_adj_daily_returns': ['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], 'docs': ['docs_WFC(t-5)', 'docs_WFC(t-4)', 'docs_WFC(t-3)', 'docs_WFC(t-2)', 'docs_WFC(t-1)', 'docs_WFC(t+0)', 'docs_WFC(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], 'docs': ['docs_JPM(t-5)', 'docs_JPM(t-4)', 'docs_JPM(t-3)', 'docs_JPM(t-2)', 'docs_JPM(t-1)', 'docs_JPM(t+0)', 'docs_JPM(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], 'docs': ['docs_BAC(t-5)', 'docs_BAC(t-4)', 'docs_BAC(t-3)', 'docs_BAC(t-2)', 'docs_BAC(t-1)', 'docs_BAC(t+0)', 'docs_BAC(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)'], 'docs': ['docs_C(t-5)', 'docs_C(t-4)', 'docs_C(t-3)', 'docs_C(t-2)', 'docs_C(t-1)', 'docs_C(t+0)', 'docs_C(t+1)']}]\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['log_adj_daily_returns', 'docs']\n",
    "col_names_obj = [{fn: [name for name in df.columns if '_'.join([fn, t]) in name] for fn in feature_names}\n",
    "             for t in tickers]\n",
    "print(col_names_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_adj_daily_returns features\n",
      "\n",
      "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
      "1                        0.001219                        0.016905   \n",
      "2                        0.011445                        0.001219   \n",
      "3                        0.010331                        0.011445   \n",
      "4                        0.006877                        0.010331   \n",
      "5                       -0.020491                        0.006877   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
      "1                       -0.010431                        0.000403   \n",
      "2                        0.016905                       -0.010431   \n",
      "3                        0.001219                        0.016905   \n",
      "4                        0.011445                        0.001219   \n",
      "5                        0.010331                        0.011445   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
      "1                        0.007230                        0.009758   \n",
      "2                        0.000403                        0.007230   \n",
      "3                       -0.010431                        0.000403   \n",
      "4                        0.016905                       -0.010431   \n",
      "5                        0.001219                        0.016905   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t+1)  \n",
      "1                        0.003166  \n",
      "2                        0.009758  \n",
      "3                        0.007230  \n",
      "4                        0.000403  \n",
      "5                       -0.010431  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_JPM(t-4)  \\\n",
      "1                        0.002666                        0.029696   \n",
      "2                        0.016758                        0.002666   \n",
      "3                        0.013931                        0.016758   \n",
      "4                        0.007218                        0.013931   \n",
      "5                       -0.022548                        0.007218   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-3)  log_adj_daily_returns_JPM(t-2)  \\\n",
      "1                       -0.002337                        0.005583   \n",
      "2                        0.029696                       -0.002337   \n",
      "3                        0.002666                        0.029696   \n",
      "4                        0.016758                        0.002666   \n",
      "5                        0.013931                        0.016758   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-1)  log_adj_daily_returns_JPM(t+0)  \\\n",
      "1                        0.001743                        0.024498   \n",
      "2                        0.005583                        0.001743   \n",
      "3                       -0.002337                        0.005583   \n",
      "4                        0.029696                       -0.002337   \n",
      "5                        0.002666                        0.029696   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t+1)  \n",
      "1                        0.009986  \n",
      "2                        0.024498  \n",
      "3                        0.001743  \n",
      "4                        0.005583  \n",
      "5                       -0.002337  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_BAC(t-5)  log_adj_daily_returns_BAC(t-4)  \\\n",
      "1                        0.007924                        0.020045   \n",
      "2                        0.016039                        0.007924   \n",
      "3                        0.019880                        0.016039   \n",
      "4                        0.009366                        0.019880   \n",
      "5                       -0.024313                        0.009366   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-3)  log_adj_daily_returns_BAC(t-2)  \\\n",
      "1                        0.014691                        0.002979   \n",
      "2                        0.020045                        0.014691   \n",
      "3                        0.007924                        0.020045   \n",
      "4                        0.016039                        0.007924   \n",
      "5                        0.019880                        0.016039   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-1)  log_adj_daily_returns_BAC(t+0)  \\\n",
      "1                        0.002970                        0.021836   \n",
      "2                        0.002979                        0.002970   \n",
      "3                        0.014691                        0.002979   \n",
      "4                        0.020045                        0.014691   \n",
      "5                        0.007924                        0.020045   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t+1)  \n",
      "1                        0.005786  \n",
      "2                        0.021836  \n",
      "3                        0.002970  \n",
      "4                        0.002979  \n",
      "5                        0.014691  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_C(t-5)  log_adj_daily_returns_C(t-4)  \\\n",
      "1                      0.001995                      0.013856   \n",
      "2                      0.021339                      0.001995   \n",
      "3                      0.017494                      0.021339   \n",
      "4                      0.015393                      0.017494   \n",
      "5                     -0.026014                      0.015393   \n",
      "\n",
      "   log_adj_daily_returns_C(t-3)  log_adj_daily_returns_C(t-2)  \\\n",
      "1                     -0.024447                      0.001438   \n",
      "2                      0.013856                     -0.024447   \n",
      "3                      0.001995                      0.013856   \n",
      "4                      0.021339                      0.001995   \n",
      "5                      0.017494                      0.021339   \n",
      "\n",
      "   log_adj_daily_returns_C(t-1)  log_adj_daily_returns_C(t+0)  \\\n",
      "1                      0.002009                      0.029250   \n",
      "2                      0.001438                      0.002009   \n",
      "3                     -0.024447                      0.001438   \n",
      "4                      0.013856                     -0.024447   \n",
      "5                      0.001995                      0.013856   \n",
      "\n",
      "   log_adj_daily_returns_C(t+1)  \n",
      "1                      0.003475  \n",
      "2                      0.029250  \n",
      "3                      0.002009  \n",
      "4                      0.001438  \n",
      "5                     -0.024447  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "docs features\n",
      "\n",
      "                                       docs_WFC(t-5)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t-4)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t-2)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t-1)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t+0)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t+1)  \n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "5                                                 []  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_JPM(t-5)                                      docs_JPM(t-4)  \\\n",
      "1            []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2            []                                                 []   \n",
      "3            []                                                 []   \n",
      "4            []                                                 []   \n",
      "5            []                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-2)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t+0) docs_JPM(t+1)  \n",
      "1                                                 []            []  \n",
      "2                                                 []            []  \n",
      "3                                                 []            []  \n",
      "4                                                 []            []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...            []  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_BAC(t-5) docs_BAC(t-4)  \\\n",
      "1            []            []   \n",
      "2            []            []   \n",
      "3            []            []   \n",
      "4            []            []   \n",
      "5            []            []   \n",
      "\n",
      "                                       docs_BAC(t-3)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t-2)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t+0)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t+1)  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3                                                 []  \n",
      "4                                                 []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_C(t-5)                                        docs_C(t-4)  \\\n",
      "1          []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2          []                                                 []   \n",
      "3          []                                                 []   \n",
      "4          []                                                 []   \n",
      "5          []                                                 []   \n",
      "\n",
      "                                         docs_C(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t-2)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t+0) docs_C(t+1)  \n",
      "1                                                 []          []  \n",
      "2                                                 []          []  \n",
      "3                                                 []          []  \n",
      "4                                                 []          []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...          []  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = [{key: df[d[key]] for key in d} for d in col_names_obj]\n",
    "\n",
    "print('log_adj_daily_returns features')\n",
    "print()\n",
    "for i in range(len(tickers)):\n",
    "    print(dfs[i]['log_adj_daily_returns'].head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "print()\n",
    "print('docs features')\n",
    "print()\n",
    "for i in range(len(tickers)):\n",
    "    print(dfs[i]['docs'].head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [{key: d[key].values for key in d} for d in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset's features: ['log_adj_daily_returns', 'docs']\n",
      "Testing if each of test_dataset's features have the same length\n",
      "Test passed, test dataset's shape: (5024, 7)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets[0] # JPM's dataset\n",
    "print('dataset\\'s features: {}'.format(list(dataset.keys())))\n",
    "print('Testing if each of test_dataset\\'s features have the same length')\n",
    "dataset_shape = dataset[list(dataset.keys())[0]].shape\n",
    "assert (dataset[key].shape == dataset_shape for key in dataset.keys())\n",
    "print('Test passed, test dataset\\'s shape: {}'.format(dataset_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of features of test_dataset with labels included: {'log_adj_daily_returns': (5024, 7), 'docs': (5024, 7)}\n",
      "Shapes of features of test_dataset with labels extracted: {'log_adj_daily_returns': (5024, 6), 'docs': (5024, 6)}\n",
      "Shapes of extracted labels from test_dataset: {'log_adj_daily_returns': (5024,)}\n",
      "Testing if the extracted labels match the last column (the final timestep) of the test_dataset\n",
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(dataset, label_names):\n",
    "    labels = {fname: dataset[fname][:, -1] for fname in dataset.keys() if fname in label_names}\n",
    "    features = {fname: dataset[fname][:, :-1] for fname in dataset.keys()}\n",
    "    return features, labels\n",
    "\n",
    "test_dataset_with_labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "test_features, test_labels = test_dataset_with_labels[0], test_dataset_with_labels[1]\n",
    "print('Shapes of features of test_dataset with labels included: {}'.format({fn: dataset[fn].shape for fn in dataset}))\n",
    "print('Shapes of features of test_dataset with labels extracted: {}'.format({fn: test_features[fn].shape for fn in test_features}))\n",
    "print('Shapes of extracted labels from test_dataset: {}'.format({fn: test_labels[fn].shape for fn in test_labels}))\n",
    "print('Testing if the extracted labels match the last column (the final timestep) of the test_dataset')\n",
    "assert np.array_equal(dataset['log_adj_daily_returns'][:, -1], test_labels['log_adj_daily_returns'])\n",
    "print('Test passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_docs_feature's shape:(7,)\n",
      "sample_docs_feature\n",
      "['[]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000383.pickle\"]'\n",
      " '[]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000393.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007742.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007757.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007803.pickle\"]']\n"
     ]
    }
   ],
   "source": [
    "test_sample_docs_feature = dataset['docs'][0] # sample 0's docs features of WFC's dataset\n",
    "print('sample_docs_feature\\'s shape:{}'.format(test_sample_docs_feature.shape))\n",
    "print('sample_docs_feature')\n",
    "print(test_sample_docs_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000383.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000393.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007742.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007757.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007803.pickle']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_docs_feature(docs_feature):\n",
    "    docs = []\n",
    "    for timestep in docs_feature:\n",
    "        docs_list = json.loads(timestep)\n",
    "        docs.extend(docs_list)\n",
    "    return docs\n",
    "\n",
    "flatten_docs_feature(test_sample_docs_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: [  1   1   1 ... 224 225 226]\n",
      "Testing if each timestep contains the same document that was sampled randomly from the original window\n",
      "Test passed\n",
      "window's shape: (7, 1546)\n",
      "window:\n",
      "[[  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]\n",
      " ...\n",
      " [  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]]\n"
     ]
    }
   ],
   "source": [
    "def decode_docs_feature(docs_feature, seed):\n",
    "    np.random.seed(seed)\n",
    "    docs_names = flatten_docs_feature(docs_feature)\n",
    "    if len(docs_names) != 0:\n",
    "        windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "        with open(windows_doc_name, 'rb') as f:\n",
    "            windows_doc = pickle.load(f)\n",
    "        window = [windows_doc for _ in range(len(docs_feature))]\n",
    "    else:\n",
    "        window = [[] for _ in range(len(docs_feature))]\n",
    "    return np.stack(window, axis=0)\n",
    "\n",
    "test_window = decode_docs_feature(test_sample_docs_feature, None)\n",
    "test_windows_doc = test_window[0]\n",
    "print('document: {}'.format(test_windows_doc))\n",
    "print('Testing if each timestep contains the same document that was sampled randomly from the original window')\n",
    "assert all(np.array_equal(test_window[i], test_windows_doc) for i in range(len(test_window)))\n",
    "print('Test passed')\n",
    "print('window\\'s shape: {}'.format(test_window.shape))\n",
    "print('window:')\n",
    "print(test_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding features and extracting labels\n",
    "features, labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "features_decoded = {key: (value if key != 'docs'\n",
    "                         else list(map(lambda docf: decode_docs_feature(docf, seed), value)))\n",
    "                   for key, value in features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out samples with no document feature\n",
    "mask = [(sample.shape[1] != 0) for sample in features_decoded['docs']]\n",
    "\n",
    "features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                           else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                     for key, value in features_decoded.items()}\n",
    "\n",
    "labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "\n",
    "assert (features_filtered['log_adj_daily_returns'].shape[0] == len(features_filtered['docs']) == labels_filtered['log_adj_daily_returns'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Dataset\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\n",
    "\n",
    "features_shuffled = {key: (value[shuffled_indices] if key != 'docs'\n",
    "                           else [value[i] for i in shuffled_indices])\n",
    "                     for key, value in features_filtered.items()}\n",
    "\n",
    "labels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\n",
    "\n",
    "assert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_documents(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, 0), (0, longest_doc_len-arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Padding Document Features to the max length of a document\n",
    "X = {key: (pad_documents(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\n",
    "y = labels_shuffled['log_adj_daily_returns']\n",
    "print(X['log_adj_daily_returns'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct model layers\n",
    "\n",
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                     weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                     input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                     embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                     activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                     mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00045633 -0.01149596  0.01969069  0.00474809 -0.00474809 -0.01346608]\n",
      " [ 0.0141506   0.01302592  0.00030917  0.0152854  -0.00456189 -0.01442841]\n",
      " [ 0.03178836  0.00458189 -0.01178251 -0.01280198  0.00525521  0.03491873]\n",
      " ...\n",
      " [ 0.01023679 -0.00519479  0.01018749 -0.0103665  -0.00305978 -0.0052389 ]\n",
      " [-0.03552021 -0.01716491  0.          0.00061975 -0.01087095 -0.01859904]\n",
      " [ 0.00563817  0.00800301  0.00635725  0.          0.00263458 -0.013784  ]]\n",
      "Shape of num features: (1000, 6)\n",
      "\n",
      "[-4.58744414e-04  1.44284099e-02  1.61850783e-02  1.03306704e-02\n",
      "  1.73141657e-03  0.00000000e+00 -2.61111440e-02  2.52574449e-03\n",
      " -3.71113578e-03 -5.25012589e-03 -2.59110728e-03  7.78406452e-04\n",
      "  7.57920325e-03 -8.54676319e-03  7.53360010e-04  7.28151782e-03\n",
      "  2.93513889e-04 -1.41144445e-03  1.06813910e-02  3.27892122e-04\n",
      "  2.89563131e-02  3.28871610e-03  3.62221522e-02 -2.42930732e-02\n",
      "  8.00114402e-03  8.93654242e-03  1.74397441e-03 -2.69755529e-03\n",
      " -8.27709547e-03  6.32774261e-03  6.61701761e-03 -1.53849485e-03\n",
      " -1.39365347e-02 -1.20737077e-01 -1.89692813e-02 -8.16164498e-03\n",
      " -1.19074668e-02  2.91301708e-02  0.00000000e+00 -1.55228548e-02\n",
      "  3.62894662e-03  1.19383500e-02 -1.90417599e-03 -1.25582619e-02\n",
      " -4.53834037e-03 -1.55528231e-03  3.48117845e-03 -7.96142202e-03\n",
      "  9.00307028e-03 -1.88346550e-02 -2.13485647e-03  1.34308588e-02\n",
      "  3.50970952e-03  9.22243488e-03 -1.81633788e-02  1.84908015e-02\n",
      " -6.32250005e-04 -4.34482569e-03  2.77956972e-02 -2.15749814e-03\n",
      "  3.86221274e-03 -9.43358994e-03  2.62021633e-02 -3.72593496e-02\n",
      "  7.69294315e-03 -1.21045391e-02 -1.70357345e-02  3.74194041e-03\n",
      " -1.10000794e-02 -2.61285080e-02 -9.74203371e-04 -7.06965293e-03\n",
      "  1.79047111e-02  2.00103442e-02  1.14810944e-02  8.80121744e-03\n",
      " -6.50079385e-03  1.18233240e-02  6.65513507e-03  3.25336468e-03\n",
      " -2.03521638e-03 -1.58090067e-02  3.23536686e-03  3.66522470e-04\n",
      " -5.52316570e-02  4.05746585e-03  1.12723263e-02 -8.76004865e-03\n",
      "  6.37290150e-03  1.68628350e-02 -1.05651596e-02 -2.85076448e-02\n",
      " -8.61458486e-03  6.62997081e-03 -5.91406926e-03 -8.44035500e-04\n",
      "  9.92197416e-03  1.68427473e-03  1.37972596e-02  7.75867333e-02\n",
      " -1.56429962e-02  4.07961855e-02 -8.56979675e-04  1.56818829e-03\n",
      " -9.44423655e-03  8.12166489e-03  8.57605178e-03 -5.66301031e-04\n",
      " -1.74531852e-03 -2.14615994e-03  3.76013687e-03 -8.30671114e-03\n",
      "  9.28589446e-03  1.15344162e-02  3.07927943e-03 -7.96469981e-03\n",
      "  1.07713219e-02  2.95552309e-02  7.51831970e-03  6.04883908e-03\n",
      "  1.94119316e-03 -1.66926001e-03 -4.75368224e-03 -1.77692938e-02\n",
      "  5.96021620e-03 -1.85990378e-02  6.96042793e-04 -6.74806783e-03\n",
      "  5.93961775e-03  4.94871161e-03 -5.70137945e-04 -1.04592482e-03\n",
      " -2.28309278e-03 -3.32858075e-03  1.31034525e-02 -1.15940318e-02\n",
      "  9.98952884e-02 -4.66820501e-03  2.68980312e-02 -9.56660477e-03\n",
      "  2.71321817e-02  2.58505800e-03 -1.05114953e-02  3.74859403e-03\n",
      "  1.19391174e-02  7.12591327e-03 -1.16451123e-02  3.59820736e-03\n",
      "  9.05535301e-03 -1.50778668e-02  4.74808799e-03 -6.31966051e-03\n",
      " -1.62896121e-02  4.89797583e-03 -1.08841930e-02  3.27328676e-03\n",
      " -1.20541997e-03  1.00306989e-02  8.04088747e-03 -4.74808799e-03\n",
      " -8.23727620e-03 -2.24093354e-02  7.11755861e-03  8.08442462e-03\n",
      "  1.02822172e-02 -5.43344082e-03  3.11703398e-02 -6.01728697e-03\n",
      " -7.31975228e-03  3.03836923e-03 -7.91149222e-03  2.90933733e-03\n",
      "  3.51206622e-02 -3.39140748e-02  7.05407038e-03  7.24779970e-03\n",
      "  4.53460018e-03  1.46101990e-02 -1.82757013e-02 -7.68303255e-03\n",
      "  2.04280430e-02  4.19751439e-03  1.21088535e-01 -4.00370990e-03\n",
      "  1.03218918e-03 -2.91326335e-02 -8.30761743e-03 -2.87267539e-02\n",
      " -5.75535542e-03  3.37040369e-02 -1.90648652e-02 -1.82779098e-04\n",
      " -8.16615082e-03  2.97750459e-03 -1.93361236e-02  1.37756357e-02\n",
      " -3.19436222e-02  1.53787791e-03 -1.57792638e-02 -1.26431068e-02\n",
      "  7.83223485e-04 -4.56189188e-03 -1.48927722e-02 -5.11233120e-03\n",
      " -8.36382323e-03  9.31442244e-04  7.06452181e-03  0.00000000e+00\n",
      "  1.26307635e-02 -8.66397704e-03  6.01614454e-04  3.43985383e-03\n",
      "  1.95804951e-02 -1.31630039e-02 -8.43559712e-04 -3.31093377e-02\n",
      "  7.32863934e-03 -1.23700159e-02  3.51544564e-03 -1.76135355e-03\n",
      "  9.85223293e-03  1.31151795e-02 -3.67632901e-03 -5.21956489e-03\n",
      "  1.79764642e-02  5.87523805e-03 -1.02627851e-02  1.15008340e-02\n",
      " -1.04947249e-02 -6.60863088e-03 -1.19856994e-02 -4.70073909e-02\n",
      "  6.01750592e-03 -5.88392572e-03 -2.72874415e-03  6.18178057e-03\n",
      "  6.89917973e-03 -3.23293537e-03 -2.17891551e-03 -5.62647810e-03\n",
      "  2.94729261e-04 -8.49735040e-04  0.00000000e+00 -1.69457180e-02\n",
      " -1.16417559e-02 -2.81375270e-02 -3.81591347e-03  1.64199632e-02\n",
      "  4.20123227e-02 -3.12130061e-03  1.64526647e-02  1.87469095e-02\n",
      "  3.23028631e-03 -2.04325924e-02  1.82305140e-02 -4.60225161e-03\n",
      " -7.29058895e-03  1.19347604e-03  1.12467156e-02  1.06373288e-02\n",
      " -7.24633511e-03 -2.69293369e-02 -4.38918489e-02 -8.20379704e-03\n",
      "  1.53215529e-02 -1.77048805e-03  2.68592407e-02  1.02103764e-02\n",
      " -1.75429520e-01  0.00000000e+00  4.21429091e-03  2.60799180e-02\n",
      "  4.45181663e-03  9.53653673e-03  0.00000000e+00 -7.60968015e-03\n",
      "  6.71435914e-03  5.08130985e-03 -3.23616898e-04  2.20063565e-02\n",
      "  1.51819740e-03 -3.82963305e-03  2.41493128e-02  6.21272333e-03\n",
      " -3.09751827e-03 -8.34445986e-03 -1.74266724e-02 -6.11729697e-03\n",
      "  2.30333931e-03 -1.39921657e-02 -7.31004553e-03  2.16475607e-02\n",
      " -9.47821758e-03 -1.52928423e-02  1.37632514e-02  2.96591039e-03\n",
      " -2.16987005e-03  1.37354150e-03  7.22046089e-03 -6.09037304e-03\n",
      " -5.27511336e-03  3.59623310e-03 -1.61796352e-02 -7.80264222e-03\n",
      "  3.69594185e-02  9.50166451e-04 -4.36705454e-03  2.03890028e-03\n",
      " -2.26043169e-03 -2.56286333e-03 -1.90865902e-02 -7.37882470e-03\n",
      " -2.33911295e-03 -6.32150318e-03  4.46313382e-02 -1.28081843e-02\n",
      "  1.88349628e-02 -1.13355286e-02 -2.17978275e-02 -3.64639432e-03\n",
      "  5.47180832e-03  5.06862056e-03  1.13763418e-02 -2.65265308e-03\n",
      "  2.11266760e-02  2.51979610e-02  1.44281374e-02 -1.32008650e-03\n",
      " -4.29996102e-03  1.31240548e-02 -6.97716487e-03 -4.93589672e-03\n",
      "  1.62019746e-02  1.15131455e-02 -5.02644394e-03  1.08737707e-02\n",
      "  2.41432474e-02 -1.75362333e-02  5.28308150e-03  6.44730920e-03\n",
      "  9.22884571e-03 -3.88161092e-04 -4.12526741e-02  3.39619346e-02\n",
      "  6.27836427e-02 -2.76005678e-03  3.05655519e-03 -3.27105266e-03\n",
      " -8.27003564e-03  4.61150769e-02 -1.25682246e-02  7.42353439e-03\n",
      "  2.95850404e-02  8.84155440e-03  1.43244021e-02  3.83809329e-03\n",
      " -6.71018650e-03 -3.06589361e-02  9.33855489e-03  4.37605201e-04\n",
      "  2.27555400e-02 -9.23205743e-03 -8.24088207e-03 -8.60206668e-03\n",
      " -6.65513507e-03  5.84353922e-03 -1.98877414e-03 -2.28188952e-02\n",
      "  4.45728158e-02 -2.54532382e-02 -3.44752525e-04 -1.40049220e-02\n",
      " -3.39015517e-02 -3.23050007e-02 -1.50018646e-02 -2.17563049e-03\n",
      " -9.60559065e-02 -3.62812531e-03  4.09837463e-04 -6.99679870e-03\n",
      " -6.96072478e-03  2.26208938e-03  2.02468113e-02 -1.52537179e-02\n",
      "  8.31869074e-03  1.45938753e-02  1.50423537e-03 -9.47912850e-02\n",
      " -1.16196524e-02  6.48221523e-03 -6.39880119e-03 -1.52123869e-02\n",
      "  5.30346376e-03  2.18398037e-02  0.00000000e+00 -2.00543925e-04\n",
      "  7.38381600e-04 -1.56117469e-02 -1.21539579e-03  2.57441684e-02\n",
      "  2.33638009e-02  5.38917447e-03 -3.18281661e-02 -1.31771517e-02\n",
      "  2.51336262e-02 -2.04255418e-02  1.14877781e-02  5.88810119e-04\n",
      " -1.37037226e-03  1.76904836e-02  1.27375990e-03 -9.67773266e-02\n",
      " -1.94843146e-02 -1.38048305e-02 -6.28478743e-03 -3.81400433e-02\n",
      "  1.11419688e-02 -1.72104072e-02  4.88787064e-03 -6.54929072e-03\n",
      "  2.41505468e-03 -2.02916308e-03  7.76400511e-03  1.14254430e-02\n",
      "  1.29617811e-02 -1.55382109e-02  1.97782319e-02  0.00000000e+00\n",
      "  1.34015762e-02  1.81350552e-02  1.73908932e-03  5.48952466e-03\n",
      "  3.20374088e-02 -6.50050567e-03 -2.28454362e-02 -1.68063992e-02\n",
      " -6.07814156e-02 -7.12254566e-03 -1.23689159e-02 -3.61547848e-03\n",
      " -7.67365973e-03  4.35077209e-03 -1.07286684e-02 -5.34740814e-03\n",
      "  1.37305262e-02 -3.95291796e-03 -1.92198569e-03 -9.33790992e-03\n",
      "  4.80252908e-03 -1.67332585e-02 -1.99621816e-02 -6.69334905e-03\n",
      " -5.83374508e-03  1.57480031e-02  9.08790574e-03  7.23039904e-03\n",
      "  1.14849499e-02 -7.32716615e-03 -1.60377826e-02 -8.67985598e-03\n",
      "  1.02082492e-03 -1.10009436e-02  2.68933221e-02 -3.07208047e-03\n",
      "  2.25335390e-02  5.64509045e-03  6.93359501e-03 -4.40235289e-03\n",
      "  1.30802820e-02 -2.10850477e-03  1.78030376e-02 -3.02093969e-02\n",
      " -1.63792769e-02  1.91637066e-03  8.78306951e-03  2.56897074e-03\n",
      " -9.80955439e-03 -1.12621489e-03  1.34959064e-02 -2.85121368e-02\n",
      "  1.45758476e-03  8.73347951e-03 -1.02362620e-02 -3.37260516e-03\n",
      " -4.40066506e-03  0.00000000e+00 -7.79810245e-03 -5.56921363e-03\n",
      " -1.69261917e-02  1.08752061e-02 -4.28741811e-03  1.16531597e-02\n",
      "  2.55633922e-03 -4.97588580e-03 -1.26816501e-02  5.70004334e-03\n",
      " -3.94967164e-03  1.08980126e-02 -3.21242097e-02  4.07377619e-02\n",
      " -5.44641722e-04  6.38346783e-02  0.00000000e+00  2.27692868e-02\n",
      " -1.64270799e-02  3.06811198e-03 -1.48158840e-02 -3.50658703e-03\n",
      "  1.64545401e-02 -2.54064373e-03 -5.85781430e-03  6.26670457e-03\n",
      "  9.50363801e-03 -5.91854332e-03 -2.87171765e-02  3.50313057e-03\n",
      " -4.39093215e-03 -3.00411434e-03 -3.19646648e-04  2.02342052e-02\n",
      " -4.41246240e-02  1.09149734e-03 -5.66515496e-04  2.06964256e-02\n",
      " -1.17754512e-03  3.05544774e-03  6.66064355e-02 -5.37624762e-03\n",
      " -7.70209809e-03 -4.39932555e-02 -8.76823764e-03  1.08958636e-03\n",
      "  2.20788113e-03 -2.06862355e-02 -1.35090778e-02 -1.02155673e-02\n",
      " -2.28967909e-02 -3.10384172e-02  9.78761015e-03  3.45921163e-02\n",
      "  4.03571025e-03 -3.27052153e-03  5.99802777e-03 -1.39343546e-02\n",
      " -2.37831792e-02  2.38450336e-02  1.05830880e-02  1.09498144e-03\n",
      "  8.00300942e-03  2.01542352e-02  2.92016058e-02  3.33461695e-02\n",
      "  4.96027084e-02 -6.17173143e-03 -2.49634217e-02  7.61817157e-03\n",
      "  3.44999617e-02 -1.14890561e-03 -4.79232641e-03  1.44351577e-03\n",
      "  1.26862680e-02  2.16697818e-02  2.89581914e-03 -3.96787737e-02\n",
      "  6.02459666e-04  1.11369801e-02  4.91128557e-03  7.15901440e-03\n",
      "  4.09069664e-04  3.17591865e-02  1.77026264e-02  1.83280317e-03\n",
      " -3.34201549e-03 -3.30516509e-03  4.02718157e-03  2.44885237e-02\n",
      "  1.33081781e-02 -1.78862178e-02  1.59874418e-03 -1.29593824e-03\n",
      " -6.63965649e-03  1.07680392e-03  1.75711981e-04  2.13714854e-02\n",
      "  0.00000000e+00  1.00145935e-02 -7.64302936e-03 -1.03931342e-02\n",
      "  1.10399047e-02 -1.42287070e-03 -1.30941392e-02  2.59671468e-03\n",
      " -1.26766959e-02 -6.60345693e-03 -1.38664300e-02 -1.25740838e-02\n",
      "  7.78909830e-03 -3.18358193e-02 -1.04258136e-03 -6.99086147e-03\n",
      " -1.13299721e-02 -2.54079538e-02 -6.80256643e-03 -1.04313885e-02\n",
      "  4.63117995e-03 -6.30267459e-03  1.69052124e-02  2.92287501e-03\n",
      "  3.81725528e-03  6.19729022e-03  1.98153976e-02 -5.31869877e-03\n",
      " -8.40684485e-03 -1.26234895e-02 -1.26776843e-03  3.20025819e-02\n",
      "  4.83825376e-03 -4.77560632e-03  1.78849232e-02  1.78676513e-03\n",
      " -9.77508371e-03 -4.28688394e-02  4.40584020e-03 -9.63830646e-03\n",
      "  5.98959673e-03  1.15648973e-02 -1.30352817e-03  1.08303239e-02\n",
      " -2.55452831e-03 -1.93155341e-02  7.62972759e-03 -1.01966822e-02\n",
      "  3.16503187e-02 -3.15790753e-02  3.02791100e-02 -8.52967595e-04\n",
      " -6.13816320e-03 -3.47291940e-04 -2.10214871e-03  3.40836145e-03\n",
      "  0.00000000e+00  2.53272903e-02 -1.52683917e-03 -5.41748732e-03\n",
      "  5.02792927e-02 -2.81374384e-03  3.47159518e-03 -1.30517993e-02\n",
      "  3.16366970e-02 -4.08830750e-04  6.10234685e-03  6.94858521e-03\n",
      " -9.39935538e-03 -1.92814437e-02  1.32685430e-03  2.71218586e-03\n",
      " -4.92195918e-03 -2.69083570e-02  1.06105921e-02 -5.56529215e-03\n",
      "  4.23143123e-03 -9.02618670e-03  9.48955633e-03  6.28742887e-03\n",
      " -5.89980387e-02  1.45552405e-02 -7.91314043e-03 -1.02724301e-02\n",
      " -1.07726016e-02  1.64994835e-02  1.38798486e-02 -1.66565421e-04\n",
      "  5.28228497e-03  2.36877221e-03 -6.19549605e-03 -5.77021605e-02\n",
      "  3.51123360e-03  8.08960682e-04 -2.06232691e-02 -7.13039126e-04\n",
      " -7.27513997e-03 -2.05187099e-03  2.37592135e-03 -1.69421983e-03\n",
      "  6.15194282e-03  4.69480158e-02  1.96418641e-02  2.78534613e-02\n",
      "  1.17706610e-02 -4.12384638e-02 -7.19451110e-04 -1.26952787e-02\n",
      "  2.26971422e-02 -4.77413305e-03 -1.26331150e-02  2.50101752e-02\n",
      "  8.13324009e-03 -6.22747073e-03  7.39562970e-03 -1.02591066e-02\n",
      " -7.29723590e-03 -4.14663669e-03 -1.61633149e-02 -1.08399922e-02\n",
      "  0.00000000e+00  1.23113686e-02  7.13651557e-03  8.40474391e-03\n",
      "  4.25757350e-03  1.26290718e-02  8.44035500e-04  9.95575305e-03\n",
      "  2.09167776e-03 -2.29447472e-02  4.86524264e-03  3.05793140e-03\n",
      "  6.40224614e-03  2.64256147e-02 -1.84833335e-03 -1.54513394e-02\n",
      "  1.84056872e-02 -9.30710087e-02 -2.72212634e-02 -7.94019882e-03\n",
      "  4.12695564e-03 -1.57238511e-02  7.40224601e-03 -1.07663447e-02\n",
      "  1.81824103e-02 -3.65403935e-03  8.00457592e-03  5.26067575e-03\n",
      "  2.16884863e-03 -2.99643228e-03  1.09216847e-02 -1.92174666e-02\n",
      " -1.52475357e-02  7.35332020e-03  1.19357329e-01 -1.14787762e-02\n",
      " -1.24579640e-02 -1.44284099e-02 -4.87677486e-03  3.56025118e-02\n",
      " -5.29472014e-02  5.25940788e-03  2.35781036e-03 -8.43699175e-03\n",
      "  1.12801205e-02 -1.75502455e-02  8.34199011e-03  7.74633981e-03\n",
      "  6.23349901e-03  7.68908804e-03 -1.98416740e-02 -1.72149367e-02\n",
      "  6.91457032e-04  6.67880577e-03 -2.04912479e-02  2.23907286e-03\n",
      "  7.83598585e-03  1.42735441e-02  1.37198267e-02  7.06532418e-03\n",
      "  1.60624951e-01  7.18090341e-03  8.53321391e-03  9.03528225e-03\n",
      " -2.03122014e-02 -6.01311564e-03  1.44184440e-02 -1.05086600e-02\n",
      "  7.23701801e-03 -5.19478664e-03  2.22126201e-02 -6.95236475e-02\n",
      "  1.61556850e-02 -2.40893595e-02  1.86238586e-03  1.18828427e-02\n",
      "  1.33213615e-02 -1.35041264e-02 -1.97042753e-02 -2.24489153e-03\n",
      "  1.17541323e-02 -6.19819804e-03 -6.01381097e-02 -4.13032155e-03\n",
      " -3.55202122e-02  1.29411199e-02  4.03225812e-04 -2.52891036e-02\n",
      " -7.96399997e-03  5.51444960e-03 -5.77691884e-03  1.91768164e-02\n",
      " -4.77439576e-02 -4.50174691e-03  1.96230646e-02 -1.47373363e-02\n",
      "  4.77667257e-03  3.48943515e-02 -1.01595472e-03  2.10708933e-02\n",
      " -1.75433938e-02 -1.09166301e-02  7.98560669e-03  1.35644042e-03\n",
      "  2.15336791e-02 -1.02386667e-02  2.98422207e-02  1.75414713e-02\n",
      " -2.08387318e-03 -1.27395708e-02  3.94041477e-03  3.73827703e-03\n",
      "  3.26656480e-03 -2.08746666e-02  1.09165363e-02  5.52991068e-04\n",
      " -4.88375669e-03  1.49627341e-02  7.95250193e-03  1.45578488e-02\n",
      " -1.40988844e-02 -6.83530179e-03 -9.36809334e-03 -5.72036848e-03\n",
      "  1.09328085e-02  6.15026401e-03  5.98035518e-02 -3.96283067e-03\n",
      "  2.21721343e-02 -1.71757477e-02 -4.10256986e-03 -7.70876977e-03\n",
      "  1.45859579e-02  1.08369305e-02  3.25118906e-03  1.42987235e-03\n",
      " -8.54837348e-03  7.40529663e-03  7.66937015e-04  1.06876094e-02\n",
      " -1.09561931e-02 -1.16935344e-02 -1.96771124e-04 -1.18318588e-02\n",
      " -2.69425706e-02  7.46894867e-03  6.98191852e-03  1.06765150e-02\n",
      "  2.82089857e-03  1.21889689e-02 -2.07300826e-02  6.32641248e-03\n",
      "  1.24505203e-03 -4.43549738e-03  8.55983621e-03 -2.85801194e-02\n",
      " -6.03366198e-02  5.37347890e-03 -2.79175462e-02  2.04708790e-03\n",
      " -8.07965303e-03 -1.79227165e-04 -8.68971954e-03 -1.18923728e-03\n",
      "  4.30063088e-02  1.22480485e-02 -5.59881560e-03  2.28441768e-02\n",
      " -1.01104394e-02 -1.54091269e-02  1.32998979e-02 -7.69809197e-04\n",
      " -5.04235343e-03 -1.54310286e-02 -2.09454171e-03 -1.96104963e-03\n",
      " -1.43590803e-02  1.00703072e-02 -2.82157946e-04  2.24708532e-02\n",
      " -8.84112377e-03  5.75054054e-03 -1.60474122e-02  0.00000000e+00\n",
      "  9.56211944e-04 -1.70615894e-03 -1.84404798e-02  1.75074242e-03\n",
      "  2.39276831e-02  2.11899763e-03 -1.52110098e-02  4.16897465e-03\n",
      "  1.52379873e-02  4.91187932e-03  7.05619920e-03  3.20557369e-03\n",
      " -1.81839518e-03 -1.32173607e-02 -2.24375338e-02 -8.48920011e-03\n",
      "  2.07216806e-02 -9.43976145e-03  1.04430375e-02  1.01849746e-03\n",
      " -8.30527819e-02  1.73103447e-02 -2.11549278e-02  2.99691065e-03\n",
      " -1.71118988e-02 -4.07436320e-03  1.29600821e-02 -7.56846610e-03\n",
      " -4.70188359e-03  2.15058208e-02  1.64215906e-03  7.28961359e-03\n",
      "  2.22596768e-03 -5.83672883e-03  2.17926502e-02 -1.37815274e-03\n",
      " -5.51818751e-02 -1.22663599e-02  8.36218109e-04 -1.20989890e-02\n",
      "  1.87908478e-02  2.30157134e-02 -2.02755106e-02  1.91884513e-02\n",
      "  5.68622608e-04 -7.80036750e-03 -1.39849030e-02 -2.23910259e-02\n",
      "  1.85970584e-03  5.83610893e-03 -1.33404725e-02 -1.16372768e-02\n",
      " -5.48582492e-03 -9.94189516e-03 -6.94546578e-03  6.71060272e-02\n",
      " -1.08632729e-01  2.26983450e-03  7.51337251e-03 -1.13555753e-02\n",
      " -1.73495552e-02  2.50838414e-03 -1.66458936e-02  1.69744303e-02\n",
      "  8.98271791e-03  2.75344237e-01  1.89403213e-02  1.87918080e-04\n",
      "  1.00710538e-02 -3.65196754e-03  5.83061295e-02  9.16000769e-03\n",
      " -2.26635859e-02  4.90217442e-03  0.00000000e+00 -1.82148704e-03\n",
      " -2.79753283e-03 -5.30295851e-03 -1.58760775e-02  6.77174153e-02\n",
      " -1.63829559e-03 -1.43455746e-02  1.18430236e-02 -1.66588535e-02\n",
      "  2.00574264e-02  1.03015606e-02 -5.08018887e-04  1.89598498e-03\n",
      "  1.51599007e-02  7.80343323e-03  2.80316202e-02  1.19961187e-02\n",
      " -2.43174176e-02  5.42255745e-03  1.22314785e-02 -4.53460018e-03\n",
      " -4.74708554e-03  1.38414839e-02 -6.77894888e-03  4.20298783e-03\n",
      "  1.07814906e-03  2.00198476e-03 -5.66529533e-03  8.73692062e-03\n",
      "  9.93170032e-03 -5.12860764e-03  1.04729982e-02 -5.27679215e-02\n",
      "  2.36897997e-02 -3.99503512e-03  4.44506428e-03 -1.33632621e-03]\n",
      "Shape of labels: (1000,)\n",
      "[[[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]]\n",
      "Shapes of docs features: (1000, 6, 2879)\n",
      "Testing if each document at each timestep for all samples in docs feature is equal each other\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test past\n"
     ]
    }
   ],
   "source": [
    "# Inspecting Dataset\n",
    "print(X['log_adj_daily_returns'])\n",
    "print('Shape of num features: {}'.format(X['log_adj_daily_returns'].shape))\n",
    "print()\n",
    "print(y)\n",
    "print('Shape of labels: {}'.format(y.shape))\n",
    "print(X['docs'])\n",
    "print('Shapes of docs features: {}'.format(X['docs'].shape))\n",
    "print('Testing if each document at each timestep for all samples in docs feature is equal each other')\n",
    "assert all(np.array_equal(X['docs'][s, i], X['docs'][s, j]) for s in range(dataset_size) for i in range(6) for j in range(6))\n",
    "print('Test past')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "                                                                 embedding[4][0]                  \n",
      "                                                                 embedding[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "32\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "  32/1000 [..............................] - ETA: 3:16"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function len> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_num_elements\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`grad` not a Tensor or IndexedSlices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7335a7449b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    596\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No gradients to aggregate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "#word_embedding_layers = [word_embedding(timeslice_layers[timestep]) for timestep in range(6)]\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "#document_embedding_layers = [document_embedding(word_embedding_layers[timestep]) for timestep in range(6)]\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_5])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigating crash of regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears from the above cell that the model is crashing somewhere in its backpropagation step. From inspection of the source code it seems like there are some issues with the shapes of gradients when slicing the docs input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 629ms/sample - loss: 0.0358 - val_loss: 0.0505\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 22ms/sample - loss: 0.0449 - val_loss: 0.0110\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 20ms/sample - loss: 0.0194 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0048 - val_loss: 6.3182e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 3.1893e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 16ms/sample - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0017 - val_loss: 6.6464e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cell it appears that if we take only one slice layer and copy it multiple times then apply our stack layer, the model seems to backpropagate fine. This implies maybe there might be something up with the stack layer: doc_features_layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 15s 1s/sample - loss: 0.0482 - val_loss: 0.0527\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0360 - val_loss: 0.0182\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 60ms/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 0.0015 - val_loss: 4.3584e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 9.8736e-04 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 57ms/sample - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 63ms/sample - loss: 0.0016 - val_loss: 4.9223e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "                                                                 embedding[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " 4/10 [===========>..................] - ETA: 8s"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "PyEval_EvalFrameEx returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_num_elements\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`grad` not a Tensor or IndexedSlices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0c497bc01f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: PyEval_EvalFrameEx returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "#word_embedding_layers = [word_embedding(timeslice_layers[timestep]) for timestep in range(6)]\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "#document_embedding_layers = [document_embedding(word_embedding_layers[timestep]) for timestep in range(6)]\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above to cells we find that the backpropagation crashes when we try to apply our stack layer to a list of more than 3 unique slice layers (as opposed to a list of contains less than 3 unique slice layers where the empty slots are filled with copies of already included slice layers). This further supports that maybe the stacking layer is the cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, None)      0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, None)         0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_14[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 571ms/sample - loss: 0.0310 - val_loss: 0.0210\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0359 - val_loss: 0.0099\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 20ms/sample - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0020 - val_loss: 6.8931e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "timeslice_layer_0 = timeslice_layers[0]\n",
    "timeslice_layer_1 = timeslice_layers[1]\n",
    "timeslice_layer_2 = timeslice_layers[2]\n",
    "timeslice_layer_3 = timeslice_layers[3]\n",
    "timeslice_layer_4 = timeslice_layers[4]\n",
    "timeslice_layer_5 = timeslice_layers[5]\n",
    "\n",
    "# Rebuilding Original Input from Time Slices\n",
    "rebuilt_input_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)), \n",
    "                                    output_shape=(6, None))([timeslice_layer_0,\n",
    "                                                            timeslice_layer_1,\n",
    "                                                            timeslice_layer_2,\n",
    "                                                            timeslice_layer_3,\n",
    "                                                            timeslice_layer_4,\n",
    "                                                            timeslice_layer_5])\n",
    "                                    \n",
    "doc_layer_0 = layers.Lambda((lambda x: x[:, 0, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_1 = layers.Lambda((lambda x: x[:, 1, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_2 = layers.Lambda((lambda x: x[:, 2, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_3 = layers.Lambda((lambda x: x[:, 3, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_4 = layers.Lambda((lambda x: x[:, 4, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_5 = layers.Lambda((lambda x: x[:, 5, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(doc_layer_0)\n",
    "word_embedding_layer_1 = word_embedding(doc_layer_1)\n",
    "word_embedding_layer_2 = word_embedding(doc_layer_2)\n",
    "word_embedding_layer_3 = word_embedding(doc_layer_3)\n",
    "word_embedding_layer_4 = word_embedding(doc_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(doc_layer_5)\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to test our stacking layer, by slicing the input_docs layer, and immediately stacking all unique slices of it, then applying a sequence of layers we know backpropagation doesn't break on. The results show that our stacking layer isn't at fault. This implies that there is something up with the layers that we apply to each slice (word_embedding, and doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2747100     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    2747100     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 300)    2747100     lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 300)    2747100     lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 300)    2747100     lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 300)    2747100     lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          160400      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100)          160400      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 100)          160400      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 100)          160400      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 100)          160400      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,462,185\n",
      "Trainable params: 979,585\n",
      "Non-trainable params: 16,482,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 23s 2s/sample - loss: 0.0108 - val_loss: 0.0158\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 0.0220 - val_loss: 0.0066\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 85ms/sample - loss: 0.0015 - val_loss: 4.0027e-04\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 2.8220e-04 - val_loss: 4.5561e-04\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 87ms/sample - loss: 6.0313e-04 - val_loss: 6.8137e-04\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 84ms/sample - loss: 7.0505e-04 - val_loss: 7.7796e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 8.3631e-04 - val_loss: 5.7608e-04\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 5.4261e-04 - val_loss: 3.1418e-04\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 83ms/sample - loss: 2.8344e-04 - val_loss: 1.4857e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[0])\n",
    "word_embedding_layer_1 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[1])\n",
    "word_embedding_layer_2 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[2])\n",
    "word_embedding_layer_3 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[3])\n",
    "word_embedding_layer_4 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding_layer_0 = layers.LSTM(100)(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = layers.LSTM(100)(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = layers.LSTM(100)(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = layers.LSTM(100)(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = layers.LSTM(100)(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = layers.LSTM(100)(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_5])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created seperate word_embedding_layers and document_embedding_layers for each slice layer ie the document and word embedding layers are seperated for each slice, and do not share weights between each slice. Backpropagation seems to work which implies that the error is raised because of the logic of sharing weights between slice layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuilding Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/90\n",
      "1000/1000 [==============================] - 35s 35ms/sample - loss: 0.0017 - val_loss: 4.9786e-04\n",
      "Epoch 2/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 6.5899e-04 - val_loss: 5.7934e-04\n",
      "Epoch 3/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 6.3177e-04 - val_loss: 6.6666e-04\n",
      "Epoch 4/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.9128e-04 - val_loss: 6.4479e-04\n",
      "Epoch 5/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.9067e-04 - val_loss: 5.0854e-04\n",
      "Epoch 6/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 5.7249e-04 - val_loss: 5.7958e-04\n",
      "Epoch 7/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.6090e-04 - val_loss: 9.4620e-04\n",
      "Epoch 8/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.4607e-04 - val_loss: 5.2152e-04\n",
      "Epoch 9/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.3434e-04 - val_loss: 4.6628e-04\n",
      "Epoch 10/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 5.2841e-04 - val_loss: 5.1600e-04\n",
      "Epoch 11/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 5.1052e-04 - val_loss: 5.3288e-04\n",
      "Epoch 12/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.0705e-04 - val_loss: 4.8728e-04\n",
      "Epoch 13/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.9052e-04 - val_loss: 4.6473e-04\n",
      "Epoch 14/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.7652e-04 - val_loss: 6.2512e-04\n",
      "Epoch 15/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.8027e-04 - val_loss: 4.7239e-04\n",
      "Epoch 16/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.9658e-04 - val_loss: 4.5157e-04\n",
      "Epoch 17/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.6760e-04 - val_loss: 5.3258e-04\n",
      "Epoch 18/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.7000e-04 - val_loss: 4.3948e-04\n",
      "Epoch 19/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.6141e-04 - val_loss: 4.6436e-04\n",
      "Epoch 20/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.6664e-04 - val_loss: 4.5532e-04\n",
      "Epoch 21/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.5985e-04 - val_loss: 4.2675e-04\n",
      "Epoch 22/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.4986e-04 - val_loss: 4.3588e-04\n",
      "Epoch 23/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.5144e-04 - val_loss: 4.7808e-04\n",
      "Epoch 24/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.5288e-04 - val_loss: 4.3577e-04\n",
      "Epoch 25/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.4376e-04 - val_loss: 4.1846e-04\n",
      "Epoch 26/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3493e-04 - val_loss: 4.9607e-04\n",
      "Epoch 27/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.4078e-04 - val_loss: 4.4006e-04\n",
      "Epoch 28/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3552e-04 - val_loss: 4.2236e-04\n",
      "Epoch 29/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3304e-04 - val_loss: 4.2932e-04\n",
      "Epoch 30/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3580e-04 - val_loss: 4.2268e-04\n",
      "Epoch 31/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.3876e-04 - val_loss: 4.4171e-04\n",
      "Epoch 32/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.3573e-04 - val_loss: 4.1188e-04\n",
      "Epoch 33/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2873e-04 - val_loss: 4.0975e-04\n",
      "Epoch 34/90\n",
      "1000/1000 [==============================] - 46s 46ms/sample - loss: 4.2602e-04 - val_loss: 4.0766e-04\n",
      "Epoch 35/90\n",
      "1000/1000 [==============================] - 43s 43ms/sample - loss: 4.2625e-04 - val_loss: 4.4234e-04\n",
      "Epoch 36/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2637e-04 - val_loss: 4.1504e-04\n",
      "Epoch 37/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2436e-04 - val_loss: 4.1370e-04\n",
      "Epoch 38/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2547e-04 - val_loss: 4.0619e-04\n",
      "Epoch 39/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.2309e-04 - val_loss: 4.0600e-04\n",
      "Epoch 40/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2192e-04 - val_loss: 4.0663e-04\n",
      "Epoch 41/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1907e-04 - val_loss: 4.2560e-04\n",
      "Epoch 42/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2815e-04 - val_loss: 4.1109e-04\n",
      "Epoch 43/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.2260e-04 - val_loss: 4.0065e-04\n",
      "Epoch 44/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1934e-04 - val_loss: 3.9744e-04\n",
      "Epoch 45/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2213e-04 - val_loss: 4.0005e-04\n",
      "Epoch 46/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1202e-04 - val_loss: 4.7875e-04\n",
      "Epoch 47/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2042e-04 - val_loss: 3.9435e-04\n",
      "Epoch 48/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1472e-04 - val_loss: 3.9992e-04\n",
      "Epoch 49/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1696e-04 - val_loss: 3.9690e-04\n",
      "Epoch 50/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1672e-04 - val_loss: 4.0635e-04\n",
      "Epoch 51/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1065e-04 - val_loss: 4.5467e-04\n",
      "Epoch 52/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1568e-04 - val_loss: 3.9750e-04\n",
      "Epoch 53/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1600e-04 - val_loss: 3.9363e-04\n",
      "Epoch 54/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.0811e-04 - val_loss: 4.2322e-04\n",
      "Epoch 55/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1203e-04 - val_loss: 4.2608e-04\n",
      "Epoch 56/90\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 4.1252e-04"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=90, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.5\n",
      "Probability of sampling a 0: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/900\n",
      "10/10 [==============================] - 9s 931ms/sample - loss: 0.7232 - binary_accuracy: 0.4000 - precision: 0.4444 - recall: 0.8000 - val_loss: 0.6295 - val_binary_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.6247 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.5701 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.5637 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.5005 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4850 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.4236 - val_binary_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4067 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.3399 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.3082 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.1929 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.2051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.1055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0878 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0811 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0553 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0464 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0359 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0340 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0291 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0283 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0228 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0173 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0148 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0124 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0121 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0107 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0103 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9966e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9281e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7411e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4426e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2621e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2054e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0421e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.9851e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7769e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6302e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.5853e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4349e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.3829e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2519e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2021e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0748e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9037e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.8589e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7370e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6948e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5338e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4239e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3872e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.2373e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0947e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9945e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8377e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7343e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.7029e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6128e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5798e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4651e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3824e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.3501e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2733e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2459e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1667e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1396e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0647e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 6.0375e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9670e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.9406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8726e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.8479e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7810e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.7583e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6928e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.6716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6077e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.5861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5256e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.5047e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4458e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4245e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.3498e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2936e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2740e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2215e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2052e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1507e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1344e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0827e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0174e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0007e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9531e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8908e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 101/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8760e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8296e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 102/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7709e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 103/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7546e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7135e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 104/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.6983e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6571e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 105/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.6431e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 106/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.5876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 107/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.5349e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4964e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 108/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.4840e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4452e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 109/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4329e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 110/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 111/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3010e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 112/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.2893e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2545e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 113/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2428e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 114/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1986e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1653e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 115/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1222e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 116/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0803e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 117/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.0695e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0390e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 118/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0277e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9985e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 119/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9873e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 120/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9473e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9187e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 121/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9077e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8797e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 122/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.8700e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 123/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8043e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 124/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7676e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 125/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7585e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7316e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 126/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7222e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6965e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.6880e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6620e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 128/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.6530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6286e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 129/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6206e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 130/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5868e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 131/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5547e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5317e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 132/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5233e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 133/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4918e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4695e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 134/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4613e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4392e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 135/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4310e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 136/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4010e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 137/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3508e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 138/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3220e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 139/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3148e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2940e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 140/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 141/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2586e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 142/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2313e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2126e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 143/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2048e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1859e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 144/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1779e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 145/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1519e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1333e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 146/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1074e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 147/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1011e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0820e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 148/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0758e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0575e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 149/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0512e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0334e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 150/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0274e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0098e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 151/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9865e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 152/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9803e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9637e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 153/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9578e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 154/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9352e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9190e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 155/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9130e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8969e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 156/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8751e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 157/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 158/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8478e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 159/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8258e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 161/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7849e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7692e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 162/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7639e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 163/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 164/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7242e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7090e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 165/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7039e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 166/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6847e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6704e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 167/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6515e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 168/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6471e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 169/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6272e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 170/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6094e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 171/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 172/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5719e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 173/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.5542e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5412e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 174/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 175/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5189e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5055e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 176/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5009e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4881e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 177/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.4838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4710e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 178/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4663e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4541e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 179/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4373e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 180/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.4331e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4207e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 181/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.4161e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4044e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 182/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3883e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 183/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 184/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3679e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3560e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 185/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.3522e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3401e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 186/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3244e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 187/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 188/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.3053e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2942e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 189/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 190/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2756e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2649e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 191/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2611e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2506e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 192/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.2468e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2363e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2330e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2221e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 194/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2185e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2082e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 195/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.2041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1944e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 196/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1805e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 197/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1773e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1668e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 198/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.1633e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 199/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1499e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1402e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 200/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1366e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 201/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1240e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 202/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1011e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 203/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.0976e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0886e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 204/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0854e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 205/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0730e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0638e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 206/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0605e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0516e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 207/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0485e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 208/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0359e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0274e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 209/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0248e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0152e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 210/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0033e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 211/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0000e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9916e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 212/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.9888e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 213/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9766e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9683e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 214/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9654e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 215/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9539e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9456e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 216/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9424e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 217/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9316e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 218/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.9204e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9122e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 219/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.9093e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9012e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 220/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.8982e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8903e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 221/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 222/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.8767e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 223/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.8658e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8581e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 224/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8552e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 225/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8447e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8372e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.8341e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8268e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 227/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 228/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 229/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8035e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 230/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7936e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7860e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 231/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 232/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7735e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 233/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7642e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 234/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7544e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7475e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 235/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7450e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 236/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7357e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 237/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7196e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 238/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7170e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7106e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 239/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7082e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 240/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6989e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6927e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 241/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6902e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 242/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6812e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6749e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 243/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6727e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6661e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 244/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6636e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6574e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 245/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6550e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6488e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 246/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6462e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6403e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 247/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6382e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 248/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6299e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 249/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6215e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 250/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6076e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 251/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6056e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5998e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 252/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5921e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 253/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5901e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5845e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 254/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5825e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5769e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 255/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5748e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 256/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5673e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5619e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 257/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5544e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 258/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5524e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5470e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5453e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5397e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 260/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5379e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 261/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.5306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5254e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 262/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5184e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 263/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5164e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5115e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 264/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5096e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5045e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 265/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5027e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4977e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 266/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4958e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4909e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 267/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4891e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4841e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 268/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4823e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4774e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 269/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4757e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4707e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 270/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4642e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 271/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4625e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4578e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 272/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4560e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4514e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 273/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4450e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 274/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4386e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 275/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 276/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4307e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4260e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 277/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.4243e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4199e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 278/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4183e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4137e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 279/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4120e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4075e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 280/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.4060e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4015e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 281/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 282/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 283/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3881e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 284/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3779e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 285/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3763e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 286/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3663e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 287/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3648e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3605e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 288/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3590e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3549e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 289/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3533e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3493e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 290/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3477e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3437e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 291/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3423e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3367e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 293/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3311e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 294/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3256e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3216e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 295/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3162e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 296/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3149e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 297/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3095e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3056e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 298/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3042e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 299/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2990e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2951e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 300/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2937e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 301/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2885e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2847e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 302/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2833e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2795e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 303/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2782e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 304/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2731e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 305/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2680e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2643e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 306/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 307/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2580e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2543e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 308/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2494e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 309/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2481e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2445e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 310/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2396e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 311/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2383e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2347e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 312/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2299e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 313/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2286e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2251e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 314/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2239e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2204e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 315/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 316/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2144e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 317/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2097e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 318/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2049e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 319/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2004e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1970e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 320/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1957e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1924e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 321/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1912e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1879e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 322/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1833e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 323/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1788e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 324/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1777e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1733e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1699e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 326/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1687e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1655e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 327/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1645e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1612e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 328/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.1600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 329/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1557e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1526e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 330/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1515e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1483e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 331/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1472e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1440e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 332/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1429e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1398e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 333/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1388e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1356e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 334/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 335/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1304e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1273e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 336/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1263e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 337/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1221e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1191e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 338/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1181e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1151e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 339/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1140e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1110e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 340/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1099e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1070e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 341/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1059e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1030e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 342/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1019e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0990e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 343/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0950e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 344/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0940e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0910e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 345/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0900e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0871e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 346/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0832e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 347/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0822e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0793e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 348/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0783e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0754e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 349/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0744e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0716e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 350/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0677e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 351/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0668e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0639e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 352/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0601e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 353/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0592e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0564e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 354/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0554e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0527e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 355/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0517e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0490e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 356/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0480e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0453e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 357/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0443e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0416e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0380e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 359/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0371e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 360/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0308e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 361/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0298e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0272e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 362/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 363/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0227e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0201e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 364/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 365/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0156e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0130e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 366/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 367/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0086e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0060e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 368/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0025e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 369/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0016e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 370/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.9817e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9563e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 371/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9471e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9222e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 372/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9135e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 373/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8544e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 374/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8455e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8209e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 375/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.8119e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7875e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 376/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7788e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 377/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7454e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7212e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 378/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6883e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 379/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6554e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 380/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6464e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6229e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 381/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.6143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5904e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 382/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 383/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5260e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 384/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5176e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 385/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4855e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4622e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 386/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4542e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4305e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 387/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 9.4226e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3992e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 388/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 389/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3603e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 390/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.3291e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3065e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2984e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2760e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 392/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.2677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 393/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2372e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2152e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 394/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.2073e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1848e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 395/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.1769e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1547e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 396/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.1468e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1248e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 397/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0951e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 398/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.0870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0654e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 399/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0575e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0278e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0064e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 401/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9983e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9770e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 402/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.9689e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9476e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 403/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 404/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.9108e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8895e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 405/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 406/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8533e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 407/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8249e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 408/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7959e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7752e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 409/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7471e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 410/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7394e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7190e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 411/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7117e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6910e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 412/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6835e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6633e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 413/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6561e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 414/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6284e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 415/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.6010e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5807e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 416/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5535e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 417/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5463e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5264e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 418/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5192e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4995e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 419/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4922e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 420/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.4655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4461e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 421/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4390e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 422/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3929e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 423/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3859e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.3593e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 425/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 426/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2879e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 427/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2807e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2618e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 428/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2546e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 429/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2293e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2101e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 430/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.2032e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 431/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1591e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 432/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1521e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1337e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 433/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1269e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 434/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.1019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0831e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 435/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 436/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0519e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0335e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 437/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0268e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0090e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 438/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 439/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.9778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 440/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9535e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9353e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9110e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9046e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8867e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.8799e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8626e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 444/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8385e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8146e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8083e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7841e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7607e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.7371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7199e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 450/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.7138e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6965e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 451/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6904e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6732e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 452/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.6674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6501e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6043e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5981e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5816e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5757e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5527e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5302e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4911e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.4852e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.4631e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4466e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.4408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4245e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.4186e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4025e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3966e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3806e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3746e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3370e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3313e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3153e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3095e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2937e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2722e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 471/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.2235e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1657e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1447e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1391e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1239e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1183e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.0772e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0620e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0364e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0161e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0012e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9958e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9811e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9758e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9610e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9410e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9210e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.9155e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.8960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8812e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8419e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.8369e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8223e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8169e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8028e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7641e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7589e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7398e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7257e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7205e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7066e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7015e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6876e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6633e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6496e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6443e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6307e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6118e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.6066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5930e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.5881e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 505/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5694e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5557e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.5507e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5189e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5006e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4957e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4775e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4462e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4414e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4282e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4236e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4055e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3925e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3748e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.3701e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3571e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3523e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3395e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.3348e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3219e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3174e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3044e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2998e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2870e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2697e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2652e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2525e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.2480e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2310e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2139e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2014e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1968e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1845e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1632e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1339e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1172e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1126e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1005e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0837e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0627e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0341e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.0298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0177e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0015e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9853e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 539/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9810e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9692e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9648e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9531e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9488e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9371e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9328e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9211e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9009e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8893e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.8851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8692e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8577e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8420e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8263e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8223e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7952e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7334e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7181e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.7140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7029e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6989e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6877e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6838e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6726e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6685e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6575e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6537e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6425e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6386e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6277e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6237e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6129e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6089e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5944e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.5796e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5503e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5397e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5213e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5069e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4963e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4926e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4819e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4677e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 573/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4640e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4393e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4355e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4214e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4112e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3971e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.3934e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3832e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3656e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3278e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3242e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3103e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2865e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2827e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2691e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2592e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2420e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2151e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2054e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2018e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1920e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1885e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1750e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1655e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1620e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1522e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1391e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1259e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1225e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1128e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1094e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0998e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0834e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0739e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0704e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0611e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0482e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 607/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0064e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9970e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.9937e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9686e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9593e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9560e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9469e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9435e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9345e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9312e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9220e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9187e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8973e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8941e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8851e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8818e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8607e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8574e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8485e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8452e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8331e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7971e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7762e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7731e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7644e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7612e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7494e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7408e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7376e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7290e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7259e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7173e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7026e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6909e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6709e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6679e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6594e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.6564e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6478e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6449e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6250e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6219e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 641/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.5992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5909e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5574e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5544e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5463e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5433e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5352e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5131e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5101e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4993e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4912e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4664e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.4448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4369e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4341e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4261e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4154e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4125e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3913e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3835e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3808e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3702e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3625e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3597e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3520e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3415e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3387e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3311e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3283e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3208e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3180e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3104e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3077e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2973e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2898e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2795e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2590e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2460e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2387e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 675/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2285e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.2157e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2056e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1856e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1783e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1684e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1658e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1559e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1487e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1461e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1389e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1363e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1292e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1267e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1072e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0903e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0808e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0687e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0521e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0426e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0331e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0306e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0237e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0142e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0118e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0023e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9955e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9931e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9862e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.9837e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9769e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9744e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9651e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9558e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9466e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9398e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9373e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9306e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9281e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9191e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 709/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.9098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9006e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8916e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8759e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8669e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8467e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8378e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8290e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8025e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7961e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7939e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7873e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7764e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7700e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7614e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7528e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7442e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7334e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7250e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7102e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7079e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7018e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6995e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6934e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6765e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6743e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6659e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6598e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6515e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6432e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6410e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6349e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6327e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6267e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6245e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6185e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 743/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6163e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6081e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6021e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5999e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5939e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5918e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5858e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5836e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5777e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5755e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5696e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5512e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5454e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5035e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4977e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4821e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4722e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4511e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4491e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4413e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4337e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4281e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4261e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4184e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4127e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4107e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4031e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3975e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3955e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3749e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3728e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3674e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3579e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3524e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 777/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3449e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3430e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3375e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3302e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3282e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3228e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3155e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3082e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3063e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3009e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2990e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2936e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2917e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2864e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2844e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2791e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2700e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2647e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2576e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2433e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2415e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2343e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2291e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2221e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2132e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2080e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2062e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1923e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1871e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1853e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1784e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1733e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1715e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1664e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.1645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1508e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1457e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1388e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1301e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1251e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1183e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1115e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 811/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1029e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0980e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0962e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0913e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0895e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0779e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0761e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0646e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0629e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0514e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0382e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0365e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0317e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0300e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0234e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0057e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0040e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9993e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9928e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9863e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9846e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9799e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9783e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9719e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9545e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9481e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9465e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9418e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9402e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9356e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9339e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9293e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9277e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9231e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9215e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9169e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9152e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.9090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9045e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8983e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8921e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 845/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8905e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8860e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8843e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8798e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8737e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8721e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8660e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8600e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8539e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8494e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8478e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8418e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8314e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8254e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8238e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8195e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8179e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8120e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8076e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8060e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8017e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8001e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7958e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7942e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7840e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7782e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.7767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7724e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7708e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7666e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7550e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7492e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7477e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7377e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7362e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7304e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7262e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7247e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7205e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7148e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7091e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7020e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6978e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6922e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 879/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6907e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6866e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6810e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6754e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6739e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6698e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6683e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6643e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6587e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6573e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6532e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6422e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6367e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6258e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6244e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6096e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6082e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6042e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5988e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5935e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5921e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5867e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5827e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5813e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5774e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5721e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5024\n",
      "1000\n",
      "(1000, 2879)\n"
     ]
    }
   ],
   "source": [
    "def decode_docs_feature_2(docs_feature, seed):\n",
    "    np.random.seed(seed)\n",
    "    docs_names = flatten_docs_feature(docs_feature)\n",
    "    if len(docs_names) != 0:\n",
    "        windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "        with open(windows_doc_name, 'rb') as f:\n",
    "            windows_doc = pickle.load(f)\n",
    "        window = windows_doc\n",
    "    else:\n",
    "        window = []\n",
    "    return np.asarray(window)\n",
    "\n",
    "features, labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "features_decoded = {key: (value if key != 'docs' \n",
    "                          else list(map(lambda docf: decode_docs_feature_2(docf, seed), value))) \n",
    "                    for key, value in features.items()}\n",
    "# Checking the above steps\n",
    "print(len(features_decoded['docs']))\n",
    "\n",
    "mask = [(sample.shape[0] != 0) for sample in features_decoded['docs']]\n",
    "\n",
    "features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                           else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                     for key, value in features_decoded.items()}\n",
    "\n",
    "labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "# Checking the above steps\n",
    "assert all(sample.shape[0] != 0 for sample in features_filtered['docs'])\n",
    "\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\n",
    "\n",
    "features_shuffled = {key: (value[shuffled_indices] if key != 'docs'\n",
    "                           else [value[i] for i in shuffled_indices])\n",
    "                     for key, value in features_filtered.items()}\n",
    "\n",
    "labels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\n",
    "\n",
    "assert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])\n",
    "print(features_shuffled['log_adj_daily_returns'].shape[0])\n",
    "\n",
    "def pad_documents_2(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, longest_doc_len-arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)\n",
    "\n",
    "X = {key: (pad_documents_2(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\n",
    "y = labels_shuffled['log_adj_daily_returns']\n",
    "print(X['docs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 6, 100)]     0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 6, 1)]       0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           tf_op_layer_stack[0][0]          \n",
      "                                                                 tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "256\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 37s 37ms/sample - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 32s 32ms/sample - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 32s 32ms/sample - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 33s 33ms/sample - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 32s 32ms/sample - loss: 0.0010 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_doc = keras.Input(shape=(None,), name='docs', dtype=tf.int64)\n",
    "# Building Word Embedding Layer\n",
    "word_embedding_layer = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)(input_doc)\n",
    "# Building Document Embedding Layer\n",
    "document_embedding_layer = layers.LSTM(100)(word_embedding_layer)\n",
    "# Creating input to time series layer\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "doc_features = tf.stack([document_embedding_layer for _ in range(6)], axis=1)\n",
    "ts_input = layers.Concatenate()([doc_features, num_features])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_doc], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=5, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the tf dataset section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to load the dataset from its TFRecord file\n",
    "\n",
    "def parse_example(example_proto, feature_description):\n",
    "    '''\n",
    "    Parses example proto from\n",
    "    \n",
    "    :param example_proto: \n",
    "    :param feature_description: \n",
    "    '''\n",
    "    \n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Reconstructing Ragged Tensors from Example\n",
    "    for t in tickers:\n",
    "        example['_'.join(['docs', t])] = tf.RaggedTensor.from_row_lengths(example['docs_{}/vals'.format(t)].values,\n",
    "                                                           row_lengths=example['docs_{}/lens'.format(t)].values)\n",
    "\n",
    "    # Deleting Redundant Keys\n",
    "    for t in tickers:\n",
    "        del example['docs_{}/vals'.format(t)]\n",
    "        del example['docs_{}/lens'.format(t)]\n",
    "        \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "# Loading the raw dataset from the TFRecord file\n",
    "dataset = tf.data.TFRecordDataset(os.path.join(path_to_data, 'dataset.tfrecord'))\n",
    "# Loading the dataset's feature_description\n",
    "with open(os.path.join(path_to_data, 'dataset_feature_description.pickle'), 'rb') as f:\n",
    "    feature_description = pickle.load(f)\n",
    "# Decoding the raw dataset using the dataset's feature_description\n",
    "dataset = dataset.map(lambda example_proto: parse_example(example_proto, feature_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Spliting the dataset by stock ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(example, features, ticker):\n",
    "    return {feature_name: example['_'.join([feature_name, ticker])] for feature_name in features}\n",
    "\n",
    "datasets = [dataset.map(lambda ex: split(ex, ['log_adj_daily_returns', 'docs'], t)) for t in tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reshaping datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to reshape datasets\n",
    "\n",
    "def make_window_dataset(ds, window_size, shift=1, stride=1):\n",
    "    \n",
    "    windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "    \n",
    "    feature_datasets = {key: windows.flat_map(lambda x: x[key].batch(window_size, drop_remainder=True))\n",
    "                        for key in windows.element_spec.keys()}\n",
    "    \n",
    "    return tf.data.Dataset.zip(feature_datasets)\n",
    "\n",
    "def extract_labels(timeslice, label_features):\n",
    "    labels = {}\n",
    "    \n",
    "    for feature_key in timeslice.keys():\n",
    "        feature_timeslice = timeslice[feature_key]\n",
    "        if feature_key in label_features:\n",
    "            labels[feature_key] = feature_timeslice[-1]\n",
    "        timeslice[feature_key] = feature_timeslice[:-1]\n",
    "        \n",
    "    return (timeslice, labels)\n",
    "\n",
    "\n",
    "def to_time_series(ds, label_features, window_size, steps_to_pred=1, num_of_preds=1):\n",
    "    \n",
    "    # making full time series Dataset object (features + labels)\n",
    "    full_ts_ds = make_window_dataset(ds, window_size=window_size+1)\n",
    "    \n",
    "    # mapping dataset to Dataset where each el is: (features: dict, labels)\n",
    "    ts_ds = full_ts_ds.map(lambda s: extract_labels(s, label_features))\n",
    "    \n",
    "    return ts_ds\n",
    "\n",
    "def sample_documents(sample):\n",
    "    # Extracting all documents in the sample\n",
    "    docs_in_sample = sample.values\n",
    "    # Sampling a random document from all the documents in the sample\n",
    "    if docs_in_sample.nrows() != 0:\n",
    "        i = tf.random.uniform([1], maxval=docs_in_sample.nrows(), dtype=tf.int64)[0]\n",
    "        sample_doc = docs_in_sample[i]\n",
    "    else:\n",
    "        sample_doc = tf.constant([], dtype=tf.int64)\n",
    "        \n",
    "    return sample_doc\n",
    "\n",
    "def select_doc(features, labels):\n",
    "    \n",
    "    for fname in features.keys():\n",
    "        feature = features[fname]\n",
    "        timesteps = feature.shape[0]\n",
    "        # Feature is a doc feature\n",
    "        if isinstance(feature, tf.RaggedTensor):\n",
    "            doc = sample_documents(feature)\n",
    "            feature = tf.stack([doc for day in range(timesteps)])\n",
    "            features[fname] = feature\n",
    "        \n",
    "    return (features, *list(labels.values()))\n",
    "\n",
    "def filter_fn(f, l):\n",
    "    shape = tf.shape(f['docs'])[1]\n",
    "    return tf.math.not_equal(shape, 0)\n",
    "\n",
    "def reshape(dataset, window_size, label_name):\n",
    "    # Converting to time series\n",
    "    ds = to_time_series(dataset, label_name, window_size=window_size)\n",
    "    # Selecting document features\n",
    "    ds = ds.map(select_doc)\n",
    "    # Filtering out elements without a document feature\n",
    "    ds = ds.filter(filter_fn)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Datasets\n",
    "reshaped_datasets = list(map(lambda d: reshape(d, TIMESTEPS, 'log_adj_daily_returns'), datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "4. Concatenating datasets, and shuffling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reduce(lambda a, b: a.concatenate(b), reshaped_datasets).shuffle(1000, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Splitting dataset into train, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes for splitting datasets into train, validation, and test datasets\n",
    "\n",
    "def k_folds(dataset, k):\n",
    "    '''\n",
    "    Splits :param dataset: into :param k: number of equally sized (or close to equally sized) components.\n",
    "    \n",
    "    :param dataset: tf.data.Dataset, dataset to split into k folds\n",
    "    :param k: int, number of folds to split :param dataset: into\n",
    "    \n",
    "    ---> list, of tf.data.Dataset objets\n",
    "    '''\n",
    "    return [dataset.shard(k, i) for i in range(k)]\n",
    "\n",
    "def train_test_split(dataset, train_size):\n",
    "    '''\n",
    "    Splits :param dataset: into\n",
    "    \n",
    "    :param dataset: tf.data.Dataset, to split into train and test datasets\n",
    "    :param train_size: float between 0 and 1, proportion of :param dataset: to put into train dataset\n",
    "    \n",
    "    ---> (tf.data.Dataset, tf.data.Dataset), representing train, test datasets\n",
    "    '''\n",
    "    train_size = Fraction(train_size).limit_denominator()\n",
    "    x, k = train_size.numerator, train_size.denominator\n",
    "    folds = k_folds(dataset, k)\n",
    "    train = reduce(lambda a, b: a.concatenate(b), folds[:x])\n",
    "    test = reduce(lambda a, b: a.concatenate(b), folds[x:])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our models we will reserve 60% of the dataset for training, 20% for validation, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our dataset into train, validation, test datasets\n",
    "\n",
    "# Creating datasets\n",
    "train_dataset, test_val_dataset = train_test_split(dataset, train_size=0.6)\n",
    "val_dataset, test_dataset = train_test_split(test_val_dataset, train_size=0.5)\n",
    "\n",
    "# Prepping datasets for modeling\n",
    "train_dataset = (train_dataset.shuffle(10)\n",
    "                 .padded_batch(BATCH_SIZE, \n",
    "                               padded_shapes=({'log_adj_daily_returns': [TIMESTEPS,], \n",
    "                                               'docs': [TIMESTEPS, None]}, [])))\n",
    "val_dataset = (val_dataset.shuffle(10)\n",
    "               .padded_batch(BATCH_SIZE,\n",
    "                             padded_shapes=({'log_adj_daily_returns': [TIMESTEPS,], \n",
    "                                             'docs': [TIMESTEPS, None]}, [])))\n",
    "test_dataset = (test_dataset.shuffle(10)\n",
    "                .padded_batch(BATCH_SIZE, \n",
    "                              padded_shapes=({'log_adj_daily_returns': [TIMESTEPS,], \n",
    "                                              'docs': [TIMESTEPS, None]}, [])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct model layers\n",
    "\n",
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                     weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                     input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                     embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                     activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                     mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct models\n",
    "\n",
    "def model_1(timesteps, vocab, doc_embedding_size, ts_layer_1_size, ts_layer_2_size, ts_layer_3_size,\n",
    "            optimizer, learning_rate, loss, metrics):\n",
    "    '''\n",
    "    Constructs a model with the architecture of \n",
    "    '''\n",
    "    \n",
    "    # Building Input Layers\n",
    "    input_docs = keras.Input(shape=(timesteps, None), name='docs', dtype=tf.int64)\n",
    "    input_log_returns = keras.Input(shape=(timesteps,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "    # Slicing Document Input Layer along time axis\n",
    "    timeslice_layer = [input_docs[:, timestep, :] for timestep in range(timesteps)]\n",
    "    # Building Word Embedding Layer\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "    word_embedding_layer = [word_embedding(timeslice) for timeslice in timeslice_layer]\n",
    "    # Building Document Embedding Layer\n",
    "    document_embedding = layers.LSTM(doc_embedding_size)\n",
    "    document_embedding_layer = [document_embedding(timeslice) for timeslice in word_embedding_layer]\n",
    "    # Preparing Features for Time Series Analysis\n",
    "    num_features = tf.expand_dims(input_log_returns, -1)\n",
    "    doc_features = tf.stack(document_embedding_layer, axis=1)\n",
    "    ts_input = num_features #layers.Concatenate()([doc_features, num_features])\n",
    "    # Building Time Series Layer\n",
    "    #ts_layer_1 = layers.LSTM(ts_layer_1_size, return_sequences=True)(ts_input)\n",
    "    ts_layer_2 = layers.LSTM(ts_layer_2_size, return_sequences=True)(ts_input)\n",
    "    ts_layer_3 = layers.LSTM(ts_layer_3_size)(ts_layer_2)\n",
    "    # Building Output Layer\n",
    "    output = layers.Dense(1, activation='sigmoid')(ts_layer_3)\n",
    "    # Building Model\n",
    "    model = keras.Model([input_docs, input_log_returns], output, name='model_1')\n",
    "    # Compiling Model\n",
    "    if learning_rate == None:\n",
    "        opt = optimizer()\n",
    "    else:\n",
    "        opt = optimizer(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "log_adj_daily_returns (InputLay [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 8, 1)]       0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 8, 1000)      4008000     tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 1000)         8004000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "docs (InputLayer)               [(None, 8, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1001        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 12,013,001\n",
      "Trainable params: 12,013,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/900\n",
      "30/30 [==============================] - 81s 3s/step - loss: 0.6933 - accuracy: 0.5046 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/900\n",
      "30/30 [==============================] - 77s 3s/step - loss: 0.6933 - accuracy: 0.4983 - val_loss: 0.6933 - val_accuracy: 0.4995\n",
      "Epoch 3/900\n",
      "30/30 [==============================] - 76s 3s/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.4995\n",
      "Epoch 4/900\n",
      "30/30 [==============================] - 78s 3s/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6932 - val_accuracy: 0.4995\n",
      "Epoch 5/900\n",
      " 1/30 [>.............................] - ETA: 1:00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-a8115fd1a423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#print(next(iter(train_dataset.unbatch().map(to_categorical).batch(BATCH_SIZE))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mt_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Model 1 with the current hyperparameters\n",
    "tf.keras.backend.clear_session()\n",
    "model = model_1(timesteps=TIMESTEPS, vocab=vocab, doc_embedding_size=DOC_EMBEDDING_UNITS,\n",
    "                ts_layer_1_size=TS_LAYER_1_UNITS, ts_layer_2_size=TS_LAYER_2_UNITS, ts_layer_3_size=TS_LAYER_3_UNITS,\n",
    "                optimizer=OPTIMIZER, learning_rate=LEARNING_RATE, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "print(model.summary())\n",
    "# Converting data to catagorical data\n",
    "def to_categorical(f, l):\n",
    "    if l > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return (f, c)\n",
    "#print(next(iter(train_dataset.unbatch().map(to_categorical).batch(BATCH_SIZE))))\n",
    "t_dataset = train_dataset.unbatch().map(to_categorical).batch(BATCH_SIZE)\n",
    "his = model.fit(t_dataset, epochs=900, validation_data=t_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "metrics = [keras.metrics.Accuracy()]\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "hparams = {'timesteps': window_size, 'vocab': vocab, 'doc_embedding_size': 500, 'ts_layer_1_size': 32,\n",
    "           'ts_layer_2_size': 10, 'ts_layer_3_size': 5}\n",
    "\n",
    "model = get_compiled_model(optimizer=optimizer, loss=loss, metrics=metrics, model=model_1, **hparams)\n",
    "keras.utils.plot_model(model, 'test.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-aab66ff54649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Preparing Inputs for Time Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_log_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdoc_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_embedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m#ts_input = layers.Concatenate()([doc_features, num_features])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mshape_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_inputs_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mreduced_inputs_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m       \u001b[0mshape_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_inputs_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "feature_names = ['log_adj_daily_returns', 'docs_WFC', 'docs_JPM', 'docs_C', 'docs_BAC']\n",
    "\n",
    "# destroying already made graph nodes in the tensorflow backend\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timesteps = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# document embedding Model\n",
    "\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json')) as f:\n",
    "    vocab = json.load(f)\n",
    "        \n",
    "#document = keras.Input(shape=(None,), name='document')\n",
    "#word_embedding = Word_Embedding(vocab, trainable=False)(document)\n",
    "#document_embedding = layers.LSTM(400)(word_embedding)\n",
    "#document_embedder = keras.Model(document, document_embedding, name='document_embedder')\n",
    "#print(document_embedder.summary())\n",
    "\n",
    "#keras.utils.plot_model(document_embedder, 'document_embedder.png', show_shapes=True)\n",
    "\n",
    "\n",
    "\n",
    "# Inputs\n",
    "input_docs_WFC = keras.Input(shape=(timesteps, None), name='docs_WFC')\n",
    "#input_docs_JPM = keras.Input(shape=(timesteps, None), name='docs_JPM')\n",
    "#input_docs_BAC = keras.Input(shape=(timesteps, None), name='docs_BAC')\n",
    "#input_docs_C = keras.Input(shape=(timesteps, None), name='docs_C')\n",
    "input_log_returns = keras.Input(shape=(timesteps,), name='log_adj_daily_returns')\n",
    "\n",
    "# Splitting docs_WFC input into its individual timesteps\n",
    "timesteps_layer = [input_docs_WFC[:, t] for t in range(timesteps)]\n",
    "\n",
    "# Flattening Documents Dimension for each timestep (cause I don't know how to deal with the extra dimension for the LSTM)\n",
    "#flattened_timesteps_layer = [tf.reshape(timestep, [-1, tf.reduce_prod(tf.shape(timestep)[1:])]) for timestep in timesteps_layer]\n",
    "\n",
    "# Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', trainable=True, mask_zero=True)\n",
    "word_embedding_layer = [word_embedding(timestep) for timestep in timesteps_layer]\n",
    "\n",
    "\n",
    "# Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "doc_embedding_layer = [document_embedding(timestep) for timestep in word_embedding_layer]\n",
    "\n",
    "# Preparing Inputs for Time Series\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "doc_features = tf.stack(doc_embedding_layer, axis=1)\n",
    "ts_input = layers.Concatenate()([doc_features, num_features])\n",
    "\n",
    "\n",
    "\n",
    "# Time Series Component\n",
    "time_series = layers.LSTM(100)(ts_input)\n",
    "\n",
    "# Output\n",
    "output = layers.Dense(1)(time_series)\n",
    "\n",
    "# Creating Model\n",
    "test_model = keras.Model({'docs_WFC': input_docs_WFC, 'log_adj_daily_returns': input_log_returns}, output, name='test_model')\n",
    "\n",
    "# Compiling Model\n",
    "test_model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training Model\n",
    "#test_ds = tsds.batch(1).repeat()\n",
    "\n",
    "\n",
    "#test_model.fit_generator(test_ds, epochs=3, steps_per_epoch=100)\n",
    "keras.utils.plot_model(test_model, 'test.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.data.Dataset.range(10)\n",
    "d.element_spec.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## topology\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name='title')\n",
    "\n",
    "keras.utils.plot_model(simple_lstm_model, 'testing.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use pretrained word vectors, and the same word embedding layer for all documents, why? Saves time, and a word in one doc should contain the same meaning as a word in another doc, but the meaning of the document as a whole is different between documents. This assumption would only be violated if each doc emerges from a different culture or micro culture and thus the words used by one microculture would contain different meanings than the same word in another micro culture. This should be the case cause I am assuming business language is to most extents hedgemonic at least in the US and because these business are writing to the SEC it should be even more hedgemonic since there is only one entity that needs to decode the documents. Yadayadayada flesh out thoughts more here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_embedding(vocab, initialize):\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fsfgsfgdsfgsfdgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('heello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEEEEEEEEEEEEEEEExaaaaaaaaaaaaaaaamplesssssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Virtual devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5009d3cbd76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_virtual_device_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVirtualDeviceConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/config.py\u001b[0m in \u001b[0;36mset_virtual_device_configuration\u001b[0;34m(device, virtual_devices)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0mvirtual_devices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mNeed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m   \"\"\"\n\u001b[0;32m--> 556\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_virtual_device_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvirtual_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mset_virtual_device_configuration\u001b[0;34m(self, dev, virtual_devices)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m       raise RuntimeError(\n\u001b[0;32m-> 1271\u001b[0;31m           \"Virtual devices cannot be modified after being initialized\")\n\u001b[0m\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_virtual_device_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvirtual_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Virtual devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3000)])\n",
    "\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path_to_data, 'raw_WFC.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>49.46</td>\n",
       "      <td>49.92</td>\n",
       "      <td>49.15</td>\n",
       "      <td>49.21</td>\n",
       "      <td>49.21</td>\n",
       "      <td>22763506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>48.33</td>\n",
       "      <td>49.07</td>\n",
       "      <td>48.16</td>\n",
       "      <td>48.65</td>\n",
       "      <td>48.65</td>\n",
       "      <td>18267800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>48.17</td>\n",
       "      <td>48.42</td>\n",
       "      <td>48.08</td>\n",
       "      <td>48.15</td>\n",
       "      <td>48.15</td>\n",
       "      <td>13467800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>48.25</td>\n",
       "      <td>48.35</td>\n",
       "      <td>47.54</td>\n",
       "      <td>47.82</td>\n",
       "      <td>47.82</td>\n",
       "      <td>19734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>48.95</td>\n",
       "      <td>49.29</td>\n",
       "      <td>48.75</td>\n",
       "      <td>48.81</td>\n",
       "      <td>48.81</td>\n",
       "      <td>15691900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   open   high    low  close  adjusted_close      volume  \\\n",
       "0  2019-10-11  49.46  49.92  49.15  49.21           49.21  22763506.0   \n",
       "1  2019-10-10  48.33  49.07  48.16  48.65           48.65  18267800.0   \n",
       "2  2019-10-09  48.17  48.42  48.08  48.15           48.15  13467800.0   \n",
       "3  2019-10-08  48.25  48.35  47.54  47.82           47.82  19734000.0   \n",
       "4  2019-10-07  48.95  49.29  48.75  48.81           48.81  15691900.0   \n",
       "\n",
       "   dividend_amount  split_coefficient  \\\n",
       "0              0.0                1.0   \n",
       "1              0.0                1.0   \n",
       "2              0.0                1.0   \n",
       "3              0.0                1.0   \n",
       "4              0.0                1.0   \n",
       "\n",
       "                                                 doc  \n",
       "0  [{\"link\": \"/media/Data/Programs/FinTech/data/d...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  [{\"link\": \"/media/Data/Programs/FinTech/data/d...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Price Data\n",
    "df['log_adj_daily_returns'] = np.log(df['adjusted_close'].shift(1)) - np.log(df['adjusted_close'])\n",
    "df.dropna(subset=['log_adj_daily_returns'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>doc</th>\n",
       "      <th>log_adj_daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>48.33</td>\n",
       "      <td>49.07</td>\n",
       "      <td>48.16</td>\n",
       "      <td>48.65</td>\n",
       "      <td>48.65</td>\n",
       "      <td>18267800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>48.17</td>\n",
       "      <td>48.42</td>\n",
       "      <td>48.08</td>\n",
       "      <td>48.15</td>\n",
       "      <td>48.15</td>\n",
       "      <td>13467800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>48.25</td>\n",
       "      <td>48.35</td>\n",
       "      <td>47.54</td>\n",
       "      <td>47.82</td>\n",
       "      <td>47.82</td>\n",
       "      <td>19734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>48.95</td>\n",
       "      <td>49.29</td>\n",
       "      <td>48.75</td>\n",
       "      <td>48.81</td>\n",
       "      <td>48.81</td>\n",
       "      <td>15691900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>48.66</td>\n",
       "      <td>49.25</td>\n",
       "      <td>48.53</td>\n",
       "      <td>49.21</td>\n",
       "      <td>49.21</td>\n",
       "      <td>15779500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>-0.008162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   open   high    low  close  adjusted_close      volume  \\\n",
       "1  2019-10-10  48.33  49.07  48.16  48.65           48.65  18267800.0   \n",
       "2  2019-10-09  48.17  48.42  48.08  48.15           48.15  13467800.0   \n",
       "3  2019-10-08  48.25  48.35  47.54  47.82           47.82  19734000.0   \n",
       "4  2019-10-07  48.95  49.29  48.75  48.81           48.81  15691900.0   \n",
       "5  2019-10-04  48.66  49.25  48.53  49.21           49.21  15779500.0   \n",
       "\n",
       "   dividend_amount  split_coefficient  \\\n",
       "1              0.0                1.0   \n",
       "2              0.0                1.0   \n",
       "3              0.0                1.0   \n",
       "4              0.0                1.0   \n",
       "5              0.0                1.0   \n",
       "\n",
       "                                                 doc  log_adj_daily_returns  \n",
       "1                                                NaN               0.011445  \n",
       "2                                                NaN               0.010331  \n",
       "3  [{\"link\": \"/media/Data/Programs/FinTech/data/d...               0.006877  \n",
       "4                                                NaN              -0.020491  \n",
       "5  [{\"link\": \"/media/Data/Programs/FinTech/data/d...              -0.008162  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>doc</th>\n",
       "      <th>log_adj_daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5028</td>\n",
       "      <td>1999-10-18</td>\n",
       "      <td>19.4690</td>\n",
       "      <td>19.844</td>\n",
       "      <td>19.2507</td>\n",
       "      <td>19.750</td>\n",
       "      <td>11.4299</td>\n",
       "      <td>5041000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5029</td>\n",
       "      <td>1999-10-15</td>\n",
       "      <td>19.3749</td>\n",
       "      <td>19.938</td>\n",
       "      <td>19.2190</td>\n",
       "      <td>19.500</td>\n",
       "      <td>11.2853</td>\n",
       "      <td>7528400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5030</td>\n",
       "      <td>1999-10-14</td>\n",
       "      <td>19.8133</td>\n",
       "      <td>20.406</td>\n",
       "      <td>19.7810</td>\n",
       "      <td>20.281</td>\n",
       "      <td>11.7374</td>\n",
       "      <td>6496800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.039279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5031</td>\n",
       "      <td>1999-10-13</td>\n",
       "      <td>20.7190</td>\n",
       "      <td>20.938</td>\n",
       "      <td>19.4690</td>\n",
       "      <td>19.844</td>\n",
       "      <td>11.4842</td>\n",
       "      <td>4730400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5032</td>\n",
       "      <td>1999-10-12</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>20.6560</td>\n",
       "      <td>20.844</td>\n",
       "      <td>12.0629</td>\n",
       "      <td>3970600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.049162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp     open    high      low   close  adjusted_close     volume  \\\n",
       "5028  1999-10-18  19.4690  19.844  19.2507  19.750         11.4299  5041000.0   \n",
       "5029  1999-10-15  19.3749  19.938  19.2190  19.500         11.2853  7528400.0   \n",
       "5030  1999-10-14  19.8133  20.406  19.7810  20.281         11.7374  6496800.0   \n",
       "5031  1999-10-13  20.7190  20.938  19.4690  19.844         11.4842  4730400.0   \n",
       "5032  1999-10-12  21.0000  21.000  20.6560  20.844         12.0629  3970600.0   \n",
       "\n",
       "      dividend_amount  split_coefficient  doc  log_adj_daily_returns  \n",
       "5028              0.0                1.0  NaN               0.052400  \n",
       "5029              0.0                1.0  NaN               0.012732  \n",
       "5030              0.0                1.0  NaN              -0.039279  \n",
       "5031              0.0                1.0  NaN               0.021808  \n",
       "5032              0.0                1.0  NaN              -0.049162  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_time_series() got an unexpected keyword argument 'n_trail'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f94281e21291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_trail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_lead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'log_adj_daily_returns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_lead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: to_time_series() got an unexpected keyword argument 'n_trail'"
     ]
    }
   ],
   "source": [
    "n_trail = 4\n",
    "n_lead = 1\n",
    "df = to_time_series(df, ['log_adj_daily_returns'], n_trail=n_trail, n_lead=n_lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>doc</th>\n",
       "      <th>log_adj_daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>48.33</td>\n",
       "      <td>49.07</td>\n",
       "      <td>48.16</td>\n",
       "      <td>48.65</td>\n",
       "      <td>48.65</td>\n",
       "      <td>18267800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>48.17</td>\n",
       "      <td>48.42</td>\n",
       "      <td>48.08</td>\n",
       "      <td>48.15</td>\n",
       "      <td>48.15</td>\n",
       "      <td>13467800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>48.25</td>\n",
       "      <td>48.35</td>\n",
       "      <td>47.54</td>\n",
       "      <td>47.82</td>\n",
       "      <td>47.82</td>\n",
       "      <td>19734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>48.95</td>\n",
       "      <td>49.29</td>\n",
       "      <td>48.75</td>\n",
       "      <td>48.81</td>\n",
       "      <td>48.81</td>\n",
       "      <td>15691900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>48.66</td>\n",
       "      <td>49.25</td>\n",
       "      <td>48.53</td>\n",
       "      <td>49.21</td>\n",
       "      <td>49.21</td>\n",
       "      <td>15779500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>-0.008162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   open   high    low  close  adjusted_close      volume  \\\n",
       "1  2019-10-10  48.33  49.07  48.16  48.65           48.65  18267800.0   \n",
       "2  2019-10-09  48.17  48.42  48.08  48.15           48.15  13467800.0   \n",
       "3  2019-10-08  48.25  48.35  47.54  47.82           47.82  19734000.0   \n",
       "4  2019-10-07  48.95  49.29  48.75  48.81           48.81  15691900.0   \n",
       "5  2019-10-04  48.66  49.25  48.53  49.21           49.21  15779500.0   \n",
       "\n",
       "   dividend_amount  split_coefficient  \\\n",
       "1              0.0                1.0   \n",
       "2              0.0                1.0   \n",
       "3              0.0                1.0   \n",
       "4              0.0                1.0   \n",
       "5              0.0                1.0   \n",
       "\n",
       "                                                 doc  log_adj_daily_returns  \n",
       "1                                                NaN               0.011445  \n",
       "2                                                NaN               0.010331  \n",
       "3  [{\"link\": \"/media/Data/Programs/FinTech/data/d...               0.006877  \n",
       "4                                                NaN              -0.020491  \n",
       "5  [{\"link\": \"/media/Data/Programs/FinTech/data/d...              -0.008162  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>doc</th>\n",
       "      <th>log_adj_daily_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>48.25</td>\n",
       "      <td>48.35</td>\n",
       "      <td>47.54</td>\n",
       "      <td>47.82</td>\n",
       "      <td>47.82</td>\n",
       "      <td>19734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>48.66</td>\n",
       "      <td>49.25</td>\n",
       "      <td>48.53</td>\n",
       "      <td>49.21</td>\n",
       "      <td>49.21</td>\n",
       "      <td>15779500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>-0.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>48.30</td>\n",
       "      <td>48.51</td>\n",
       "      <td>47.32</td>\n",
       "      <td>48.48</td>\n",
       "      <td>48.48</td>\n",
       "      <td>20212200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>0.014946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>48.72</td>\n",
       "      <td>49.04</td>\n",
       "      <td>48.37</td>\n",
       "      <td>48.47</td>\n",
       "      <td>48.47</td>\n",
       "      <td>23515900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>50.77</td>\n",
       "      <td>50.85</td>\n",
       "      <td>50.06</td>\n",
       "      <td>50.44</td>\n",
       "      <td>50.44</td>\n",
       "      <td>26897100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{\"link\": \"/media/Data/Programs/FinTech/data/d...</td>\n",
       "      <td>-0.027740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp   open   high    low  close  adjusted_close      volume  \\\n",
       "3  2019-10-08  48.25  48.35  47.54  47.82           47.82  19734000.0   \n",
       "5  2019-10-04  48.66  49.25  48.53  49.21           49.21  15779500.0   \n",
       "6  2019-10-03  48.30  48.51  47.32  48.48           48.48  20212200.0   \n",
       "7  2019-10-02  48.72  49.04  48.37  48.47           48.47  23515900.0   \n",
       "9  2019-09-30  50.77  50.85  50.06  50.44           50.44  26897100.0   \n",
       "\n",
       "   dividend_amount  split_coefficient  \\\n",
       "3              0.0                1.0   \n",
       "5              0.0                1.0   \n",
       "6              0.0                1.0   \n",
       "7              0.0                1.0   \n",
       "9              0.0                1.0   \n",
       "\n",
       "                                                 doc  log_adj_daily_returns  \n",
       "3  [{\"link\": \"/media/Data/Programs/FinTech/data/d...               0.006877  \n",
       "5  [{\"link\": \"/media/Data/Programs/FinTech/data/d...              -0.008162  \n",
       "6  [{\"link\": \"/media/Data/Programs/FinTech/data/d...               0.014946  \n",
       "7  [{\"link\": \"/media/Data/Programs/FinTech/data/d...               0.000206  \n",
       "9  [{\"link\": \"/media/Data/Programs/FinTech/data/d...              -0.027740  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 17860 into shape (1786,5,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4fcbdb7812f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Reshaping X the features to be of dimensions (samples, timesteps, features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trail\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trail\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 17860 into shape (1786,5,1)"
     ]
    }
   ],
   "source": [
    "feature_cols = df.columns[0:(len(df.columns) - 1)]\n",
    "target_cols = df.columns[-1:]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "\n",
    "# Randomly sampling our rows of data into training and testing dataset (LSTM's state is reset after stepping through each timestep of a single sampe)\n",
    "train_split = 0.75\n",
    "\n",
    "mask = np.random.rand(len(y)) < train_split\n",
    "\n",
    "X_train, y_train = X[mask], y[mask]\n",
    "X_test, y_test = X[~mask], y[~mask]\n",
    "\n",
    "# Reshaping X the features to be of dimensions (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], n_trail + 1, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_trail + 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single window of past history\n",
      "['2019-10-04' 48.66 49.25 48.53 49.21 49.21 15779500.0 0.0 1.0\n",
      " '[{\"link\": \"/media/Data/Programs/FinTech/data/documents/WFC/0001387131-19-007434.txt\", \"ticker\": \"WFC\"}]']\n",
      "\n",
      " Target temperature to predict\n",
      "[-0.00816164]\n"
     ]
    }
   ],
   "source": [
    "print ('Single window of past history')\n",
    "print (X_train[0])\n",
    "print ('\\n Target temperature to predict')\n",
    "print (y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "    time_steps = []\n",
    "    for i in range(-length, 0, 1):\n",
    "        time_steps.append(i)\n",
    "    return time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = ['History', 'True Future', 'Model Prediction']\n",
    "    marker = ['.-', 'rx', 'go']\n",
    "    time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, x in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
    "                     label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future+5)*2])\n",
    "    plt.xlabel('Time-Step')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "48.66 is not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8bbd71dca813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sample Example'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-002766c00a45>\u001b[0m in \u001b[0;36mshow_plot\u001b[0;34m(plot_data, delta, title)\u001b[0m\n\u001b[1;32m     14\u001b[0m                      label=labels[i])\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mbx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mupdate_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0mneednew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m         \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/category.py\u001b[0m in \u001b[0;36mdefault_units\u001b[0;34m(data, axis)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# default_units->axis_info->convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/category.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/matplotlib/category.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;31m# OrderedDict just iterates over unique values in data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{val!r} is not a string\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvertible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;31m# this will only be called so long as convertible is True.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 48.66 is not a string"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plot([X_train[0], y_train[0]], 0, 'Sample Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(history):\n",
    "    return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c5002b88212b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Baseline Prediction Example'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-877f3f81bc73>\u001b[0m in \u001b[0;36mbaseline\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "show_plot([X_train[0], y_train[0], baseline(X_train[0])], 0, 'Baseline Prediction Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f81dd90c9e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBUFFER_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    433\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 111\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    112\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-93e4d7fbfe28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m simple_lstm_model = tf.keras.models.Sequential([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    t,\n",
    "    tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')\n",
    "simple_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-28b00083f406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset.take(1):\n",
    "    print(simple_lstm_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple_lstm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-cdac5b91eb1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = simple_lstm_model.fit(train_dataset, epochs=EPOCHS,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEVALUATION_INTERVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                   validation_data=test_dataset, validation_steps=50)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_lstm_model' is not defined"
     ]
    }
   ],
   "source": [
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = simple_lstm_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                                  steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                  validation_data=test_dataset, validation_steps=50)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d26dcf3ac1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     plot = show_plot([x[0].numpy(), y[0].numpy(),\n\u001b[1;32m      3\u001b[0m                      simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n\u001b[1;32m      4\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset.take(3):\n",
    "    plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
    "                     simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_time_series(df, columns, start_from_t0=1, end_from_t0=1):\n",
    "    '''\n",
    "    :param df: DataFrame, dataframe object where the columns are the features and labels and the rows are days\n",
    "    :param columns: list of strings, names of the features and labels (columns of df) to be used in the time series\n",
    "    :param n_trail: int, number of days behind day 0 that will be used to predict days after day 0\n",
    "    :param n_lead: int, number of days ahead of day 0 that will be predicted\n",
    "    \n",
    "    ---> DataFrame, dataframe object structured like a time series where each row represents an element in the time\n",
    "                    series, and each column is a feature or label a certain amount of days in the future or past.\n",
    "    '''\n",
    "    df = df[columns]\n",
    "    dfs = []\n",
    "    col_names = []\n",
    "    \n",
    "    # Create trailing columns\n",
    "    for i in range(start_from_t0, end_from_t0+1):\n",
    "        dfs.append(df.shift(i))\n",
    "        col_names += [(col_name + '(t{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    agg = pd.concat(dfs, axis=1)\n",
    "    agg.columns = col_names\n",
    "    \n",
    "    #agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_pm(raw_df):\n",
    "    '''\n",
    "    Preprocessing raw_df into the shape raw_df should have been after coming out of the fetch process, as well as \n",
    "    normalizing the documents.\n",
    "    '''\n",
    "    \n",
    "    # Reshaping DataFrame\n",
    "    reshaped_df = reshape(raw_df)\n",
    "    \n",
    "    # Normalizing and updating documents    \n",
    "    def update_doclist(s):\n",
    "        doclist = json.loads(s)\n",
    "        updated_doclist = []\n",
    "        for docpath in doclist:\n",
    "            save_point = os.path.join(os.path.split(docpath)[0], 'normalized')\n",
    "            norm_docpath = normalize_save_document(docpath, save_point)\n",
    "            updated_doclist.append(norm_docpath)\n",
    "            \n",
    "        return json.dumps(updated_doclist)\n",
    "    \n",
    "    for t in tickers:\n",
    "        reshaped_df['_'.join(['docs', t])] = reshaped_df['_'.join(['docs', t])].map(update_doclist)\n",
    "        \n",
    "    # Preprocessing numerical data\n",
    "    reshaped_df['log_adj_close'] = np.log(reshaped_df['adjusted_close'])\n",
    "    reshaped_df['log_adj_daily_returns'] = reshaped_df['log_adj_close'] - reshaped_df['log_adj_close'].shift(-1)\n",
    "    reshaped_df.dropna(subset=['log_adj_daily_returns'], inplace=True)\n",
    "    \n",
    "    # Building vocabulary json file\n",
    "    path_to_vocab = os.path.join(path_to_data, 'vocab.json')\n",
    "    \n",
    "    def vocab_from_doclist(s):\n",
    "        \n",
    "        doclist = json.loads(s)\n",
    "        \n",
    "        for docpath in doclist:\n",
    "            with open(docpath, 'r') as f:\n",
    "                doc = f.read()\n",
    "            \n",
    "            build_vocab(doc)\n",
    "        \n",
    "        return json.dumps(doclist)\n",
    "    \n",
    "    for t in tickers:\n",
    "        reshaped_df['_'.join(['docs', t])].map(vocab_from_doclist)\n",
    "        \n",
    "    # Encoding documents based off of vocabulary json file\n",
    "    \n",
    "    \n",
    "    return reshaped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing tfrecords\n",
    "\n",
    "feature_names = ['log_adj_daily_returns', 'docs_WFC', 'docs_JPM', 'docs_C', 'docs_BAC']\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "\n",
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    '''Returns a bytes_list from a string / byte.'''\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    '''Returns a float_list from a float / double.'''\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    '''Returns an int64_list from a bool / enum / int / uint.'''\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(sample, feature_names):\n",
    "    \n",
    "    feature = {}\n",
    "    \n",
    "    for feature_name in feature_names:\n",
    "        # if feature is a number \n",
    "        if isinstance(sample[feature_name], float):\n",
    "            feature[feature_name] = tf.train.Feature(float_list=tf.train.FloatList(value=[sample[feature_name]]))\n",
    "        \n",
    "        # if feature is a doclist\n",
    "        elif isinstance(sample[feature_name], list):\n",
    "            lens = list(map(len, sample[feature_name]))\n",
    "            values = [word for doc in sample[feature_name] for word in doc]\n",
    "            feature[feature_name + '/vals'] = tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "            feature[feature_name + '/lens'] = tf.train.Feature(int64_list=tf.train.Int64List(value=lens))\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "\n",
    "\n",
    "def unpack_doclist(doclist_string):        \n",
    "    def load_encode_file(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            text = f.read()\n",
    "        return [vocab[word] for word in text.split()]\n",
    "    return list(map(load_encode_file, json.loads(doclist_string)))\n",
    "\n",
    "\n",
    "record_file = 'test.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for i in range(300, -1, -1):\n",
    "        row = raw_df_fixed.iloc[i].copy(deep=True)\n",
    "        # Unpacking Text Features\n",
    "        row[['_'.join(['docs', t]) for t in tickers]] = row[['_'.join(['docs', t]) for t in tickers]].map(unpack_doclist)\n",
    "        # Serializing Example to disk\n",
    "        example = serialize_example(row, feature_names)\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def decode_docs_feature_2(docs_feature, seed):\\n    np.random.seed(seed)\\n    docs_names = flatten_docs_feature(docs_feature)\\n    if len(docs_names) != 0:\\n        windows_doc_name = np.random.choice(docs_names, size=1)[0]\\n        with open(windows_doc_name, 'rb') as f:\\n            windows_doc = pickle.load(f)\\n        window = windows_doc\\n    else:\\n        window = []\\n    return np.asarray(window)\\n\\nfeatures, labels = extract_labels(dataset, ['log_adj_daily_returns'])\\nfeatures_decoded = {key: (value if key != 'docs' \\n                          else list(map(lambda docf: decode_docs_feature_2(docf, seed), value))) \\n                    for key, value in features.items()}\\n# Checking the above steps\\nprint(len(features_decoded['docs']))\\n\\nmask = [(sample.shape[0] != 0) for sample in features_decoded['docs']]\\n\\nfeatures_filtered = {key: (value[mask, :] if key != 'docs'\\n                           else [value[i] for i in range(len(mask)) if mask[i]])\\n                     for key, value in features_decoded.items()}\\n\\nlabels_filtered = {key: value[mask] for key, value in labels.items()}\\n# Checking the above steps\\nassert all(sample.shape[0] != 0 for sample in features_filtered['docs'])\\n\\nnp.random.seed(seed)\\nshuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\\n\\nfeatures_shuffled = {key: (value[shuffled_indices] if key != 'docs'\\n                           else [value[i] for i in shuffled_indices])\\n                     for key, value in features_filtered.items()}\\n\\nlabels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\\n\\nassert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])\\nprint(features_shuffled['log_adj_daily_returns'].shape[0])\\n\\ndef pad_documents_2(docs_feature):\\n    shapes = map(lambda arr: arr.shape, docs_feature)\\n    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\\n    pad_doc = lambda arr:  np.pad(arr, ((0, longest_doc_len-arr.shape[-1])), constant_values=0)\\n    return np.stack(list(map(pad_doc, docs_feature)), axis=0)\\n\\nX = {key: (pad_documents_2(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\\ny = labels_shuffled['log_adj_daily_returns']\\nprint(X['docs'].shape)\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def decode_docs_feature_2(docs_feature, seed):\n",
    "    np.random.seed(seed)\n",
    "    docs_names = flatten_docs_feature(docs_feature)\n",
    "    if len(docs_names) != 0:\n",
    "        windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "        with open(windows_doc_name, 'rb') as f:\n",
    "            windows_doc = pickle.load(f)\n",
    "        window = windows_doc\n",
    "    else:\n",
    "        window = []\n",
    "    return np.asarray(window)\n",
    "\n",
    "features, labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "features_decoded = {key: (value if key != 'docs' \n",
    "                          else list(map(lambda docf: decode_docs_feature_2(docf, seed), value))) \n",
    "                    for key, value in features.items()}\n",
    "# Checking the above steps\n",
    "print(len(features_decoded['docs']))\n",
    "\n",
    "mask = [(sample.shape[0] != 0) for sample in features_decoded['docs']]\n",
    "\n",
    "features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                           else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                     for key, value in features_decoded.items()}\n",
    "\n",
    "labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "# Checking the above steps\n",
    "assert all(sample.shape[0] != 0 for sample in features_filtered['docs'])\n",
    "\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\n",
    "\n",
    "features_shuffled = {key: (value[shuffled_indices] if key != 'docs'\n",
    "                           else [value[i] for i in shuffled_indices])\n",
    "                     for key, value in features_filtered.items()}\n",
    "\n",
    "labels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\n",
    "\n",
    "assert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])\n",
    "print(features_shuffled['log_adj_daily_returns'].shape[0])\n",
    "\n",
    "def pad_documents_2(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, longest_doc_len-arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)\n",
    "\n",
    "X = {key: (pad_documents_2(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\n",
    "y = labels_shuffled['log_adj_daily_returns']\n",
    "print(X['docs'].shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Creating a Model and attempting to overfit it\\n## Defining Model\\ntf.keras.backend.clear_session()\\n\\n# Input Layers\\ninput_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\\ninput_doc = keras.Input(shape=(None,), name='docs', dtype=tf.int64)\\n# Building Word Embedding Layer\\nword_embedding_layer = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)(input_doc)\\n# Building Document Embedding Layer\\ndocument_embedding_layer = layers.LSTM(100)(word_embedding_layer)\\n# Creating input to time series layer\\nnum_features = tf.expand_dims(input_log_returns, -1)\\ndoc_features = tf.stack([document_embedding_layer for _ in range(6)], axis=1)\\nts_input = layers.Concatenate()([doc_features, num_features])\\n# Time series component\\nts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\\n#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\\n#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\\n#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\\n#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\\noutput = layers.Dense(1)(ts_layer_1)\\n\\nmodel = keras.Model([input_log_returns, input_doc], output, name='test_model')\\nmodel.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\\nprint(model.summary())\\nkeras.utils.plot_model(model, 'test.png', show_shapes=True)\\nprint(batch_size)\\nhistory = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_doc = keras.Input(shape=(None,), name='docs', dtype=tf.int64)\n",
    "# Building Word Embedding Layer\n",
    "word_embedding_layer = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)(input_doc)\n",
    "# Building Document Embedding Layer\n",
    "document_embedding_layer = layers.LSTM(100)(word_embedding_layer)\n",
    "# Creating input to time series layer\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "doc_features = tf.stack([document_embedding_layer for _ in range(6)], axis=1)\n",
    "ts_input = layers.Concatenate()([doc_features, num_features])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_doc], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing our data involves:\n",
    "1. Loading the dataset from the TFRecord file\n",
    "2. Splitting the dataset by stock ticker\n",
    "3. Reshaping each dataset to prepare it for training:\n",
    "    1. Windowing the dataset so each element produces a time series of features along with there corresponding label\n",
    "    2. Sampling the document feature for the document that will represent the specific window's document and cloning that document for each timestep in our defined window size\n",
    "    3. Filtering our dataset to include only elements with a document feature\n",
    "4. Concatenating the reshaped datasets together, and shuffling the dataset\n",
    "5. Splitting the dataset into train, validation, and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the dataset from TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Dataset to TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sucessfully preprocessing our dataset we next write our dataset to a TFRecords file (https://www.tensorflow.org/tutorials/load_data/tfrecord) a binary file format that is read efficiently by the TensorFlow framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes used to write TFRecord files\n",
    "\n",
    "def serialize_example(sample, feature_names):\n",
    "    '''\n",
    "    Maps dictionary :param sample: to a tf.train.Example object where the list feature_names determines which \n",
    "    subset of :param sample:'s keys are to be used. \n",
    "    \n",
    "    :param sample: dict, where the keys are the names of the features of the specific data sample, and the values \n",
    "                   are the values each feature takes on for the specific data sample\n",
    "    :param feature_names: list, of strings, a subset of sample.keys(), these are the features we will\n",
    "                          be considering for analysis\n",
    "    \n",
    "    ---> tf.train.Example, object representing the data sample\n",
    "    '''\n",
    "    \n",
    "    feature = {}\n",
    "    feature_description = {}\n",
    "    \n",
    "    for feature_name in feature_names:\n",
    "        # if feature is a float number \n",
    "        if isinstance(sample[feature_name], float):\n",
    "            feature[feature_name] = tf.train.Feature(float_list=tf.train.FloatList(value=[sample[feature_name]]))\n",
    "            feature_description[feature_name] = tf.io.FixedLenFeature([], tf.float32)\n",
    "        \n",
    "        # if feature is a list of documents\n",
    "        elif isinstance(sample[feature_name], list) and all(isinstance(word, int) for doc in sample[feature_name] for word in doc):\n",
    "            lens = list(map(len, sample[feature_name]))\n",
    "            values = [word for doc in sample[feature_name] for word in doc]\n",
    "            feature[feature_name + '/vals'] = tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "            feature[feature_name + '/lens'] = tf.train.Feature(int64_list=tf.train.Int64List(value=lens))\n",
    "            feature_description[feature_name + '/vals'] = tf.io.VarLenFeature(dtype=tf.int64)\n",
    "            feature_description[feature_name + '/lens'] = tf.io.VarLenFeature(dtype=tf.int64)\n",
    "        \n",
    "        # if feature is an integer number\n",
    "        elif isinstance(sample[feature_name], int):\n",
    "            feature[feature_name] = tf.train.Feature(int64_list=tf.train.Int64List(value=[sample[feature_name]]))\n",
    "            feature_description[feature_name] = tf.io.FixedLenFeature([], tf.int64)\n",
    "        \n",
    "        # Feature doesn't fit any of the tf example types\n",
    "        else:\n",
    "            raise ValueError('Value of Feature does not fit any of the tf.train.Feature serializable types')\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature)), feature_description\n",
    "\n",
    "\n",
    "def write_tfrecord(df, feature_names, filename='dataset.tfrecord'):\n",
    "    '''\n",
    "    Writes TFRecord file named :param filename: to dataset directory, and generates the corresponding \n",
    "    feature_description dictionary mapping a sample's feature name to the data type description of that\n",
    "    feature.\n",
    "    \n",
    "    :param df: pd.DataFrame, containing data and refrences to data that needs to be written to disk\n",
    "    :param feature_names, list of strings, a subset of the names of columns of df, that represents which subset\n",
    "                          of features from our preprocessed DataFrame that will be considered for modeling\n",
    "    :param filename: string, name of TFRecord file\n",
    "    \n",
    "    ---> dict, of names of features mapping to tf.io.VarLenFeature and tf.io.FixedLenFeature objects\n",
    "    '''\n",
    "    \n",
    "    def unpack_doclist(doclist_string):\n",
    "        '''\n",
    "        Takes a json format string that when loaded contains a list of paths to encoded document pickle files, and\n",
    "        returns a list of the objects loaded from these pickle files.\n",
    "        \n",
    "        :param doclist_string: string, json formated, contain a list of paths to encoded document pickle files\n",
    "        \n",
    "        ---> list, of encoded documents\n",
    "        '''\n",
    "        \n",
    "        def load_file(filename):\n",
    "            '''\n",
    "            Takes a path to a pickle file, and returns the loaded object.\n",
    "            \n",
    "            :param filename: string, path to pickle file\n",
    "            \n",
    "            ---> python object loaded file located at :param filename:\n",
    "            '''\n",
    "            \n",
    "            with open(filename, 'rb') as f:\n",
    "                doc = pickle.load(f)\n",
    "            return doc\n",
    "        \n",
    "        return list(map(load_file, json.loads(doclist_string)))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(os.path.join(path_to_data, filename)) as writer:\n",
    "        print('Writing TFRecord file to: {}'.format(os.path.join(path_to_data, filename)))\n",
    "        for i in range(len(df)-1, -1, -1):\n",
    "            row = df.iloc[i].copy(deep=True)\n",
    "            # Unpacking Text Features\n",
    "            row[['_'.join(['docs', t]) for t in tickers]] = row[['_'.join(['docs', t]) for t in tickers]].map(unpack_doclist)\n",
    "            # Serializing Example to disk\n",
    "            example, feature_description = serialize_example(row, feature_names)\n",
    "            writer.write(example.SerializeToString())\n",
    "    print('Finished writing TFRecord file.')\n",
    "\n",
    "    return feature_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features we will be considering for analysis are: log_adj_daily_returns_WFC, log_adj_daily_returns_JPM, log_adj_daily_returns_BAC, log_adj_daily_returns_C, docs_WFC, docs_JPM, docs_BAC, docs_C\n",
      "\n",
      "Writing TFRecord file to: /media/Data/Programs/FinTech/data/dataset.tfrecord\n",
      "Finished writing TFRecord file.\n"
     ]
    }
   ],
   "source": [
    "# Writing TFRecord file\n",
    "\n",
    "# Defining the subset of features from our preprocessed DataFrame that we will be using for modeling\n",
    "feature_names = ['_'.join([feature, t]) for feature in ['log_adj_daily_returns', 'docs'] for t in tickers]\n",
    "print('The features we will be considering for analysis are: {}'.format(', '.join(feature_names)))\n",
    "print()\n",
    "# Loading the preprocessed DataFrame from disk if it has not been instantiated\n",
    "try:\n",
    "    preprocessed_df\n",
    "except:\n",
    "    preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "# Writing the TFRecord file\n",
    "feature_description = write_tfrecord(preprocessed_df, feature_names)\n",
    "# Writing the TFRecord's feature_description object to disk\n",
    "with open(os.path.join(path_to_data, 'dataset_feature_description.pickle'), 'wb') as f:\n",
    "    pickle.dump(feature_description, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we will be using only the bare minimum amount of features for modeling ie: our text features listed in the doc columns and the feature we are trying to predict in time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
