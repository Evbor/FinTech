{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predicting Stock Yields using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "- update text portions of notebook for intro price EDA\n",
    "- make notebook able to updated dfs.\n",
    "- get rid of hardcoded feature names in modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning NLP techniques to map raw text to dense vector representations have had some surprising success in the world of computer natural language processing compared to classical means of encoding text. In this project we will attempt to leverage some of these techniques to help assist us in time series analysis on stock yields. The company we will choose to investigate is Wells Fargo (stock ticker: WFC), and the text data we will be leveraging are the SEC forms of Wells Fargo along with its competitors: JPMorgan Chase, Bank of America, and Citigroup. Specifically the 8-K form. The 8-K form was chosen because it tends to be the more text rich SEC document when compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Notebook Global Variables\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "# Company Stock Ticker and CIK number\n",
    "ticker = 'WFC'\n",
    "competitors = ['JPM', 'BAC', 'C']\n",
    "tickers = [ticker] + competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: Model Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must have preprocessing component ran, and saved the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fractions import Fraction\n",
    "from functools import reduce\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Random Seed\n",
    "seed = 15\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame:\n",
      "    numbers letters\n",
      "25       26       z\n",
      "24       25       y\n",
      "23       24       x\n",
      "22       23       w\n",
      "21       22       v\n",
      "20       21       u\n",
      "19       20       t\n",
      "18       19       s\n",
      "17       18       r\n",
      "16       17       q\n",
      "15       16       p\n",
      "14       15       o\n",
      "13       14       n\n",
      "12       13       m\n",
      "11       12       l\n",
      "10       11       k\n",
      "9        10       j\n",
      "8         9       i\n",
      "7         8       h\n",
      "6         7       g\n",
      "5         6       f\n",
      "4         5       e\n",
      "3         4       d\n",
      "2         3       c\n",
      "1         2       b\n",
      "0         1       a\n",
      "\n",
      "Time Series DataFrame with a window size of n_trail+1\n",
      "    numbers(t-5) letters(t-5)  numbers(t-4) letters(t-4)  numbers(t-3)  \\\n",
      "24          20.0            t          21.0            u          22.0   \n",
      "23          19.0            s          20.0            t          21.0   \n",
      "22          18.0            r          19.0            s          20.0   \n",
      "21          17.0            q          18.0            r          19.0   \n",
      "20          16.0            p          17.0            q          18.0   \n",
      "19          15.0            o          16.0            p          17.0   \n",
      "18          14.0            n          15.0            o          16.0   \n",
      "17          13.0            m          14.0            n          15.0   \n",
      "16          12.0            l          13.0            m          14.0   \n",
      "15          11.0            k          12.0            l          13.0   \n",
      "14          10.0            j          11.0            k          12.0   \n",
      "13           9.0            i          10.0            j          11.0   \n",
      "12           8.0            h           9.0            i          10.0   \n",
      "11           7.0            g           8.0            h           9.0   \n",
      "10           6.0            f           7.0            g           8.0   \n",
      "9            5.0            e           6.0            f           7.0   \n",
      "8            4.0            d           5.0            e           6.0   \n",
      "7            3.0            c           4.0            d           5.0   \n",
      "6            2.0            b           3.0            c           4.0   \n",
      "5            1.0            a           2.0            b           3.0   \n",
      "\n",
      "   letters(t-3)  numbers(t-2) letters(t-2)  numbers(t-1) letters(t-1)  \\\n",
      "24            v          23.0            w          24.0            x   \n",
      "23            u          22.0            v          23.0            w   \n",
      "22            t          21.0            u          22.0            v   \n",
      "21            s          20.0            t          21.0            u   \n",
      "20            r          19.0            s          20.0            t   \n",
      "19            q          18.0            r          19.0            s   \n",
      "18            p          17.0            q          18.0            r   \n",
      "17            o          16.0            p          17.0            q   \n",
      "16            n          15.0            o          16.0            p   \n",
      "15            m          14.0            n          15.0            o   \n",
      "14            l          13.0            m          14.0            n   \n",
      "13            k          12.0            l          13.0            m   \n",
      "12            j          11.0            k          12.0            l   \n",
      "11            i          10.0            j          11.0            k   \n",
      "10            h           9.0            i          10.0            j   \n",
      "9             g           8.0            h           9.0            i   \n",
      "8             f           7.0            g           8.0            h   \n",
      "7             e           6.0            f           7.0            g   \n",
      "6             d           5.0            e           6.0            f   \n",
      "5             c           4.0            d           5.0            e   \n",
      "\n",
      "    numbers(t+0) letters(t+0)  numbers(t+1) letters(t+1)  \n",
      "24            25            y          26.0            z  \n",
      "23            24            x          25.0            y  \n",
      "22            23            w          24.0            x  \n",
      "21            22            v          23.0            w  \n",
      "20            21            u          22.0            v  \n",
      "19            20            t          21.0            u  \n",
      "18            19            s          20.0            t  \n",
      "17            18            r          19.0            s  \n",
      "16            17            q          18.0            r  \n",
      "15            16            p          17.0            q  \n",
      "14            15            o          16.0            p  \n",
      "13            14            n          15.0            o  \n",
      "12            13            m          14.0            n  \n",
      "11            12            l          13.0            m  \n",
      "10            11            k          12.0            l  \n",
      "9             10            j          11.0            k  \n",
      "8              9            i          10.0            j  \n",
      "7              8            h           9.0            i  \n",
      "6              7            g           8.0            h  \n",
      "5              6            f           7.0            g  \n"
     ]
    }
   ],
   "source": [
    "def to_time_series(df, columns, n_trail=1, n_lead=1):\n",
    "    '''\n",
    "    :param df: DataFrame, dataframe object where the columns are the features and labels and the rows are days\n",
    "    :param columns: list of strings, names of the features and labels (columns of df) to be used in the time series\n",
    "    :param n_trail: int, number of days behind day 0 that will be used to predict days after day 0\n",
    "    :param n_lead: int, number of days ahead of day 0 that will be predicted\n",
    "    \n",
    "    ---> DataFrame, dataframe object structured like a time series where each row represents an element in the time\n",
    "                    series, and each column is a feature or label a certain amount of days in the future or past.\n",
    "    '''\n",
    "    df = df[columns]\n",
    "    dfs = []\n",
    "    col_names = []\n",
    "    \n",
    "    # Create trailing columns\n",
    "    for i in range(n_trail, 0, -1):\n",
    "        dfs.append(df.shift(-i))\n",
    "        col_names += [(col_name + '(t-{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    # Create leading columns\n",
    "    for i in range(0, n_lead+1):\n",
    "        dfs.append(df.shift(i))\n",
    "        col_names += [(col_name + '(t+{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    agg = pd.concat(dfs, axis=1)\n",
    "    agg.columns = col_names\n",
    "    \n",
    "    agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Testing Function\n",
    "test_df = pd.DataFrame([(1, 'a'), (2, 'b'), (3, 'c'),\n",
    "                        (4, 'd'), (5, 'e'), (6, 'f'),\n",
    "                        (7, 'g'), (8, 'h'), (9, 'i'),\n",
    "                        (10, 'j'), (11, 'k'), (12, 'l'),\n",
    "                        (13, 'm'), (14, 'n'), (15, 'o'),\n",
    "                        (16, 'p'), (17, 'q'), (18, 'r'),\n",
    "                        (19, 's'), (20, 't'), (21, 'u'),\n",
    "                        (22, 'v'), (23, 'w'), (24, 'x'),\n",
    "                        (25, 'y'), (26, 'z')], columns=['numbers', 'letters'])\n",
    "test_df = test_df.reindex(index=test_df.index[::-1])\n",
    "print('Test DataFrame:')\n",
    "print(test_df)\n",
    "df = to_time_series(test_df, columns=test_df.columns, n_trail=5)\n",
    "print()\n",
    "print('Time Series DataFrame with a window size of n_trail+1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only pricing data from one ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  log_adj_daily_returns_JPM  \\\n",
       "0 2019-10-22                   0.003166                   0.009986   \n",
       "1 2019-10-21                   0.009758                   0.024498   \n",
       "2 2019-10-18                   0.007230                   0.001743   \n",
       "3 2019-10-17                   0.000403                   0.005583   \n",
       "4 2019-10-16                  -0.010431                  -0.002337   \n",
       "5 2019-10-15                   0.016905                   0.029696   \n",
       "6 2019-10-14                   0.001219                   0.002666   \n",
       "7 2019-10-11                   0.011445                   0.016758   \n",
       "\n",
       "   log_adj_daily_returns_BAC  log_adj_daily_returns_C  \n",
       "0                   0.005786                 0.003475  \n",
       "1                   0.021836                 0.029250  \n",
       "2                   0.002970                 0.002009  \n",
       "3                   0.002979                 0.001438  \n",
       "4                   0.014691                -0.024447  \n",
       "5                   0.020045                 0.013856  \n",
       "6                   0.007924                 0.001995  \n",
       "7                   0.016039                 0.021339  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 1000\n",
    "batch_size = 1000\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-4)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_C(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+0)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_BAC(t-5)  \\\n",
       "1                        0.002666                        0.007924   \n",
       "2                        0.016758                        0.016039   \n",
       "3                        0.013931                        0.019880   \n",
       "4                        0.007218                        0.009366   \n",
       "5                       -0.022548                       -0.024313   \n",
       "\n",
       "   log_adj_daily_returns_C(t-5) timestamp(t-4)  \\\n",
       "1                      0.001995     2019-10-15   \n",
       "2                      0.021339     2019-10-14   \n",
       "3                      0.017494     2019-10-11   \n",
       "4                      0.015393     2019-10-10   \n",
       "5                     -0.026014     2019-10-09   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-4)  log_adj_daily_returns_JPM(t-4)  \\\n",
       "1                        0.016905                        0.029696   \n",
       "2                        0.001219                        0.002666   \n",
       "3                        0.011445                        0.016758   \n",
       "4                        0.010331                        0.013931   \n",
       "5                        0.006877                        0.007218   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-4)  log_adj_daily_returns_C(t-4)  ...  \\\n",
       "1                        0.020045                      0.013856  ...   \n",
       "2                        0.007924                      0.001995  ...   \n",
       "3                        0.016039                      0.021339  ...   \n",
       "4                        0.019880                      0.017494  ...   \n",
       "5                        0.009366                      0.015393  ...   \n",
       "\n",
       "  timestamp(t+0)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1     2019-10-21                        0.009758   \n",
       "2     2019-10-18                        0.007230   \n",
       "3     2019-10-17                        0.000403   \n",
       "4     2019-10-16                       -0.010431   \n",
       "5     2019-10-15                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+0)  log_adj_daily_returns_BAC(t+0)  \\\n",
       "1                        0.024498                        0.021836   \n",
       "2                        0.001743                        0.002970   \n",
       "3                        0.005583                        0.002979   \n",
       "4                       -0.002337                        0.014691   \n",
       "5                        0.029696                        0.020045   \n",
       "\n",
       "   log_adj_daily_returns_C(t+0) timestamp(t+1)  \\\n",
       "1                      0.029250     2019-10-22   \n",
       "2                      0.002009     2019-10-21   \n",
       "3                      0.001438     2019-10-18   \n",
       "4                     -0.024447     2019-10-17   \n",
       "5                      0.013856     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  log_adj_daily_returns_JPM(t+1)  \\\n",
       "1                        0.003166                        0.009986   \n",
       "2                        0.009758                        0.024498   \n",
       "3                        0.007230                        0.001743   \n",
       "4                        0.000403                        0.005583   \n",
       "5                       -0.010431                       -0.002337   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  log_adj_daily_returns_C(t+1)  \n",
       "1                        0.005786                      0.003475  \n",
       "2                        0.021836                      0.029250  \n",
       "3                        0.002970                      0.002009  \n",
       "4                        0.002979                      0.001438  \n",
       "5                        0.014691                     -0.024447  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)']]\n"
     ]
    }
   ],
   "source": [
    "column_names_by_ticker = [[name for name in df.columns if 'log_adj_daily_returns_' + t in name] for t in tickers]\n",
    "print(column_names_by_ticker)\n",
    "# Using only data from ticker WFC\n",
    "cols = column_names_by_ticker[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-3)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-2)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
       "1                        0.001219                        0.016905   \n",
       "2                        0.011445                        0.001219   \n",
       "3                        0.010331                        0.011445   \n",
       "4                        0.006877                        0.010331   \n",
       "5                       -0.020491                        0.006877   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
       "1                       -0.010431                        0.000403   \n",
       "2                        0.016905                       -0.010431   \n",
       "3                        0.001219                        0.016905   \n",
       "4                        0.011445                        0.001219   \n",
       "5                        0.010331                        0.011445   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1                        0.007230                        0.009758   \n",
       "2                        0.000403                        0.007230   \n",
       "3                       -0.010431                        0.000403   \n",
       "4                        0.016905                       -0.010431   \n",
       "5                        0.001219                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  \n",
       "1                        0.003166  \n",
       "2                        0.009758  \n",
       "3                        0.007230  \n",
       "4                        0.000403  \n",
       "5                       -0.010431  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if columns are still in the right order\n",
    "df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset: 5024\n"
     ]
    }
   ],
   "source": [
    "dataset = df[cols].values\n",
    "print('Length of Dataset: {}'.format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00121852  0.01690521 -0.01043139  0.00040323  0.0072304   0.00975812\n",
      "  0.00316581]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled Dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and Sampling Dataset\n",
    "shuffled_indices = np.random.choice(len(dataset), size=dataset_size, replace=False)\n",
    "assert (len(shuffled_indices) == dataset_size) and (shuffled_indices.dtype == np.int64)\n",
    "shuffled_dataset = dataset[shuffled_indices]\n",
    "print('Shuffled Dataset size: {}'.format(len(shuffled_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Dataset into Features and Labels\n",
    "X, y = shuffled_dataset[:, :-1], shuffled_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/900\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 5.5342e-04 - val_loss: 9.4334e-04\n",
      "Epoch 2/900\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 9.4334e-04 - val_loss: 5.6727e-04\n",
      "Epoch 3/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.6727e-04 - val_loss: 6.2682e-04\n",
      "Epoch 4/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 6.2682e-04 - val_loss: 7.2747e-04\n",
      "Epoch 5/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 7.2747e-04 - val_loss: 6.8187e-04\n",
      "Epoch 6/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 6.8187e-04 - val_loss: 5.9401e-04\n",
      "Epoch 7/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.9401e-04 - val_loss: 5.5202e-04\n",
      "Epoch 8/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5202e-04 - val_loss: 5.6980e-04\n",
      "Epoch 9/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.6980e-04 - val_loss: 6.0640e-04\n",
      "Epoch 10/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 6.0640e-04 - val_loss: 6.1700e-04\n",
      "Epoch 11/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 6.1700e-04 - val_loss: 5.9880e-04\n",
      "Epoch 12/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.9880e-04 - val_loss: 5.7252e-04\n",
      "Epoch 13/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.7252e-04 - val_loss: 5.5519e-04\n",
      "Epoch 14/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5519e-04 - val_loss: 5.5169e-04\n",
      "Epoch 15/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5169e-04 - val_loss: 5.5797e-04\n",
      "Epoch 16/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5797e-04 - val_loss: 5.6661e-04\n",
      "Epoch 17/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.6661e-04 - val_loss: 5.7150e-04\n",
      "Epoch 18/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.7150e-04 - val_loss: 5.7037e-04\n",
      "Epoch 19/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.7037e-04 - val_loss: 5.6462e-04\n",
      "Epoch 20/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.6462e-04 - val_loss: 5.5762e-04\n",
      "Epoch 21/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5762e-04 - val_loss: 5.5266e-04\n",
      "Epoch 22/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5266e-04 - val_loss: 5.5149e-04\n",
      "Epoch 23/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5149e-04 - val_loss: 5.5378e-04\n",
      "Epoch 24/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5378e-04 - val_loss: 5.5746e-04\n",
      "Epoch 25/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5746e-04 - val_loss: 5.6000e-04\n",
      "Epoch 26/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.6000e-04 - val_loss: 5.5993e-04\n",
      "Epoch 27/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5993e-04 - val_loss: 5.5757e-04\n",
      "Epoch 28/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5757e-04 - val_loss: 5.5442e-04\n",
      "Epoch 29/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5442e-04 - val_loss: 5.5210e-04\n",
      "Epoch 30/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5210e-04 - val_loss: 5.5142e-04\n",
      "Epoch 31/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5142e-04 - val_loss: 5.5222e-04\n",
      "Epoch 32/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5222e-04 - val_loss: 5.5366e-04\n",
      "Epoch 33/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5366e-04 - val_loss: 5.5480e-04\n",
      "Epoch 34/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5480e-04 - val_loss: 5.5506e-04\n",
      "Epoch 35/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5506e-04 - val_loss: 5.5437e-04\n",
      "Epoch 36/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5437e-04 - val_loss: 5.5316e-04\n",
      "Epoch 37/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5316e-04 - val_loss: 5.5202e-04\n",
      "Epoch 38/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5202e-04 - val_loss: 5.5144e-04\n",
      "Epoch 39/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5144e-04 - val_loss: 5.5154e-04\n",
      "Epoch 40/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5154e-04 - val_loss: 5.5210e-04\n",
      "Epoch 41/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5210e-04 - val_loss: 5.5269e-04\n",
      "Epoch 42/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5269e-04 - val_loss: 5.5297e-04\n",
      "Epoch 43/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5297e-04 - val_loss: 5.5279e-04\n",
      "Epoch 44/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5279e-04 - val_loss: 5.5230e-04\n",
      "Epoch 45/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5230e-04 - val_loss: 5.5177e-04\n",
      "Epoch 46/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5177e-04 - val_loss: 5.5144e-04\n",
      "Epoch 47/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5144e-04 - val_loss: 5.5143e-04\n",
      "Epoch 48/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5143e-04 - val_loss: 5.5165e-04\n",
      "Epoch 49/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5165e-04 - val_loss: 5.5192e-04\n",
      "Epoch 50/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5192e-04 - val_loss: 5.5207e-04\n",
      "Epoch 51/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5207e-04 - val_loss: 5.5202e-04\n",
      "Epoch 52/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.5202e-04 - val_loss: 5.5181e-04\n",
      "Epoch 53/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5181e-04 - val_loss: 5.5157e-04\n",
      "Epoch 54/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5157e-04 - val_loss: 5.5142e-04\n",
      "Epoch 55/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5142e-04 - val_loss: 5.5140e-04\n",
      "Epoch 56/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5140e-04 - val_loss: 5.5150e-04\n",
      "Epoch 57/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5150e-04 - val_loss: 5.5162e-04\n",
      "Epoch 58/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5162e-04 - val_loss: 5.5169e-04\n",
      "Epoch 59/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5169e-04 - val_loss: 5.5166e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5166e-04 - val_loss: 5.5156e-04\n",
      "Epoch 61/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 5.5156e-04 - val_loss: 5.5146e-04\n",
      "Epoch 62/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5146e-04 - val_loss: 5.5139e-04\n",
      "Epoch 63/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.5139e-04 - val_loss: 5.5140e-04\n",
      "Epoch 64/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5140e-04 - val_loss: 5.5145e-04\n",
      "Epoch 65/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5145e-04 - val_loss: 5.5150e-04\n",
      "Epoch 66/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5150e-04 - val_loss: 5.5152e-04\n",
      "Epoch 67/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5152e-04 - val_loss: 5.5150e-04\n",
      "Epoch 68/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5150e-04 - val_loss: 5.5145e-04\n",
      "Epoch 69/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5145e-04 - val_loss: 5.5140e-04\n",
      "Epoch 70/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.5140e-04 - val_loss: 5.5138e-04\n",
      "Epoch 71/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5138e-04 - val_loss: 5.5139e-04\n",
      "Epoch 72/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5139e-04 - val_loss: 5.5142e-04\n",
      "Epoch 73/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5142e-04 - val_loss: 5.5144e-04\n",
      "Epoch 74/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5144e-04 - val_loss: 5.5144e-04\n",
      "Epoch 75/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.5144e-04 - val_loss: 5.5142e-04\n",
      "Epoch 76/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5142e-04 - val_loss: 5.5139e-04\n",
      "Epoch 77/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5139e-04 - val_loss: 5.5137e-04\n",
      "Epoch 78/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 79/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5137e-04 - val_loss: 5.5138e-04\n",
      "Epoch 80/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5138e-04 - val_loss: 5.5140e-04\n",
      "Epoch 81/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 5.5140e-04 - val_loss: 5.5140e-04\n",
      "Epoch 82/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.5140e-04 - val_loss: 5.5139e-04\n",
      "Epoch 83/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5139e-04 - val_loss: 5.5138e-04\n",
      "Epoch 84/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5138e-04 - val_loss: 5.5137e-04\n",
      "Epoch 85/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5137e-04 - val_loss: 5.5136e-04\n",
      "Epoch 86/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5136e-04 - val_loss: 5.5137e-04\n",
      "Epoch 87/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 88/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5137e-04 - val_loss: 5.5138e-04\n",
      "Epoch 89/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5138e-04 - val_loss: 5.5137e-04\n",
      "Epoch 90/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 91/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 92/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 93/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 94/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 95/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 96/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 97/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5136e-04 - val_loss: 5.5135e-04\n",
      "Epoch 98/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 99/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 100/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 101/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 102/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 103/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 104/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5135e-04 - val_loss: 5.5134e-04\n",
      "Epoch 105/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 106/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 107/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 108/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 109/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 110/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5134e-04 - val_loss: 5.5133e-04\n",
      "Epoch 111/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 112/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 113/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 114/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 115/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 116/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5133e-04 - val_loss: 5.5132e-04\n",
      "Epoch 117/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 118/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 119/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 120/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 121/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 122/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5132e-04 - val_loss: 5.5131e-04\n",
      "Epoch 123/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 124/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 125/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 126/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 127/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5131e-04 - val_loss: 5.5130e-04\n",
      "Epoch 128/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 129/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 130/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 132/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5129e-04\n",
      "Epoch 133/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 134/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 135/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 136/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 137/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5129e-04 - val_loss: 5.5128e-04\n",
      "Epoch 138/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 139/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 140/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 141/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5128e-04 - val_loss: 5.5127e-04\n",
      "Epoch 142/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 143/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 144/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 145/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5127e-04 - val_loss: 5.5126e-04\n",
      "Epoch 146/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 147/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 148/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 149/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5126e-04 - val_loss: 5.5125e-04\n",
      "Epoch 150/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5125e-04 - val_loss: 5.5125e-04\n",
      "Epoch 151/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5125e-04 - val_loss: 5.5125e-04\n",
      "Epoch 152/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5125e-04 - val_loss: 5.5124e-04\n",
      "Epoch 153/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 154/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 155/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 156/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5124e-04 - val_loss: 5.5123e-04\n",
      "Epoch 157/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5123e-04 - val_loss: 5.5123e-04\n",
      "Epoch 158/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5123e-04 - val_loss: 5.5123e-04\n",
      "Epoch 159/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5123e-04 - val_loss: 5.5122e-04\n",
      "Epoch 160/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5122e-04 - val_loss: 5.5122e-04\n",
      "Epoch 161/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5122e-04 - val_loss: 5.5122e-04\n",
      "Epoch 162/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5122e-04 - val_loss: 5.5121e-04\n",
      "Epoch 163/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5121e-04 - val_loss: 5.5121e-04\n",
      "Epoch 164/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5121e-04 - val_loss: 5.5120e-04\n",
      "Epoch 165/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5120e-04 - val_loss: 5.5120e-04\n",
      "Epoch 166/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5120e-04 - val_loss: 5.5120e-04\n",
      "Epoch 167/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5120e-04 - val_loss: 5.5119e-04\n",
      "Epoch 168/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5119e-04 - val_loss: 5.5119e-04\n",
      "Epoch 169/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5119e-04 - val_loss: 5.5118e-04\n",
      "Epoch 170/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5118e-04 - val_loss: 5.5118e-04\n",
      "Epoch 171/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5118e-04 - val_loss: 5.5117e-04\n",
      "Epoch 172/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5117e-04 - val_loss: 5.5117e-04\n",
      "Epoch 173/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5117e-04 - val_loss: 5.5117e-04\n",
      "Epoch 174/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5117e-04 - val_loss: 5.5116e-04\n",
      "Epoch 175/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5116e-04 - val_loss: 5.5116e-04\n",
      "Epoch 176/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5116e-04 - val_loss: 5.5115e-04\n",
      "Epoch 177/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5115e-04 - val_loss: 5.5115e-04\n",
      "Epoch 178/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5115e-04 - val_loss: 5.5114e-04\n",
      "Epoch 179/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5114e-04 - val_loss: 5.5114e-04\n",
      "Epoch 180/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5114e-04 - val_loss: 5.5113e-04\n",
      "Epoch 181/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5113e-04 - val_loss: 5.5112e-04\n",
      "Epoch 182/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5112e-04 - val_loss: 5.5112e-04\n",
      "Epoch 183/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5112e-04 - val_loss: 5.5111e-04\n",
      "Epoch 184/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5111e-04 - val_loss: 5.5111e-04\n",
      "Epoch 185/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5111e-04 - val_loss: 5.5110e-04\n",
      "Epoch 186/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5110e-04 - val_loss: 5.5109e-04\n",
      "Epoch 187/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5109e-04 - val_loss: 5.5109e-04\n",
      "Epoch 188/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5109e-04 - val_loss: 5.5108e-04\n",
      "Epoch 189/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5108e-04 - val_loss: 5.5107e-04\n",
      "Epoch 190/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5107e-04 - val_loss: 5.5107e-04\n",
      "Epoch 191/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5107e-04 - val_loss: 5.5106e-04\n",
      "Epoch 192/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5106e-04 - val_loss: 5.5105e-04\n",
      "Epoch 193/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5105e-04 - val_loss: 5.5104e-04\n",
      "Epoch 194/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5104e-04 - val_loss: 5.5103e-04\n",
      "Epoch 195/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5103e-04 - val_loss: 5.5103e-04\n",
      "Epoch 196/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5103e-04 - val_loss: 5.5102e-04\n",
      "Epoch 197/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5102e-04 - val_loss: 5.5101e-04\n",
      "Epoch 198/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5101e-04 - val_loss: 5.5100e-04\n",
      "Epoch 199/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5100e-04 - val_loss: 5.5099e-04\n",
      "Epoch 200/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5099e-04 - val_loss: 5.5098e-04\n",
      "Epoch 201/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5098e-04 - val_loss: 5.5097e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5097e-04 - val_loss: 5.5096e-04\n",
      "Epoch 203/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5096e-04 - val_loss: 5.5095e-04\n",
      "Epoch 204/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5095e-04 - val_loss: 5.5094e-04\n",
      "Epoch 205/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5094e-04 - val_loss: 5.5093e-04\n",
      "Epoch 206/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5093e-04 - val_loss: 5.5092e-04\n",
      "Epoch 207/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5092e-04 - val_loss: 5.5091e-04\n",
      "Epoch 208/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5091e-04 - val_loss: 5.5089e-04\n",
      "Epoch 209/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5089e-04 - val_loss: 5.5088e-04\n",
      "Epoch 210/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5088e-04 - val_loss: 5.5087e-04\n",
      "Epoch 211/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5087e-04 - val_loss: 5.5086e-04\n",
      "Epoch 212/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5086e-04 - val_loss: 5.5084e-04\n",
      "Epoch 213/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5084e-04 - val_loss: 5.5083e-04\n",
      "Epoch 214/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5083e-04 - val_loss: 5.5081e-04\n",
      "Epoch 215/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5081e-04 - val_loss: 5.5080e-04\n",
      "Epoch 216/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5080e-04 - val_loss: 5.5078e-04\n",
      "Epoch 217/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5078e-04 - val_loss: 5.5076e-04\n",
      "Epoch 218/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5076e-04 - val_loss: 5.5075e-04\n",
      "Epoch 219/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5075e-04 - val_loss: 5.5073e-04\n",
      "Epoch 220/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5073e-04 - val_loss: 5.5071e-04\n",
      "Epoch 221/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5071e-04 - val_loss: 5.5069e-04\n",
      "Epoch 222/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5069e-04 - val_loss: 5.5067e-04\n",
      "Epoch 223/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5067e-04 - val_loss: 5.5065e-04\n",
      "Epoch 224/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5065e-04 - val_loss: 5.5063e-04\n",
      "Epoch 225/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5063e-04 - val_loss: 5.5061e-04\n",
      "Epoch 226/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5061e-04 - val_loss: 5.5059e-04\n",
      "Epoch 227/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 5.5059e-04 - val_loss: 5.5057e-04\n",
      "Epoch 228/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5057e-04 - val_loss: 5.5054e-04\n",
      "Epoch 229/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5054e-04 - val_loss: 5.5052e-04\n",
      "Epoch 230/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5052e-04 - val_loss: 5.5049e-04\n",
      "Epoch 231/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5049e-04 - val_loss: 5.5046e-04\n",
      "Epoch 232/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5046e-04 - val_loss: 5.5043e-04\n",
      "Epoch 233/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5043e-04 - val_loss: 5.5041e-04\n",
      "Epoch 234/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5041e-04 - val_loss: 5.5038e-04\n",
      "Epoch 235/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5038e-04 - val_loss: 5.5034e-04\n",
      "Epoch 236/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5034e-04 - val_loss: 5.5031e-04\n",
      "Epoch 237/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5031e-04 - val_loss: 5.5028e-04\n",
      "Epoch 238/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5028e-04 - val_loss: 5.5024e-04\n",
      "Epoch 239/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5024e-04 - val_loss: 5.5020e-04\n",
      "Epoch 240/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5020e-04 - val_loss: 5.5017e-04\n",
      "Epoch 241/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5017e-04 - val_loss: 5.5013e-04\n",
      "Epoch 242/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5013e-04 - val_loss: 5.5008e-04\n",
      "Epoch 243/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5008e-04 - val_loss: 5.5004e-04\n",
      "Epoch 244/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5004e-04 - val_loss: 5.5000e-04\n",
      "Epoch 245/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5000e-04 - val_loss: 5.4995e-04\n",
      "Epoch 246/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4995e-04 - val_loss: 5.4990e-04\n",
      "Epoch 247/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4990e-04 - val_loss: 5.4985e-04\n",
      "Epoch 248/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4985e-04 - val_loss: 5.4980e-04\n",
      "Epoch 249/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4980e-04 - val_loss: 5.4974e-04\n",
      "Epoch 250/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.4974e-04 - val_loss: 5.4968e-04\n",
      "Epoch 251/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4968e-04 - val_loss: 5.4962e-04\n",
      "Epoch 252/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4962e-04 - val_loss: 5.4956e-04\n",
      "Epoch 253/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4956e-04 - val_loss: 5.4950e-04\n",
      "Epoch 254/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4950e-04 - val_loss: 5.4943e-04\n",
      "Epoch 255/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4943e-04 - val_loss: 5.4936e-04\n",
      "Epoch 256/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4936e-04 - val_loss: 5.4928e-04\n",
      "Epoch 257/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4928e-04 - val_loss: 5.4921e-04\n",
      "Epoch 258/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4921e-04 - val_loss: 5.4913e-04\n",
      "Epoch 259/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4913e-04 - val_loss: 5.4905e-04\n",
      "Epoch 260/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4905e-04 - val_loss: 5.4896e-04\n",
      "Epoch 261/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4896e-04 - val_loss: 5.4888e-04\n",
      "Epoch 262/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4888e-04 - val_loss: 5.4879e-04\n",
      "Epoch 263/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4879e-04 - val_loss: 5.4869e-04\n",
      "Epoch 264/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4869e-04 - val_loss: 5.4860e-04\n",
      "Epoch 265/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4860e-04 - val_loss: 5.4850e-04\n",
      "Epoch 266/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4850e-04 - val_loss: 5.4840e-04\n",
      "Epoch 267/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4840e-04 - val_loss: 5.4829e-04\n",
      "Epoch 268/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4829e-04 - val_loss: 5.4819e-04\n",
      "Epoch 269/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4819e-04 - val_loss: 5.4808e-04\n",
      "Epoch 270/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4808e-04 - val_loss: 5.4797e-04\n",
      "Epoch 271/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4797e-04 - val_loss: 5.4786e-04\n",
      "Epoch 272/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4786e-04 - val_loss: 5.4776e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4776e-04 - val_loss: 5.4765e-04\n",
      "Epoch 274/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4765e-04 - val_loss: 5.4754e-04\n",
      "Epoch 275/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4754e-04 - val_loss: 5.4743e-04\n",
      "Epoch 276/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4743e-04 - val_loss: 5.4733e-04\n",
      "Epoch 277/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4733e-04 - val_loss: 5.4723e-04\n",
      "Epoch 278/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4723e-04 - val_loss: 5.4714e-04\n",
      "Epoch 279/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4714e-04 - val_loss: 5.4705e-04\n",
      "Epoch 280/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4705e-04 - val_loss: 5.4696e-04\n",
      "Epoch 281/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4696e-04 - val_loss: 5.4689e-04\n",
      "Epoch 282/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4689e-04 - val_loss: 5.4682e-04\n",
      "Epoch 283/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4682e-04 - val_loss: 5.4676e-04\n",
      "Epoch 284/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4676e-04 - val_loss: 5.4671e-04\n",
      "Epoch 285/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4671e-04 - val_loss: 5.4667e-04\n",
      "Epoch 286/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4667e-04 - val_loss: 5.4663e-04\n",
      "Epoch 287/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.4663e-04 - val_loss: 5.4661e-04\n",
      "Epoch 288/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4661e-04 - val_loss: 5.4665e-04\n",
      "Epoch 289/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4665e-04 - val_loss: 5.4748e-04\n",
      "Epoch 290/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4748e-04 - val_loss: 5.5622e-04\n",
      "Epoch 291/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5622e-04 - val_loss: 5.7902e-04\n",
      "Epoch 292/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.7902e-04 - val_loss: 5.5763e-04\n",
      "Epoch 293/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5763e-04 - val_loss: 5.5668e-04\n",
      "Epoch 294/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5668e-04 - val_loss: 5.5424e-04\n",
      "Epoch 295/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5424e-04 - val_loss: 5.5573e-04\n",
      "Epoch 296/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5573e-04 - val_loss: 5.4783e-04\n",
      "Epoch 297/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4783e-04 - val_loss: 5.5567e-04\n",
      "Epoch 298/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5567e-04 - val_loss: 5.4926e-04\n",
      "Epoch 299/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4926e-04 - val_loss: 5.4876e-04\n",
      "Epoch 300/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4876e-04 - val_loss: 5.5265e-04\n",
      "Epoch 301/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5265e-04 - val_loss: 5.4968e-04\n",
      "Epoch 302/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4968e-04 - val_loss: 5.4802e-04\n",
      "Epoch 303/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4802e-04 - val_loss: 5.5041e-04\n",
      "Epoch 304/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5041e-04 - val_loss: 5.5072e-04\n",
      "Epoch 305/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5072e-04 - val_loss: 5.4872e-04\n",
      "Epoch 306/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4872e-04 - val_loss: 5.4851e-04\n",
      "Epoch 307/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4851e-04 - val_loss: 5.4988e-04\n",
      "Epoch 308/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4988e-04 - val_loss: 5.4992e-04\n",
      "Epoch 309/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4992e-04 - val_loss: 5.4875e-04\n",
      "Epoch 310/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4875e-04 - val_loss: 5.4850e-04\n",
      "Epoch 311/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4850e-04 - val_loss: 5.4928e-04\n",
      "Epoch 312/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4928e-04 - val_loss: 5.4945e-04\n",
      "Epoch 313/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4945e-04 - val_loss: 5.4873e-04\n",
      "Epoch 314/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.4873e-04 - val_loss: 5.4834e-04\n",
      "Epoch 315/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4834e-04 - val_loss: 5.4873e-04\n",
      "Epoch 316/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4873e-04 - val_loss: 5.4895e-04\n",
      "Epoch 317/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4895e-04 - val_loss: 5.4849e-04\n",
      "Epoch 318/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4849e-04 - val_loss: 5.4810e-04\n",
      "Epoch 319/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4810e-04 - val_loss: 5.4826e-04\n",
      "Epoch 320/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4826e-04 - val_loss: 5.4842e-04\n",
      "Epoch 321/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4842e-04 - val_loss: 5.4809e-04\n",
      "Epoch 322/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4809e-04 - val_loss: 5.4774e-04\n",
      "Epoch 323/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4774e-04 - val_loss: 5.4781e-04\n",
      "Epoch 324/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4781e-04 - val_loss: 5.4787e-04\n",
      "Epoch 325/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4787e-04 - val_loss: 5.4756e-04\n",
      "Epoch 326/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4756e-04 - val_loss: 5.4730e-04\n",
      "Epoch 327/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4730e-04 - val_loss: 5.4736e-04\n",
      "Epoch 328/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4736e-04 - val_loss: 5.4730e-04\n",
      "Epoch 329/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4730e-04 - val_loss: 5.4699e-04\n",
      "Epoch 330/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4699e-04 - val_loss: 5.4689e-04\n",
      "Epoch 331/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4689e-04 - val_loss: 5.4692e-04\n",
      "Epoch 332/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4692e-04 - val_loss: 5.4671e-04\n",
      "Epoch 333/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4671e-04 - val_loss: 5.4654e-04\n",
      "Epoch 334/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4654e-04 - val_loss: 5.4657e-04\n",
      "Epoch 335/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4657e-04 - val_loss: 5.4643e-04\n",
      "Epoch 336/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4643e-04 - val_loss: 5.4628e-04\n",
      "Epoch 337/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4628e-04 - val_loss: 5.4631e-04\n",
      "Epoch 338/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4631e-04 - val_loss: 5.4621e-04\n",
      "Epoch 339/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4621e-04 - val_loss: 5.4611e-04\n",
      "Epoch 340/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4611e-04 - val_loss: 5.4615e-04\n",
      "Epoch 341/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4615e-04 - val_loss: 5.4605e-04\n",
      "Epoch 342/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4605e-04 - val_loss: 5.4604e-04\n",
      "Epoch 343/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4604e-04 - val_loss: 5.4606e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4606e-04 - val_loss: 5.4598e-04\n",
      "Epoch 345/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4598e-04 - val_loss: 5.4603e-04\n",
      "Epoch 346/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4603e-04 - val_loss: 5.4600e-04\n",
      "Epoch 347/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4600e-04 - val_loss: 5.4599e-04\n",
      "Epoch 348/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4599e-04 - val_loss: 5.4601e-04\n",
      "Epoch 349/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4601e-04 - val_loss: 5.4596e-04\n",
      "Epoch 350/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4596e-04 - val_loss: 5.4599e-04\n",
      "Epoch 351/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4599e-04 - val_loss: 5.4595e-04\n",
      "Epoch 352/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4595e-04 - val_loss: 5.4594e-04\n",
      "Epoch 353/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4594e-04 - val_loss: 5.4593e-04\n",
      "Epoch 354/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4593e-04 - val_loss: 5.4589e-04\n",
      "Epoch 355/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4589e-04 - val_loss: 5.4589e-04\n",
      "Epoch 356/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4589e-04 - val_loss: 5.4584e-04\n",
      "Epoch 357/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4584e-04 - val_loss: 5.4583e-04\n",
      "Epoch 358/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4583e-04 - val_loss: 5.4580e-04\n",
      "Epoch 359/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4580e-04 - val_loss: 5.4578e-04\n",
      "Epoch 360/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4578e-04 - val_loss: 5.4576e-04\n",
      "Epoch 361/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4576e-04 - val_loss: 5.4573e-04\n",
      "Epoch 362/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4573e-04 - val_loss: 5.4572e-04\n",
      "Epoch 363/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4572e-04 - val_loss: 5.4569e-04\n",
      "Epoch 364/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4569e-04 - val_loss: 5.4567e-04\n",
      "Epoch 365/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4567e-04 - val_loss: 5.4566e-04\n",
      "Epoch 366/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4566e-04 - val_loss: 5.4563e-04\n",
      "Epoch 367/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4563e-04 - val_loss: 5.4562e-04\n",
      "Epoch 368/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4562e-04 - val_loss: 5.4560e-04\n",
      "Epoch 369/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4560e-04 - val_loss: 5.4558e-04\n",
      "Epoch 370/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4558e-04 - val_loss: 5.4557e-04\n",
      "Epoch 371/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4557e-04 - val_loss: 5.4554e-04\n",
      "Epoch 372/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4554e-04 - val_loss: 5.4553e-04\n",
      "Epoch 373/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4553e-04 - val_loss: 5.4551e-04\n",
      "Epoch 374/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4551e-04 - val_loss: 5.4549e-04\n",
      "Epoch 375/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4549e-04 - val_loss: 5.4547e-04\n",
      "Epoch 376/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4547e-04 - val_loss: 5.4545e-04\n",
      "Epoch 377/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4545e-04 - val_loss: 5.4543e-04\n",
      "Epoch 378/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4543e-04 - val_loss: 5.4541e-04\n",
      "Epoch 379/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4541e-04 - val_loss: 5.4539e-04\n",
      "Epoch 380/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4539e-04 - val_loss: 5.4537e-04\n",
      "Epoch 381/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4537e-04 - val_loss: 5.4535e-04\n",
      "Epoch 382/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4535e-04 - val_loss: 5.4533e-04\n",
      "Epoch 383/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4533e-04 - val_loss: 5.4530e-04\n",
      "Epoch 384/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4530e-04 - val_loss: 5.4528e-04\n",
      "Epoch 385/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4528e-04 - val_loss: 5.4526e-04\n",
      "Epoch 386/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4526e-04 - val_loss: 5.4524e-04\n",
      "Epoch 387/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4524e-04 - val_loss: 5.4521e-04\n",
      "Epoch 388/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4521e-04 - val_loss: 5.4519e-04\n",
      "Epoch 389/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4519e-04 - val_loss: 5.4517e-04\n",
      "Epoch 390/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4517e-04 - val_loss: 5.4514e-04\n",
      "Epoch 391/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4514e-04 - val_loss: 5.4512e-04\n",
      "Epoch 392/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4512e-04 - val_loss: 5.4510e-04\n",
      "Epoch 393/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4510e-04 - val_loss: 5.4507e-04\n",
      "Epoch 394/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4507e-04 - val_loss: 5.4505e-04\n",
      "Epoch 395/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4505e-04 - val_loss: 5.4502e-04\n",
      "Epoch 396/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4502e-04 - val_loss: 5.4500e-04\n",
      "Epoch 397/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4500e-04 - val_loss: 5.4497e-04\n",
      "Epoch 398/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4497e-04 - val_loss: 5.4495e-04\n",
      "Epoch 399/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4494e-04 - val_loss: 5.4492e-04\n",
      "Epoch 400/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4492e-04 - val_loss: 5.4489e-04\n",
      "Epoch 401/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.4489e-04 - val_loss: 5.4487e-04\n",
      "Epoch 402/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.4487e-04 - val_loss: 5.4484e-04\n",
      "Epoch 403/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4484e-04 - val_loss: 5.4481e-04\n",
      "Epoch 404/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4481e-04 - val_loss: 5.4478e-04\n",
      "Epoch 405/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4478e-04 - val_loss: 5.4475e-04\n",
      "Epoch 406/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4475e-04 - val_loss: 5.4472e-04\n",
      "Epoch 407/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4472e-04 - val_loss: 5.4470e-04\n",
      "Epoch 408/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4470e-04 - val_loss: 5.4467e-04\n",
      "Epoch 409/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4467e-04 - val_loss: 5.4464e-04\n",
      "Epoch 410/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4464e-04 - val_loss: 5.4460e-04\n",
      "Epoch 411/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4460e-04 - val_loss: 5.4457e-04\n",
      "Epoch 412/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4457e-04 - val_loss: 5.4454e-04\n",
      "Epoch 413/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4454e-04 - val_loss: 5.4451e-04\n",
      "Epoch 414/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4451e-04 - val_loss: 5.4448e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4448e-04 - val_loss: 5.4445e-04\n",
      "Epoch 416/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4445e-04 - val_loss: 5.4441e-04\n",
      "Epoch 417/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4441e-04 - val_loss: 5.4438e-04\n",
      "Epoch 418/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4438e-04 - val_loss: 5.4434e-04\n",
      "Epoch 419/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4434e-04 - val_loss: 5.4431e-04\n",
      "Epoch 420/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4431e-04 - val_loss: 5.4428e-04\n",
      "Epoch 421/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4428e-04 - val_loss: 5.4424e-04\n",
      "Epoch 422/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4424e-04 - val_loss: 5.4420e-04\n",
      "Epoch 423/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4420e-04 - val_loss: 5.4417e-04\n",
      "Epoch 424/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4417e-04 - val_loss: 5.4413e-04\n",
      "Epoch 425/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4413e-04 - val_loss: 5.4409e-04\n",
      "Epoch 426/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4409e-04 - val_loss: 5.4405e-04\n",
      "Epoch 427/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4405e-04 - val_loss: 5.4401e-04\n",
      "Epoch 428/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4401e-04 - val_loss: 5.4397e-04\n",
      "Epoch 429/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4397e-04 - val_loss: 5.4393e-04\n",
      "Epoch 430/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4393e-04 - val_loss: 5.4389e-04\n",
      "Epoch 431/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4389e-04 - val_loss: 5.4385e-04\n",
      "Epoch 432/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4385e-04 - val_loss: 5.4381e-04\n",
      "Epoch 433/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4381e-04 - val_loss: 5.4377e-04\n",
      "Epoch 434/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4377e-04 - val_loss: 5.4372e-04\n",
      "Epoch 435/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4372e-04 - val_loss: 5.4368e-04\n",
      "Epoch 436/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4368e-04 - val_loss: 5.4364e-04\n",
      "Epoch 437/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4364e-04 - val_loss: 5.4359e-04\n",
      "Epoch 438/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4359e-04 - val_loss: 5.4354e-04\n",
      "Epoch 439/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4354e-04 - val_loss: 5.4350e-04\n",
      "Epoch 440/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4350e-04 - val_loss: 5.4345e-04\n",
      "Epoch 441/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.4345e-04 - val_loss: 5.4340e-04\n",
      "Epoch 442/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4340e-04 - val_loss: 5.4335e-04\n",
      "Epoch 443/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4335e-04 - val_loss: 5.4330e-04\n",
      "Epoch 444/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4330e-04 - val_loss: 5.4325e-04\n",
      "Epoch 445/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4325e-04 - val_loss: 5.4320e-04\n",
      "Epoch 446/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4320e-04 - val_loss: 5.4315e-04\n",
      "Epoch 447/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4315e-04 - val_loss: 5.4310e-04\n",
      "Epoch 448/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4310e-04 - val_loss: 5.4304e-04\n",
      "Epoch 449/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4304e-04 - val_loss: 5.4299e-04\n",
      "Epoch 450/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4299e-04 - val_loss: 5.4293e-04\n",
      "Epoch 451/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4293e-04 - val_loss: 5.4288e-04\n",
      "Epoch 452/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4288e-04 - val_loss: 5.4282e-04\n",
      "Epoch 453/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4282e-04 - val_loss: 5.4276e-04\n",
      "Epoch 454/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4276e-04 - val_loss: 5.4270e-04\n",
      "Epoch 455/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4270e-04 - val_loss: 5.4264e-04\n",
      "Epoch 456/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4264e-04 - val_loss: 5.4258e-04\n",
      "Epoch 457/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4258e-04 - val_loss: 5.4252e-04\n",
      "Epoch 458/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4252e-04 - val_loss: 5.4246e-04\n",
      "Epoch 459/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4246e-04 - val_loss: 5.4240e-04\n",
      "Epoch 460/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4240e-04 - val_loss: 5.4234e-04\n",
      "Epoch 461/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4234e-04 - val_loss: 5.4227e-04\n",
      "Epoch 462/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4227e-04 - val_loss: 5.4221e-04\n",
      "Epoch 463/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4221e-04 - val_loss: 5.4214e-04\n",
      "Epoch 464/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4214e-04 - val_loss: 5.4207e-04\n",
      "Epoch 465/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4207e-04 - val_loss: 5.4201e-04\n",
      "Epoch 466/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4201e-04 - val_loss: 5.4194e-04\n",
      "Epoch 467/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4194e-04 - val_loss: 5.4187e-04\n",
      "Epoch 468/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4187e-04 - val_loss: 5.4180e-04\n",
      "Epoch 469/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4180e-04 - val_loss: 5.4173e-04\n",
      "Epoch 470/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4173e-04 - val_loss: 5.4165e-04\n",
      "Epoch 471/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4165e-04 - val_loss: 5.4158e-04\n",
      "Epoch 472/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4158e-04 - val_loss: 5.4151e-04\n",
      "Epoch 473/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4151e-04 - val_loss: 5.4144e-04\n",
      "Epoch 474/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4144e-04 - val_loss: 5.4136e-04\n",
      "Epoch 475/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4136e-04 - val_loss: 5.4129e-04\n",
      "Epoch 476/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4129e-04 - val_loss: 5.4121e-04\n",
      "Epoch 477/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.4121e-04 - val_loss: 5.4113e-04\n",
      "Epoch 478/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4113e-04 - val_loss: 5.4106e-04\n",
      "Epoch 479/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4106e-04 - val_loss: 5.4098e-04\n",
      "Epoch 480/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4098e-04 - val_loss: 5.4090e-04\n",
      "Epoch 481/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4090e-04 - val_loss: 5.4082e-04\n",
      "Epoch 482/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4083e-04 - val_loss: 5.4075e-04\n",
      "Epoch 483/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4075e-04 - val_loss: 5.4067e-04\n",
      "Epoch 484/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4067e-04 - val_loss: 5.4059e-04\n",
      "Epoch 485/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4059e-04 - val_loss: 5.4051e-04\n",
      "Epoch 486/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4051e-04 - val_loss: 5.4043e-04\n",
      "Epoch 487/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4043e-04 - val_loss: 5.4035e-04\n",
      "Epoch 488/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4035e-04 - val_loss: 5.4027e-04\n",
      "Epoch 489/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4027e-04 - val_loss: 5.4019e-04\n",
      "Epoch 490/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4019e-04 - val_loss: 5.4011e-04\n",
      "Epoch 491/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4011e-04 - val_loss: 5.4002e-04\n",
      "Epoch 492/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4002e-04 - val_loss: 5.3994e-04\n",
      "Epoch 493/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3994e-04 - val_loss: 5.3986e-04\n",
      "Epoch 494/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3986e-04 - val_loss: 5.3978e-04\n",
      "Epoch 495/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3978e-04 - val_loss: 5.3970e-04\n",
      "Epoch 496/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3970e-04 - val_loss: 5.3962e-04\n",
      "Epoch 497/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3962e-04 - val_loss: 5.3954e-04\n",
      "Epoch 498/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3954e-04 - val_loss: 5.3945e-04\n",
      "Epoch 499/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.3945e-04 - val_loss: 5.3937e-04\n",
      "Epoch 500/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3937e-04 - val_loss: 5.3929e-04\n",
      "Epoch 501/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3929e-04 - val_loss: 5.3921e-04\n",
      "Epoch 502/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3921e-04 - val_loss: 5.3912e-04\n",
      "Epoch 503/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3912e-04 - val_loss: 5.3904e-04\n",
      "Epoch 504/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3904e-04 - val_loss: 5.3896e-04\n",
      "Epoch 505/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3896e-04 - val_loss: 5.3887e-04\n",
      "Epoch 506/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3887e-04 - val_loss: 5.3879e-04\n",
      "Epoch 507/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3879e-04 - val_loss: 5.3870e-04\n",
      "Epoch 508/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3870e-04 - val_loss: 5.3862e-04\n",
      "Epoch 509/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.3862e-04 - val_loss: 5.3853e-04\n",
      "Epoch 510/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3853e-04 - val_loss: 5.3844e-04\n",
      "Epoch 511/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3844e-04 - val_loss: 5.3835e-04\n",
      "Epoch 512/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.3835e-04 - val_loss: 5.3826e-04\n",
      "Epoch 513/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3826e-04 - val_loss: 5.3817e-04\n",
      "Epoch 514/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3817e-04 - val_loss: 5.3808e-04\n",
      "Epoch 515/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3808e-04 - val_loss: 5.3799e-04\n",
      "Epoch 516/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3799e-04 - val_loss: 5.3789e-04\n",
      "Epoch 517/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3789e-04 - val_loss: 5.3779e-04\n",
      "Epoch 518/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3779e-04 - val_loss: 5.3770e-04\n",
      "Epoch 519/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3770e-04 - val_loss: 5.3760e-04\n",
      "Epoch 520/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3760e-04 - val_loss: 5.3750e-04\n",
      "Epoch 521/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3750e-04 - val_loss: 5.3739e-04\n",
      "Epoch 522/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3739e-04 - val_loss: 5.3729e-04\n",
      "Epoch 523/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3729e-04 - val_loss: 5.3718e-04\n",
      "Epoch 524/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3718e-04 - val_loss: 5.3707e-04\n",
      "Epoch 525/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3707e-04 - val_loss: 5.3696e-04\n",
      "Epoch 526/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3696e-04 - val_loss: 5.3684e-04\n",
      "Epoch 527/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3684e-04 - val_loss: 5.3672e-04\n",
      "Epoch 528/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3672e-04 - val_loss: 5.3660e-04\n",
      "Epoch 529/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.3660e-04 - val_loss: 5.3648e-04\n",
      "Epoch 530/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3648e-04 - val_loss: 5.3635e-04\n",
      "Epoch 531/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3635e-04 - val_loss: 5.3623e-04\n",
      "Epoch 532/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.3623e-04 - val_loss: 5.3609e-04\n",
      "Epoch 533/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3609e-04 - val_loss: 5.3596e-04\n",
      "Epoch 534/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3596e-04 - val_loss: 5.3582e-04\n",
      "Epoch 535/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3582e-04 - val_loss: 5.3568e-04\n",
      "Epoch 536/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3568e-04 - val_loss: 5.3554e-04\n",
      "Epoch 537/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3554e-04 - val_loss: 5.3539e-04\n",
      "Epoch 538/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3539e-04 - val_loss: 5.3524e-04\n",
      "Epoch 539/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3524e-04 - val_loss: 5.3508e-04\n",
      "Epoch 540/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3508e-04 - val_loss: 5.3492e-04\n",
      "Epoch 541/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3492e-04 - val_loss: 5.3476e-04\n",
      "Epoch 542/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3476e-04 - val_loss: 5.3459e-04\n",
      "Epoch 543/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3459e-04 - val_loss: 5.3442e-04\n",
      "Epoch 544/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3442e-04 - val_loss: 5.3424e-04\n",
      "Epoch 545/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3424e-04 - val_loss: 5.3406e-04\n",
      "Epoch 546/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3406e-04 - val_loss: 5.3387e-04\n",
      "Epoch 547/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3387e-04 - val_loss: 5.3368e-04\n",
      "Epoch 548/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3368e-04 - val_loss: 5.3349e-04\n",
      "Epoch 549/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3349e-04 - val_loss: 5.3329e-04\n",
      "Epoch 550/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3329e-04 - val_loss: 5.3308e-04\n",
      "Epoch 551/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3308e-04 - val_loss: 5.3287e-04\n",
      "Epoch 552/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3287e-04 - val_loss: 5.3265e-04\n",
      "Epoch 553/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3265e-04 - val_loss: 5.3242e-04\n",
      "Epoch 554/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3242e-04 - val_loss: 5.3219e-04\n",
      "Epoch 555/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3219e-04 - val_loss: 5.3195e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3195e-04 - val_loss: 5.3171e-04\n",
      "Epoch 557/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3171e-04 - val_loss: 5.3146e-04\n",
      "Epoch 558/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3146e-04 - val_loss: 5.3120e-04\n",
      "Epoch 559/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3120e-04 - val_loss: 5.3093e-04\n",
      "Epoch 560/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3093e-04 - val_loss: 5.3066e-04\n",
      "Epoch 561/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3066e-04 - val_loss: 5.3037e-04\n",
      "Epoch 562/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3037e-04 - val_loss: 5.3008e-04\n",
      "Epoch 563/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3008e-04 - val_loss: 5.2978e-04\n",
      "Epoch 564/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2978e-04 - val_loss: 5.2947e-04\n",
      "Epoch 565/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2947e-04 - val_loss: 5.2915e-04\n",
      "Epoch 566/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2915e-04 - val_loss: 5.2882e-04\n",
      "Epoch 567/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.2882e-04 - val_loss: 5.2848e-04\n",
      "Epoch 568/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2848e-04 - val_loss: 5.2814e-04\n",
      "Epoch 569/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2814e-04 - val_loss: 5.2777e-04\n",
      "Epoch 570/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2777e-04 - val_loss: 5.2740e-04\n",
      "Epoch 571/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2740e-04 - val_loss: 5.2702e-04\n",
      "Epoch 572/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.2702e-04 - val_loss: 5.2662e-04\n",
      "Epoch 573/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.2662e-04 - val_loss: 5.2622e-04\n",
      "Epoch 574/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2622e-04 - val_loss: 5.2580e-04\n",
      "Epoch 575/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2580e-04 - val_loss: 5.2536e-04\n",
      "Epoch 576/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.2536e-04 - val_loss: 5.2492e-04\n",
      "Epoch 577/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2492e-04 - val_loss: 5.2446e-04\n",
      "Epoch 578/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2446e-04 - val_loss: 5.2398e-04\n",
      "Epoch 579/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.2398e-04 - val_loss: 5.2350e-04\n",
      "Epoch 580/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.2350e-04 - val_loss: 5.2299e-04\n",
      "Epoch 581/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2299e-04 - val_loss: 5.2248e-04\n",
      "Epoch 582/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2248e-04 - val_loss: 5.2195e-04\n",
      "Epoch 583/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2195e-04 - val_loss: 5.2140e-04\n",
      "Epoch 584/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2140e-04 - val_loss: 5.2085e-04\n",
      "Epoch 585/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2085e-04 - val_loss: 5.2027e-04\n",
      "Epoch 586/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2027e-04 - val_loss: 5.1969e-04\n",
      "Epoch 587/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1969e-04 - val_loss: 5.1909e-04\n",
      "Epoch 588/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1909e-04 - val_loss: 5.1848e-04\n",
      "Epoch 589/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.1848e-04 - val_loss: 5.1785e-04\n",
      "Epoch 590/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.1785e-04 - val_loss: 5.1722e-04\n",
      "Epoch 591/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.1722e-04 - val_loss: 5.1658e-04\n",
      "Epoch 592/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1658e-04 - val_loss: 5.1593e-04\n",
      "Epoch 593/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1593e-04 - val_loss: 5.1527e-04\n",
      "Epoch 594/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1527e-04 - val_loss: 5.1461e-04\n",
      "Epoch 595/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1461e-04 - val_loss: 5.1395e-04\n",
      "Epoch 596/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1395e-04 - val_loss: 5.1329e-04\n",
      "Epoch 597/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1329e-04 - val_loss: 5.1263e-04\n",
      "Epoch 598/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.1263e-04 - val_loss: 5.1199e-04\n",
      "Epoch 599/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1199e-04 - val_loss: 5.1135e-04\n",
      "Epoch 600/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1135e-04 - val_loss: 5.1072e-04\n",
      "Epoch 601/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1072e-04 - val_loss: 5.1012e-04\n",
      "Epoch 602/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1012e-04 - val_loss: 5.0953e-04\n",
      "Epoch 603/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0953e-04 - val_loss: 5.0898e-04\n",
      "Epoch 604/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0898e-04 - val_loss: 5.0845e-04\n",
      "Epoch 605/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0845e-04 - val_loss: 5.0796e-04\n",
      "Epoch 606/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0796e-04 - val_loss: 5.0751e-04\n",
      "Epoch 607/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0751e-04 - val_loss: 5.0710e-04\n",
      "Epoch 608/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0710e-04 - val_loss: 5.0673e-04\n",
      "Epoch 609/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0673e-04 - val_loss: 5.0641e-04\n",
      "Epoch 610/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0641e-04 - val_loss: 5.0613e-04\n",
      "Epoch 611/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0613e-04 - val_loss: 5.0590e-04\n",
      "Epoch 612/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0590e-04 - val_loss: 5.0572e-04\n",
      "Epoch 613/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0572e-04 - val_loss: 5.0558e-04\n",
      "Epoch 614/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0558e-04 - val_loss: 5.0548e-04\n",
      "Epoch 615/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0548e-04 - val_loss: 5.0541e-04\n",
      "Epoch 616/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0541e-04 - val_loss: 5.0537e-04\n",
      "Epoch 617/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0537e-04 - val_loss: 5.0535e-04\n",
      "Epoch 618/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0535e-04 - val_loss: 5.0536e-04\n",
      "Epoch 619/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0536e-04 - val_loss: 5.0537e-04\n",
      "Epoch 620/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0537e-04 - val_loss: 5.0539e-04\n",
      "Epoch 621/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0539e-04 - val_loss: 5.0542e-04\n",
      "Epoch 622/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0542e-04 - val_loss: 5.0544e-04\n",
      "Epoch 623/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0544e-04 - val_loss: 5.0545e-04\n",
      "Epoch 624/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0545e-04 - val_loss: 5.0546e-04\n",
      "Epoch 625/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0546e-04 - val_loss: 5.0545e-04\n",
      "Epoch 626/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0545e-04 - val_loss: 5.0544e-04\n",
      "Epoch 627/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0544e-04 - val_loss: 5.0541e-04\n",
      "Epoch 628/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0541e-04 - val_loss: 5.0538e-04\n",
      "Epoch 629/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0538e-04 - val_loss: 5.0536e-04\n",
      "Epoch 630/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0536e-04 - val_loss: 5.0540e-04\n",
      "Epoch 631/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0540e-04 - val_loss: 5.0580e-04\n",
      "Epoch 632/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0580e-04 - val_loss: 5.0785e-04\n",
      "Epoch 633/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0785e-04 - val_loss: 5.1600e-04\n",
      "Epoch 634/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1600e-04 - val_loss: 5.3276e-04\n",
      "Epoch 635/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3276e-04 - val_loss: 5.2725e-04\n",
      "Epoch 636/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2725e-04 - val_loss: 5.0600e-04\n",
      "Epoch 637/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0600e-04 - val_loss: 5.2096e-04\n",
      "Epoch 638/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.2096e-04 - val_loss: 5.0736e-04\n",
      "Epoch 639/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0736e-04 - val_loss: 5.1734e-04\n",
      "Epoch 640/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1734e-04 - val_loss: 5.0927e-04\n",
      "Epoch 641/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0927e-04 - val_loss: 5.1322e-04\n",
      "Epoch 642/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1322e-04 - val_loss: 5.1207e-04\n",
      "Epoch 643/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1207e-04 - val_loss: 5.0873e-04\n",
      "Epoch 644/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0873e-04 - val_loss: 5.1248e-04\n",
      "Epoch 645/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.1248e-04 - val_loss: 5.0710e-04\n",
      "Epoch 646/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0710e-04 - val_loss: 5.0975e-04\n",
      "Epoch 647/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0975e-04 - val_loss: 5.0737e-04\n",
      "Epoch 648/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0737e-04 - val_loss: 5.0715e-04\n",
      "Epoch 649/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0715e-04 - val_loss: 5.0767e-04\n",
      "Epoch 650/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0767e-04 - val_loss: 5.0618e-04\n",
      "Epoch 651/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0618e-04 - val_loss: 5.0764e-04\n",
      "Epoch 652/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0764e-04 - val_loss: 5.0627e-04\n",
      "Epoch 653/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0627e-04 - val_loss: 5.0723e-04\n",
      "Epoch 654/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0723e-04 - val_loss: 5.0641e-04\n",
      "Epoch 655/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0641e-04 - val_loss: 5.0653e-04\n",
      "Epoch 656/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0653e-04 - val_loss: 5.0611e-04\n",
      "Epoch 657/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0611e-04 - val_loss: 5.0595e-04\n",
      "Epoch 658/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0595e-04 - val_loss: 5.0556e-04\n",
      "Epoch 659/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0556e-04 - val_loss: 5.0574e-04\n",
      "Epoch 660/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0574e-04 - val_loss: 5.0514e-04\n",
      "Epoch 661/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0514e-04 - val_loss: 5.0576e-04\n",
      "Epoch 662/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0576e-04 - val_loss: 5.0495e-04\n",
      "Epoch 663/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0495e-04 - val_loss: 5.0570e-04\n",
      "Epoch 664/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0570e-04 - val_loss: 5.0496e-04\n",
      "Epoch 665/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0496e-04 - val_loss: 5.0540e-04\n",
      "Epoch 666/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0540e-04 - val_loss: 5.0501e-04\n",
      "Epoch 667/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0501e-04 - val_loss: 5.0500e-04\n",
      "Epoch 668/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0500e-04 - val_loss: 5.0500e-04\n",
      "Epoch 669/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0500e-04 - val_loss: 5.0470e-04\n",
      "Epoch 670/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0470e-04 - val_loss: 5.0493e-04\n",
      "Epoch 671/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0493e-04 - val_loss: 5.0458e-04\n",
      "Epoch 672/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0458e-04 - val_loss: 5.0488e-04\n",
      "Epoch 673/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.0488e-04 - val_loss: 5.0456e-04\n",
      "Epoch 674/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0456e-04 - val_loss: 5.0484e-04\n",
      "Epoch 675/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0484e-04 - val_loss: 5.0455e-04\n",
      "Epoch 676/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0455e-04 - val_loss: 5.0476e-04\n",
      "Epoch 677/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0476e-04 - val_loss: 5.0451e-04\n",
      "Epoch 678/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0451e-04 - val_loss: 5.0465e-04\n",
      "Epoch 679/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0465e-04 - val_loss: 5.0447e-04\n",
      "Epoch 680/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0447e-04 - val_loss: 5.0456e-04\n",
      "Epoch 681/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0456e-04 - val_loss: 5.0446e-04\n",
      "Epoch 682/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0446e-04 - val_loss: 5.0450e-04\n",
      "Epoch 683/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0450e-04 - val_loss: 5.0446e-04\n",
      "Epoch 684/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0446e-04 - val_loss: 5.0445e-04\n",
      "Epoch 685/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0445e-04 - val_loss: 5.0445e-04\n",
      "Epoch 686/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0445e-04 - val_loss: 5.0439e-04\n",
      "Epoch 687/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0439e-04 - val_loss: 5.0442e-04\n",
      "Epoch 688/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0442e-04 - val_loss: 5.0434e-04\n",
      "Epoch 689/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0434e-04 - val_loss: 5.0438e-04\n",
      "Epoch 690/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0438e-04 - val_loss: 5.0431e-04\n",
      "Epoch 691/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0431e-04 - val_loss: 5.0435e-04\n",
      "Epoch 692/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0435e-04 - val_loss: 5.0430e-04\n",
      "Epoch 693/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0430e-04 - val_loss: 5.0432e-04\n",
      "Epoch 694/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0432e-04 - val_loss: 5.0428e-04\n",
      "Epoch 695/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0428e-04 - val_loss: 5.0429e-04\n",
      "Epoch 696/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0429e-04 - val_loss: 5.0426e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0426e-04 - val_loss: 5.0426e-04\n",
      "Epoch 698/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0426e-04 - val_loss: 5.0424e-04\n",
      "Epoch 699/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0424e-04 - val_loss: 5.0424e-04\n",
      "Epoch 700/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0424e-04 - val_loss: 5.0423e-04\n",
      "Epoch 701/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0423e-04 - val_loss: 5.0422e-04\n",
      "Epoch 702/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0422e-04 - val_loss: 5.0421e-04\n",
      "Epoch 703/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0421e-04 - val_loss: 5.0420e-04\n",
      "Epoch 704/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0420e-04 - val_loss: 5.0420e-04\n",
      "Epoch 705/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0420e-04 - val_loss: 5.0418e-04\n",
      "Epoch 706/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0418e-04 - val_loss: 5.0418e-04\n",
      "Epoch 707/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0418e-04 - val_loss: 5.0417e-04\n",
      "Epoch 708/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0417e-04 - val_loss: 5.0417e-04\n",
      "Epoch 709/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0417e-04 - val_loss: 5.0415e-04\n",
      "Epoch 710/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0415e-04 - val_loss: 5.0415e-04\n",
      "Epoch 711/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0415e-04 - val_loss: 5.0414e-04\n",
      "Epoch 712/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0414e-04 - val_loss: 5.0414e-04\n",
      "Epoch 713/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0414e-04 - val_loss: 5.0413e-04\n",
      "Epoch 714/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0413e-04 - val_loss: 5.0412e-04\n",
      "Epoch 715/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0412e-04 - val_loss: 5.0412e-04\n",
      "Epoch 716/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0412e-04 - val_loss: 5.0411e-04\n",
      "Epoch 717/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0411e-04 - val_loss: 5.0410e-04\n",
      "Epoch 718/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0410e-04 - val_loss: 5.0410e-04\n",
      "Epoch 719/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0410e-04 - val_loss: 5.0409e-04\n",
      "Epoch 720/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0409e-04 - val_loss: 5.0409e-04\n",
      "Epoch 721/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0409e-04 - val_loss: 5.0408e-04\n",
      "Epoch 722/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0408e-04 - val_loss: 5.0408e-04\n",
      "Epoch 723/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0408e-04 - val_loss: 5.0407e-04\n",
      "Epoch 724/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0407e-04 - val_loss: 5.0406e-04\n",
      "Epoch 725/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0406e-04 - val_loss: 5.0406e-04\n",
      "Epoch 726/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0406e-04 - val_loss: 5.0405e-04\n",
      "Epoch 727/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0405e-04 - val_loss: 5.0405e-04\n",
      "Epoch 728/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0405e-04 - val_loss: 5.0404e-04\n",
      "Epoch 729/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0404e-04 - val_loss: 5.0404e-04\n",
      "Epoch 730/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0404e-04 - val_loss: 5.0403e-04\n",
      "Epoch 731/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0403e-04 - val_loss: 5.0403e-04\n",
      "Epoch 732/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0403e-04 - val_loss: 5.0402e-04\n",
      "Epoch 733/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0402e-04 - val_loss: 5.0402e-04\n",
      "Epoch 734/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0402e-04 - val_loss: 5.0401e-04\n",
      "Epoch 735/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0401e-04 - val_loss: 5.0401e-04\n",
      "Epoch 736/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0401e-04 - val_loss: 5.0400e-04\n",
      "Epoch 737/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0400e-04 - val_loss: 5.0400e-04\n",
      "Epoch 738/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0400e-04 - val_loss: 5.0399e-04\n",
      "Epoch 739/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0399e-04 - val_loss: 5.0399e-04\n",
      "Epoch 740/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0399e-04 - val_loss: 5.0398e-04\n",
      "Epoch 741/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0398e-04 - val_loss: 5.0398e-04\n",
      "Epoch 742/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0398e-04 - val_loss: 5.0397e-04\n",
      "Epoch 743/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0397e-04 - val_loss: 5.0397e-04\n",
      "Epoch 744/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0397e-04 - val_loss: 5.0396e-04\n",
      "Epoch 745/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0396e-04 - val_loss: 5.0396e-04\n",
      "Epoch 746/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0396e-04 - val_loss: 5.0395e-04\n",
      "Epoch 747/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0395e-04 - val_loss: 5.0395e-04\n",
      "Epoch 748/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0395e-04 - val_loss: 5.0394e-04\n",
      "Epoch 749/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0394e-04 - val_loss: 5.0394e-04\n",
      "Epoch 750/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0394e-04 - val_loss: 5.0393e-04\n",
      "Epoch 751/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0393e-04 - val_loss: 5.0393e-04\n",
      "Epoch 752/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0393e-04 - val_loss: 5.0392e-04\n",
      "Epoch 753/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0392e-04 - val_loss: 5.0392e-04\n",
      "Epoch 754/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0392e-04 - val_loss: 5.0391e-04\n",
      "Epoch 755/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0391e-04 - val_loss: 5.0391e-04\n",
      "Epoch 756/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0391e-04 - val_loss: 5.0390e-04\n",
      "Epoch 757/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0390e-04 - val_loss: 5.0390e-04\n",
      "Epoch 758/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0390e-04 - val_loss: 5.0389e-04\n",
      "Epoch 759/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0389e-04 - val_loss: 5.0389e-04\n",
      "Epoch 760/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0389e-04 - val_loss: 5.0388e-04\n",
      "Epoch 761/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0388e-04 - val_loss: 5.0388e-04\n",
      "Epoch 762/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0388e-04 - val_loss: 5.0387e-04\n",
      "Epoch 763/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0387e-04 - val_loss: 5.0387e-04\n",
      "Epoch 764/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0387e-04 - val_loss: 5.0386e-04\n",
      "Epoch 765/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0386e-04 - val_loss: 5.0386e-04\n",
      "Epoch 766/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0386e-04 - val_loss: 5.0385e-04\n",
      "Epoch 767/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0385e-04 - val_loss: 5.0385e-04\n",
      "Epoch 768/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0385e-04 - val_loss: 5.0384e-04\n",
      "Epoch 769/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0384e-04 - val_loss: 5.0384e-04\n",
      "Epoch 770/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0384e-04 - val_loss: 5.0383e-04\n",
      "Epoch 771/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0383e-04 - val_loss: 5.0383e-04\n",
      "Epoch 772/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0383e-04 - val_loss: 5.0382e-04\n",
      "Epoch 773/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0382e-04 - val_loss: 5.0382e-04\n",
      "Epoch 774/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0382e-04 - val_loss: 5.0381e-04\n",
      "Epoch 775/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0381e-04 - val_loss: 5.0381e-04\n",
      "Epoch 776/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0380e-04 - val_loss: 5.0380e-04\n",
      "Epoch 777/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0380e-04 - val_loss: 5.0379e-04\n",
      "Epoch 778/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0379e-04 - val_loss: 5.0379e-04\n",
      "Epoch 779/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0379e-04 - val_loss: 5.0378e-04\n",
      "Epoch 780/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0378e-04 - val_loss: 5.0378e-04\n",
      "Epoch 781/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0378e-04 - val_loss: 5.0377e-04\n",
      "Epoch 782/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0377e-04 - val_loss: 5.0377e-04\n",
      "Epoch 783/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0377e-04 - val_loss: 5.0376e-04\n",
      "Epoch 784/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0376e-04 - val_loss: 5.0375e-04\n",
      "Epoch 785/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0375e-04 - val_loss: 5.0375e-04\n",
      "Epoch 786/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0375e-04 - val_loss: 5.0374e-04\n",
      "Epoch 787/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0374e-04 - val_loss: 5.0374e-04\n",
      "Epoch 788/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0374e-04 - val_loss: 5.0373e-04\n",
      "Epoch 789/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0373e-04 - val_loss: 5.0373e-04\n",
      "Epoch 790/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0373e-04 - val_loss: 5.0372e-04\n",
      "Epoch 791/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0372e-04 - val_loss: 5.0371e-04\n",
      "Epoch 792/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0371e-04 - val_loss: 5.0371e-04\n",
      "Epoch 793/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0371e-04 - val_loss: 5.0370e-04\n",
      "Epoch 794/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0370e-04 - val_loss: 5.0370e-04\n",
      "Epoch 795/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0370e-04 - val_loss: 5.0369e-04\n",
      "Epoch 796/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0369e-04 - val_loss: 5.0368e-04\n",
      "Epoch 797/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0368e-04 - val_loss: 5.0368e-04\n",
      "Epoch 798/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0368e-04 - val_loss: 5.0367e-04\n",
      "Epoch 799/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0367e-04 - val_loss: 5.0366e-04\n",
      "Epoch 800/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0366e-04 - val_loss: 5.0366e-04\n",
      "Epoch 801/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0366e-04 - val_loss: 5.0365e-04\n",
      "Epoch 802/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0365e-04 - val_loss: 5.0365e-04\n",
      "Epoch 803/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0365e-04 - val_loss: 5.0364e-04\n",
      "Epoch 804/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0364e-04 - val_loss: 5.0363e-04\n",
      "Epoch 805/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0363e-04 - val_loss: 5.0363e-04\n",
      "Epoch 806/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0363e-04 - val_loss: 5.0362e-04\n",
      "Epoch 807/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0362e-04 - val_loss: 5.0361e-04\n",
      "Epoch 808/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0361e-04 - val_loss: 5.0361e-04\n",
      "Epoch 809/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0361e-04 - val_loss: 5.0360e-04\n",
      "Epoch 810/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0360e-04 - val_loss: 5.0359e-04\n",
      "Epoch 811/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0359e-04 - val_loss: 5.0359e-04\n",
      "Epoch 812/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0359e-04 - val_loss: 5.0358e-04\n",
      "Epoch 813/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0358e-04 - val_loss: 5.0357e-04\n",
      "Epoch 814/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0357e-04 - val_loss: 5.0357e-04\n",
      "Epoch 815/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0357e-04 - val_loss: 5.0356e-04\n",
      "Epoch 816/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0356e-04 - val_loss: 5.0355e-04\n",
      "Epoch 817/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0355e-04 - val_loss: 5.0354e-04\n",
      "Epoch 818/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0354e-04 - val_loss: 5.0354e-04\n",
      "Epoch 819/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0354e-04 - val_loss: 5.0353e-04\n",
      "Epoch 820/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0353e-04 - val_loss: 5.0352e-04\n",
      "Epoch 821/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0352e-04 - val_loss: 5.0352e-04\n",
      "Epoch 822/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0352e-04 - val_loss: 5.0351e-04\n",
      "Epoch 823/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0351e-04 - val_loss: 5.0350e-04\n",
      "Epoch 824/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0350e-04 - val_loss: 5.0349e-04\n",
      "Epoch 825/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0349e-04 - val_loss: 5.0348e-04\n",
      "Epoch 826/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0348e-04 - val_loss: 5.0348e-04\n",
      "Epoch 827/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0348e-04 - val_loss: 5.0347e-04\n",
      "Epoch 828/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0347e-04 - val_loss: 5.0346e-04\n",
      "Epoch 829/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0346e-04 - val_loss: 5.0345e-04\n",
      "Epoch 830/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0345e-04 - val_loss: 5.0345e-04\n",
      "Epoch 831/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0345e-04 - val_loss: 5.0344e-04\n",
      "Epoch 832/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0344e-04 - val_loss: 5.0343e-04\n",
      "Epoch 833/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0343e-04 - val_loss: 5.0342e-04\n",
      "Epoch 834/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0342e-04 - val_loss: 5.0341e-04\n",
      "Epoch 835/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0341e-04 - val_loss: 5.0340e-04\n",
      "Epoch 836/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 5.0340e-04 - val_loss: 5.0340e-04\n",
      "Epoch 837/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0340e-04 - val_loss: 5.0339e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0339e-04 - val_loss: 5.0338e-04\n",
      "Epoch 839/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0338e-04 - val_loss: 5.0337e-04\n",
      "Epoch 840/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0337e-04 - val_loss: 5.0336e-04\n",
      "Epoch 841/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0336e-04 - val_loss: 5.0335e-04\n",
      "Epoch 842/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0335e-04 - val_loss: 5.0334e-04\n",
      "Epoch 843/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0334e-04 - val_loss: 5.0333e-04\n",
      "Epoch 844/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 5.0333e-04 - val_loss: 5.0332e-04\n",
      "Epoch 845/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0332e-04 - val_loss: 5.0332e-04\n",
      "Epoch 846/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0332e-04 - val_loss: 5.0331e-04\n",
      "Epoch 847/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0331e-04 - val_loss: 5.0330e-04\n",
      "Epoch 848/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0330e-04 - val_loss: 5.0329e-04\n",
      "Epoch 849/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0329e-04 - val_loss: 5.0328e-04\n",
      "Epoch 850/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0328e-04 - val_loss: 5.0327e-04\n",
      "Epoch 851/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0327e-04 - val_loss: 5.0326e-04\n",
      "Epoch 852/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0326e-04 - val_loss: 5.0325e-04\n",
      "Epoch 853/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0325e-04 - val_loss: 5.0324e-04\n",
      "Epoch 854/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0324e-04 - val_loss: 5.0323e-04\n",
      "Epoch 855/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0323e-04 - val_loss: 5.0322e-04\n",
      "Epoch 856/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0322e-04 - val_loss: 5.0321e-04\n",
      "Epoch 857/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0321e-04 - val_loss: 5.0319e-04\n",
      "Epoch 858/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0319e-04 - val_loss: 5.0318e-04\n",
      "Epoch 859/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0318e-04 - val_loss: 5.0317e-04\n",
      "Epoch 860/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0317e-04 - val_loss: 5.0316e-04\n",
      "Epoch 861/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0316e-04 - val_loss: 5.0315e-04\n",
      "Epoch 862/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0315e-04 - val_loss: 5.0314e-04\n",
      "Epoch 863/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0314e-04 - val_loss: 5.0313e-04\n",
      "Epoch 864/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0313e-04 - val_loss: 5.0312e-04\n",
      "Epoch 865/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0312e-04 - val_loss: 5.0310e-04\n",
      "Epoch 866/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0310e-04 - val_loss: 5.0309e-04\n",
      "Epoch 867/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0309e-04 - val_loss: 5.0308e-04\n",
      "Epoch 868/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0308e-04 - val_loss: 5.0307e-04\n",
      "Epoch 869/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0307e-04 - val_loss: 5.0305e-04\n",
      "Epoch 870/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0305e-04 - val_loss: 5.0304e-04\n",
      "Epoch 871/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0304e-04 - val_loss: 5.0303e-04\n",
      "Epoch 872/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0303e-04 - val_loss: 5.0301e-04\n",
      "Epoch 873/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0301e-04 - val_loss: 5.0300e-04\n",
      "Epoch 874/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0300e-04 - val_loss: 5.0299e-04\n",
      "Epoch 875/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0299e-04 - val_loss: 5.0297e-04\n",
      "Epoch 876/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0297e-04 - val_loss: 5.0296e-04\n",
      "Epoch 877/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0296e-04 - val_loss: 5.0295e-04\n",
      "Epoch 878/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0295e-04 - val_loss: 5.0293e-04\n",
      "Epoch 879/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0293e-04 - val_loss: 5.0292e-04\n",
      "Epoch 880/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0292e-04 - val_loss: 5.0290e-04\n",
      "Epoch 881/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0290e-04 - val_loss: 5.0289e-04\n",
      "Epoch 882/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0289e-04 - val_loss: 5.0287e-04\n",
      "Epoch 883/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0287e-04 - val_loss: 5.0285e-04\n",
      "Epoch 884/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0285e-04 - val_loss: 5.0284e-04\n",
      "Epoch 885/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0284e-04 - val_loss: 5.0282e-04\n",
      "Epoch 886/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0282e-04 - val_loss: 5.0281e-04\n",
      "Epoch 887/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0281e-04 - val_loss: 5.0279e-04\n",
      "Epoch 888/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0279e-04 - val_loss: 5.0277e-04\n",
      "Epoch 889/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0277e-04 - val_loss: 5.0275e-04\n",
      "Epoch 890/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0275e-04 - val_loss: 5.0274e-04\n",
      "Epoch 891/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0274e-04 - val_loss: 5.0272e-04\n",
      "Epoch 892/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0272e-04 - val_loss: 5.0270e-04\n",
      "Epoch 893/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0270e-04 - val_loss: 5.0268e-04\n",
      "Epoch 894/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0268e-04 - val_loss: 5.0266e-04\n",
      "Epoch 895/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0266e-04 - val_loss: 5.0264e-04\n",
      "Epoch 896/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0264e-04 - val_loss: 5.0262e-04\n",
      "Epoch 897/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0262e-04 - val_loss: 5.0260e-04\n",
      "Epoch 898/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0260e-04 - val_loss: 5.0258e-04\n",
      "Epoch 899/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0258e-04 - val_loss: 5.0256e-04\n",
      "Epoch 900/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0256e-04 - val_loss: 5.0254e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_5)\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.506\n",
      "Probability of sampling a 0: 0.494\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/900\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 0.6931 - binary_accuracy: 0.4850 - precision: 0.4909 - recall: 0.4783 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 27/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9980\n",
      "Epoch 46/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9980 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9960\n",
      "Epoch 47/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9960 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9960\n",
      "Epoch 48/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9960 - val_loss: 0.6928 - val_binary_accuracy: 0.5110 - val_precision: 0.5086 - val_recall: 0.9960\n",
      "Epoch 49/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6928 - binary_accuracy: 0.5110 - precision: 0.5086 - recall: 0.9960 - val_loss: 0.6928 - val_binary_accuracy: 0.5090 - val_precision: 0.5079 - val_recall: 0.9565\n",
      "Epoch 50/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6928 - binary_accuracy: 0.5090 - precision: 0.5079 - recall: 0.9565 - val_loss: 0.6927 - val_binary_accuracy: 0.5110 - val_precision: 0.5086 - val_recall: 0.9960\n",
      "Epoch 51/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6927 - binary_accuracy: 0.5110 - precision: 0.5086 - recall: 0.9960 - val_loss: 0.6926 - val_binary_accuracy: 0.5160 - val_precision: 0.5166 - val_recall: 0.6759\n",
      "Epoch 52/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6926 - binary_accuracy: 0.5160 - precision: 0.5166 - recall: 0.6759 - val_loss: 0.6923 - val_binary_accuracy: 0.5150 - val_precision: 0.5118 - val_recall: 0.8972\n",
      "Epoch 53/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6923 - binary_accuracy: 0.5150 - precision: 0.5118 - recall: 0.8972 - val_loss: 0.6922 - val_binary_accuracy: 0.5120 - val_precision: 0.5096 - val_recall: 0.9466\n",
      "Epoch 54/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6922 - binary_accuracy: 0.5120 - precision: 0.5096 - recall: 0.9466 - val_loss: 0.6924 - val_binary_accuracy: 0.5130 - val_precision: 0.5772 - val_recall: 0.1403\n",
      "Epoch 55/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6924 - binary_accuracy: 0.5130 - precision: 0.5772 - recall: 0.1403 - val_loss: 0.6919 - val_binary_accuracy: 0.5130 - val_precision: 0.5106 - val_recall: 0.9032\n",
      "Epoch 56/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6919 - binary_accuracy: 0.5130 - precision: 0.5106 - recall: 0.9032 - val_loss: 0.6917 - val_binary_accuracy: 0.5170 - val_precision: 0.5135 - val_recall: 0.8617\n",
      "Epoch 57/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6917 - binary_accuracy: 0.5170 - precision: 0.5135 - recall: 0.8617 - val_loss: 0.6925 - val_binary_accuracy: 0.5050 - val_precision: 0.5311 - val_recall: 0.1858\n",
      "Epoch 58/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6925 - binary_accuracy: 0.5050 - precision: 0.5311 - recall: 0.1858 - val_loss: 0.6915 - val_binary_accuracy: 0.5070 - val_precision: 0.5083 - val_recall: 0.7866\n",
      "Epoch 59/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6915 - binary_accuracy: 0.5070 - precision: 0.5083 - recall: 0.7866 - val_loss: 0.6919 - val_binary_accuracy: 0.5130 - val_precision: 0.5106 - val_recall: 0.9051\n",
      "Epoch 60/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6919 - binary_accuracy: 0.5130 - precision: 0.5106 - recall: 0.9051 - val_loss: 0.6913 - val_binary_accuracy: 0.5080 - val_precision: 0.5102 - val_recall: 0.6897\n",
      "Epoch 61/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6913 - binary_accuracy: 0.5080 - precision: 0.5102 - recall: 0.6897 - val_loss: 0.6915 - val_binary_accuracy: 0.5020 - val_precision: 0.5132 - val_recall: 0.3063\n",
      "Epoch 62/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6915 - binary_accuracy: 0.5020 - precision: 0.5132 - recall: 0.3063 - val_loss: 0.6914 - val_binary_accuracy: 0.5050 - val_precision: 0.5169 - val_recall: 0.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6914 - binary_accuracy: 0.5050 - precision: 0.5169 - recall: 0.3320 - val_loss: 0.6911 - val_binary_accuracy: 0.5230 - val_precision: 0.5228 - val_recall: 0.6561\n",
      "Epoch 64/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6911 - binary_accuracy: 0.5230 - precision: 0.5228 - recall: 0.6561 - val_loss: 0.6911 - val_binary_accuracy: 0.5150 - val_precision: 0.5122 - val_recall: 0.8696\n",
      "Epoch 65/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6911 - binary_accuracy: 0.5150 - precision: 0.5122 - recall: 0.8696 - val_loss: 0.6911 - val_binary_accuracy: 0.5150 - val_precision: 0.5118 - val_recall: 0.8992\n",
      "Epoch 66/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6911 - binary_accuracy: 0.5150 - precision: 0.5118 - recall: 0.8992 - val_loss: 0.6907 - val_binary_accuracy: 0.5120 - val_precision: 0.5112 - val_recall: 0.8103\n",
      "Epoch 67/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6907 - binary_accuracy: 0.5120 - precision: 0.5112 - recall: 0.8103 - val_loss: 0.6905 - val_binary_accuracy: 0.5160 - val_precision: 0.5208 - val_recall: 0.5435\n",
      "Epoch 68/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6905 - binary_accuracy: 0.5160 - precision: 0.5208 - recall: 0.5435 - val_loss: 0.6904 - val_binary_accuracy: 0.5030 - val_precision: 0.5117 - val_recall: 0.3893\n",
      "Epoch 69/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6904 - binary_accuracy: 0.5030 - precision: 0.5117 - recall: 0.3893 - val_loss: 0.6900 - val_binary_accuracy: 0.5160 - val_precision: 0.5202 - val_recall: 0.5593\n",
      "Epoch 70/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6900 - binary_accuracy: 0.5160 - precision: 0.5202 - recall: 0.5593 - val_loss: 0.6899 - val_binary_accuracy: 0.5200 - val_precision: 0.5171 - val_recall: 0.7767\n",
      "Epoch 71/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6899 - binary_accuracy: 0.5200 - precision: 0.5171 - recall: 0.7767 - val_loss: 0.6895 - val_binary_accuracy: 0.5280 - val_precision: 0.5241 - val_recall: 0.7312\n",
      "Epoch 72/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6895 - binary_accuracy: 0.5280 - precision: 0.5241 - recall: 0.7312 - val_loss: 0.6892 - val_binary_accuracy: 0.5160 - val_precision: 0.5234 - val_recall: 0.4862\n",
      "Epoch 73/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6892 - binary_accuracy: 0.5160 - precision: 0.5234 - recall: 0.4862 - val_loss: 0.6888 - val_binary_accuracy: 0.5140 - val_precision: 0.5216 - val_recall: 0.4783\n",
      "Epoch 74/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6888 - binary_accuracy: 0.5140 - precision: 0.5216 - recall: 0.4783 - val_loss: 0.6883 - val_binary_accuracy: 0.5210 - val_precision: 0.5201 - val_recall: 0.6917\n",
      "Epoch 75/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6883 - binary_accuracy: 0.5210 - precision: 0.5201 - recall: 0.6917 - val_loss: 0.6880 - val_binary_accuracy: 0.5220 - val_precision: 0.5183 - val_recall: 0.7826\n",
      "Epoch 76/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6880 - binary_accuracy: 0.5220 - precision: 0.5183 - recall: 0.7826 - val_loss: 0.6874 - val_binary_accuracy: 0.5190 - val_precision: 0.5197 - val_recall: 0.6522\n",
      "Epoch 77/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6874 - binary_accuracy: 0.5190 - precision: 0.5197 - recall: 0.6522 - val_loss: 0.6870 - val_binary_accuracy: 0.5290 - val_precision: 0.5386 - val_recall: 0.4822\n",
      "Epoch 78/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6870 - binary_accuracy: 0.5290 - precision: 0.5386 - recall: 0.4822 - val_loss: 0.6864 - val_binary_accuracy: 0.5360 - val_precision: 0.5378 - val_recall: 0.5909\n",
      "Epoch 79/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6864 - binary_accuracy: 0.5360 - precision: 0.5378 - recall: 0.5909 - val_loss: 0.6861 - val_binary_accuracy: 0.5420 - val_precision: 0.5347 - val_recall: 0.7312\n",
      "Epoch 80/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6861 - binary_accuracy: 0.5420 - precision: 0.5347 - recall: 0.7312 - val_loss: 0.6856 - val_binary_accuracy: 0.5420 - val_precision: 0.5506 - val_recall: 0.5158\n",
      "Epoch 81/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6856 - binary_accuracy: 0.5420 - precision: 0.5506 - recall: 0.5158 - val_loss: 0.6852 - val_binary_accuracy: 0.5420 - val_precision: 0.5500 - val_recall: 0.5217\n",
      "Epoch 82/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6852 - binary_accuracy: 0.5420 - precision: 0.5500 - recall: 0.5217 - val_loss: 0.6848 - val_binary_accuracy: 0.5540 - val_precision: 0.5463 - val_recall: 0.6996\n",
      "Epoch 83/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6848 - binary_accuracy: 0.5540 - precision: 0.5463 - recall: 0.6996 - val_loss: 0.6841 - val_binary_accuracy: 0.5550 - val_precision: 0.5552 - val_recall: 0.6067\n",
      "Epoch 84/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6841 - binary_accuracy: 0.5550 - precision: 0.5552 - recall: 0.6067 - val_loss: 0.6835 - val_binary_accuracy: 0.5610 - val_precision: 0.5720 - val_recall: 0.5257\n",
      "Epoch 85/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6835 - binary_accuracy: 0.5610 - precision: 0.5720 - recall: 0.5257 - val_loss: 0.6826 - val_binary_accuracy: 0.5570 - val_precision: 0.5552 - val_recall: 0.6265\n",
      "Epoch 86/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6826 - binary_accuracy: 0.5570 - precision: 0.5552 - recall: 0.6265 - val_loss: 0.6818 - val_binary_accuracy: 0.5570 - val_precision: 0.5519 - val_recall: 0.6621\n",
      "Epoch 87/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6818 - binary_accuracy: 0.5570 - precision: 0.5519 - recall: 0.6621 - val_loss: 0.6810 - val_binary_accuracy: 0.5640 - val_precision: 0.5781 - val_recall: 0.5119\n",
      "Epoch 88/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6810 - binary_accuracy: 0.5640 - precision: 0.5781 - recall: 0.5119 - val_loss: 0.6801 - val_binary_accuracy: 0.5680 - val_precision: 0.5615 - val_recall: 0.6680\n",
      "Epoch 89/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6801 - binary_accuracy: 0.5680 - precision: 0.5615 - recall: 0.6680 - val_loss: 0.6793 - val_binary_accuracy: 0.5670 - val_precision: 0.5672 - val_recall: 0.6087\n",
      "Epoch 90/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6793 - binary_accuracy: 0.5670 - precision: 0.5672 - recall: 0.6087 - val_loss: 0.6788 - val_binary_accuracy: 0.5630 - val_precision: 0.5729 - val_recall: 0.5356\n",
      "Epoch 91/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6788 - binary_accuracy: 0.5630 - precision: 0.5729 - recall: 0.5356 - val_loss: 0.6789 - val_binary_accuracy: 0.5550 - val_precision: 0.5461 - val_recall: 0.7134\n",
      "Epoch 92/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6789 - binary_accuracy: 0.5550 - precision: 0.5461 - recall: 0.7134 - val_loss: 0.6810 - val_binary_accuracy: 0.5430 - val_precision: 0.5968 - val_recall: 0.2984\n",
      "Epoch 93/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6810 - binary_accuracy: 0.5430 - precision: 0.5968 - recall: 0.2984 - val_loss: 0.6799 - val_binary_accuracy: 0.5590 - val_precision: 0.5470 - val_recall: 0.7470\n",
      "Epoch 94/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6799 - binary_accuracy: 0.5590 - precision: 0.5470 - recall: 0.7470 - val_loss: 0.6796 - val_binary_accuracy: 0.5630 - val_precision: 0.5522 - val_recall: 0.7213\n",
      "Epoch 95/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6796 - binary_accuracy: 0.5630 - precision: 0.5522 - recall: 0.7213 - val_loss: 0.6796 - val_binary_accuracy: 0.5780 - val_precision: 0.6186 - val_recall: 0.4328\n",
      "Epoch 96/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6796 - binary_accuracy: 0.5780 - precision: 0.6186 - recall: 0.4328 - val_loss: 0.6782 - val_binary_accuracy: 0.5840 - val_precision: 0.5991 - val_recall: 0.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6782 - binary_accuracy: 0.5840 - precision: 0.5991 - recall: 0.5375 - val_loss: 0.6801 - val_binary_accuracy: 0.5470 - val_precision: 0.5381 - val_recall: 0.7391\n",
      "Epoch 98/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6801 - binary_accuracy: 0.5470 - precision: 0.5381 - recall: 0.7391 - val_loss: 0.6779 - val_binary_accuracy: 0.5770 - val_precision: 0.5870 - val_recall: 0.5534\n",
      "Epoch 99/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6779 - binary_accuracy: 0.5770 - precision: 0.5870 - recall: 0.5534 - val_loss: 0.6785 - val_binary_accuracy: 0.5910 - val_precision: 0.6228 - val_recall: 0.4862\n",
      "Epoch 100/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6785 - binary_accuracy: 0.5910 - precision: 0.6228 - recall: 0.4862 - val_loss: 0.6775 - val_binary_accuracy: 0.5730 - val_precision: 0.5727 - val_recall: 0.6146\n",
      "Epoch 101/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6775 - binary_accuracy: 0.5730 - precision: 0.5727 - recall: 0.6146 - val_loss: 0.6780 - val_binary_accuracy: 0.5550 - val_precision: 0.5455 - val_recall: 0.7233\n",
      "Epoch 102/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6780 - binary_accuracy: 0.5550 - precision: 0.5455 - recall: 0.7233 - val_loss: 0.6775 - val_binary_accuracy: 0.5620 - val_precision: 0.5531 - val_recall: 0.6996\n",
      "Epoch 103/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6775 - binary_accuracy: 0.5620 - precision: 0.5531 - recall: 0.6996 - val_loss: 0.6770 - val_binary_accuracy: 0.5800 - val_precision: 0.5843 - val_recall: 0.5889\n",
      "Epoch 104/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6770 - binary_accuracy: 0.5800 - precision: 0.5843 - recall: 0.5889 - val_loss: 0.6774 - val_binary_accuracy: 0.5760 - val_precision: 0.6030 - val_recall: 0.4743\n",
      "Epoch 105/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6774 - binary_accuracy: 0.5760 - precision: 0.6030 - recall: 0.4743 - val_loss: 0.6768 - val_binary_accuracy: 0.5620 - val_precision: 0.5620 - val_recall: 0.6087\n",
      "Epoch 106/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6768 - binary_accuracy: 0.5620 - precision: 0.5620 - recall: 0.6087 - val_loss: 0.6773 - val_binary_accuracy: 0.5600 - val_precision: 0.5502 - val_recall: 0.7154\n",
      "Epoch 107/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6773 - binary_accuracy: 0.5600 - precision: 0.5502 - recall: 0.7154 - val_loss: 0.6767 - val_binary_accuracy: 0.5670 - val_precision: 0.5599 - val_recall: 0.6739\n",
      "Epoch 108/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6767 - binary_accuracy: 0.5670 - precision: 0.5599 - recall: 0.6739 - val_loss: 0.6767 - val_binary_accuracy: 0.5750 - val_precision: 0.5835 - val_recall: 0.5593\n",
      "Epoch 109/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6767 - binary_accuracy: 0.5750 - precision: 0.5835 - recall: 0.5593 - val_loss: 0.6768 - val_binary_accuracy: 0.5760 - val_precision: 0.5899 - val_recall: 0.5316\n",
      "Epoch 110/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6768 - binary_accuracy: 0.5760 - precision: 0.5899 - recall: 0.5316 - val_loss: 0.6764 - val_binary_accuracy: 0.5700 - val_precision: 0.5679 - val_recall: 0.6285\n",
      "Epoch 111/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6764 - binary_accuracy: 0.5700 - precision: 0.5679 - recall: 0.6285 - val_loss: 0.6764 - val_binary_accuracy: 0.5590 - val_precision: 0.5513 - val_recall: 0.6897\n",
      "Epoch 112/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6764 - binary_accuracy: 0.5590 - precision: 0.5513 - recall: 0.6897 - val_loss: 0.6762 - val_binary_accuracy: 0.5580 - val_precision: 0.5508 - val_recall: 0.6858\n",
      "Epoch 113/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6762 - binary_accuracy: 0.5580 - precision: 0.5508 - recall: 0.6858 - val_loss: 0.6759 - val_binary_accuracy: 0.5740 - val_precision: 0.5725 - val_recall: 0.6245\n",
      "Epoch 114/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6759 - binary_accuracy: 0.5740 - precision: 0.5725 - recall: 0.6245 - val_loss: 0.6760 - val_binary_accuracy: 0.5670 - val_precision: 0.5746 - val_recall: 0.5553\n",
      "Epoch 115/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6760 - binary_accuracy: 0.5670 - precision: 0.5746 - recall: 0.5553 - val_loss: 0.6756 - val_binary_accuracy: 0.5750 - val_precision: 0.5719 - val_recall: 0.6364\n",
      "Epoch 116/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6756 - binary_accuracy: 0.5750 - precision: 0.5719 - recall: 0.6364 - val_loss: 0.6757 - val_binary_accuracy: 0.5610 - val_precision: 0.5534 - val_recall: 0.6858\n",
      "Epoch 117/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6757 - binary_accuracy: 0.5610 - precision: 0.5534 - recall: 0.6858 - val_loss: 0.6756 - val_binary_accuracy: 0.5610 - val_precision: 0.5543 - val_recall: 0.6759\n",
      "Epoch 118/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6756 - binary_accuracy: 0.5610 - precision: 0.5543 - recall: 0.6759 - val_loss: 0.6754 - val_binary_accuracy: 0.5790 - val_precision: 0.5766 - val_recall: 0.6324\n",
      "Epoch 119/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6754 - binary_accuracy: 0.5790 - precision: 0.5766 - recall: 0.6324 - val_loss: 0.6753 - val_binary_accuracy: 0.5720 - val_precision: 0.5747 - val_recall: 0.5929\n",
      "Epoch 120/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6753 - binary_accuracy: 0.5720 - precision: 0.5747 - recall: 0.5929 - val_loss: 0.6750 - val_binary_accuracy: 0.5690 - val_precision: 0.5650 - val_recall: 0.6443\n",
      "Epoch 121/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6750 - binary_accuracy: 0.5690 - precision: 0.5650 - recall: 0.6443 - val_loss: 0.6750 - val_binary_accuracy: 0.5690 - val_precision: 0.5608 - val_recall: 0.6838\n",
      "Epoch 122/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6750 - binary_accuracy: 0.5690 - precision: 0.5608 - recall: 0.6838 - val_loss: 0.6746 - val_binary_accuracy: 0.5690 - val_precision: 0.5635 - val_recall: 0.6581\n",
      "Epoch 123/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6746 - binary_accuracy: 0.5690 - precision: 0.5635 - recall: 0.6581 - val_loss: 0.6745 - val_binary_accuracy: 0.5730 - val_precision: 0.5738 - val_recall: 0.6067\n",
      "Epoch 124/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6745 - binary_accuracy: 0.5730 - precision: 0.5738 - recall: 0.6067 - val_loss: 0.6742 - val_binary_accuracy: 0.5680 - val_precision: 0.5680 - val_recall: 0.6107\n",
      "Epoch 125/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6742 - binary_accuracy: 0.5680 - precision: 0.5680 - recall: 0.6107 - val_loss: 0.6740 - val_binary_accuracy: 0.5710 - val_precision: 0.5641 - val_recall: 0.6700\n",
      "Epoch 126/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6740 - binary_accuracy: 0.5710 - precision: 0.5641 - recall: 0.6700 - val_loss: 0.6738 - val_binary_accuracy: 0.5680 - val_precision: 0.5611 - val_recall: 0.6719\n",
      "Epoch 127/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6738 - binary_accuracy: 0.5680 - precision: 0.5611 - recall: 0.6719 - val_loss: 0.6735 - val_binary_accuracy: 0.5640 - val_precision: 0.5648 - val_recall: 0.6028\n",
      "Epoch 128/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6735 - binary_accuracy: 0.5640 - precision: 0.5648 - recall: 0.6028 - val_loss: 0.6732 - val_binary_accuracy: 0.5650 - val_precision: 0.5637 - val_recall: 0.6206\n",
      "Epoch 129/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6732 - binary_accuracy: 0.5650 - precision: 0.5637 - recall: 0.6206 - val_loss: 0.6730 - val_binary_accuracy: 0.5710 - val_precision: 0.5632 - val_recall: 0.6779\n",
      "Epoch 130/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6730 - binary_accuracy: 0.5710 - precision: 0.5632 - recall: 0.6779 - val_loss: 0.6727 - val_binary_accuracy: 0.5680 - val_precision: 0.5636 - val_recall: 0.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6727 - binary_accuracy: 0.5680 - precision: 0.5636 - recall: 0.6482 - val_loss: 0.6725 - val_binary_accuracy: 0.5720 - val_precision: 0.5717 - val_recall: 0.6146\n",
      "Epoch 132/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6725 - binary_accuracy: 0.5720 - precision: 0.5717 - recall: 0.6146 - val_loss: 0.6722 - val_binary_accuracy: 0.5720 - val_precision: 0.5641 - val_recall: 0.6779\n",
      "Epoch 133/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6722 - binary_accuracy: 0.5720 - precision: 0.5641 - recall: 0.6779 - val_loss: 0.6720 - val_binary_accuracy: 0.5690 - val_precision: 0.5654 - val_recall: 0.6403\n",
      "Epoch 134/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6720 - binary_accuracy: 0.5690 - precision: 0.5654 - recall: 0.6403 - val_loss: 0.6719 - val_binary_accuracy: 0.5800 - val_precision: 0.5796 - val_recall: 0.6186\n",
      "Epoch 135/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6719 - binary_accuracy: 0.5800 - precision: 0.5796 - recall: 0.6186 - val_loss: 0.6718 - val_binary_accuracy: 0.5750 - val_precision: 0.5659 - val_recall: 0.6877\n",
      "Epoch 136/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6718 - binary_accuracy: 0.5750 - precision: 0.5659 - recall: 0.6877 - val_loss: 0.6717 - val_binary_accuracy: 0.5870 - val_precision: 0.5882 - val_recall: 0.6126\n",
      "Epoch 137/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6717 - binary_accuracy: 0.5870 - precision: 0.5882 - recall: 0.6126 - val_loss: 0.6716 - val_binary_accuracy: 0.5700 - val_precision: 0.5617 - val_recall: 0.6838\n",
      "Epoch 138/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6716 - binary_accuracy: 0.5700 - precision: 0.5617 - recall: 0.6838 - val_loss: 0.6712 - val_binary_accuracy: 0.5890 - val_precision: 0.5875 - val_recall: 0.6304\n",
      "Epoch 139/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6712 - binary_accuracy: 0.5890 - precision: 0.5875 - recall: 0.6304 - val_loss: 0.6709 - val_binary_accuracy: 0.5780 - val_precision: 0.5717 - val_recall: 0.6621\n",
      "Epoch 140/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6709 - binary_accuracy: 0.5780 - precision: 0.5717 - recall: 0.6621 - val_loss: 0.6707 - val_binary_accuracy: 0.5860 - val_precision: 0.5790 - val_recall: 0.6660\n",
      "Epoch 141/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6707 - binary_accuracy: 0.5860 - precision: 0.5790 - recall: 0.6660 - val_loss: 0.6705 - val_binary_accuracy: 0.5900 - val_precision: 0.5886 - val_recall: 0.6304\n",
      "Epoch 142/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6705 - binary_accuracy: 0.5900 - precision: 0.5886 - recall: 0.6304 - val_loss: 0.6702 - val_binary_accuracy: 0.5810 - val_precision: 0.5721 - val_recall: 0.6818\n",
      "Epoch 143/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6702 - binary_accuracy: 0.5810 - precision: 0.5721 - recall: 0.6818 - val_loss: 0.6699 - val_binary_accuracy: 0.5850 - val_precision: 0.5814 - val_recall: 0.6423\n",
      "Epoch 144/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6699 - binary_accuracy: 0.5850 - precision: 0.5814 - recall: 0.6423 - val_loss: 0.6695 - val_binary_accuracy: 0.5850 - val_precision: 0.5802 - val_recall: 0.6502\n",
      "Epoch 145/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6695 - binary_accuracy: 0.5850 - precision: 0.5802 - recall: 0.6502 - val_loss: 0.6692 - val_binary_accuracy: 0.5870 - val_precision: 0.5789 - val_recall: 0.6739\n",
      "Epoch 146/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6692 - binary_accuracy: 0.5870 - precision: 0.5789 - recall: 0.6739 - val_loss: 0.6689 - val_binary_accuracy: 0.5850 - val_precision: 0.5800 - val_recall: 0.6522\n",
      "Epoch 147/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6689 - binary_accuracy: 0.5850 - precision: 0.5800 - recall: 0.6522 - val_loss: 0.6686 - val_binary_accuracy: 0.5920 - val_precision: 0.5854 - val_recall: 0.6640\n",
      "Epoch 148/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6686 - binary_accuracy: 0.5920 - precision: 0.5854 - recall: 0.6640 - val_loss: 0.6682 - val_binary_accuracy: 0.5900 - val_precision: 0.5822 - val_recall: 0.6719\n",
      "Epoch 149/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6682 - binary_accuracy: 0.5900 - precision: 0.5822 - recall: 0.6719 - val_loss: 0.6679 - val_binary_accuracy: 0.5870 - val_precision: 0.5782 - val_recall: 0.6798\n",
      "Epoch 150/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6679 - binary_accuracy: 0.5870 - precision: 0.5782 - recall: 0.6798 - val_loss: 0.6673 - val_binary_accuracy: 0.5970 - val_precision: 0.5921 - val_recall: 0.6542\n",
      "Epoch 151/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6673 - binary_accuracy: 0.5970 - precision: 0.5921 - recall: 0.6542 - val_loss: 0.6668 - val_binary_accuracy: 0.5910 - val_precision: 0.5821 - val_recall: 0.6798\n",
      "Epoch 152/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6668 - binary_accuracy: 0.5910 - precision: 0.5821 - recall: 0.6798 - val_loss: 0.6662 - val_binary_accuracy: 0.5940 - val_precision: 0.5871 - val_recall: 0.6660\n",
      "Epoch 153/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6662 - binary_accuracy: 0.5940 - precision: 0.5871 - recall: 0.6660 - val_loss: 0.6657 - val_binary_accuracy: 0.5900 - val_precision: 0.5836 - val_recall: 0.6621\n",
      "Epoch 154/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.6657 - binary_accuracy: 0.5900 - precision: 0.5836 - recall: 0.6621 - val_loss: 0.6652 - val_binary_accuracy: 0.5860 - val_precision: 0.5790 - val_recall: 0.6660\n",
      "Epoch 155/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6652 - binary_accuracy: 0.5860 - precision: 0.5790 - recall: 0.6660 - val_loss: 0.6648 - val_binary_accuracy: 0.5910 - val_precision: 0.5849 - val_recall: 0.6601\n",
      "Epoch 156/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.6648 - binary_accuracy: 0.5910 - precision: 0.5849 - recall: 0.6601 - val_loss: 0.6645 - val_binary_accuracy: 0.5900 - val_precision: 0.5857 - val_recall: 0.6482\n",
      "Epoch 157/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6645 - binary_accuracy: 0.5900 - precision: 0.5857 - recall: 0.6482 - val_loss: 0.6652 - val_binary_accuracy: 0.5840 - val_precision: 0.5792 - val_recall: 0.6502\n",
      "Epoch 158/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6652 - binary_accuracy: 0.5840 - precision: 0.5792 - recall: 0.6502 - val_loss: 0.6632 - val_binary_accuracy: 0.5810 - val_precision: 0.5724 - val_recall: 0.6798\n",
      "Epoch 159/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6632 - binary_accuracy: 0.5810 - precision: 0.5724 - recall: 0.6798 - val_loss: 0.6631 - val_binary_accuracy: 0.6030 - val_precision: 0.6079 - val_recall: 0.6067\n",
      "Epoch 160/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6631 - binary_accuracy: 0.6030 - precision: 0.6079 - recall: 0.6067 - val_loss: 0.6638 - val_binary_accuracy: 0.5670 - val_precision: 0.5575 - val_recall: 0.6996\n",
      "Epoch 161/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.6638 - binary_accuracy: 0.5670 - precision: 0.5575 - recall: 0.6996 - val_loss: 0.6617 - val_binary_accuracy: 0.5740 - val_precision: 0.5660 - val_recall: 0.6779\n",
      "Epoch 162/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6617 - binary_accuracy: 0.5740 - precision: 0.5660 - recall: 0.6779 - val_loss: 0.6630 - val_binary_accuracy: 0.5990 - val_precision: 0.6048 - val_recall: 0.5988\n",
      "Epoch 163/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.6630 - binary_accuracy: 0.5990 - precision: 0.6048 - recall: 0.5988 - val_loss: 0.6614 - val_binary_accuracy: 0.5650 - val_precision: 0.5514 - val_recall: 0.7530\n",
      "Epoch 164/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6614 - binary_accuracy: 0.5650 - precision: 0.5514 - recall: 0.7530 - val_loss: 0.6624 - val_binary_accuracy: 0.5960 - val_precision: 0.6016 - val_recall: 0.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6624 - binary_accuracy: 0.5960 - precision: 0.6016 - recall: 0.5968 - val_loss: 0.6587 - val_binary_accuracy: 0.5890 - val_precision: 0.5832 - val_recall: 0.6581\n",
      "Epoch 166/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6587 - binary_accuracy: 0.5890 - precision: 0.5832 - recall: 0.6581 - val_loss: 0.6603 - val_binary_accuracy: 0.5850 - val_precision: 0.5740 - val_recall: 0.6976\n",
      "Epoch 167/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.6603 - binary_accuracy: 0.5850 - precision: 0.5740 - recall: 0.6976 - val_loss: 0.6582 - val_binary_accuracy: 0.6010 - val_precision: 0.6131 - val_recall: 0.5731\n",
      "Epoch 168/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6582 - binary_accuracy: 0.6010 - precision: 0.6131 - recall: 0.5731 - val_loss: 0.6582 - val_binary_accuracy: 0.5830 - val_precision: 0.5728 - val_recall: 0.6917\n",
      "Epoch 169/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6582 - binary_accuracy: 0.5830 - precision: 0.5728 - recall: 0.6917 - val_loss: 0.6575 - val_binary_accuracy: 0.5870 - val_precision: 0.5800 - val_recall: 0.6660\n",
      "Epoch 170/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6575 - binary_accuracy: 0.5870 - precision: 0.5800 - recall: 0.6660 - val_loss: 0.6556 - val_binary_accuracy: 0.6020 - val_precision: 0.6038 - val_recall: 0.6206\n",
      "Epoch 171/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6556 - binary_accuracy: 0.6020 - precision: 0.6038 - recall: 0.6206 - val_loss: 0.6562 - val_binary_accuracy: 0.5850 - val_precision: 0.5735 - val_recall: 0.7016\n",
      "Epoch 172/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6562 - binary_accuracy: 0.5850 - precision: 0.5735 - recall: 0.7016 - val_loss: 0.6538 - val_binary_accuracy: 0.6020 - val_precision: 0.5996 - val_recall: 0.6423\n",
      "Epoch 173/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6538 - binary_accuracy: 0.6020 - precision: 0.5996 - recall: 0.6423 - val_loss: 0.6535 - val_binary_accuracy: 0.6020 - val_precision: 0.5996 - val_recall: 0.6423\n",
      "Epoch 174/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6535 - binary_accuracy: 0.6020 - precision: 0.5996 - recall: 0.6423 - val_loss: 0.6530 - val_binary_accuracy: 0.5910 - val_precision: 0.5823 - val_recall: 0.6779\n",
      "Epoch 175/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6530 - binary_accuracy: 0.5910 - precision: 0.5823 - recall: 0.6779 - val_loss: 0.6512 - val_binary_accuracy: 0.6030 - val_precision: 0.6030 - val_recall: 0.6304\n",
      "Epoch 176/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6512 - binary_accuracy: 0.6030 - precision: 0.6030 - recall: 0.6304 - val_loss: 0.6510 - val_binary_accuracy: 0.6010 - val_precision: 0.5896 - val_recall: 0.6957\n",
      "Epoch 177/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6510 - binary_accuracy: 0.6010 - precision: 0.5896 - recall: 0.6957 - val_loss: 0.6492 - val_binary_accuracy: 0.6010 - val_precision: 0.5964 - val_recall: 0.6542\n",
      "Epoch 178/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6492 - binary_accuracy: 0.6010 - precision: 0.5964 - recall: 0.6542 - val_loss: 0.6489 - val_binary_accuracy: 0.5970 - val_precision: 0.5899 - val_recall: 0.6680\n",
      "Epoch 179/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6489 - binary_accuracy: 0.5970 - precision: 0.5899 - recall: 0.6680 - val_loss: 0.6473 - val_binary_accuracy: 0.5940 - val_precision: 0.5916 - val_recall: 0.6383\n",
      "Epoch 180/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6473 - binary_accuracy: 0.5940 - precision: 0.5916 - recall: 0.6383 - val_loss: 0.6471 - val_binary_accuracy: 0.5980 - val_precision: 0.5864 - val_recall: 0.6976\n",
      "Epoch 181/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6471 - binary_accuracy: 0.5980 - precision: 0.5864 - recall: 0.6976 - val_loss: 0.6464 - val_binary_accuracy: 0.6070 - val_precision: 0.6231 - val_recall: 0.5652\n",
      "Epoch 182/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6464 - binary_accuracy: 0.6070 - precision: 0.6231 - recall: 0.5652 - val_loss: 0.6547 - val_binary_accuracy: 0.5720 - val_precision: 0.5490 - val_recall: 0.8636\n",
      "Epoch 183/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6547 - binary_accuracy: 0.5720 - precision: 0.5490 - recall: 0.8636 - val_loss: 0.6558 - val_binary_accuracy: 0.5930 - val_precision: 0.6495 - val_recall: 0.4249\n",
      "Epoch 184/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6558 - binary_accuracy: 0.5930 - precision: 0.6495 - recall: 0.4249 - val_loss: 0.6486 - val_binary_accuracy: 0.6010 - val_precision: 0.6213 - val_recall: 0.5415\n",
      "Epoch 185/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6486 - binary_accuracy: 0.6010 - precision: 0.6213 - recall: 0.5415 - val_loss: 0.6465 - val_binary_accuracy: 0.5920 - val_precision: 0.5710 - val_recall: 0.7787\n",
      "Epoch 186/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.6465 - binary_accuracy: 0.5920 - precision: 0.5710 - recall: 0.7787 - val_loss: 0.6471 - val_binary_accuracy: 0.5850 - val_precision: 0.5633 - val_recall: 0.8004\n",
      "Epoch 187/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6471 - binary_accuracy: 0.5850 - precision: 0.5633 - recall: 0.8004 - val_loss: 0.6454 - val_binary_accuracy: 0.6070 - val_precision: 0.6151 - val_recall: 0.5968\n",
      "Epoch 188/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.6454 - binary_accuracy: 0.6070 - precision: 0.6151 - recall: 0.5968 - val_loss: 0.6463 - val_binary_accuracy: 0.5990 - val_precision: 0.5989 - val_recall: 0.6285\n",
      "Epoch 189/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6463 - binary_accuracy: 0.5990 - precision: 0.5989 - recall: 0.6285 - val_loss: 0.6442 - val_binary_accuracy: 0.5890 - val_precision: 0.5872 - val_recall: 0.6324\n",
      "Epoch 190/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6442 - binary_accuracy: 0.5890 - precision: 0.5872 - recall: 0.6324 - val_loss: 0.6430 - val_binary_accuracy: 0.5980 - val_precision: 0.5959 - val_recall: 0.6383\n",
      "Epoch 191/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6430 - binary_accuracy: 0.5980 - precision: 0.5959 - recall: 0.6383 - val_loss: 0.6426 - val_binary_accuracy: 0.6020 - val_precision: 0.5954 - val_recall: 0.6660\n",
      "Epoch 192/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6426 - binary_accuracy: 0.6020 - precision: 0.5954 - recall: 0.6660 - val_loss: 0.6417 - val_binary_accuracy: 0.5870 - val_precision: 0.5817 - val_recall: 0.6542\n",
      "Epoch 193/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6417 - binary_accuracy: 0.5870 - precision: 0.5817 - recall: 0.6542 - val_loss: 0.6401 - val_binary_accuracy: 0.6020 - val_precision: 0.6120 - val_recall: 0.5830\n",
      "Epoch 194/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6401 - binary_accuracy: 0.6020 - precision: 0.6120 - recall: 0.5830 - val_loss: 0.6396 - val_binary_accuracy: 0.6130 - val_precision: 0.6308 - val_recall: 0.5672\n",
      "Epoch 195/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6396 - binary_accuracy: 0.6130 - precision: 0.6308 - recall: 0.5672 - val_loss: 0.6385 - val_binary_accuracy: 0.6050 - val_precision: 0.6061 - val_recall: 0.6265\n",
      "Epoch 196/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.6385 - binary_accuracy: 0.6050 - precision: 0.6061 - recall: 0.6265 - val_loss: 0.6377 - val_binary_accuracy: 0.5980 - val_precision: 0.5884 - val_recall: 0.6838\n",
      "Epoch 197/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6377 - binary_accuracy: 0.5980 - precision: 0.5884 - recall: 0.6838 - val_loss: 0.6370 - val_binary_accuracy: 0.5940 - val_precision: 0.5820 - val_recall: 0.7016\n",
      "Epoch 198/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.6370 - binary_accuracy: 0.5940 - precision: 0.5820 - recall: 0.7016 - val_loss: 0.6353 - val_binary_accuracy: 0.6080 - val_precision: 0.5997 - val_recall: 0.6779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6353 - binary_accuracy: 0.6080 - precision: 0.5997 - recall: 0.6779 - val_loss: 0.6348 - val_binary_accuracy: 0.6050 - val_precision: 0.6126 - val_recall: 0.5968\n",
      "Epoch 200/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6348 - binary_accuracy: 0.6050 - precision: 0.6126 - recall: 0.5968 - val_loss: 0.6347 - val_binary_accuracy: 0.6050 - val_precision: 0.6188 - val_recall: 0.5711\n",
      "Epoch 201/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6347 - binary_accuracy: 0.6050 - precision: 0.6188 - recall: 0.5711 - val_loss: 0.6327 - val_binary_accuracy: 0.6070 - val_precision: 0.6119 - val_recall: 0.6107\n",
      "Epoch 202/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6327 - binary_accuracy: 0.6070 - precision: 0.6119 - recall: 0.6107 - val_loss: 0.6317 - val_binary_accuracy: 0.6080 - val_precision: 0.6022 - val_recall: 0.6640\n",
      "Epoch 203/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6317 - binary_accuracy: 0.6080 - precision: 0.6022 - recall: 0.6640 - val_loss: 0.6318 - val_binary_accuracy: 0.6060 - val_precision: 0.5949 - val_recall: 0.6937\n",
      "Epoch 204/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6318 - binary_accuracy: 0.6060 - precision: 0.5949 - recall: 0.6937 - val_loss: 0.6300 - val_binary_accuracy: 0.6110 - val_precision: 0.6085 - val_recall: 0.6482\n",
      "Epoch 205/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6300 - binary_accuracy: 0.6110 - precision: 0.6085 - recall: 0.6482 - val_loss: 0.6294 - val_binary_accuracy: 0.6100 - val_precision: 0.6169 - val_recall: 0.6047\n",
      "Epoch 206/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6294 - binary_accuracy: 0.6100 - precision: 0.6169 - recall: 0.6047 - val_loss: 0.6288 - val_binary_accuracy: 0.6120 - val_precision: 0.6239 - val_recall: 0.5870\n",
      "Epoch 207/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6288 - binary_accuracy: 0.6120 - precision: 0.6239 - recall: 0.5870 - val_loss: 0.6270 - val_binary_accuracy: 0.6130 - val_precision: 0.6192 - val_recall: 0.6107\n",
      "Epoch 208/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6270 - binary_accuracy: 0.6130 - precision: 0.6192 - recall: 0.6107 - val_loss: 0.6265 - val_binary_accuracy: 0.6200 - val_precision: 0.6113 - val_recall: 0.6838\n",
      "Epoch 209/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.6265 - binary_accuracy: 0.6200 - precision: 0.6113 - recall: 0.6838 - val_loss: 0.6258 - val_binary_accuracy: 0.6200 - val_precision: 0.6094 - val_recall: 0.6937\n",
      "Epoch 210/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6258 - binary_accuracy: 0.6200 - precision: 0.6094 - recall: 0.6937 - val_loss: 0.6241 - val_binary_accuracy: 0.6170 - val_precision: 0.6167 - val_recall: 0.6423\n",
      "Epoch 211/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6241 - binary_accuracy: 0.6170 - precision: 0.6167 - recall: 0.6423 - val_loss: 0.6235 - val_binary_accuracy: 0.6190 - val_precision: 0.6268 - val_recall: 0.6107\n",
      "Epoch 212/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6235 - binary_accuracy: 0.6190 - precision: 0.6268 - recall: 0.6107 - val_loss: 0.6223 - val_binary_accuracy: 0.6180 - val_precision: 0.6270 - val_recall: 0.6047\n",
      "Epoch 213/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6223 - binary_accuracy: 0.6180 - precision: 0.6270 - recall: 0.6047 - val_loss: 0.6210 - val_binary_accuracy: 0.6110 - val_precision: 0.6168 - val_recall: 0.6107\n",
      "Epoch 214/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6210 - binary_accuracy: 0.6110 - precision: 0.6168 - recall: 0.6107 - val_loss: 0.6203 - val_binary_accuracy: 0.6180 - val_precision: 0.6157 - val_recall: 0.6522\n",
      "Epoch 215/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6203 - binary_accuracy: 0.6180 - precision: 0.6157 - recall: 0.6522 - val_loss: 0.6188 - val_binary_accuracy: 0.6210 - val_precision: 0.6252 - val_recall: 0.6265\n",
      "Epoch 216/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6188 - binary_accuracy: 0.6210 - precision: 0.6252 - recall: 0.6265 - val_loss: 0.6177 - val_binary_accuracy: 0.6240 - val_precision: 0.6305 - val_recall: 0.6206\n",
      "Epoch 217/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6177 - binary_accuracy: 0.6240 - precision: 0.6305 - recall: 0.6206 - val_loss: 0.6166 - val_binary_accuracy: 0.6260 - val_precision: 0.6369 - val_recall: 0.6067\n",
      "Epoch 218/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6166 - binary_accuracy: 0.6260 - precision: 0.6369 - recall: 0.6067 - val_loss: 0.6150 - val_binary_accuracy: 0.6270 - val_precision: 0.6322 - val_recall: 0.6285\n",
      "Epoch 219/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6150 - binary_accuracy: 0.6270 - precision: 0.6322 - recall: 0.6285 - val_loss: 0.6140 - val_binary_accuracy: 0.6190 - val_precision: 0.6181 - val_recall: 0.6462\n",
      "Epoch 220/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6140 - binary_accuracy: 0.6190 - precision: 0.6181 - recall: 0.6462 - val_loss: 0.6125 - val_binary_accuracy: 0.6320 - val_precision: 0.6397 - val_recall: 0.6245\n",
      "Epoch 221/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6125 - binary_accuracy: 0.6320 - precision: 0.6397 - recall: 0.6245 - val_loss: 0.6113 - val_binary_accuracy: 0.6260 - val_precision: 0.6347 - val_recall: 0.6146\n",
      "Epoch 222/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6113 - binary_accuracy: 0.6260 - precision: 0.6347 - recall: 0.6146 - val_loss: 0.6104 - val_binary_accuracy: 0.6350 - val_precision: 0.6613 - val_recall: 0.5711\n",
      "Epoch 223/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6104 - binary_accuracy: 0.6350 - precision: 0.6613 - recall: 0.5711 - val_loss: 0.6113 - val_binary_accuracy: 0.6170 - val_precision: 0.6085 - val_recall: 0.6818\n",
      "Epoch 224/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6113 - binary_accuracy: 0.6170 - precision: 0.6085 - recall: 0.6818 - val_loss: 0.6148 - val_binary_accuracy: 0.6250 - val_precision: 0.6625 - val_recall: 0.5277\n",
      "Epoch 225/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6148 - binary_accuracy: 0.6250 - precision: 0.6625 - recall: 0.5277 - val_loss: 0.6238 - val_binary_accuracy: 0.6240 - val_precision: 0.6016 - val_recall: 0.7609\n",
      "Epoch 226/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6238 - binary_accuracy: 0.6240 - precision: 0.6016 - recall: 0.7609 - val_loss: 0.6112 - val_binary_accuracy: 0.6360 - val_precision: 0.6387 - val_recall: 0.6462\n",
      "Epoch 227/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6112 - binary_accuracy: 0.6360 - precision: 0.6387 - recall: 0.6462 - val_loss: 0.6219 - val_binary_accuracy: 0.6210 - val_precision: 0.6667 - val_recall: 0.5020\n",
      "Epoch 228/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6219 - binary_accuracy: 0.6210 - precision: 0.6667 - recall: 0.5020 - val_loss: 0.6057 - val_binary_accuracy: 0.6250 - val_precision: 0.6215 - val_recall: 0.6621\n",
      "Epoch 229/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6057 - binary_accuracy: 0.6250 - precision: 0.6215 - recall: 0.6621 - val_loss: 0.6146 - val_binary_accuracy: 0.6290 - val_precision: 0.6119 - val_recall: 0.7292\n",
      "Epoch 230/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6146 - binary_accuracy: 0.6290 - precision: 0.6119 - recall: 0.7292 - val_loss: 0.6043 - val_binary_accuracy: 0.6460 - val_precision: 0.6743 - val_recall: 0.5810\n",
      "Epoch 231/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.6043 - binary_accuracy: 0.6460 - precision: 0.6743 - recall: 0.5810 - val_loss: 0.6079 - val_binary_accuracy: 0.6520 - val_precision: 0.7124 - val_recall: 0.5237\n",
      "Epoch 232/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6079 - binary_accuracy: 0.6520 - precision: 0.7124 - recall: 0.5237 - val_loss: 0.6013 - val_binary_accuracy: 0.6500 - val_precision: 0.6773 - val_recall: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6013 - binary_accuracy: 0.6500 - precision: 0.6773 - recall: 0.5889 - val_loss: 0.6035 - val_binary_accuracy: 0.6460 - val_precision: 0.6234 - val_recall: 0.7589\n",
      "Epoch 234/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6035 - binary_accuracy: 0.6460 - precision: 0.6234 - recall: 0.7589 - val_loss: 0.5999 - val_binary_accuracy: 0.6370 - val_precision: 0.6288 - val_recall: 0.6897\n",
      "Epoch 235/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.5999 - binary_accuracy: 0.6370 - precision: 0.6288 - recall: 0.6897 - val_loss: 0.5980 - val_binary_accuracy: 0.6560 - val_precision: 0.7056 - val_recall: 0.5494\n",
      "Epoch 236/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5980 - binary_accuracy: 0.6560 - precision: 0.7056 - recall: 0.5494 - val_loss: 0.5985 - val_binary_accuracy: 0.6590 - val_precision: 0.7177 - val_recall: 0.5375\n",
      "Epoch 237/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.5985 - binary_accuracy: 0.6590 - precision: 0.7177 - recall: 0.5375 - val_loss: 0.5942 - val_binary_accuracy: 0.6370 - val_precision: 0.6505 - val_recall: 0.6107\n",
      "Epoch 238/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5942 - binary_accuracy: 0.6370 - precision: 0.6505 - recall: 0.6107 - val_loss: 0.5949 - val_binary_accuracy: 0.6430 - val_precision: 0.6244 - val_recall: 0.7391\n",
      "Epoch 239/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.5949 - binary_accuracy: 0.6430 - precision: 0.6244 - recall: 0.7391 - val_loss: 0.5916 - val_binary_accuracy: 0.6570 - val_precision: 0.6506 - val_recall: 0.6957\n",
      "Epoch 240/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.5916 - binary_accuracy: 0.6570 - precision: 0.6506 - recall: 0.6957 - val_loss: 0.5915 - val_binary_accuracy: 0.6490 - val_precision: 0.6815 - val_recall: 0.5751\n",
      "Epoch 241/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5915 - binary_accuracy: 0.6490 - precision: 0.6815 - recall: 0.5751 - val_loss: 0.5889 - val_binary_accuracy: 0.6560 - val_precision: 0.6884 - val_recall: 0.5850\n",
      "Epoch 242/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.5889 - binary_accuracy: 0.6560 - precision: 0.6884 - recall: 0.5850 - val_loss: 0.5884 - val_binary_accuracy: 0.6570 - val_precision: 0.6660 - val_recall: 0.6462\n",
      "Epoch 243/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.5884 - binary_accuracy: 0.6570 - precision: 0.6660 - recall: 0.6462 - val_loss: 0.5857 - val_binary_accuracy: 0.6530 - val_precision: 0.6492 - val_recall: 0.6838\n",
      "Epoch 244/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.5857 - binary_accuracy: 0.6530 - precision: 0.6492 - recall: 0.6838 - val_loss: 0.5851 - val_binary_accuracy: 0.6590 - val_precision: 0.6590 - val_recall: 0.6759\n",
      "Epoch 245/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.5851 - binary_accuracy: 0.6590 - precision: 0.6590 - recall: 0.6759 - val_loss: 0.5826 - val_binary_accuracy: 0.6750 - val_precision: 0.6828 - val_recall: 0.6680\n",
      "Epoch 246/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5826 - binary_accuracy: 0.6750 - precision: 0.6828 - recall: 0.6680 - val_loss: 0.5813 - val_binary_accuracy: 0.6550 - val_precision: 0.6777 - val_recall: 0.6067\n",
      "Epoch 247/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5813 - binary_accuracy: 0.6550 - precision: 0.6777 - recall: 0.6067 - val_loss: 0.5800 - val_binary_accuracy: 0.6590 - val_precision: 0.6837 - val_recall: 0.6067\n",
      "Epoch 248/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5800 - binary_accuracy: 0.6590 - precision: 0.6837 - recall: 0.6067 - val_loss: 0.5776 - val_binary_accuracy: 0.6630 - val_precision: 0.6749 - val_recall: 0.6443\n",
      "Epoch 249/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.5776 - binary_accuracy: 0.6630 - precision: 0.6749 - recall: 0.6443 - val_loss: 0.5770 - val_binary_accuracy: 0.6720 - val_precision: 0.6654 - val_recall: 0.7075\n",
      "Epoch 250/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.5770 - binary_accuracy: 0.6720 - precision: 0.6654 - recall: 0.7075 - val_loss: 0.5740 - val_binary_accuracy: 0.6780 - val_precision: 0.6870 - val_recall: 0.6680\n",
      "Epoch 251/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.5740 - binary_accuracy: 0.6780 - precision: 0.6870 - recall: 0.6680 - val_loss: 0.5732 - val_binary_accuracy: 0.6680 - val_precision: 0.6925 - val_recall: 0.6186\n",
      "Epoch 252/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.5732 - binary_accuracy: 0.6680 - precision: 0.6925 - recall: 0.6186 - val_loss: 0.5709 - val_binary_accuracy: 0.6770 - val_precision: 0.6943 - val_recall: 0.6462\n",
      "Epoch 253/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5709 - binary_accuracy: 0.6770 - precision: 0.6943 - recall: 0.6462 - val_loss: 0.5692 - val_binary_accuracy: 0.6810 - val_precision: 0.6728 - val_recall: 0.7194\n",
      "Epoch 254/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5692 - binary_accuracy: 0.6810 - precision: 0.6728 - recall: 0.7194 - val_loss: 0.5674 - val_binary_accuracy: 0.6730 - val_precision: 0.6679 - val_recall: 0.7036\n",
      "Epoch 255/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.5674 - binary_accuracy: 0.6730 - precision: 0.6679 - recall: 0.7036 - val_loss: 0.5648 - val_binary_accuracy: 0.6840 - val_precision: 0.6939 - val_recall: 0.6719\n",
      "Epoch 256/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.5648 - binary_accuracy: 0.6840 - precision: 0.6939 - recall: 0.6719 - val_loss: 0.5635 - val_binary_accuracy: 0.6860 - val_precision: 0.7051 - val_recall: 0.6522\n",
      "Epoch 257/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.5635 - binary_accuracy: 0.6860 - precision: 0.7051 - recall: 0.6522 - val_loss: 0.5606 - val_binary_accuracy: 0.6920 - val_precision: 0.7012 - val_recall: 0.6818\n",
      "Epoch 258/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5606 - binary_accuracy: 0.6920 - precision: 0.7012 - recall: 0.6818 - val_loss: 0.5590 - val_binary_accuracy: 0.6900 - val_precision: 0.6856 - val_recall: 0.7154\n",
      "Epoch 259/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5590 - binary_accuracy: 0.6900 - precision: 0.6856 - recall: 0.7154 - val_loss: 0.5563 - val_binary_accuracy: 0.6970 - val_precision: 0.7018 - val_recall: 0.6976\n",
      "Epoch 260/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.5563 - binary_accuracy: 0.6970 - precision: 0.7018 - recall: 0.6976 - val_loss: 0.5544 - val_binary_accuracy: 0.6920 - val_precision: 0.7152 - val_recall: 0.6502\n",
      "Epoch 261/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5544 - binary_accuracy: 0.6920 - precision: 0.7152 - recall: 0.6502 - val_loss: 0.5517 - val_binary_accuracy: 0.6990 - val_precision: 0.7071 - val_recall: 0.6917\n",
      "Epoch 262/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.5517 - binary_accuracy: 0.6990 - precision: 0.7071 - recall: 0.6917 - val_loss: 0.5490 - val_binary_accuracy: 0.7020 - val_precision: 0.7000 - val_recall: 0.7194\n",
      "Epoch 263/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5490 - binary_accuracy: 0.7020 - precision: 0.7000 - recall: 0.7194 - val_loss: 0.5461 - val_binary_accuracy: 0.7000 - val_precision: 0.7012 - val_recall: 0.7095\n",
      "Epoch 264/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5461 - binary_accuracy: 0.7000 - precision: 0.7012 - recall: 0.7095 - val_loss: 0.5434 - val_binary_accuracy: 0.7090 - val_precision: 0.7292 - val_recall: 0.6759\n",
      "Epoch 265/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5434 - binary_accuracy: 0.7090 - precision: 0.7292 - recall: 0.6759 - val_loss: 0.5401 - val_binary_accuracy: 0.7120 - val_precision: 0.7290 - val_recall: 0.6858\n",
      "Epoch 266/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5401 - binary_accuracy: 0.7120 - precision: 0.7290 - recall: 0.6858 - val_loss: 0.5371 - val_binary_accuracy: 0.7110 - val_precision: 0.7166 - val_recall: 0.7095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5371 - binary_accuracy: 0.7110 - precision: 0.7166 - recall: 0.7095 - val_loss: 0.5336 - val_binary_accuracy: 0.7170 - val_precision: 0.7290 - val_recall: 0.7016\n",
      "Epoch 268/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5336 - binary_accuracy: 0.7170 - precision: 0.7290 - recall: 0.7016 - val_loss: 0.5313 - val_binary_accuracy: 0.7130 - val_precision: 0.7386 - val_recall: 0.6700\n",
      "Epoch 269/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.5313 - binary_accuracy: 0.7130 - precision: 0.7386 - recall: 0.6700 - val_loss: 0.5339 - val_binary_accuracy: 0.7200 - val_precision: 0.7116 - val_recall: 0.7510\n",
      "Epoch 270/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.5339 - binary_accuracy: 0.7200 - precision: 0.7116 - recall: 0.7510 - val_loss: 0.5614 - val_binary_accuracy: 0.6730 - val_precision: 0.7254 - val_recall: 0.5692\n",
      "Epoch 271/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5614 - binary_accuracy: 0.6730 - precision: 0.7254 - recall: 0.5692 - val_loss: 0.5782 - val_binary_accuracy: 0.6620 - val_precision: 0.6391 - val_recall: 0.7628\n",
      "Epoch 272/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.5782 - binary_accuracy: 0.6620 - precision: 0.6391 - recall: 0.7628 - val_loss: 0.5545 - val_binary_accuracy: 0.6860 - val_precision: 0.6868 - val_recall: 0.6976\n",
      "Epoch 273/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.5545 - binary_accuracy: 0.6860 - precision: 0.6868 - recall: 0.6976 - val_loss: 0.5457 - val_binary_accuracy: 0.6980 - val_precision: 0.7073 - val_recall: 0.6877\n",
      "Epoch 274/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5457 - binary_accuracy: 0.6980 - precision: 0.7073 - recall: 0.6877 - val_loss: 0.5328 - val_binary_accuracy: 0.7030 - val_precision: 0.7370 - val_recall: 0.6423\n",
      "Epoch 275/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5328 - binary_accuracy: 0.7030 - precision: 0.7370 - recall: 0.6423 - val_loss: 0.5389 - val_binary_accuracy: 0.7120 - val_precision: 0.7163 - val_recall: 0.7134\n",
      "Epoch 276/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.5389 - binary_accuracy: 0.7120 - precision: 0.7163 - recall: 0.7134 - val_loss: 0.5336 - val_binary_accuracy: 0.6940 - val_precision: 0.7703 - val_recall: 0.5632\n",
      "Epoch 277/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5336 - binary_accuracy: 0.6940 - precision: 0.7703 - recall: 0.5632 - val_loss: 0.5191 - val_binary_accuracy: 0.7340 - val_precision: 0.7857 - val_recall: 0.6522\n",
      "Epoch 278/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5191 - binary_accuracy: 0.7340 - precision: 0.7857 - recall: 0.6522 - val_loss: 0.5224 - val_binary_accuracy: 0.7010 - val_precision: 0.6872 - val_recall: 0.7510\n",
      "Epoch 279/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5224 - binary_accuracy: 0.7010 - precision: 0.6872 - recall: 0.7510 - val_loss: 0.5169 - val_binary_accuracy: 0.7020 - val_precision: 0.6763 - val_recall: 0.7885\n",
      "Epoch 280/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5169 - binary_accuracy: 0.7020 - precision: 0.6763 - recall: 0.7885 - val_loss: 0.5067 - val_binary_accuracy: 0.7310 - val_precision: 0.7687 - val_recall: 0.6700\n",
      "Epoch 281/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5067 - binary_accuracy: 0.7310 - precision: 0.7687 - recall: 0.6700 - val_loss: 0.5045 - val_binary_accuracy: 0.7260 - val_precision: 0.7959 - val_recall: 0.6166\n",
      "Epoch 282/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5045 - binary_accuracy: 0.7260 - precision: 0.7959 - recall: 0.6166 - val_loss: 0.5000 - val_binary_accuracy: 0.7460 - val_precision: 0.7480 - val_recall: 0.7510\n",
      "Epoch 283/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5000 - binary_accuracy: 0.7460 - precision: 0.7480 - recall: 0.7510 - val_loss: 0.4966 - val_binary_accuracy: 0.7360 - val_precision: 0.7224 - val_recall: 0.7767\n",
      "Epoch 284/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.4966 - binary_accuracy: 0.7360 - precision: 0.7224 - recall: 0.7767 - val_loss: 0.4880 - val_binary_accuracy: 0.7570 - val_precision: 0.7929 - val_recall: 0.7036\n",
      "Epoch 285/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.4880 - binary_accuracy: 0.7570 - precision: 0.7929 - recall: 0.7036 - val_loss: 0.4912 - val_binary_accuracy: 0.7490 - val_precision: 0.7972 - val_recall: 0.6759\n",
      "Epoch 286/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4912 - binary_accuracy: 0.7490 - precision: 0.7972 - recall: 0.6759 - val_loss: 0.4800 - val_binary_accuracy: 0.7630 - val_precision: 0.7751 - val_recall: 0.7490\n",
      "Epoch 287/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4800 - binary_accuracy: 0.7630 - precision: 0.7751 - recall: 0.7490 - val_loss: 0.4777 - val_binary_accuracy: 0.7550 - val_precision: 0.7495 - val_recall: 0.7747\n",
      "Epoch 288/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.4777 - binary_accuracy: 0.7550 - precision: 0.7495 - recall: 0.7747 - val_loss: 0.4730 - val_binary_accuracy: 0.7670 - val_precision: 0.7714 - val_recall: 0.7668\n",
      "Epoch 289/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4730 - binary_accuracy: 0.7670 - precision: 0.7714 - recall: 0.7668 - val_loss: 0.4705 - val_binary_accuracy: 0.7570 - val_precision: 0.8009 - val_recall: 0.6917\n",
      "Epoch 290/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4705 - binary_accuracy: 0.7570 - precision: 0.8009 - recall: 0.6917 - val_loss: 0.4618 - val_binary_accuracy: 0.7640 - val_precision: 0.8013 - val_recall: 0.7095\n",
      "Epoch 291/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.4618 - binary_accuracy: 0.7640 - precision: 0.8013 - recall: 0.7095 - val_loss: 0.4611 - val_binary_accuracy: 0.7620 - val_precision: 0.7648 - val_recall: 0.7648\n",
      "Epoch 292/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4611 - binary_accuracy: 0.7620 - precision: 0.7648 - recall: 0.7648 - val_loss: 0.4553 - val_binary_accuracy: 0.7650 - val_precision: 0.7853 - val_recall: 0.7372\n",
      "Epoch 293/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.4553 - binary_accuracy: 0.7650 - precision: 0.7853 - recall: 0.7372 - val_loss: 0.4502 - val_binary_accuracy: 0.7770 - val_precision: 0.7979 - val_recall: 0.7490\n",
      "Epoch 294/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.4502 - binary_accuracy: 0.7770 - precision: 0.7979 - recall: 0.7490 - val_loss: 0.4439 - val_binary_accuracy: 0.7830 - val_precision: 0.7774 - val_recall: 0.8004\n",
      "Epoch 295/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.4439 - binary_accuracy: 0.7830 - precision: 0.7774 - recall: 0.8004 - val_loss: 0.4413 - val_binary_accuracy: 0.7830 - val_precision: 0.7873 - val_recall: 0.7826\n",
      "Epoch 296/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.4413 - binary_accuracy: 0.7830 - precision: 0.7873 - recall: 0.7826 - val_loss: 0.4372 - val_binary_accuracy: 0.7820 - val_precision: 0.8051 - val_recall: 0.7510\n",
      "Epoch 297/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.4372 - binary_accuracy: 0.7820 - precision: 0.8051 - recall: 0.7510 - val_loss: 0.4336 - val_binary_accuracy: 0.7940 - val_precision: 0.8151 - val_recall: 0.7668\n",
      "Epoch 298/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.4336 - binary_accuracy: 0.7940 - precision: 0.8151 - recall: 0.7668 - val_loss: 0.4347 - val_binary_accuracy: 0.7880 - val_precision: 0.7579 - val_recall: 0.8538\n",
      "Epoch 299/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4347 - binary_accuracy: 0.7880 - precision: 0.7579 - recall: 0.8538 - val_loss: 0.4365 - val_binary_accuracy: 0.7730 - val_precision: 0.8462 - val_recall: 0.6739\n",
      "Epoch 300/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.4365 - binary_accuracy: 0.7730 - precision: 0.8462 - recall: 0.6739 - val_loss: 0.4296 - val_binary_accuracy: 0.7850 - val_precision: 0.7437 - val_recall: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4296 - binary_accuracy: 0.7850 - precision: 0.7437 - recall: 0.8775 - val_loss: 0.4217 - val_binary_accuracy: 0.7990 - val_precision: 0.8144 - val_recall: 0.7806\n",
      "Epoch 302/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.4217 - binary_accuracy: 0.7990 - precision: 0.8144 - recall: 0.7806 - val_loss: 0.4225 - val_binary_accuracy: 0.8170 - val_precision: 0.8473 - val_recall: 0.7787\n",
      "Epoch 303/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.4225 - binary_accuracy: 0.8170 - precision: 0.8473 - recall: 0.7787 - val_loss: 0.4045 - val_binary_accuracy: 0.8160 - val_precision: 0.8061 - val_recall: 0.8379\n",
      "Epoch 304/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.4045 - binary_accuracy: 0.8160 - precision: 0.8061 - recall: 0.8379 - val_loss: 0.4077 - val_binary_accuracy: 0.8110 - val_precision: 0.8176 - val_recall: 0.8063\n",
      "Epoch 305/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4077 - binary_accuracy: 0.8110 - precision: 0.8176 - recall: 0.8063 - val_loss: 0.4178 - val_binary_accuracy: 0.7910 - val_precision: 0.7839 - val_recall: 0.8103\n",
      "Epoch 306/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4178 - binary_accuracy: 0.7910 - precision: 0.7839 - recall: 0.8103 - val_loss: 0.3974 - val_binary_accuracy: 0.8130 - val_precision: 0.8344 - val_recall: 0.7866\n",
      "Epoch 307/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3974 - binary_accuracy: 0.8130 - precision: 0.8344 - recall: 0.7866 - val_loss: 0.3979 - val_binary_accuracy: 0.8140 - val_precision: 0.7797 - val_recall: 0.8814\n",
      "Epoch 308/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.3979 - binary_accuracy: 0.8140 - precision: 0.7797 - recall: 0.8814 - val_loss: 0.3922 - val_binary_accuracy: 0.8200 - val_precision: 0.8368 - val_recall: 0.8004\n",
      "Epoch 309/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.3922 - binary_accuracy: 0.8200 - precision: 0.8368 - recall: 0.8004 - val_loss: 0.3854 - val_binary_accuracy: 0.8190 - val_precision: 0.8806 - val_recall: 0.7431\n",
      "Epoch 310/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.3854 - binary_accuracy: 0.8190 - precision: 0.8806 - recall: 0.7431 - val_loss: 0.3823 - val_binary_accuracy: 0.8230 - val_precision: 0.7774 - val_recall: 0.9111\n",
      "Epoch 311/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3823 - binary_accuracy: 0.8230 - precision: 0.7774 - recall: 0.9111 - val_loss: 0.3709 - val_binary_accuracy: 0.8340 - val_precision: 0.8220 - val_recall: 0.8577\n",
      "Epoch 312/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3709 - binary_accuracy: 0.8340 - precision: 0.8220 - recall: 0.8577 - val_loss: 0.3739 - val_binary_accuracy: 0.8250 - val_precision: 0.8913 - val_recall: 0.7451\n",
      "Epoch 313/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3739 - binary_accuracy: 0.8250 - precision: 0.8913 - recall: 0.7451 - val_loss: 0.3639 - val_binary_accuracy: 0.8470 - val_precision: 0.8227 - val_recall: 0.8893\n",
      "Epoch 314/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.3639 - binary_accuracy: 0.8470 - precision: 0.8227 - recall: 0.8893 - val_loss: 0.3594 - val_binary_accuracy: 0.8470 - val_precision: 0.8287 - val_recall: 0.8794\n",
      "Epoch 315/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.3594 - binary_accuracy: 0.8470 - precision: 0.8287 - recall: 0.8794 - val_loss: 0.3569 - val_binary_accuracy: 0.8370 - val_precision: 0.8924 - val_recall: 0.7708\n",
      "Epoch 316/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.3569 - binary_accuracy: 0.8370 - precision: 0.8924 - recall: 0.7708 - val_loss: 0.3470 - val_binary_accuracy: 0.8480 - val_precision: 0.8540 - val_recall: 0.8439\n",
      "Epoch 317/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3470 - binary_accuracy: 0.8480 - precision: 0.8540 - recall: 0.8439 - val_loss: 0.3527 - val_binary_accuracy: 0.8370 - val_precision: 0.7922 - val_recall: 0.9190\n",
      "Epoch 318/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.3527 - binary_accuracy: 0.8370 - precision: 0.7922 - recall: 0.9190 - val_loss: 0.3531 - val_binary_accuracy: 0.8480 - val_precision: 0.8703 - val_recall: 0.8221\n",
      "Epoch 319/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.3531 - binary_accuracy: 0.8480 - precision: 0.8703 - recall: 0.8221 - val_loss: 0.3771 - val_binary_accuracy: 0.8110 - val_precision: 0.8126 - val_recall: 0.8142\n",
      "Epoch 320/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3771 - binary_accuracy: 0.8110 - precision: 0.8126 - recall: 0.8142 - val_loss: 0.3794 - val_binary_accuracy: 0.8250 - val_precision: 0.8214 - val_recall: 0.8360\n",
      "Epoch 321/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3794 - binary_accuracy: 0.8250 - precision: 0.8214 - recall: 0.8360 - val_loss: 0.3526 - val_binary_accuracy: 0.8490 - val_precision: 0.8233 - val_recall: 0.8933\n",
      "Epoch 322/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3526 - binary_accuracy: 0.8490 - precision: 0.8233 - recall: 0.8933 - val_loss: 0.3410 - val_binary_accuracy: 0.8520 - val_precision: 0.8874 - val_recall: 0.8103\n",
      "Epoch 323/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.3410 - binary_accuracy: 0.8520 - precision: 0.8874 - recall: 0.8103 - val_loss: 0.3586 - val_binary_accuracy: 0.8340 - val_precision: 0.8498 - val_recall: 0.8162\n",
      "Epoch 324/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.3586 - binary_accuracy: 0.8340 - precision: 0.8498 - recall: 0.8162 - val_loss: 0.3297 - val_binary_accuracy: 0.8560 - val_precision: 0.8131 - val_recall: 0.9289\n",
      "Epoch 325/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.3297 - binary_accuracy: 0.8560 - precision: 0.8131 - recall: 0.9289 - val_loss: 0.3268 - val_binary_accuracy: 0.8620 - val_precision: 0.8651 - val_recall: 0.8617\n",
      "Epoch 326/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3268 - binary_accuracy: 0.8620 - precision: 0.8651 - recall: 0.8617 - val_loss: 0.3216 - val_binary_accuracy: 0.8610 - val_precision: 0.9069 - val_recall: 0.8083\n",
      "Epoch 327/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3216 - binary_accuracy: 0.8610 - precision: 0.9069 - recall: 0.8083 - val_loss: 0.3181 - val_binary_accuracy: 0.8700 - val_precision: 0.8469 - val_recall: 0.9071\n",
      "Epoch 328/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3181 - binary_accuracy: 0.8700 - precision: 0.8469 - recall: 0.9071 - val_loss: 0.3056 - val_binary_accuracy: 0.8720 - val_precision: 0.8677 - val_recall: 0.8814\n",
      "Epoch 329/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3056 - binary_accuracy: 0.8720 - precision: 0.8677 - recall: 0.8814 - val_loss: 0.3068 - val_binary_accuracy: 0.8780 - val_precision: 0.9120 - val_recall: 0.8399\n",
      "Epoch 330/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.3068 - binary_accuracy: 0.8780 - precision: 0.9120 - recall: 0.8399 - val_loss: 0.2955 - val_binary_accuracy: 0.8760 - val_precision: 0.8617 - val_recall: 0.8992\n",
      "Epoch 331/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.2955 - binary_accuracy: 0.8760 - precision: 0.8617 - recall: 0.8992 - val_loss: 0.2960 - val_binary_accuracy: 0.8810 - val_precision: 0.8486 - val_recall: 0.9308\n",
      "Epoch 332/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.2960 - binary_accuracy: 0.8810 - precision: 0.8486 - recall: 0.9308 - val_loss: 0.2834 - val_binary_accuracy: 0.8790 - val_precision: 0.8782 - val_recall: 0.8834\n",
      "Epoch 333/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.2834 - binary_accuracy: 0.8790 - precision: 0.8782 - recall: 0.8834 - val_loss: 0.2872 - val_binary_accuracy: 0.8800 - val_precision: 0.9055 - val_recall: 0.8518\n",
      "Epoch 334/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.2872 - binary_accuracy: 0.8800 - precision: 0.9055 - recall: 0.8518 - val_loss: 0.2788 - val_binary_accuracy: 0.8950 - val_precision: 0.8878 - val_recall: 0.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.2788 - binary_accuracy: 0.8950 - precision: 0.8878 - recall: 0.9071 - val_loss: 0.2793 - val_binary_accuracy: 0.8870 - val_precision: 0.8579 - val_recall: 0.9308\n",
      "Epoch 336/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.2793 - binary_accuracy: 0.8870 - precision: 0.8579 - recall: 0.9308 - val_loss: 0.2684 - val_binary_accuracy: 0.8900 - val_precision: 0.9125 - val_recall: 0.8656\n",
      "Epoch 337/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.2684 - binary_accuracy: 0.8900 - precision: 0.9125 - recall: 0.8656 - val_loss: 0.2628 - val_binary_accuracy: 0.9010 - val_precision: 0.9046 - val_recall: 0.8992\n",
      "Epoch 338/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.2628 - binary_accuracy: 0.9010 - precision: 0.9046 - recall: 0.8992 - val_loss: 0.2578 - val_binary_accuracy: 0.9050 - val_precision: 0.8813 - val_recall: 0.9387\n",
      "Epoch 339/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.2578 - binary_accuracy: 0.9050 - precision: 0.8813 - recall: 0.9387 - val_loss: 0.2528 - val_binary_accuracy: 0.9020 - val_precision: 0.8953 - val_recall: 0.9130\n",
      "Epoch 340/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.2528 - binary_accuracy: 0.9020 - precision: 0.8953 - recall: 0.9130 - val_loss: 0.2516 - val_binary_accuracy: 0.8970 - val_precision: 0.9155 - val_recall: 0.8775\n",
      "Epoch 341/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2516 - binary_accuracy: 0.8970 - precision: 0.9155 - recall: 0.8775 - val_loss: 0.2497 - val_binary_accuracy: 0.9050 - val_precision: 0.8944 - val_recall: 0.9209\n",
      "Epoch 342/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.2497 - binary_accuracy: 0.9050 - precision: 0.8944 - recall: 0.9209 - val_loss: 0.2568 - val_binary_accuracy: 0.8960 - val_precision: 0.8641 - val_recall: 0.9427\n",
      "Epoch 343/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.2568 - binary_accuracy: 0.8960 - precision: 0.8641 - recall: 0.9427 - val_loss: 0.2761 - val_binary_accuracy: 0.8760 - val_precision: 0.9099 - val_recall: 0.8379\n",
      "Epoch 344/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.2761 - binary_accuracy: 0.8760 - precision: 0.9099 - recall: 0.8379 - val_loss: 0.3024 - val_binary_accuracy: 0.8610 - val_precision: 0.8522 - val_recall: 0.8775\n",
      "Epoch 345/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.3024 - binary_accuracy: 0.8610 - precision: 0.8522 - recall: 0.8775 - val_loss: 0.2476 - val_binary_accuracy: 0.9140 - val_precision: 0.8875 - val_recall: 0.9506\n",
      "Epoch 346/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.2476 - binary_accuracy: 0.9140 - precision: 0.8875 - recall: 0.9506 - val_loss: 0.2971 - val_binary_accuracy: 0.8700 - val_precision: 0.9178 - val_recall: 0.8162\n",
      "Epoch 347/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2971 - binary_accuracy: 0.8700 - precision: 0.9178 - recall: 0.8162 - val_loss: 0.3423 - val_binary_accuracy: 0.8340 - val_precision: 0.8269 - val_recall: 0.8498\n",
      "Epoch 348/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.3423 - binary_accuracy: 0.8340 - precision: 0.8269 - recall: 0.8498 - val_loss: 0.2537 - val_binary_accuracy: 0.8920 - val_precision: 0.8685 - val_recall: 0.9269\n",
      "Epoch 349/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.2537 - binary_accuracy: 0.8920 - precision: 0.8685 - recall: 0.9269 - val_loss: 0.3255 - val_binary_accuracy: 0.8540 - val_precision: 0.8830 - val_recall: 0.8202\n",
      "Epoch 350/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.3255 - binary_accuracy: 0.8540 - precision: 0.8830 - recall: 0.8202 - val_loss: 0.2331 - val_binary_accuracy: 0.9220 - val_precision: 0.9084 - val_recall: 0.9407\n",
      "Epoch 351/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2331 - binary_accuracy: 0.9220 - precision: 0.9084 - recall: 0.9407 - val_loss: 0.2849 - val_binary_accuracy: 0.8690 - val_precision: 0.8641 - val_recall: 0.8794\n",
      "Epoch 352/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.2849 - binary_accuracy: 0.8690 - precision: 0.8641 - recall: 0.8794 - val_loss: 0.2255 - val_binary_accuracy: 0.9110 - val_precision: 0.9353 - val_recall: 0.8854\n",
      "Epoch 353/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.2255 - binary_accuracy: 0.9110 - precision: 0.9353 - recall: 0.8854 - val_loss: 0.2647 - val_binary_accuracy: 0.8930 - val_precision: 0.8950 - val_recall: 0.8933\n",
      "Epoch 354/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2647 - binary_accuracy: 0.8930 - precision: 0.8950 - recall: 0.8933 - val_loss: 0.2279 - val_binary_accuracy: 0.9200 - val_precision: 0.8859 - val_recall: 0.9664\n",
      "Epoch 355/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2279 - binary_accuracy: 0.9200 - precision: 0.8859 - recall: 0.9664 - val_loss: 0.2408 - val_binary_accuracy: 0.9100 - val_precision: 0.9160 - val_recall: 0.9051\n",
      "Epoch 356/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.2408 - binary_accuracy: 0.9100 - precision: 0.9160 - recall: 0.9051 - val_loss: 0.2103 - val_binary_accuracy: 0.9260 - val_precision: 0.9337 - val_recall: 0.9190\n",
      "Epoch 357/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.2103 - binary_accuracy: 0.9260 - precision: 0.9337 - recall: 0.9190 - val_loss: 0.2314 - val_binary_accuracy: 0.9050 - val_precision: 0.9022 - val_recall: 0.9111\n",
      "Epoch 358/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.2314 - binary_accuracy: 0.9050 - precision: 0.9022 - recall: 0.9111 - val_loss: 0.2099 - val_binary_accuracy: 0.9250 - val_precision: 0.9105 - val_recall: 0.9447\n",
      "Epoch 359/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.2099 - binary_accuracy: 0.9250 - precision: 0.9105 - recall: 0.9447 - val_loss: 0.2062 - val_binary_accuracy: 0.9300 - val_precision: 0.9431 - val_recall: 0.9170\n",
      "Epoch 360/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2062 - binary_accuracy: 0.9300 - precision: 0.9431 - recall: 0.9170 - val_loss: 0.1997 - val_binary_accuracy: 0.9350 - val_precision: 0.9401 - val_recall: 0.9308\n",
      "Epoch 361/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.1997 - binary_accuracy: 0.9350 - precision: 0.9401 - recall: 0.9308 - val_loss: 0.1952 - val_binary_accuracy: 0.9310 - val_precision: 0.9039 - val_recall: 0.9664\n",
      "Epoch 362/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1952 - binary_accuracy: 0.9310 - precision: 0.9039 - recall: 0.9664 - val_loss: 0.1885 - val_binary_accuracy: 0.9360 - val_precision: 0.9234 - val_recall: 0.9526\n",
      "Epoch 363/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1885 - binary_accuracy: 0.9360 - precision: 0.9234 - recall: 0.9526 - val_loss: 0.1870 - val_binary_accuracy: 0.9410 - val_precision: 0.9589 - val_recall: 0.9229\n",
      "Epoch 364/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.1870 - binary_accuracy: 0.9410 - precision: 0.9589 - recall: 0.9229 - val_loss: 0.1799 - val_binary_accuracy: 0.9400 - val_precision: 0.9390 - val_recall: 0.9427\n",
      "Epoch 365/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.1799 - binary_accuracy: 0.9400 - precision: 0.9390 - recall: 0.9427 - val_loss: 0.1774 - val_binary_accuracy: 0.9430 - val_precision: 0.9342 - val_recall: 0.9545\n",
      "Epoch 366/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1774 - binary_accuracy: 0.9430 - precision: 0.9342 - recall: 0.9545 - val_loss: 0.1676 - val_binary_accuracy: 0.9510 - val_precision: 0.9454 - val_recall: 0.9585\n",
      "Epoch 367/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1676 - binary_accuracy: 0.9510 - precision: 0.9454 - recall: 0.9585 - val_loss: 0.1684 - val_binary_accuracy: 0.9470 - val_precision: 0.9557 - val_recall: 0.9387\n",
      "Epoch 368/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.1684 - binary_accuracy: 0.9470 - precision: 0.9557 - recall: 0.9387 - val_loss: 0.1622 - val_binary_accuracy: 0.9550 - val_precision: 0.9493 - val_recall: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1622 - binary_accuracy: 0.9550 - precision: 0.9493 - recall: 0.9625 - val_loss: 0.1550 - val_binary_accuracy: 0.9570 - val_precision: 0.9513 - val_recall: 0.9644\n",
      "Epoch 370/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.1550 - binary_accuracy: 0.9570 - precision: 0.9513 - recall: 0.9644 - val_loss: 0.1548 - val_binary_accuracy: 0.9590 - val_precision: 0.9568 - val_recall: 0.9625\n",
      "Epoch 371/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.1548 - binary_accuracy: 0.9590 - precision: 0.9568 - recall: 0.9625 - val_loss: 0.1477 - val_binary_accuracy: 0.9620 - val_precision: 0.9625 - val_recall: 0.9625\n",
      "Epoch 372/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1477 - binary_accuracy: 0.9620 - precision: 0.9625 - recall: 0.9625 - val_loss: 0.1438 - val_binary_accuracy: 0.9590 - val_precision: 0.9586 - val_recall: 0.9605\n",
      "Epoch 373/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.1438 - binary_accuracy: 0.9590 - precision: 0.9586 - recall: 0.9605 - val_loss: 0.1417 - val_binary_accuracy: 0.9610 - val_precision: 0.9587 - val_recall: 0.9644\n",
      "Epoch 374/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1417 - binary_accuracy: 0.9610 - precision: 0.9587 - recall: 0.9644 - val_loss: 0.1368 - val_binary_accuracy: 0.9650 - val_precision: 0.9663 - val_recall: 0.9644\n",
      "Epoch 375/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1368 - binary_accuracy: 0.9650 - precision: 0.9663 - recall: 0.9644 - val_loss: 0.1335 - val_binary_accuracy: 0.9690 - val_precision: 0.9684 - val_recall: 0.9704\n",
      "Epoch 376/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1335 - binary_accuracy: 0.9690 - precision: 0.9684 - recall: 0.9704 - val_loss: 0.1274 - val_binary_accuracy: 0.9690 - val_precision: 0.9684 - val_recall: 0.9704\n",
      "Epoch 377/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.1274 - binary_accuracy: 0.9690 - precision: 0.9684 - recall: 0.9704 - val_loss: 0.1274 - val_binary_accuracy: 0.9730 - val_precision: 0.9724 - val_recall: 0.9743\n",
      "Epoch 378/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.1274 - binary_accuracy: 0.9730 - precision: 0.9724 - recall: 0.9743 - val_loss: 0.1202 - val_binary_accuracy: 0.9770 - val_precision: 0.9801 - val_recall: 0.9743\n",
      "Epoch 379/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1202 - binary_accuracy: 0.9770 - precision: 0.9801 - recall: 0.9743 - val_loss: 0.1191 - val_binary_accuracy: 0.9770 - val_precision: 0.9763 - val_recall: 0.9783\n",
      "Epoch 380/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.1191 - binary_accuracy: 0.9770 - precision: 0.9763 - recall: 0.9783 - val_loss: 0.1139 - val_binary_accuracy: 0.9790 - val_precision: 0.9783 - val_recall: 0.9802\n",
      "Epoch 381/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1139 - binary_accuracy: 0.9790 - precision: 0.9783 - recall: 0.9802 - val_loss: 0.1116 - val_binary_accuracy: 0.9790 - val_precision: 0.9764 - val_recall: 0.9822\n",
      "Epoch 382/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.1116 - binary_accuracy: 0.9790 - precision: 0.9764 - recall: 0.9822 - val_loss: 0.1077 - val_binary_accuracy: 0.9810 - val_precision: 0.9803 - val_recall: 0.9822\n",
      "Epoch 383/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.1077 - binary_accuracy: 0.9810 - precision: 0.9803 - recall: 0.9822 - val_loss: 0.1041 - val_binary_accuracy: 0.9820 - val_precision: 0.9822 - val_recall: 0.9822\n",
      "Epoch 384/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1041 - binary_accuracy: 0.9820 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.1016 - val_binary_accuracy: 0.9830 - val_precision: 0.9842 - val_recall: 0.9822\n",
      "Epoch 385/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1016 - binary_accuracy: 0.9830 - precision: 0.9842 - recall: 0.9822 - val_loss: 0.0970 - val_binary_accuracy: 0.9850 - val_precision: 0.9861 - val_recall: 0.9842\n",
      "Epoch 386/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0970 - binary_accuracy: 0.9850 - precision: 0.9861 - recall: 0.9842 - val_loss: 0.0953 - val_binary_accuracy: 0.9850 - val_precision: 0.9861 - val_recall: 0.9842\n",
      "Epoch 387/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0953 - binary_accuracy: 0.9850 - precision: 0.9861 - recall: 0.9842 - val_loss: 0.0912 - val_binary_accuracy: 0.9850 - val_precision: 0.9842 - val_recall: 0.9862\n",
      "Epoch 388/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0912 - binary_accuracy: 0.9850 - precision: 0.9842 - recall: 0.9862 - val_loss: 0.0888 - val_binary_accuracy: 0.9830 - val_precision: 0.9842 - val_recall: 0.9822\n",
      "Epoch 389/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0888 - binary_accuracy: 0.9830 - precision: 0.9842 - recall: 0.9822 - val_loss: 0.0854 - val_binary_accuracy: 0.9870 - val_precision: 0.9843 - val_recall: 0.9901\n",
      "Epoch 390/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0854 - binary_accuracy: 0.9870 - precision: 0.9843 - recall: 0.9901 - val_loss: 0.0827 - val_binary_accuracy: 0.9900 - val_precision: 0.9901 - val_recall: 0.9901\n",
      "Epoch 391/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0827 - binary_accuracy: 0.9900 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0798 - val_binary_accuracy: 0.9880 - val_precision: 0.9862 - val_recall: 0.9901\n",
      "Epoch 392/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0798 - binary_accuracy: 0.9880 - precision: 0.9862 - recall: 0.9901 - val_loss: 0.0767 - val_binary_accuracy: 0.9890 - val_precision: 0.9901 - val_recall: 0.9881\n",
      "Epoch 393/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0767 - binary_accuracy: 0.9890 - precision: 0.9901 - recall: 0.9881 - val_loss: 0.0745 - val_binary_accuracy: 0.9920 - val_precision: 0.9882 - val_recall: 0.9960\n",
      "Epoch 394/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0745 - binary_accuracy: 0.9920 - precision: 0.9882 - recall: 0.9960 - val_loss: 0.0714 - val_binary_accuracy: 0.9950 - val_precision: 0.9960 - val_recall: 0.9941\n",
      "Epoch 395/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0714 - binary_accuracy: 0.9950 - precision: 0.9960 - recall: 0.9941 - val_loss: 0.0695 - val_binary_accuracy: 0.9920 - val_precision: 0.9882 - val_recall: 0.9960\n",
      "Epoch 396/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0695 - binary_accuracy: 0.9920 - precision: 0.9882 - recall: 0.9960 - val_loss: 0.0675 - val_binary_accuracy: 0.9940 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 397/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0675 - binary_accuracy: 0.9940 - precision: 0.9960 - recall: 0.9921 - val_loss: 0.0679 - val_binary_accuracy: 0.9890 - val_precision: 0.9825 - val_recall: 0.9960\n",
      "Epoch 398/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0679 - binary_accuracy: 0.9890 - precision: 0.9825 - recall: 0.9960 - val_loss: 0.0732 - val_binary_accuracy: 0.9880 - val_precision: 1.0000 - val_recall: 0.9763\n",
      "Epoch 399/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0732 - binary_accuracy: 0.9880 - precision: 1.0000 - recall: 0.9763 - val_loss: 0.0892 - val_binary_accuracy: 0.9740 - val_precision: 0.9511 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0892 - binary_accuracy: 0.9740 - precision: 0.9511 - recall: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9510 - val_precision: 1.0000 - val_recall: 0.9032\n",
      "Epoch 401/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.1213 - binary_accuracy: 0.9510 - precision: 1.0000 - recall: 0.9032 - val_loss: 0.1359 - val_binary_accuracy: 0.9490 - val_precision: 0.9129 - val_recall: 0.9941\n",
      "Epoch 402/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.1359 - binary_accuracy: 0.9490 - precision: 0.9129 - recall: 0.9941 - val_loss: 0.1934 - val_binary_accuracy: 0.9230 - val_precision: 0.9351 - val_recall: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.1934 - binary_accuracy: 0.9230 - precision: 0.9351 - recall: 0.9111 - val_loss: 0.3141 - val_binary_accuracy: 0.8760 - val_precision: 0.9505 - val_recall: 0.7964\n",
      "Epoch 404/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.3141 - binary_accuracy: 0.8760 - precision: 0.9505 - recall: 0.7964 - val_loss: 0.3272 - val_binary_accuracy: 0.8710 - val_precision: 0.7997 - val_recall: 0.9941\n",
      "Epoch 405/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3272 - binary_accuracy: 0.8710 - precision: 0.7997 - recall: 0.9941 - val_loss: 0.2221 - val_binary_accuracy: 0.9080 - val_precision: 0.8935 - val_recall: 0.9289\n",
      "Epoch 406/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.2221 - binary_accuracy: 0.9080 - precision: 0.8935 - recall: 0.9289 - val_loss: 0.2248 - val_binary_accuracy: 0.9190 - val_precision: 0.9691 - val_recall: 0.8676\n",
      "Epoch 407/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.2248 - binary_accuracy: 0.9190 - precision: 0.9691 - recall: 0.8676 - val_loss: 0.2568 - val_binary_accuracy: 0.8980 - val_precision: 0.9509 - val_recall: 0.8419\n",
      "Epoch 408/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.2568 - binary_accuracy: 0.8980 - precision: 0.9509 - recall: 0.8419 - val_loss: 0.1391 - val_binary_accuracy: 0.9510 - val_precision: 0.9369 - val_recall: 0.9684\n",
      "Epoch 409/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1391 - binary_accuracy: 0.9510 - precision: 0.9369 - recall: 0.9684 - val_loss: 0.2502 - val_binary_accuracy: 0.8920 - val_precision: 0.8579 - val_recall: 0.9427\n",
      "Epoch 410/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.2502 - binary_accuracy: 0.8920 - precision: 0.8579 - recall: 0.9427 - val_loss: 0.1124 - val_binary_accuracy: 0.9660 - val_precision: 0.9487 - val_recall: 0.9862\n",
      "Epoch 411/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.1124 - binary_accuracy: 0.9660 - precision: 0.9487 - recall: 0.9862 - val_loss: 0.1784 - val_binary_accuracy: 0.9280 - val_precision: 0.9306 - val_recall: 0.9269\n",
      "Epoch 412/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.1784 - binary_accuracy: 0.9280 - precision: 0.9306 - recall: 0.9269 - val_loss: 0.1323 - val_binary_accuracy: 0.9590 - val_precision: 0.9895 - val_recall: 0.9289\n",
      "Epoch 413/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.1323 - binary_accuracy: 0.9590 - precision: 0.9895 - recall: 0.9289 - val_loss: 0.1205 - val_binary_accuracy: 0.9670 - val_precision: 0.9896 - val_recall: 0.9447\n",
      "Epoch 414/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1205 - binary_accuracy: 0.9670 - precision: 0.9896 - recall: 0.9447 - val_loss: 0.1398 - val_binary_accuracy: 0.9610 - val_precision: 0.9624 - val_recall: 0.9605\n",
      "Epoch 415/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1398 - binary_accuracy: 0.9610 - precision: 0.9624 - recall: 0.9605 - val_loss: 0.0951 - val_binary_accuracy: 0.9790 - val_precision: 0.9709 - val_recall: 0.9881\n",
      "Epoch 416/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0951 - binary_accuracy: 0.9790 - precision: 0.9709 - recall: 0.9881 - val_loss: 0.1213 - val_binary_accuracy: 0.9720 - val_precision: 0.9668 - val_recall: 0.9783\n",
      "Epoch 417/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1213 - binary_accuracy: 0.9720 - precision: 0.9668 - recall: 0.9783 - val_loss: 0.0926 - val_binary_accuracy: 0.9850 - val_precision: 0.9881 - val_recall: 0.9822\n",
      "Epoch 418/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0926 - binary_accuracy: 0.9850 - precision: 0.9881 - recall: 0.9822 - val_loss: 0.0848 - val_binary_accuracy: 0.9850 - val_precision: 0.9920 - val_recall: 0.9783\n",
      "Epoch 419/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0848 - binary_accuracy: 0.9850 - precision: 0.9920 - recall: 0.9783 - val_loss: 0.0853 - val_binary_accuracy: 0.9850 - val_precision: 0.9842 - val_recall: 0.9862\n",
      "Epoch 420/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0853 - binary_accuracy: 0.9850 - precision: 0.9842 - recall: 0.9862 - val_loss: 0.0805 - val_binary_accuracy: 0.9860 - val_precision: 0.9824 - val_recall: 0.9901\n",
      "Epoch 421/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0805 - binary_accuracy: 0.9860 - precision: 0.9824 - recall: 0.9901 - val_loss: 0.0739 - val_binary_accuracy: 0.9890 - val_precision: 0.9843 - val_recall: 0.9941\n",
      "Epoch 422/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0739 - binary_accuracy: 0.9890 - precision: 0.9843 - recall: 0.9941 - val_loss: 0.0716 - val_binary_accuracy: 0.9890 - val_precision: 0.9882 - val_recall: 0.9901\n",
      "Epoch 423/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0716 - binary_accuracy: 0.9890 - precision: 0.9882 - recall: 0.9901 - val_loss: 0.0687 - val_binary_accuracy: 0.9940 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 424/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0687 - binary_accuracy: 0.9940 - precision: 0.9960 - recall: 0.9921 - val_loss: 0.0627 - val_binary_accuracy: 0.9920 - val_precision: 0.9940 - val_recall: 0.9901\n",
      "Epoch 425/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0627 - binary_accuracy: 0.9920 - precision: 0.9940 - recall: 0.9901 - val_loss: 0.0601 - val_binary_accuracy: 0.9940 - val_precision: 0.9921 - val_recall: 0.9960\n",
      "Epoch 426/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0601 - binary_accuracy: 0.9940 - precision: 0.9921 - recall: 0.9960 - val_loss: 0.0626 - val_binary_accuracy: 0.9920 - val_precision: 0.9902 - val_recall: 0.9941\n",
      "Epoch 427/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0626 - binary_accuracy: 0.9920 - precision: 0.9902 - recall: 0.9941 - val_loss: 0.0610 - val_binary_accuracy: 0.9910 - val_precision: 0.9901 - val_recall: 0.9921\n",
      "Epoch 428/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0610 - binary_accuracy: 0.9910 - precision: 0.9901 - recall: 0.9921 - val_loss: 0.0518 - val_binary_accuracy: 0.9970 - val_precision: 1.0000 - val_recall: 0.9941\n",
      "Epoch 429/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0518 - binary_accuracy: 0.9970 - precision: 1.0000 - recall: 0.9941 - val_loss: 0.0494 - val_binary_accuracy: 0.9970 - val_precision: 1.0000 - val_recall: 0.9941\n",
      "Epoch 430/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0494 - binary_accuracy: 0.9970 - precision: 1.0000 - recall: 0.9941 - val_loss: 0.0519 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 431/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0519 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0488 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 432/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0488 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0471 - val_binary_accuracy: 0.9970 - val_precision: 0.9961 - val_recall: 0.9980\n",
      "Epoch 433/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0471 - binary_accuracy: 0.9970 - precision: 0.9961 - recall: 0.9980 - val_loss: 0.0440 - val_binary_accuracy: 0.9970 - val_precision: 0.9961 - val_recall: 0.9980\n",
      "Epoch 434/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0440 - binary_accuracy: 0.9970 - precision: 0.9961 - recall: 0.9980 - val_loss: 0.0419 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 435/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0419 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0428 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 436/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0428 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0406 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0406 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0383 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 438/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0383 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0367 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 439/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0367 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0358 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 440/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0358 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0354 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0354 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0341 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0341 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0330 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0330 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0326 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 444/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0326 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0315 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0315 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0301 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0301 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0295 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0295 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0288 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0288 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0277 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0277 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0273 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 450/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0273 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0269 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 451/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0269 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0260 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 452/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0260 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0252 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0252 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0247 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0241 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0241 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0235 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0235 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0231 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 457/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0231 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0227 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0227 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0221 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0221 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0216 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0216 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0211 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0211 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0208 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0208 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0204 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0204 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0199 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0199 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0196 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0196 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0192 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0192 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0188 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0188 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0184 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0181 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0181 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0178 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0178 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0174 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0174 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0171 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0171 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0169 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0169 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0166 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0166 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0163 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0163 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0160 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0160 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0157 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0157 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0155 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0155 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0152 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0152 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0150 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0150 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0147 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0147 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0145 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0145 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0143 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0143 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0141 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0139 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0139 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0136 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0136 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0134 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0134 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0132 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0132 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0130 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0130 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0129 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 490/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0129 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0127 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0127 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0125 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0125 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0123 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0123 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0122 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0122 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0120 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0120 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0118 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0118 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0117 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0117 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0115 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0115 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0114 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0114 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0112 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0112 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0111 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0111 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0109 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0109 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0108 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0108 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0106 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0106 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0105 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0105 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0104 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0104 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0102 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0101 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0101 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0100 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0100 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0099 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0098 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0098 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0096 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0096 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0095 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0094 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0093 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0092 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0092 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0089 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0088 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0088 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0087 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0086 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 523/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0085 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0084 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0083 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0082 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0081 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0081 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0080 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0078 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0076 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0075 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0074 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0074 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0073 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0072 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0070 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0068 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0066 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0066 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0065 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 556/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0060 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 589/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 622/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 655/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 675/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 688/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 721/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 754/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 787/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 820/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 853/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 886/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model for classification\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_5)\n",
    "\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "print(model.summary())\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only pricing data from all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  log_adj_daily_returns_JPM  \\\n",
       "0 2019-10-22                   0.003166                   0.009986   \n",
       "1 2019-10-21                   0.009758                   0.024498   \n",
       "2 2019-10-18                   0.007230                   0.001743   \n",
       "3 2019-10-17                   0.000403                   0.005583   \n",
       "4 2019-10-16                  -0.010431                  -0.002337   \n",
       "5 2019-10-15                   0.016905                   0.029696   \n",
       "6 2019-10-14                   0.001219                   0.002666   \n",
       "7 2019-10-11                   0.011445                   0.016758   \n",
       "\n",
       "   log_adj_daily_returns_BAC  log_adj_daily_returns_C  \n",
       "0                   0.005786                 0.003475  \n",
       "1                   0.021836                 0.029250  \n",
       "2                   0.002970                 0.002009  \n",
       "3                   0.002979                 0.001438  \n",
       "4                   0.014691                -0.024447  \n",
       "5                   0.020045                 0.013856  \n",
       "6                   0.007924                 0.001995  \n",
       "7                   0.016039                 0.021339  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size_by_ticker = [200, 100, 50, 300]\n",
    "batch_size = 650\n",
    "assert batch_size == sum(dataset_size_by_ticker)\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-4)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_C(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+0)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_BAC(t-5)  \\\n",
       "1                        0.002666                        0.007924   \n",
       "2                        0.016758                        0.016039   \n",
       "3                        0.013931                        0.019880   \n",
       "4                        0.007218                        0.009366   \n",
       "5                       -0.022548                       -0.024313   \n",
       "\n",
       "   log_adj_daily_returns_C(t-5) timestamp(t-4)  \\\n",
       "1                      0.001995     2019-10-15   \n",
       "2                      0.021339     2019-10-14   \n",
       "3                      0.017494     2019-10-11   \n",
       "4                      0.015393     2019-10-10   \n",
       "5                     -0.026014     2019-10-09   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-4)  log_adj_daily_returns_JPM(t-4)  \\\n",
       "1                        0.016905                        0.029696   \n",
       "2                        0.001219                        0.002666   \n",
       "3                        0.011445                        0.016758   \n",
       "4                        0.010331                        0.013931   \n",
       "5                        0.006877                        0.007218   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-4)  log_adj_daily_returns_C(t-4)  ...  \\\n",
       "1                        0.020045                      0.013856  ...   \n",
       "2                        0.007924                      0.001995  ...   \n",
       "3                        0.016039                      0.021339  ...   \n",
       "4                        0.019880                      0.017494  ...   \n",
       "5                        0.009366                      0.015393  ...   \n",
       "\n",
       "  timestamp(t+0)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1     2019-10-21                        0.009758   \n",
       "2     2019-10-18                        0.007230   \n",
       "3     2019-10-17                        0.000403   \n",
       "4     2019-10-16                       -0.010431   \n",
       "5     2019-10-15                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+0)  log_adj_daily_returns_BAC(t+0)  \\\n",
       "1                        0.024498                        0.021836   \n",
       "2                        0.001743                        0.002970   \n",
       "3                        0.005583                        0.002979   \n",
       "4                       -0.002337                        0.014691   \n",
       "5                        0.029696                        0.020045   \n",
       "\n",
       "   log_adj_daily_returns_C(t+0) timestamp(t+1)  \\\n",
       "1                      0.029250     2019-10-22   \n",
       "2                      0.002009     2019-10-21   \n",
       "3                      0.001438     2019-10-18   \n",
       "4                     -0.024447     2019-10-17   \n",
       "5                      0.013856     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  log_adj_daily_returns_JPM(t+1)  \\\n",
       "1                        0.003166                        0.009986   \n",
       "2                        0.009758                        0.024498   \n",
       "3                        0.007230                        0.001743   \n",
       "4                        0.000403                        0.005583   \n",
       "5                       -0.010431                       -0.002337   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  log_adj_daily_returns_C(t+1)  \n",
       "1                        0.005786                      0.003475  \n",
       "2                        0.021836                      0.029250  \n",
       "3                        0.002970                      0.002009  \n",
       "4                        0.002979                      0.001438  \n",
       "5                        0.014691                     -0.024447  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)']]\n"
     ]
    }
   ],
   "source": [
    "column_names_by_ticker = [[name for name in df.columns if 'log_adj_daily_returns_' + t in name] for t in tickers]\n",
    "print(column_names_by_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list(map(lambda cols: df[cols], column_names_by_ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
      "1                        0.001219                        0.016905   \n",
      "2                        0.011445                        0.001219   \n",
      "3                        0.010331                        0.011445   \n",
      "4                        0.006877                        0.010331   \n",
      "5                       -0.020491                        0.006877   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
      "1                       -0.010431                        0.000403   \n",
      "2                        0.016905                       -0.010431   \n",
      "3                        0.001219                        0.016905   \n",
      "4                        0.011445                        0.001219   \n",
      "5                        0.010331                        0.011445   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
      "1                        0.007230                        0.009758   \n",
      "2                        0.000403                        0.007230   \n",
      "3                       -0.010431                        0.000403   \n",
      "4                        0.016905                       -0.010431   \n",
      "5                        0.001219                        0.016905   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t+1)  \n",
      "1                        0.003166  \n",
      "2                        0.009758  \n",
      "3                        0.007230  \n",
      "4                        0.000403  \n",
      "5                       -0.010431  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_JPM(t-4)  \\\n",
      "1                        0.002666                        0.029696   \n",
      "2                        0.016758                        0.002666   \n",
      "3                        0.013931                        0.016758   \n",
      "4                        0.007218                        0.013931   \n",
      "5                       -0.022548                        0.007218   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-3)  log_adj_daily_returns_JPM(t-2)  \\\n",
      "1                       -0.002337                        0.005583   \n",
      "2                        0.029696                       -0.002337   \n",
      "3                        0.002666                        0.029696   \n",
      "4                        0.016758                        0.002666   \n",
      "5                        0.013931                        0.016758   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-1)  log_adj_daily_returns_JPM(t+0)  \\\n",
      "1                        0.001743                        0.024498   \n",
      "2                        0.005583                        0.001743   \n",
      "3                       -0.002337                        0.005583   \n",
      "4                        0.029696                       -0.002337   \n",
      "5                        0.002666                        0.029696   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t+1)  \n",
      "1                        0.009986  \n",
      "2                        0.024498  \n",
      "3                        0.001743  \n",
      "4                        0.005583  \n",
      "5                       -0.002337  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_BAC(t-5)  log_adj_daily_returns_BAC(t-4)  \\\n",
      "1                        0.007924                        0.020045   \n",
      "2                        0.016039                        0.007924   \n",
      "3                        0.019880                        0.016039   \n",
      "4                        0.009366                        0.019880   \n",
      "5                       -0.024313                        0.009366   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-3)  log_adj_daily_returns_BAC(t-2)  \\\n",
      "1                        0.014691                        0.002979   \n",
      "2                        0.020045                        0.014691   \n",
      "3                        0.007924                        0.020045   \n",
      "4                        0.016039                        0.007924   \n",
      "5                        0.019880                        0.016039   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-1)  log_adj_daily_returns_BAC(t+0)  \\\n",
      "1                        0.002970                        0.021836   \n",
      "2                        0.002979                        0.002970   \n",
      "3                        0.014691                        0.002979   \n",
      "4                        0.020045                        0.014691   \n",
      "5                        0.007924                        0.020045   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t+1)  \n",
      "1                        0.005786  \n",
      "2                        0.021836  \n",
      "3                        0.002970  \n",
      "4                        0.002979  \n",
      "5                        0.014691  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_C(t-5)  log_adj_daily_returns_C(t-4)  \\\n",
      "1                      0.001995                      0.013856   \n",
      "2                      0.021339                      0.001995   \n",
      "3                      0.017494                      0.021339   \n",
      "4                      0.015393                      0.017494   \n",
      "5                     -0.026014                      0.015393   \n",
      "\n",
      "   log_adj_daily_returns_C(t-3)  log_adj_daily_returns_C(t-2)  \\\n",
      "1                     -0.024447                      0.001438   \n",
      "2                      0.013856                     -0.024447   \n",
      "3                      0.001995                      0.013856   \n",
      "4                      0.021339                      0.001995   \n",
      "5                      0.017494                      0.021339   \n",
      "\n",
      "   log_adj_daily_returns_C(t-1)  log_adj_daily_returns_C(t+0)  \\\n",
      "1                      0.002009                      0.029250   \n",
      "2                      0.001438                      0.002009   \n",
      "3                     -0.024447                      0.001438   \n",
      "4                      0.013856                     -0.024447   \n",
      "5                      0.001995                      0.013856   \n",
      "\n",
      "   log_adj_daily_returns_C(t+1)  \n",
      "1                      0.003475  \n",
      "2                      0.029250  \n",
      "3                      0.002009  \n",
      "4                      0.001438  \n",
      "5                     -0.024447  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking dfs\n",
    "for el in dfs:\n",
    "    print(el.head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_by_ticker = list(map(lambda d: d.values, dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 4\n",
      "Shape of each dataset: [(5024, 7), (5024, 7), (5024, 7), (5024, 7)]\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets: {}'.format(len(datasets_by_ticker)))\n",
    "print('Shape of each dataset: {}'.format(list(map(lambda d: d.shape, datasets_by_ticker))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each ticker: [200, 100, 50, 300]\n",
      "Shape of each sampled dataset: [(200, 7), (100, 7), (50, 7), (300, 7)]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and Sampling Datasets\n",
    "shuffled_indices_per_ticker = [np.random.choice(len(datasets_by_ticker[i]),\n",
    "                                                size=dataset_size_by_ticker[i],\n",
    "                                                replace=False)\n",
    "                               for i in range(len(dataset_size_by_ticker))]\n",
    "print('Number of samples for each ticker: {}'.format(list(map(len, shuffled_indices_per_ticker))))\n",
    "sampled_datasets_by_ticker = [datasets_by_ticker[i][shuffled_indices_per_ticker[i]] for i in range(len(datasets_by_ticker))]\n",
    "print('Shape of each sampled dataset: {}'.format(list(map(lambda d: d.shape, sampled_datasets_by_ticker))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (650, 7)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating datasets\n",
    "dataset = np.concatenate(sampled_datasets_by_ticker, axis=0)\n",
    "print('Shape of dataset: {}'.format(dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161 521 569 584 609 256 218  17 513 207 584 503 547 157 253  21 565 589\n",
      " 107 533 490  32 189 399  22 104 197  23 491 255   5  91 435 105 323 198\n",
      " 607 406 383 591 329 255 514 497  30 624 575  41 573  66  36 279 630 261\n",
      " 373 618 574 129 504 531 524  68 363 100 145  95 166 156 525 585 459 162\n",
      " 346 194 173 157 353  55 357 478  96 521 395 131 222  94 514 437 433 104\n",
      " 306  90 602 560 175 347 151 644 152 455  97 634  92 194 231 495 529 557\n",
      " 166 189 286 311  58 290 238 549 430 599 509 171 216  73 601 541 600 106\n",
      " 542 310 466 232 479 279 300 305 635 263 383 389 555  70 250 350 424 121\n",
      " 391 111 495  98 147  18 173 454  64 148 553 584 626 423 555 431 141 362\n",
      "  42 239  79 282 123 592  17 632 321 334  87 562 327 337 569 329 116 158\n",
      " 517 258 381 624 597 151 450 487 546 113 406 542  13 261 138 350 301 379\n",
      " 521  60 410 368 595 123 212 577 485 367 378 505 500 548 112 544 614 446\n",
      " 520 112 375 297 249 596 483 186 616 194 243 534 583 216 240 496 363 572\n",
      " 527 624 278 151 423 649 354 281 635 511 131 583 452 193 234 534 111 569\n",
      " 578 120 508  92  89 451 458 282 605 303  35 306 543 116 241 278 369 321\n",
      " 244 146 540 529 424  62 463 424 597 281 406 339 530 445 625  53 303 246\n",
      "  96 377 286  33 505 431 317  81 516 236 109 175 571 451   0 588  95 111\n",
      " 248 405 180 404 635 207 295 147 396 351 642 362 272 322 110 649 515 642\n",
      " 420 406 345 231 379 437  38 318 171  56 396 591 279 476 354 626  46 143\n",
      " 567 507 505 641 324 129 608 516  37 534 485 534 555 608 210 507  39 168\n",
      " 443 208 420 282 368 274 524  58 424 366 183 142 137 630 293 102 452 243\n",
      " 300  13 220 407  29 482 331 358 288 553 486 109 628 618 486 217 281 244\n",
      " 270 347 300 354 149 470 174 613  54 289 638 223 230 593 345 508 187 250\n",
      " 401 268 558  34 242 443 544 486  95 352 241 342 640 168 144 519 496 291\n",
      "  82 272 510 645 617 620 495  84 580 566 261 273 364 542 498 102 239 611\n",
      " 612 320 456 373 170 103 610 545 576 370 557  32 641 398 582 256 170  71\n",
      " 245 300 402 485 546 347 497 149  28 544 554 219 234 590 155  65 460 226\n",
      " 244   0 143 451 200 471 583 372 280 360 568 424 377 457 499 126  59 122\n",
      " 450 395 391 174  99 599 594 128 345 649 447 507 418  86 290 492 265 499\n",
      " 370 273 511 116 362 630 289 642 124 311  63 242 449 603 220 457 102 438\n",
      " 478 399 426 582 101 495  64 211 347  76  59  43  26 176 228 494 435 107\n",
      " 164 464 543 343 368 420 214 335 209 592 290 382 310 369 499 528 120 611\n",
      "   9 477 218 518 368 634 148  98 438 415 165 303 584 216 432 629 372 447\n",
      " 219  60 543 151 570 280 198  47 244 209  60 619   7  80  61   8 101 462\n",
      " 265 451 441 421 540  99 167 400 587 599 197 624 166 618 317   3  18 500\n",
      " 344 158 464  65 140 399 631 190 239  43 123  80  58 187 508 462 224  18\n",
      "  80  22]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling merged dataset\n",
    "shuffle_indices = np.random.randint(len(dataset), size=len(dataset))\n",
    "assert len(shuffle_indices) == len(dataset)\n",
    "print(shuffle_indices)\n",
    "shuffled_dataset = dataset[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (650, 6)\n",
      "Shape of targets: (650,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting Dataset into Features and Labels\n",
    "X, y = shuffled_dataset[:, :-1], shuffled_dataset[:, -1]\n",
    "print('Shape of features: {}'.format(X.shape))\n",
    "print('Shape of targets: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 650 samples, validate on 650 samples\n",
      "Epoch 1/900\n",
      "650/650 [==============================] - 6s 9ms/sample - loss: 7.4908e-04 - val_loss: 0.0010\n",
      "Epoch 2/900\n",
      "650/650 [==============================] - 0s 75us/sample - loss: 0.0010 - val_loss: 7.5246e-04\n",
      "Epoch 3/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5246e-04 - val_loss: 8.4625e-04\n",
      "Epoch 4/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 8.4625e-04 - val_loss: 9.0363e-04\n",
      "Epoch 5/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 9.0363e-04 - val_loss: 8.3249e-04\n",
      "Epoch 6/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 8.3249e-04 - val_loss: 7.6318e-04\n",
      "Epoch 7/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.6318e-04 - val_loss: 7.5113e-04\n",
      "Epoch 8/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5113e-04 - val_loss: 7.7838e-04\n",
      "Epoch 9/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.7838e-04 - val_loss: 8.0174e-04\n",
      "Epoch 10/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 8.0174e-04 - val_loss: 7.9987e-04\n",
      "Epoch 11/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.9987e-04 - val_loss: 7.8066e-04\n",
      "Epoch 12/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.8066e-04 - val_loss: 7.6049e-04\n",
      "Epoch 13/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.6049e-04 - val_loss: 7.4984e-04\n",
      "Epoch 14/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4984e-04 - val_loss: 7.5042e-04\n",
      "Epoch 15/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.5042e-04 - val_loss: 7.5765e-04\n",
      "Epoch 16/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5765e-04 - val_loss: 7.6486e-04\n",
      "Epoch 17/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.6486e-04 - val_loss: 7.6728e-04\n",
      "Epoch 18/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.6728e-04 - val_loss: 7.6414e-04\n",
      "Epoch 19/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.6414e-04 - val_loss: 7.5789e-04\n",
      "Epoch 20/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5789e-04 - val_loss: 7.5201e-04\n",
      "Epoch 21/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5201e-04 - val_loss: 7.4908e-04\n",
      "Epoch 22/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4908e-04 - val_loss: 7.4975e-04\n",
      "Epoch 23/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4975e-04 - val_loss: 7.5272e-04\n",
      "Epoch 24/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.5272e-04 - val_loss: 7.5566e-04\n",
      "Epoch 25/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.5566e-04 - val_loss: 7.5667e-04\n",
      "Epoch 26/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5667e-04 - val_loss: 7.5532e-04\n",
      "Epoch 27/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.5532e-04 - val_loss: 7.5265e-04\n",
      "Epoch 28/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.5265e-04 - val_loss: 7.5018e-04\n",
      "Epoch 29/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.5018e-04 - val_loss: 7.4898e-04\n",
      "Epoch 30/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4898e-04 - val_loss: 7.4923e-04\n",
      "Epoch 31/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4923e-04 - val_loss: 7.5037e-04\n",
      "Epoch 32/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5037e-04 - val_loss: 7.5155e-04\n",
      "Epoch 33/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5155e-04 - val_loss: 7.5209e-04\n",
      "Epoch 34/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5209e-04 - val_loss: 7.5178e-04\n",
      "Epoch 35/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.5178e-04 - val_loss: 7.5084e-04\n",
      "Epoch 36/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5084e-04 - val_loss: 7.4977e-04\n",
      "Epoch 37/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4977e-04 - val_loss: 7.4905e-04\n",
      "Epoch 38/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4905e-04 - val_loss: 7.4891e-04\n",
      "Epoch 39/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4891e-04 - val_loss: 7.4925e-04\n",
      "Epoch 40/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4925e-04 - val_loss: 7.4979e-04\n",
      "Epoch 41/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4979e-04 - val_loss: 7.5016e-04\n",
      "Epoch 42/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5016e-04 - val_loss: 7.5017e-04\n",
      "Epoch 43/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.5017e-04 - val_loss: 7.4984e-04\n",
      "Epoch 44/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4984e-04 - val_loss: 7.4937e-04\n",
      "Epoch 45/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.4937e-04 - val_loss: 7.4899e-04\n",
      "Epoch 46/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.4899e-04 - val_loss: 7.4884e-04\n",
      "Epoch 47/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4884e-04 - val_loss: 7.4894e-04\n",
      "Epoch 48/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.4894e-04 - val_loss: 7.4916e-04\n",
      "Epoch 49/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4916e-04 - val_loss: 7.4935e-04\n",
      "Epoch 50/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.4935e-04 - val_loss: 7.4939e-04\n",
      "Epoch 51/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4939e-04 - val_loss: 7.4927e-04\n",
      "Epoch 52/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4927e-04 - val_loss: 7.4907e-04\n",
      "Epoch 53/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4907e-04 - val_loss: 7.4888e-04\n",
      "Epoch 54/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.4888e-04 - val_loss: 7.4879e-04\n",
      "Epoch 55/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4879e-04 - val_loss: 7.4882e-04\n",
      "Epoch 56/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.4882e-04 - val_loss: 7.4892e-04\n",
      "Epoch 57/900\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 7.4892e-04 - val_loss: 7.4900e-04\n",
      "Epoch 58/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4900e-04 - val_loss: 7.4902e-04\n",
      "Epoch 59/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4902e-04 - val_loss: 7.4896e-04\n",
      "Epoch 60/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4896e-04 - val_loss: 7.4886e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4886e-04 - val_loss: 7.4877e-04\n",
      "Epoch 62/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4877e-04 - val_loss: 7.4873e-04\n",
      "Epoch 63/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4873e-04 - val_loss: 7.4874e-04\n",
      "Epoch 64/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4874e-04 - val_loss: 7.4878e-04\n",
      "Epoch 65/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4878e-04 - val_loss: 7.4881e-04\n",
      "Epoch 66/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4881e-04 - val_loss: 7.4880e-04\n",
      "Epoch 67/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4880e-04 - val_loss: 7.4876e-04\n",
      "Epoch 68/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4876e-04 - val_loss: 7.4871e-04\n",
      "Epoch 69/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4871e-04 - val_loss: 7.4867e-04\n",
      "Epoch 70/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4865e-04\n",
      "Epoch 71/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4865e-04 - val_loss: 7.4866e-04\n",
      "Epoch 72/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4866e-04 - val_loss: 7.4867e-04\n",
      "Epoch 73/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4867e-04\n",
      "Epoch 74/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4865e-04\n",
      "Epoch 75/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4865e-04 - val_loss: 7.4861e-04\n",
      "Epoch 76/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.4861e-04 - val_loss: 7.4858e-04\n",
      "Epoch 77/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4858e-04 - val_loss: 7.4856e-04\n",
      "Epoch 78/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4856e-04 - val_loss: 7.4855e-04\n",
      "Epoch 79/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4855e-04 - val_loss: 7.4855e-04\n",
      "Epoch 80/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4855e-04 - val_loss: 7.4854e-04\n",
      "Epoch 81/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4854e-04 - val_loss: 7.4853e-04\n",
      "Epoch 82/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4853e-04 - val_loss: 7.4850e-04\n",
      "Epoch 83/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4850e-04 - val_loss: 7.4847e-04\n",
      "Epoch 84/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4847e-04 - val_loss: 7.4845e-04\n",
      "Epoch 85/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4845e-04 - val_loss: 7.4844e-04\n",
      "Epoch 86/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4844e-04 - val_loss: 7.4842e-04\n",
      "Epoch 87/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4842e-04 - val_loss: 7.4841e-04\n",
      "Epoch 88/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4841e-04 - val_loss: 7.4839e-04\n",
      "Epoch 89/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4839e-04 - val_loss: 7.4836e-04\n",
      "Epoch 90/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4836e-04 - val_loss: 7.4833e-04\n",
      "Epoch 91/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4833e-04 - val_loss: 7.4831e-04\n",
      "Epoch 92/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4831e-04 - val_loss: 7.4829e-04\n",
      "Epoch 93/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4829e-04 - val_loss: 7.4827e-04\n",
      "Epoch 94/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4827e-04 - val_loss: 7.4824e-04\n",
      "Epoch 95/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4824e-04 - val_loss: 7.4821e-04\n",
      "Epoch 96/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4821e-04 - val_loss: 7.4818e-04\n",
      "Epoch 97/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4818e-04 - val_loss: 7.4815e-04\n",
      "Epoch 98/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4815e-04 - val_loss: 7.4812e-04\n",
      "Epoch 99/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4812e-04 - val_loss: 7.4809e-04\n",
      "Epoch 100/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4809e-04 - val_loss: 7.4806e-04\n",
      "Epoch 101/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4806e-04 - val_loss: 7.4802e-04\n",
      "Epoch 102/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4802e-04 - val_loss: 7.4799e-04\n",
      "Epoch 103/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4799e-04 - val_loss: 7.4795e-04\n",
      "Epoch 104/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4795e-04 - val_loss: 7.4791e-04\n",
      "Epoch 105/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4791e-04 - val_loss: 7.4787e-04\n",
      "Epoch 106/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4787e-04 - val_loss: 7.4782e-04\n",
      "Epoch 107/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4782e-04 - val_loss: 7.4778e-04\n",
      "Epoch 108/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4778e-04 - val_loss: 7.4773e-04\n",
      "Epoch 109/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4773e-04 - val_loss: 7.4768e-04\n",
      "Epoch 110/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4768e-04 - val_loss: 7.4762e-04\n",
      "Epoch 111/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4762e-04 - val_loss: 7.4757e-04\n",
      "Epoch 112/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4757e-04 - val_loss: 7.4751e-04\n",
      "Epoch 113/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4751e-04 - val_loss: 7.4745e-04\n",
      "Epoch 114/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4745e-04 - val_loss: 7.4738e-04\n",
      "Epoch 115/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4738e-04 - val_loss: 7.4731e-04\n",
      "Epoch 116/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4731e-04 - val_loss: 7.4724e-04\n",
      "Epoch 117/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4724e-04 - val_loss: 7.4716e-04\n",
      "Epoch 118/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4716e-04 - val_loss: 7.4708e-04\n",
      "Epoch 119/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4708e-04 - val_loss: 7.4699e-04\n",
      "Epoch 120/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4699e-04 - val_loss: 7.4690e-04\n",
      "Epoch 121/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4690e-04 - val_loss: 7.4680e-04\n",
      "Epoch 122/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4680e-04 - val_loss: 7.4670e-04\n",
      "Epoch 123/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4670e-04 - val_loss: 7.4659e-04\n",
      "Epoch 124/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4659e-04 - val_loss: 7.4647e-04\n",
      "Epoch 125/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4647e-04 - val_loss: 7.4635e-04\n",
      "Epoch 126/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4635e-04 - val_loss: 7.4621e-04\n",
      "Epoch 127/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4621e-04 - val_loss: 7.4607e-04\n",
      "Epoch 128/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4607e-04 - val_loss: 7.4592e-04\n",
      "Epoch 129/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4592e-04 - val_loss: 7.4576e-04\n",
      "Epoch 130/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4576e-04 - val_loss: 7.4559e-04\n",
      "Epoch 131/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4559e-04 - val_loss: 7.4541e-04\n",
      "Epoch 132/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4541e-04 - val_loss: 7.4522e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4522e-04 - val_loss: 7.4501e-04\n",
      "Epoch 134/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4501e-04 - val_loss: 7.4479e-04\n",
      "Epoch 135/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4479e-04 - val_loss: 7.4455e-04\n",
      "Epoch 136/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4455e-04 - val_loss: 7.4430e-04\n",
      "Epoch 137/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4430e-04 - val_loss: 7.4403e-04\n",
      "Epoch 138/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4403e-04 - val_loss: 7.4375e-04\n",
      "Epoch 139/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4375e-04 - val_loss: 7.4344e-04\n",
      "Epoch 140/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4344e-04 - val_loss: 7.4311e-04\n",
      "Epoch 141/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4311e-04 - val_loss: 7.4277e-04\n",
      "Epoch 142/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4277e-04 - val_loss: 7.4240e-04\n",
      "Epoch 143/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4240e-04 - val_loss: 7.4201e-04\n",
      "Epoch 144/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4201e-04 - val_loss: 7.4160e-04\n",
      "Epoch 145/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4160e-04 - val_loss: 7.4117e-04\n",
      "Epoch 146/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4117e-04 - val_loss: 7.4072e-04\n",
      "Epoch 147/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4071e-04 - val_loss: 7.4025e-04\n",
      "Epoch 148/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4025e-04 - val_loss: 7.3976e-04\n",
      "Epoch 149/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3976e-04 - val_loss: 7.3927e-04\n",
      "Epoch 150/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3927e-04 - val_loss: 7.3877e-04\n",
      "Epoch 151/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3877e-04 - val_loss: 7.3828e-04\n",
      "Epoch 152/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3828e-04 - val_loss: 7.3780e-04\n",
      "Epoch 153/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3780e-04 - val_loss: 7.3734e-04\n",
      "Epoch 154/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3734e-04 - val_loss: 7.3692e-04\n",
      "Epoch 155/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3692e-04 - val_loss: 7.3654e-04\n",
      "Epoch 156/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3654e-04 - val_loss: 7.3623e-04\n",
      "Epoch 157/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3623e-04 - val_loss: 7.3598e-04\n",
      "Epoch 158/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3598e-04 - val_loss: 7.3580e-04\n",
      "Epoch 159/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3580e-04 - val_loss: 7.3569e-04\n",
      "Epoch 160/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3569e-04 - val_loss: 7.3566e-04\n",
      "Epoch 161/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.3566e-04 - val_loss: 7.3578e-04\n",
      "Epoch 162/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3578e-04 - val_loss: 7.3721e-04\n",
      "Epoch 163/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3721e-04 - val_loss: 7.4729e-04\n",
      "Epoch 164/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4729e-04 - val_loss: 7.5673e-04\n",
      "Epoch 165/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5673e-04 - val_loss: 7.3667e-04\n",
      "Epoch 166/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3667e-04 - val_loss: 7.4711e-04\n",
      "Epoch 167/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4711e-04 - val_loss: 7.3761e-04\n",
      "Epoch 168/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3761e-04 - val_loss: 7.4314e-04\n",
      "Epoch 169/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4314e-04 - val_loss: 7.3564e-04\n",
      "Epoch 170/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3564e-04 - val_loss: 7.4189e-04\n",
      "Epoch 171/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4189e-04 - val_loss: 7.3525e-04\n",
      "Epoch 172/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3525e-04 - val_loss: 7.3887e-04\n",
      "Epoch 173/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3887e-04 - val_loss: 7.3781e-04\n",
      "Epoch 174/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3781e-04 - val_loss: 7.3544e-04\n",
      "Epoch 175/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3544e-04 - val_loss: 7.3841e-04\n",
      "Epoch 176/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3841e-04 - val_loss: 7.3638e-04\n",
      "Epoch 177/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3638e-04 - val_loss: 7.3564e-04\n",
      "Epoch 178/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3564e-04 - val_loss: 7.3743e-04\n",
      "Epoch 179/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3743e-04 - val_loss: 7.3582e-04\n",
      "Epoch 180/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3582e-04 - val_loss: 7.3531e-04\n",
      "Epoch 181/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3531e-04 - val_loss: 7.3648e-04\n",
      "Epoch 182/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3648e-04 - val_loss: 7.3524e-04\n",
      "Epoch 183/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3524e-04 - val_loss: 7.3474e-04\n",
      "Epoch 184/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3474e-04 - val_loss: 7.3553e-04\n",
      "Epoch 185/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.3553e-04 - val_loss: 7.3450e-04\n",
      "Epoch 186/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3450e-04 - val_loss: 7.3412e-04\n",
      "Epoch 187/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.3412e-04 - val_loss: 7.3463e-04\n",
      "Epoch 188/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3463e-04 - val_loss: 7.3369e-04\n",
      "Epoch 189/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3369e-04 - val_loss: 7.3360e-04\n",
      "Epoch 190/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3360e-04 - val_loss: 7.3383e-04\n",
      "Epoch 191/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3383e-04 - val_loss: 7.3301e-04\n",
      "Epoch 192/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3301e-04 - val_loss: 7.3326e-04\n",
      "Epoch 193/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3326e-04 - val_loss: 7.3309e-04\n",
      "Epoch 194/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.3309e-04 - val_loss: 7.3264e-04\n",
      "Epoch 195/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3264e-04 - val_loss: 7.3297e-04\n",
      "Epoch 196/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.3297e-04 - val_loss: 7.3248e-04\n",
      "Epoch 197/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3248e-04 - val_loss: 7.3252e-04\n",
      "Epoch 198/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3252e-04 - val_loss: 7.3246e-04\n",
      "Epoch 199/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3246e-04 - val_loss: 7.3210e-04\n",
      "Epoch 200/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3210e-04 - val_loss: 7.3224e-04\n",
      "Epoch 201/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3224e-04 - val_loss: 7.3186e-04\n",
      "Epoch 202/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3186e-04 - val_loss: 7.3182e-04\n",
      "Epoch 203/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3182e-04 - val_loss: 7.3168e-04\n",
      "Epoch 204/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3168e-04 - val_loss: 7.3140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3140e-04 - val_loss: 7.3139e-04\n",
      "Epoch 206/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3139e-04 - val_loss: 7.3110e-04\n",
      "Epoch 207/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3110e-04 - val_loss: 7.3099e-04\n",
      "Epoch 208/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3099e-04 - val_loss: 7.3087e-04\n",
      "Epoch 209/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3087e-04 - val_loss: 7.3062e-04\n",
      "Epoch 210/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3062e-04 - val_loss: 7.3056e-04\n",
      "Epoch 211/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3056e-04 - val_loss: 7.3035e-04\n",
      "Epoch 212/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3035e-04 - val_loss: 7.3019e-04\n",
      "Epoch 213/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3019e-04 - val_loss: 7.3007e-04\n",
      "Epoch 214/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.3007e-04 - val_loss: 7.2985e-04\n",
      "Epoch 215/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.2985e-04 - val_loss: 7.2972e-04\n",
      "Epoch 216/900\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 7.2972e-04 - val_loss: 7.2954e-04\n",
      "Epoch 217/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2954e-04 - val_loss: 7.2933e-04\n",
      "Epoch 218/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2933e-04 - val_loss: 7.2919e-04\n",
      "Epoch 219/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2919e-04 - val_loss: 7.2897e-04\n",
      "Epoch 220/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2897e-04 - val_loss: 7.2878e-04\n",
      "Epoch 221/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2878e-04 - val_loss: 7.2859e-04\n",
      "Epoch 222/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2859e-04 - val_loss: 7.2836e-04\n",
      "Epoch 223/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2836e-04 - val_loss: 7.2818e-04\n",
      "Epoch 224/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2818e-04 - val_loss: 7.2795e-04\n",
      "Epoch 225/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2795e-04 - val_loss: 7.2773e-04\n",
      "Epoch 226/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2773e-04 - val_loss: 7.2752e-04\n",
      "Epoch 227/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2752e-04 - val_loss: 7.2728e-04\n",
      "Epoch 228/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2728e-04 - val_loss: 7.2706e-04\n",
      "Epoch 229/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2706e-04 - val_loss: 7.2682e-04\n",
      "Epoch 230/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.2682e-04 - val_loss: 7.2657e-04\n",
      "Epoch 231/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.2657e-04 - val_loss: 7.2632e-04\n",
      "Epoch 232/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.2632e-04 - val_loss: 7.2605e-04\n",
      "Epoch 233/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2605e-04 - val_loss: 7.2580e-04\n",
      "Epoch 234/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.2580e-04 - val_loss: 7.2552e-04\n",
      "Epoch 235/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2552e-04 - val_loss: 7.2524e-04\n",
      "Epoch 236/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2524e-04 - val_loss: 7.2496e-04\n",
      "Epoch 237/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2496e-04 - val_loss: 7.2466e-04\n",
      "Epoch 238/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2466e-04 - val_loss: 7.2437e-04\n",
      "Epoch 239/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.2437e-04 - val_loss: 7.2406e-04\n",
      "Epoch 240/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2405e-04 - val_loss: 7.2374e-04\n",
      "Epoch 241/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2374e-04 - val_loss: 7.2342e-04\n",
      "Epoch 242/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2342e-04 - val_loss: 7.2309e-04\n",
      "Epoch 243/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2309e-04 - val_loss: 7.2276e-04\n",
      "Epoch 244/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.2276e-04 - val_loss: 7.2241e-04\n",
      "Epoch 245/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2241e-04 - val_loss: 7.2206e-04\n",
      "Epoch 246/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2206e-04 - val_loss: 7.2171e-04\n",
      "Epoch 247/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2171e-04 - val_loss: 7.2134e-04\n",
      "Epoch 248/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2134e-04 - val_loss: 7.2098e-04\n",
      "Epoch 249/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2098e-04 - val_loss: 7.2060e-04\n",
      "Epoch 250/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2060e-04 - val_loss: 7.2023e-04\n",
      "Epoch 251/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2023e-04 - val_loss: 7.1985e-04\n",
      "Epoch 252/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1985e-04 - val_loss: 7.1948e-04\n",
      "Epoch 253/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1948e-04 - val_loss: 7.1911e-04\n",
      "Epoch 254/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1911e-04 - val_loss: 7.1874e-04\n",
      "Epoch 255/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1874e-04 - val_loss: 7.1837e-04\n",
      "Epoch 256/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1837e-04 - val_loss: 7.1802e-04\n",
      "Epoch 257/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.1802e-04 - val_loss: 7.1768e-04\n",
      "Epoch 258/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1768e-04 - val_loss: 7.1735e-04\n",
      "Epoch 259/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1735e-04 - val_loss: 7.1704e-04\n",
      "Epoch 260/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1704e-04 - val_loss: 7.1675e-04\n",
      "Epoch 261/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.1675e-04 - val_loss: 7.1648e-04\n",
      "Epoch 262/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1648e-04 - val_loss: 7.1624e-04\n",
      "Epoch 263/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1624e-04 - val_loss: 7.1603e-04\n",
      "Epoch 264/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1603e-04 - val_loss: 7.1585e-04\n",
      "Epoch 265/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1585e-04 - val_loss: 7.1570e-04\n",
      "Epoch 266/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1570e-04 - val_loss: 7.1557e-04\n",
      "Epoch 267/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1557e-04 - val_loss: 7.1548e-04\n",
      "Epoch 268/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1548e-04 - val_loss: 7.1542e-04\n",
      "Epoch 269/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1542e-04 - val_loss: 7.1539e-04\n",
      "Epoch 270/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1539e-04 - val_loss: 7.1537e-04\n",
      "Epoch 271/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1537e-04 - val_loss: 7.1538e-04\n",
      "Epoch 272/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1538e-04 - val_loss: 7.1540e-04\n",
      "Epoch 273/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1540e-04 - val_loss: 7.1542e-04\n",
      "Epoch 274/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1542e-04 - val_loss: 7.1546e-04\n",
      "Epoch 275/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1546e-04 - val_loss: 7.1549e-04\n",
      "Epoch 276/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1549e-04 - val_loss: 7.1551e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1551e-04 - val_loss: 7.1553e-04\n",
      "Epoch 278/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1553e-04 - val_loss: 7.1555e-04\n",
      "Epoch 279/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1555e-04 - val_loss: 7.1555e-04\n",
      "Epoch 280/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1555e-04 - val_loss: 7.1555e-04\n",
      "Epoch 281/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1555e-04 - val_loss: 7.1554e-04\n",
      "Epoch 282/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1554e-04 - val_loss: 7.1552e-04\n",
      "Epoch 283/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1552e-04 - val_loss: 7.1550e-04\n",
      "Epoch 284/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1550e-04 - val_loss: 7.1547e-04\n",
      "Epoch 285/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1547e-04 - val_loss: 7.1545e-04\n",
      "Epoch 286/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1545e-04 - val_loss: 7.1542e-04\n",
      "Epoch 287/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1542e-04 - val_loss: 7.1540e-04\n",
      "Epoch 288/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1540e-04 - val_loss: 7.1538e-04\n",
      "Epoch 289/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1538e-04 - val_loss: 7.1536e-04\n",
      "Epoch 290/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1536e-04 - val_loss: 7.1534e-04\n",
      "Epoch 291/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1534e-04 - val_loss: 7.1533e-04\n",
      "Epoch 292/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1533e-04 - val_loss: 7.1532e-04\n",
      "Epoch 293/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1532e-04 - val_loss: 7.1531e-04\n",
      "Epoch 294/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1531e-04 - val_loss: 7.1531e-04\n",
      "Epoch 295/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1531e-04 - val_loss: 7.1531e-04\n",
      "Epoch 296/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1531e-04 - val_loss: 7.1530e-04\n",
      "Epoch 297/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 298/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 299/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 300/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 301/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 302/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 303/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 304/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 305/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 306/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1529e-04\n",
      "Epoch 307/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1529e-04 - val_loss: 7.1529e-04\n",
      "Epoch 308/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1529e-04 - val_loss: 7.1529e-04\n",
      "Epoch 309/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1529e-04 - val_loss: 7.1528e-04\n",
      "Epoch 310/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1528e-04 - val_loss: 7.1528e-04\n",
      "Epoch 311/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1528e-04 - val_loss: 7.1528e-04\n",
      "Epoch 312/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1528e-04 - val_loss: 7.1527e-04\n",
      "Epoch 313/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1527e-04 - val_loss: 7.1527e-04\n",
      "Epoch 314/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1527e-04 - val_loss: 7.1526e-04\n",
      "Epoch 315/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1526e-04\n",
      "Epoch 316/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1526e-04\n",
      "Epoch 317/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1525e-04\n",
      "Epoch 318/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 319/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 320/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 321/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1525e-04 - val_loss: 7.1524e-04\n",
      "Epoch 322/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 323/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 324/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 325/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 7.1524e-04 - val_loss: 7.1523e-04\n",
      "Epoch 326/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 327/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 328/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 329/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1523e-04 - val_loss: 7.1522e-04\n",
      "Epoch 330/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 331/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 332/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 333/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 334/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1522e-04 - val_loss: 7.1521e-04\n",
      "Epoch 335/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 336/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 337/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 338/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1521e-04 - val_loss: 7.1520e-04\n",
      "Epoch 339/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 340/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 341/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 342/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.1520e-04 - val_loss: 7.1519e-04\n",
      "Epoch 343/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 344/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 345/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 346/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 7.1519e-04 - val_loss: 7.1518e-04\n",
      "Epoch 347/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n",
      "Epoch 348/900\n",
      "650/650 [==============================] - 0s 94us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n",
      "Epoch 350/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1518e-04 - val_loss: 7.1517e-04\n",
      "Epoch 351/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 352/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 353/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 354/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1517e-04 - val_loss: 7.1516e-04\n",
      "Epoch 355/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 356/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 357/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 358/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 7.1516e-04 - val_loss: 7.1515e-04\n",
      "Epoch 359/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 360/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 361/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 362/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1515e-04 - val_loss: 7.1514e-04\n",
      "Epoch 363/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 364/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 365/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 366/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1514e-04 - val_loss: 7.1513e-04\n",
      "Epoch 367/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 368/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 369/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 370/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1513e-04 - val_loss: 7.1512e-04\n",
      "Epoch 371/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 372/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 373/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 374/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1512e-04 - val_loss: 7.1511e-04\n",
      "Epoch 375/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 376/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 377/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 378/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1510e-04\n",
      "Epoch 379/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 380/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 381/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 382/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 383/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 384/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 385/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 386/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 387/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 7.1509e-04 - val_loss: 7.1508e-04\n",
      "Epoch 388/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 389/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 390/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 391/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1508e-04 - val_loss: 7.1507e-04\n",
      "Epoch 392/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 393/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 394/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 395/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1507e-04 - val_loss: 7.1506e-04\n",
      "Epoch 396/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 397/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 398/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 399/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1506e-04 - val_loss: 7.1505e-04\n",
      "Epoch 400/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 401/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 402/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 403/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1505e-04 - val_loss: 7.1504e-04\n",
      "Epoch 404/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 405/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 406/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 407/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1504e-04 - val_loss: 7.1503e-04\n",
      "Epoch 408/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 409/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 410/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 411/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1503e-04 - val_loss: 7.1502e-04\n",
      "Epoch 412/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1502e-04 - val_loss: 7.1502e-04\n",
      "Epoch 413/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1502e-04 - val_loss: 7.1502e-04\n",
      "Epoch 414/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1502e-04 - val_loss: 7.1501e-04\n",
      "Epoch 415/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1502e-04 - val_loss: 7.1501e-04\n",
      "Epoch 416/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1501e-04 - val_loss: 7.1501e-04\n",
      "Epoch 417/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1501e-04 - val_loss: 7.1501e-04\n",
      "Epoch 418/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1501e-04 - val_loss: 7.1500e-04\n",
      "Epoch 419/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n",
      "Epoch 420/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n",
      "Epoch 422/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1500e-04 - val_loss: 7.1499e-04\n",
      "Epoch 423/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 424/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 425/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 426/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1499e-04 - val_loss: 7.1498e-04\n",
      "Epoch 427/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 428/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 429/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 430/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1498e-04 - val_loss: 7.1497e-04\n",
      "Epoch 431/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 432/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 433/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 434/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1497e-04 - val_loss: 7.1496e-04\n",
      "Epoch 435/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 436/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 437/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 438/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1495e-04\n",
      "Epoch 439/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 440/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 441/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 442/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1495e-04 - val_loss: 7.1494e-04\n",
      "Epoch 443/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 444/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 445/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 446/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1493e-04\n",
      "Epoch 447/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1493e-04 - val_loss: 7.1493e-04\n",
      "Epoch 448/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1493e-04 - val_loss: 7.1493e-04\n",
      "Epoch 449/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1493e-04 - val_loss: 7.1492e-04\n",
      "Epoch 450/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 451/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 452/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 453/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1491e-04\n",
      "Epoch 454/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 455/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 456/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 457/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1491e-04 - val_loss: 7.1490e-04\n",
      "Epoch 458/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 459/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 460/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 461/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1490e-04 - val_loss: 7.1489e-04\n",
      "Epoch 462/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1489e-04 - val_loss: 7.1489e-04\n",
      "Epoch 463/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1489e-04 - val_loss: 7.1489e-04\n",
      "Epoch 464/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1489e-04 - val_loss: 7.1488e-04\n",
      "Epoch 465/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 466/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 467/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 468/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1487e-04\n",
      "Epoch 469/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 470/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 471/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 472/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1487e-04 - val_loss: 7.1486e-04\n",
      "Epoch 473/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1486e-04\n",
      "Epoch 474/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1486e-04\n",
      "Epoch 475/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1485e-04\n",
      "Epoch 476/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 477/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 478/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 479/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1485e-04 - val_loss: 7.1484e-04\n",
      "Epoch 480/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 481/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 482/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 483/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1484e-04 - val_loss: 7.1483e-04\n",
      "Epoch 484/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1483e-04 - val_loss: 7.1483e-04\n",
      "Epoch 485/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1483e-04 - val_loss: 7.1483e-04\n",
      "Epoch 486/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1483e-04 - val_loss: 7.1482e-04\n",
      "Epoch 487/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 488/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 489/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 490/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1482e-04 - val_loss: 7.1481e-04\n",
      "Epoch 491/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1481e-04 - val_loss: 7.1481e-04\n",
      "Epoch 492/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1481e-04 - val_loss: 7.1481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1481e-04 - val_loss: 7.1480e-04\n",
      "Epoch 494/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 495/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 496/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 497/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1480e-04 - val_loss: 7.1479e-04\n",
      "Epoch 498/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1479e-04 - val_loss: 7.1479e-04\n",
      "Epoch 499/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1479e-04 - val_loss: 7.1479e-04\n",
      "Epoch 500/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1479e-04 - val_loss: 7.1478e-04\n",
      "Epoch 501/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 502/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 503/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 504/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1478e-04 - val_loss: 7.1477e-04\n",
      "Epoch 505/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1477e-04 - val_loss: 7.1477e-04\n",
      "Epoch 506/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1477e-04 - val_loss: 7.1477e-04\n",
      "Epoch 507/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1477e-04 - val_loss: 7.1476e-04\n",
      "Epoch 508/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 509/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 510/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 511/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1476e-04 - val_loss: 7.1475e-04\n",
      "Epoch 512/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1475e-04 - val_loss: 7.1475e-04\n",
      "Epoch 513/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1475e-04 - val_loss: 7.1475e-04\n",
      "Epoch 514/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1475e-04 - val_loss: 7.1474e-04\n",
      "Epoch 515/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 516/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 517/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 518/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1474e-04 - val_loss: 7.1473e-04\n",
      "Epoch 519/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1473e-04 - val_loss: 7.1473e-04\n",
      "Epoch 520/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1473e-04 - val_loss: 7.1473e-04\n",
      "Epoch 521/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1473e-04 - val_loss: 7.1472e-04\n",
      "Epoch 522/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1472e-04 - val_loss: 7.1472e-04\n",
      "Epoch 523/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1472e-04 - val_loss: 7.1472e-04\n",
      "Epoch 524/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1472e-04 - val_loss: 7.1471e-04\n",
      "Epoch 525/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 526/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 527/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 528/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1471e-04 - val_loss: 7.1470e-04\n",
      "Epoch 529/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1470e-04 - val_loss: 7.1470e-04\n",
      "Epoch 530/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1470e-04 - val_loss: 7.1470e-04\n",
      "Epoch 531/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1470e-04 - val_loss: 7.1469e-04\n",
      "Epoch 532/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1469e-04 - val_loss: 7.1469e-04\n",
      "Epoch 533/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1469e-04 - val_loss: 7.1469e-04\n",
      "Epoch 534/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1469e-04 - val_loss: 7.1468e-04\n",
      "Epoch 535/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1468e-04 - val_loss: 7.1468e-04\n",
      "Epoch 536/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1468e-04 - val_loss: 7.1468e-04\n",
      "Epoch 537/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1468e-04 - val_loss: 7.1467e-04\n",
      "Epoch 538/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 539/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 540/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 541/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1467e-04 - val_loss: 7.1466e-04\n",
      "Epoch 542/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1466e-04 - val_loss: 7.1466e-04\n",
      "Epoch 543/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1466e-04 - val_loss: 7.1466e-04\n",
      "Epoch 544/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1466e-04 - val_loss: 7.1465e-04\n",
      "Epoch 545/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1465e-04 - val_loss: 7.1465e-04\n",
      "Epoch 546/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1465e-04 - val_loss: 7.1465e-04\n",
      "Epoch 547/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1465e-04 - val_loss: 7.1464e-04\n",
      "Epoch 548/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1464e-04 - val_loss: 7.1464e-04\n",
      "Epoch 549/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1464e-04 - val_loss: 7.1464e-04\n",
      "Epoch 550/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1464e-04 - val_loss: 7.1463e-04\n",
      "Epoch 551/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1463e-04 - val_loss: 7.1463e-04\n",
      "Epoch 552/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1463e-04 - val_loss: 7.1463e-04\n",
      "Epoch 553/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1463e-04 - val_loss: 7.1462e-04\n",
      "Epoch 554/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1462e-04 - val_loss: 7.1462e-04\n",
      "Epoch 555/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1462e-04 - val_loss: 7.1462e-04\n",
      "Epoch 556/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1462e-04 - val_loss: 7.1461e-04\n",
      "Epoch 557/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1461e-04 - val_loss: 7.1461e-04\n",
      "Epoch 558/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1461e-04 - val_loss: 7.1461e-04\n",
      "Epoch 559/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 7.1461e-04 - val_loss: 7.1460e-04\n",
      "Epoch 560/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 7.1460e-04 - val_loss: 7.1460e-04\n",
      "Epoch 561/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 7.1460e-04 - val_loss: 7.1460e-04\n",
      "Epoch 562/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1460e-04 - val_loss: 7.1459e-04\n",
      "Epoch 563/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 7.1459e-04 - val_loss: 7.1459e-04\n",
      "Epoch 564/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1459e-04 - val_loss: 7.1459e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1459e-04 - val_loss: 7.1458e-04\n",
      "Epoch 566/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1458e-04 - val_loss: 7.1458e-04\n",
      "Epoch 567/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1458e-04 - val_loss: 7.1458e-04\n",
      "Epoch 568/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1458e-04 - val_loss: 7.1457e-04\n",
      "Epoch 569/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1457e-04 - val_loss: 7.1457e-04\n",
      "Epoch 570/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1457e-04 - val_loss: 7.1457e-04\n",
      "Epoch 571/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1457e-04 - val_loss: 7.1456e-04\n",
      "Epoch 572/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1456e-04 - val_loss: 7.1456e-04\n",
      "Epoch 573/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1456e-04 - val_loss: 7.1456e-04\n",
      "Epoch 574/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1456e-04 - val_loss: 7.1455e-04\n",
      "Epoch 575/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1455e-04 - val_loss: 7.1455e-04\n",
      "Epoch 576/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1455e-04 - val_loss: 7.1455e-04\n",
      "Epoch 577/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1455e-04 - val_loss: 7.1454e-04\n",
      "Epoch 578/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1454e-04 - val_loss: 7.1454e-04\n",
      "Epoch 579/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1454e-04 - val_loss: 7.1454e-04\n",
      "Epoch 580/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1454e-04 - val_loss: 7.1453e-04\n",
      "Epoch 581/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1453e-04 - val_loss: 7.1453e-04\n",
      "Epoch 582/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1453e-04 - val_loss: 7.1453e-04\n",
      "Epoch 583/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1453e-04 - val_loss: 7.1452e-04\n",
      "Epoch 584/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1452e-04 - val_loss: 7.1452e-04\n",
      "Epoch 585/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1452e-04 - val_loss: 7.1451e-04\n",
      "Epoch 586/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1451e-04 - val_loss: 7.1451e-04\n",
      "Epoch 587/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1451e-04 - val_loss: 7.1451e-04\n",
      "Epoch 588/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 7.1451e-04 - val_loss: 7.1450e-04\n",
      "Epoch 589/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1450e-04 - val_loss: 7.1450e-04\n",
      "Epoch 590/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1450e-04 - val_loss: 7.1450e-04\n",
      "Epoch 591/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1450e-04 - val_loss: 7.1449e-04\n",
      "Epoch 592/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1449e-04 - val_loss: 7.1449e-04\n",
      "Epoch 593/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1449e-04 - val_loss: 7.1449e-04\n",
      "Epoch 594/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1449e-04 - val_loss: 7.1448e-04\n",
      "Epoch 595/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1448e-04 - val_loss: 7.1448e-04\n",
      "Epoch 596/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1448e-04 - val_loss: 7.1447e-04\n",
      "Epoch 597/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1447e-04 - val_loss: 7.1447e-04\n",
      "Epoch 598/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1447e-04 - val_loss: 7.1447e-04\n",
      "Epoch 599/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1447e-04 - val_loss: 7.1446e-04\n",
      "Epoch 600/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1446e-04 - val_loss: 7.1446e-04\n",
      "Epoch 601/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1446e-04 - val_loss: 7.1446e-04\n",
      "Epoch 602/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1446e-04 - val_loss: 7.1445e-04\n",
      "Epoch 603/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1445e-04 - val_loss: 7.1445e-04\n",
      "Epoch 604/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1445e-04 - val_loss: 7.1444e-04\n",
      "Epoch 605/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1444e-04 - val_loss: 7.1444e-04\n",
      "Epoch 606/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1444e-04 - val_loss: 7.1444e-04\n",
      "Epoch 607/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1444e-04 - val_loss: 7.1443e-04\n",
      "Epoch 608/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1443e-04 - val_loss: 7.1443e-04\n",
      "Epoch 609/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1443e-04 - val_loss: 7.1443e-04\n",
      "Epoch 610/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1443e-04 - val_loss: 7.1442e-04\n",
      "Epoch 611/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1442e-04 - val_loss: 7.1442e-04\n",
      "Epoch 612/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1442e-04 - val_loss: 7.1441e-04\n",
      "Epoch 613/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1441e-04 - val_loss: 7.1441e-04\n",
      "Epoch 614/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1441e-04 - val_loss: 7.1441e-04\n",
      "Epoch 615/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1441e-04 - val_loss: 7.1440e-04\n",
      "Epoch 616/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1440e-04 - val_loss: 7.1440e-04\n",
      "Epoch 617/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1440e-04 - val_loss: 7.1439e-04\n",
      "Epoch 618/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1439e-04 - val_loss: 7.1439e-04\n",
      "Epoch 619/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1439e-04 - val_loss: 7.1439e-04\n",
      "Epoch 620/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1439e-04 - val_loss: 7.1438e-04\n",
      "Epoch 621/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1438e-04 - val_loss: 7.1438e-04\n",
      "Epoch 622/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1438e-04 - val_loss: 7.1437e-04\n",
      "Epoch 623/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1437e-04 - val_loss: 7.1437e-04\n",
      "Epoch 624/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1437e-04 - val_loss: 7.1436e-04\n",
      "Epoch 625/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1436e-04 - val_loss: 7.1436e-04\n",
      "Epoch 626/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1436e-04 - val_loss: 7.1436e-04\n",
      "Epoch 627/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1436e-04 - val_loss: 7.1435e-04\n",
      "Epoch 628/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1435e-04 - val_loss: 7.1435e-04\n",
      "Epoch 629/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1435e-04 - val_loss: 7.1434e-04\n",
      "Epoch 630/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1434e-04 - val_loss: 7.1434e-04\n",
      "Epoch 631/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1434e-04 - val_loss: 7.1434e-04\n",
      "Epoch 632/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1434e-04 - val_loss: 7.1433e-04\n",
      "Epoch 633/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1433e-04 - val_loss: 7.1433e-04\n",
      "Epoch 634/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1433e-04 - val_loss: 7.1432e-04\n",
      "Epoch 635/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1432e-04 - val_loss: 7.1432e-04\n",
      "Epoch 636/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1432e-04 - val_loss: 7.1431e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 637/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1431e-04 - val_loss: 7.1431e-04\n",
      "Epoch 638/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1431e-04 - val_loss: 7.1431e-04\n",
      "Epoch 639/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1431e-04 - val_loss: 7.1430e-04\n",
      "Epoch 640/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1430e-04 - val_loss: 7.1430e-04\n",
      "Epoch 641/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1430e-04 - val_loss: 7.1429e-04\n",
      "Epoch 642/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1429e-04 - val_loss: 7.1429e-04\n",
      "Epoch 643/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1429e-04 - val_loss: 7.1428e-04\n",
      "Epoch 644/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1428e-04 - val_loss: 7.1428e-04\n",
      "Epoch 645/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1428e-04 - val_loss: 7.1427e-04\n",
      "Epoch 646/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1427e-04 - val_loss: 7.1427e-04\n",
      "Epoch 647/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1427e-04 - val_loss: 7.1426e-04\n",
      "Epoch 648/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1426e-04 - val_loss: 7.1426e-04\n",
      "Epoch 649/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1426e-04 - val_loss: 7.1426e-04\n",
      "Epoch 650/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1426e-04 - val_loss: 7.1425e-04\n",
      "Epoch 651/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1425e-04 - val_loss: 7.1425e-04\n",
      "Epoch 652/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1425e-04 - val_loss: 7.1424e-04\n",
      "Epoch 653/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1424e-04 - val_loss: 7.1424e-04\n",
      "Epoch 654/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1424e-04 - val_loss: 7.1423e-04\n",
      "Epoch 655/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 7.1423e-04 - val_loss: 7.1423e-04\n",
      "Epoch 656/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1423e-04 - val_loss: 7.1422e-04\n",
      "Epoch 657/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 7.1422e-04 - val_loss: 7.1422e-04\n",
      "Epoch 658/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1422e-04 - val_loss: 7.1421e-04\n",
      "Epoch 659/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1421e-04 - val_loss: 7.1421e-04\n",
      "Epoch 660/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1421e-04 - val_loss: 7.1420e-04\n",
      "Epoch 661/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1420e-04 - val_loss: 7.1420e-04\n",
      "Epoch 662/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1420e-04 - val_loss: 7.1419e-04\n",
      "Epoch 663/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1419e-04 - val_loss: 7.1419e-04\n",
      "Epoch 664/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1419e-04 - val_loss: 7.1418e-04\n",
      "Epoch 665/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1418e-04 - val_loss: 7.1418e-04\n",
      "Epoch 666/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1418e-04 - val_loss: 7.1417e-04\n",
      "Epoch 667/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1417e-04 - val_loss: 7.1417e-04\n",
      "Epoch 668/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1417e-04 - val_loss: 7.1416e-04\n",
      "Epoch 669/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1416e-04 - val_loss: 7.1416e-04\n",
      "Epoch 670/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1416e-04 - val_loss: 7.1415e-04\n",
      "Epoch 671/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1415e-04 - val_loss: 7.1415e-04\n",
      "Epoch 672/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1415e-04 - val_loss: 7.1414e-04\n",
      "Epoch 673/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1414e-04 - val_loss: 7.1414e-04\n",
      "Epoch 674/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1414e-04 - val_loss: 7.1413e-04\n",
      "Epoch 675/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1413e-04 - val_loss: 7.1413e-04\n",
      "Epoch 676/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1413e-04 - val_loss: 7.1412e-04\n",
      "Epoch 677/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1412e-04 - val_loss: 7.1412e-04\n",
      "Epoch 678/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1412e-04 - val_loss: 7.1411e-04\n",
      "Epoch 679/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1411e-04 - val_loss: 7.1411e-04\n",
      "Epoch 680/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1411e-04 - val_loss: 7.1410e-04\n",
      "Epoch 681/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1410e-04 - val_loss: 7.1409e-04\n",
      "Epoch 682/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1409e-04 - val_loss: 7.1409e-04\n",
      "Epoch 683/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1409e-04 - val_loss: 7.1408e-04\n",
      "Epoch 684/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1408e-04 - val_loss: 7.1408e-04\n",
      "Epoch 685/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1408e-04 - val_loss: 7.1407e-04\n",
      "Epoch 686/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1407e-04 - val_loss: 7.1407e-04\n",
      "Epoch 687/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1407e-04 - val_loss: 7.1406e-04\n",
      "Epoch 688/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1406e-04 - val_loss: 7.1405e-04\n",
      "Epoch 689/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1405e-04 - val_loss: 7.1405e-04\n",
      "Epoch 690/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1405e-04 - val_loss: 7.1404e-04\n",
      "Epoch 691/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1404e-04 - val_loss: 7.1404e-04\n",
      "Epoch 692/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1404e-04 - val_loss: 7.1403e-04\n",
      "Epoch 693/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1403e-04 - val_loss: 7.1403e-04\n",
      "Epoch 694/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1403e-04 - val_loss: 7.1402e-04\n",
      "Epoch 695/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1402e-04 - val_loss: 7.1401e-04\n",
      "Epoch 696/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1401e-04 - val_loss: 7.1401e-04\n",
      "Epoch 697/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1401e-04 - val_loss: 7.1400e-04\n",
      "Epoch 698/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1400e-04 - val_loss: 7.1400e-04\n",
      "Epoch 699/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1400e-04 - val_loss: 7.1399e-04\n",
      "Epoch 700/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1399e-04 - val_loss: 7.1398e-04\n",
      "Epoch 701/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1398e-04 - val_loss: 7.1398e-04\n",
      "Epoch 702/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1398e-04 - val_loss: 7.1397e-04\n",
      "Epoch 703/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1397e-04 - val_loss: 7.1396e-04\n",
      "Epoch 704/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1396e-04 - val_loss: 7.1396e-04\n",
      "Epoch 705/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1396e-04 - val_loss: 7.1395e-04\n",
      "Epoch 706/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1395e-04 - val_loss: 7.1395e-04\n",
      "Epoch 707/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1395e-04 - val_loss: 7.1394e-04\n",
      "Epoch 708/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1394e-04 - val_loss: 7.1393e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1393e-04 - val_loss: 7.1393e-04\n",
      "Epoch 710/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1393e-04 - val_loss: 7.1392e-04\n",
      "Epoch 711/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1392e-04 - val_loss: 7.1391e-04\n",
      "Epoch 712/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1391e-04 - val_loss: 7.1391e-04\n",
      "Epoch 713/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1391e-04 - val_loss: 7.1390e-04\n",
      "Epoch 714/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1390e-04 - val_loss: 7.1389e-04\n",
      "Epoch 715/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1389e-04 - val_loss: 7.1388e-04\n",
      "Epoch 716/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1388e-04 - val_loss: 7.1388e-04\n",
      "Epoch 717/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1388e-04 - val_loss: 7.1387e-04\n",
      "Epoch 718/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1387e-04 - val_loss: 7.1386e-04\n",
      "Epoch 719/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1386e-04 - val_loss: 7.1386e-04\n",
      "Epoch 720/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1386e-04 - val_loss: 7.1385e-04\n",
      "Epoch 721/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1385e-04 - val_loss: 7.1384e-04\n",
      "Epoch 722/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1384e-04 - val_loss: 7.1383e-04\n",
      "Epoch 723/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1383e-04 - val_loss: 7.1383e-04\n",
      "Epoch 724/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1383e-04 - val_loss: 7.1382e-04\n",
      "Epoch 725/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1382e-04 - val_loss: 7.1381e-04\n",
      "Epoch 726/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1381e-04 - val_loss: 7.1381e-04\n",
      "Epoch 727/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1381e-04 - val_loss: 7.1380e-04\n",
      "Epoch 728/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1380e-04 - val_loss: 7.1379e-04\n",
      "Epoch 729/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1379e-04 - val_loss: 7.1378e-04\n",
      "Epoch 730/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1378e-04 - val_loss: 7.1377e-04\n",
      "Epoch 731/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1377e-04 - val_loss: 7.1377e-04\n",
      "Epoch 732/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1377e-04 - val_loss: 7.1376e-04\n",
      "Epoch 733/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1376e-04 - val_loss: 7.1375e-04\n",
      "Epoch 734/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1375e-04 - val_loss: 7.1374e-04\n",
      "Epoch 735/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1374e-04 - val_loss: 7.1373e-04\n",
      "Epoch 736/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1373e-04 - val_loss: 7.1373e-04\n",
      "Epoch 737/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1373e-04 - val_loss: 7.1372e-04\n",
      "Epoch 738/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1372e-04 - val_loss: 7.1371e-04\n",
      "Epoch 739/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1371e-04 - val_loss: 7.1370e-04\n",
      "Epoch 740/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1370e-04 - val_loss: 7.1369e-04\n",
      "Epoch 741/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1369e-04 - val_loss: 7.1368e-04\n",
      "Epoch 742/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1368e-04 - val_loss: 7.1367e-04\n",
      "Epoch 743/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1367e-04 - val_loss: 7.1367e-04\n",
      "Epoch 744/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1367e-04 - val_loss: 7.1366e-04\n",
      "Epoch 745/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1366e-04 - val_loss: 7.1365e-04\n",
      "Epoch 746/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1365e-04 - val_loss: 7.1364e-04\n",
      "Epoch 747/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1364e-04 - val_loss: 7.1363e-04\n",
      "Epoch 748/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1363e-04 - val_loss: 7.1362e-04\n",
      "Epoch 749/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1362e-04 - val_loss: 7.1361e-04\n",
      "Epoch 750/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1361e-04 - val_loss: 7.1360e-04\n",
      "Epoch 751/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1360e-04 - val_loss: 7.1359e-04\n",
      "Epoch 752/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1359e-04 - val_loss: 7.1358e-04\n",
      "Epoch 753/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1358e-04 - val_loss: 7.1357e-04\n",
      "Epoch 754/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1357e-04 - val_loss: 7.1356e-04\n",
      "Epoch 755/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1356e-04 - val_loss: 7.1355e-04\n",
      "Epoch 756/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1355e-04 - val_loss: 7.1354e-04\n",
      "Epoch 757/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1354e-04 - val_loss: 7.1353e-04\n",
      "Epoch 758/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1353e-04 - val_loss: 7.1352e-04\n",
      "Epoch 759/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1352e-04 - val_loss: 7.1351e-04\n",
      "Epoch 760/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1351e-04 - val_loss: 7.1350e-04\n",
      "Epoch 761/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1350e-04 - val_loss: 7.1349e-04\n",
      "Epoch 762/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1349e-04 - val_loss: 7.1348e-04\n",
      "Epoch 763/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1348e-04 - val_loss: 7.1347e-04\n",
      "Epoch 764/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1347e-04 - val_loss: 7.1346e-04\n",
      "Epoch 765/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1346e-04 - val_loss: 7.1345e-04\n",
      "Epoch 766/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1345e-04 - val_loss: 7.1343e-04\n",
      "Epoch 767/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1343e-04 - val_loss: 7.1342e-04\n",
      "Epoch 768/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1342e-04 - val_loss: 7.1341e-04\n",
      "Epoch 769/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1341e-04 - val_loss: 7.1340e-04\n",
      "Epoch 770/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1340e-04 - val_loss: 7.1339e-04\n",
      "Epoch 771/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1339e-04 - val_loss: 7.1337e-04\n",
      "Epoch 772/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1337e-04 - val_loss: 7.1336e-04\n",
      "Epoch 773/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1336e-04 - val_loss: 7.1335e-04\n",
      "Epoch 774/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1335e-04 - val_loss: 7.1334e-04\n",
      "Epoch 775/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1334e-04 - val_loss: 7.1332e-04\n",
      "Epoch 776/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1332e-04 - val_loss: 7.1331e-04\n",
      "Epoch 777/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1331e-04 - val_loss: 7.1330e-04\n",
      "Epoch 778/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1330e-04 - val_loss: 7.1328e-04\n",
      "Epoch 779/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1328e-04 - val_loss: 7.1327e-04\n",
      "Epoch 780/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1327e-04 - val_loss: 7.1326e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1326e-04 - val_loss: 7.1324e-04\n",
      "Epoch 782/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1324e-04 - val_loss: 7.1323e-04\n",
      "Epoch 783/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1323e-04 - val_loss: 7.1321e-04\n",
      "Epoch 784/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1321e-04 - val_loss: 7.1320e-04\n",
      "Epoch 785/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1320e-04 - val_loss: 7.1318e-04\n",
      "Epoch 786/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1318e-04 - val_loss: 7.1317e-04\n",
      "Epoch 787/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1317e-04 - val_loss: 7.1315e-04\n",
      "Epoch 788/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1315e-04 - val_loss: 7.1313e-04\n",
      "Epoch 789/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1313e-04 - val_loss: 7.1312e-04\n",
      "Epoch 790/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1312e-04 - val_loss: 7.1310e-04\n",
      "Epoch 791/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1310e-04 - val_loss: 7.1308e-04\n",
      "Epoch 792/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1308e-04 - val_loss: 7.1307e-04\n",
      "Epoch 793/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1307e-04 - val_loss: 7.1305e-04\n",
      "Epoch 794/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1305e-04 - val_loss: 7.1303e-04\n",
      "Epoch 795/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1303e-04 - val_loss: 7.1301e-04\n",
      "Epoch 796/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1301e-04 - val_loss: 7.1299e-04\n",
      "Epoch 797/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1299e-04 - val_loss: 7.1297e-04\n",
      "Epoch 798/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1297e-04 - val_loss: 7.1295e-04\n",
      "Epoch 799/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1295e-04 - val_loss: 7.1293e-04\n",
      "Epoch 800/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1293e-04 - val_loss: 7.1291e-04\n",
      "Epoch 801/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 7.1291e-04 - val_loss: 7.1289e-04\n",
      "Epoch 802/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1289e-04 - val_loss: 7.1287e-04\n",
      "Epoch 803/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1287e-04 - val_loss: 7.1285e-04\n",
      "Epoch 804/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1285e-04 - val_loss: 7.1282e-04\n",
      "Epoch 805/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1282e-04 - val_loss: 7.1280e-04\n",
      "Epoch 806/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1280e-04 - val_loss: 7.1278e-04\n",
      "Epoch 807/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1278e-04 - val_loss: 7.1275e-04\n",
      "Epoch 808/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1275e-04 - val_loss: 7.1273e-04\n",
      "Epoch 809/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1273e-04 - val_loss: 7.1270e-04\n",
      "Epoch 810/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1270e-04 - val_loss: 7.1267e-04\n",
      "Epoch 811/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1267e-04 - val_loss: 7.1264e-04\n",
      "Epoch 812/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1264e-04 - val_loss: 7.1262e-04\n",
      "Epoch 813/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1262e-04 - val_loss: 7.1259e-04\n",
      "Epoch 814/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1259e-04 - val_loss: 7.1255e-04\n",
      "Epoch 815/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1255e-04 - val_loss: 7.1252e-04\n",
      "Epoch 816/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1252e-04 - val_loss: 7.1249e-04\n",
      "Epoch 817/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1249e-04 - val_loss: 7.1245e-04\n",
      "Epoch 818/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1245e-04 - val_loss: 7.1242e-04\n",
      "Epoch 819/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1242e-04 - val_loss: 7.1238e-04\n",
      "Epoch 820/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1238e-04 - val_loss: 7.1234e-04\n",
      "Epoch 821/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1234e-04 - val_loss: 7.1230e-04\n",
      "Epoch 822/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1230e-04 - val_loss: 7.1226e-04\n",
      "Epoch 823/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1226e-04 - val_loss: 7.1221e-04\n",
      "Epoch 824/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1221e-04 - val_loss: 7.1217e-04\n",
      "Epoch 825/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1217e-04 - val_loss: 7.1212e-04\n",
      "Epoch 826/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1212e-04 - val_loss: 7.1206e-04\n",
      "Epoch 827/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1206e-04 - val_loss: 7.1201e-04\n",
      "Epoch 828/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1201e-04 - val_loss: 7.1195e-04\n",
      "Epoch 829/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1195e-04 - val_loss: 7.1189e-04\n",
      "Epoch 830/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1189e-04 - val_loss: 7.1182e-04\n",
      "Epoch 831/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1182e-04 - val_loss: 7.1175e-04\n",
      "Epoch 832/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1175e-04 - val_loss: 7.1167e-04\n",
      "Epoch 833/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1167e-04 - val_loss: 7.1159e-04\n",
      "Epoch 834/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1159e-04 - val_loss: 7.1150e-04\n",
      "Epoch 835/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1150e-04 - val_loss: 7.1141e-04\n",
      "Epoch 836/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1141e-04 - val_loss: 7.1130e-04\n",
      "Epoch 837/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1130e-04 - val_loss: 7.1119e-04\n",
      "Epoch 838/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1119e-04 - val_loss: 7.1107e-04\n",
      "Epoch 839/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1107e-04 - val_loss: 7.1093e-04\n",
      "Epoch 840/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1093e-04 - val_loss: 7.1077e-04\n",
      "Epoch 841/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1077e-04 - val_loss: 7.1060e-04\n",
      "Epoch 842/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1060e-04 - val_loss: 7.1041e-04\n",
      "Epoch 843/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1041e-04 - val_loss: 7.1019e-04\n",
      "Epoch 844/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1019e-04 - val_loss: 7.0994e-04\n",
      "Epoch 845/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0994e-04 - val_loss: 7.0965e-04\n",
      "Epoch 846/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.0965e-04 - val_loss: 7.0931e-04\n",
      "Epoch 847/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0931e-04 - val_loss: 7.0892e-04\n",
      "Epoch 848/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.0892e-04 - val_loss: 7.0844e-04\n",
      "Epoch 849/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.0844e-04 - val_loss: 7.0787e-04\n",
      "Epoch 850/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0787e-04 - val_loss: 7.0718e-04\n",
      "Epoch 851/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0718e-04 - val_loss: 7.0632e-04\n",
      "Epoch 852/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0632e-04 - val_loss: 7.0525e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.0525e-04 - val_loss: 7.0390e-04\n",
      "Epoch 854/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.0390e-04 - val_loss: 7.0216e-04\n",
      "Epoch 855/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0216e-04 - val_loss: 6.9994e-04\n",
      "Epoch 856/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.9994e-04 - val_loss: 6.9707e-04\n",
      "Epoch 857/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 6.9707e-04 - val_loss: 6.9344e-04\n",
      "Epoch 858/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.9344e-04 - val_loss: 6.8894e-04\n",
      "Epoch 859/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.8894e-04 - val_loss: 6.8372e-04\n",
      "Epoch 860/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 6.8372e-04 - val_loss: 6.7852e-04\n",
      "Epoch 861/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 6.7852e-04 - val_loss: 6.7554e-04\n",
      "Epoch 862/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 6.7554e-04 - val_loss: 6.8865e-04\n",
      "Epoch 863/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 6.8865e-04 - val_loss: 0.0011\n",
      "Epoch 864/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 865/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 866/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 867/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.0010 - val_loss: 8.3454e-04\n",
      "Epoch 868/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 8.3454e-04 - val_loss: 7.7928e-04\n",
      "Epoch 869/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.7928e-04 - val_loss: 7.6302e-04\n",
      "Epoch 870/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.6302e-04 - val_loss: 7.5708e-04\n",
      "Epoch 871/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.5708e-04 - val_loss: 7.4853e-04\n",
      "Epoch 872/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4853e-04 - val_loss: 7.4984e-04\n",
      "Epoch 873/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4984e-04 - val_loss: 7.5138e-04\n",
      "Epoch 874/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.5138e-04 - val_loss: 7.4593e-04\n",
      "Epoch 875/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4593e-04 - val_loss: 7.4912e-04\n",
      "Epoch 876/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.4912e-04 - val_loss: 7.4807e-04\n",
      "Epoch 877/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.4807e-04 - val_loss: 7.4602e-04\n",
      "Epoch 878/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.4602e-04 - val_loss: 7.4916e-04\n",
      "Epoch 879/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.4916e-04 - val_loss: 7.4504e-04\n",
      "Epoch 880/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4504e-04 - val_loss: 7.4746e-04\n",
      "Epoch 881/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.4746e-04 - val_loss: 7.4512e-04\n",
      "Epoch 882/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.4512e-04 - val_loss: 7.4528e-04\n",
      "Epoch 883/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4528e-04 - val_loss: 7.4474e-04\n",
      "Epoch 884/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4474e-04 - val_loss: 7.4335e-04\n",
      "Epoch 885/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.4335e-04 - val_loss: 7.4365e-04\n",
      "Epoch 886/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.4365e-04 - val_loss: 7.4167e-04\n",
      "Epoch 887/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4167e-04 - val_loss: 7.4203e-04\n",
      "Epoch 888/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.4203e-04 - val_loss: 7.4015e-04\n",
      "Epoch 889/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4015e-04 - val_loss: 7.3993e-04\n",
      "Epoch 890/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.3993e-04 - val_loss: 7.3870e-04\n",
      "Epoch 891/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.3870e-04 - val_loss: 7.3733e-04\n",
      "Epoch 892/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3733e-04 - val_loss: 7.3738e-04\n",
      "Epoch 893/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3738e-04 - val_loss: 7.3485e-04\n",
      "Epoch 894/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3485e-04 - val_loss: 7.3503e-04\n",
      "Epoch 895/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.3503e-04 - val_loss: 7.3432e-04\n",
      "Epoch 896/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.3432e-04 - val_loss: 7.3202e-04\n",
      "Epoch 897/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.3202e-04 - val_loss: 7.3146e-04\n",
      "Epoch 898/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.3146e-04 - val_loss: 7.3247e-04\n",
      "Epoch 899/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.3247e-04 - val_loss: 7.3442e-04\n",
      "Epoch 900/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.3442e-04 - val_loss: 7.3996e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_5)\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.4553846153846154\n",
      "Probability of sampling a 0: 0.5446153846153846\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 650 samples, validate on 650 samples\n",
      "Epoch 1/900\n",
      "650/650 [==============================] - 6s 10ms/sample - loss: 0.6931 - binary_accuracy: 0.5077 - precision: 0.4615 - recall: 0.4865 - val_loss: 0.6922 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 0.6922 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6913 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6913 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6904 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6904 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6895 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6895 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6898 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 0.6898 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6900 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 0.6900 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6896 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6896 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6894 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6894 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6894 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6894 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 81/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 82/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 83/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 84/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 86/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 87/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 88/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 89/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 90/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 92/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 93/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 94/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 95/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 96/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 97/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 98/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 99/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 100/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 101/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 102/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 103/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 104/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 105/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 106/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 107/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 108/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 109/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 110/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 111/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 112/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 113/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 114/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 115/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 116/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 117/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 118/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 119/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 120/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 121/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 122/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 124/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 125/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 126/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 127/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5477 - val_precision: 1.0000 - val_recall: 0.0068\n",
      "Epoch 128/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6890 - binary_accuracy: 0.5477 - precision: 1.0000 - recall: 0.0068 - val_loss: 0.6890 - val_binary_accuracy: 0.5477 - val_precision: 1.0000 - val_recall: 0.0068\n",
      "Epoch 129/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6890 - binary_accuracy: 0.5477 - precision: 1.0000 - recall: 0.0068 - val_loss: 0.6890 - val_binary_accuracy: 0.5462 - val_precision: 0.6667 - val_recall: 0.0068\n",
      "Epoch 130/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6890 - binary_accuracy: 0.5462 - precision: 0.6667 - recall: 0.0068 - val_loss: 0.6889 - val_binary_accuracy: 0.5462 - val_precision: 0.6667 - val_recall: 0.0068\n",
      "Epoch 131/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6889 - binary_accuracy: 0.5462 - precision: 0.6667 - recall: 0.0068 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 132/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 133/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 134/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6888 - val_binary_accuracy: 0.5462 - val_precision: 0.5714 - val_recall: 0.0135\n",
      "Epoch 135/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6888 - binary_accuracy: 0.5462 - precision: 0.5714 - recall: 0.0135 - val_loss: 0.6888 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 136/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6888 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6888 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 137/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6888 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6887 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 138/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6887 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6887 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 139/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6887 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6886 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 140/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6886 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6886 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 141/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6886 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6885 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 142/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6885 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6884 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 143/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6884 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6883 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 144/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6883 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6882 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 145/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6882 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6881 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 146/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6881 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6879 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 147/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6879 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6877 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 148/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6877 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6875 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 149/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6875 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6872 - val_binary_accuracy: 0.5431 - val_precision: 0.4545 - val_recall: 0.0169\n",
      "Epoch 150/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6872 - binary_accuracy: 0.5431 - precision: 0.4545 - recall: 0.0169 - val_loss: 0.6869 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0236\n",
      "Epoch 151/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6869 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0236 - val_loss: 0.6866 - val_binary_accuracy: 0.5492 - val_precision: 0.5789 - val_recall: 0.0372\n",
      "Epoch 152/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6866 - binary_accuracy: 0.5492 - precision: 0.5789 - recall: 0.0372 - val_loss: 0.6867 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0270\n",
      "Epoch 153/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 0.6867 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0270 - val_loss: 0.6873 - val_binary_accuracy: 0.5292 - val_precision: 0.4324 - val_recall: 0.1081\n",
      "Epoch 154/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6873 - binary_accuracy: 0.5292 - precision: 0.4324 - recall: 0.1081 - val_loss: 0.6870 - val_binary_accuracy: 0.5538 - val_precision: 0.6154 - val_recall: 0.0541\n",
      "Epoch 155/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6870 - binary_accuracy: 0.5538 - precision: 0.6154 - recall: 0.0541 - val_loss: 0.6870 - val_binary_accuracy: 0.5508 - val_precision: 0.6000 - val_recall: 0.0405\n",
      "Epoch 156/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6870 - binary_accuracy: 0.5508 - precision: 0.6000 - recall: 0.0405 - val_loss: 0.6864 - val_binary_accuracy: 0.5600 - val_precision: 0.6667 - val_recall: 0.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6864 - binary_accuracy: 0.5600 - precision: 0.6667 - recall: 0.0676 - val_loss: 0.6863 - val_binary_accuracy: 0.5646 - val_precision: 0.7241 - val_recall: 0.0709\n",
      "Epoch 158/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6863 - binary_accuracy: 0.5646 - precision: 0.7241 - recall: 0.0709 - val_loss: 0.6862 - val_binary_accuracy: 0.5492 - val_precision: 0.5789 - val_recall: 0.0372\n",
      "Epoch 159/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6862 - binary_accuracy: 0.5492 - precision: 0.5789 - recall: 0.0372 - val_loss: 0.6861 - val_binary_accuracy: 0.5462 - val_precision: 0.5455 - val_recall: 0.0203\n",
      "Epoch 160/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6861 - binary_accuracy: 0.5462 - precision: 0.5455 - recall: 0.0203 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 161/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 162/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 163/900\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6860 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 164/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6860 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6859 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 165/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6859 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6859 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 166/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6859 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6857 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 167/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6857 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6856 - val_binary_accuracy: 0.5462 - val_precision: 0.5714 - val_recall: 0.0135\n",
      "Epoch 168/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6856 - binary_accuracy: 0.5462 - precision: 0.5714 - recall: 0.0135 - val_loss: 0.6855 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 169/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6855 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6853 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 170/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6853 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6851 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 171/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6851 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6850 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 172/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6850 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6849 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0135\n",
      "Epoch 173/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6849 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0135 - val_loss: 0.6847 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 174/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6847 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6844 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 175/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6844 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6842 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 176/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6842 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6840 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 177/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6840 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6838 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 178/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6838 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6836 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 179/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6836 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6833 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 180/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6833 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6831 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 181/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6831 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6829 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 182/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6829 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6827 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 183/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6827 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6827 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 184/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6827 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 185/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6822 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 186/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6822 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6820 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 187/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6820 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 188/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6818 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 189/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 190/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6814 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6875 - val_binary_accuracy: 0.5738 - val_precision: 0.7568 - val_recall: 0.0946\n",
      "Epoch 192/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6875 - binary_accuracy: 0.5738 - precision: 0.7568 - recall: 0.0946 - val_loss: 0.6830 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 193/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6830 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6889 - val_binary_accuracy: 0.5508 - val_precision: 0.8333 - val_recall: 0.0169\n",
      "Epoch 194/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6889 - binary_accuracy: 0.5508 - precision: 0.8333 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 195/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6814 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6845 - val_binary_accuracy: 0.5631 - val_precision: 0.7500 - val_recall: 0.0608\n",
      "Epoch 196/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6845 - binary_accuracy: 0.5631 - precision: 0.7500 - recall: 0.0608 - val_loss: 0.6830 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 197/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6830 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6815 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 198/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6815 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6823 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 199/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6823 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6833 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 200/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6833 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6828 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 201/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6828 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6819 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 202/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 0.6819 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 203/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6818 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 204/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6821 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 205/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6821 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 206/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6817 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 207/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 208/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 209/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6816 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 210/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6814 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 211/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 212/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6811 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 213/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6811 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6808 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 214/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6808 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 215/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 216/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 217/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 218/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 219/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6806 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 220/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6806 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 221/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6805 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 222/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 223/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 224/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 226/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 227/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 228/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 229/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 230/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 231/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 232/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 233/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 234/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 235/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 236/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6801 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 237/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 238/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 239/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 240/900\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 241/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 242/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 243/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 244/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6799 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 245/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6799 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5477 - val_precision: 0.6000 - val_recall: 0.0203\n",
      "Epoch 246/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6799 - binary_accuracy: 0.5477 - precision: 0.6000 - recall: 0.0203 - val_loss: 0.6798 - val_binary_accuracy: 0.5492 - val_precision: 0.6364 - val_recall: 0.0236\n",
      "Epoch 247/900\n",
      "650/650 [==============================] - 0s 92us/sample - loss: 0.6798 - binary_accuracy: 0.5492 - precision: 0.6364 - recall: 0.0236 - val_loss: 0.6798 - val_binary_accuracy: 0.5492 - val_precision: 0.6364 - val_recall: 0.0236\n",
      "Epoch 248/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6798 - binary_accuracy: 0.5492 - precision: 0.6364 - recall: 0.0236 - val_loss: 0.6797 - val_binary_accuracy: 0.5508 - val_precision: 0.6667 - val_recall: 0.0270\n",
      "Epoch 249/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 0.6797 - binary_accuracy: 0.5508 - precision: 0.6667 - recall: 0.0270 - val_loss: 0.6796 - val_binary_accuracy: 0.5508 - val_precision: 0.6667 - val_recall: 0.0270\n",
      "Epoch 250/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6796 - binary_accuracy: 0.5508 - precision: 0.6667 - recall: 0.0270 - val_loss: 0.6795 - val_binary_accuracy: 0.5554 - val_precision: 0.7333 - val_recall: 0.0372\n",
      "Epoch 251/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6795 - binary_accuracy: 0.5554 - precision: 0.7333 - recall: 0.0372 - val_loss: 0.6794 - val_binary_accuracy: 0.5585 - val_precision: 0.7647 - val_recall: 0.0439\n",
      "Epoch 252/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6794 - binary_accuracy: 0.5585 - precision: 0.7647 - recall: 0.0439 - val_loss: 0.6793 - val_binary_accuracy: 0.5569 - val_precision: 0.7222 - val_recall: 0.0439\n",
      "Epoch 253/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6793 - binary_accuracy: 0.5569 - precision: 0.7222 - recall: 0.0439 - val_loss: 0.6791 - val_binary_accuracy: 0.5569 - val_precision: 0.7222 - val_recall: 0.0439\n",
      "Epoch 254/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6791 - binary_accuracy: 0.5569 - precision: 0.7222 - recall: 0.0439 - val_loss: 0.6788 - val_binary_accuracy: 0.5554 - val_precision: 0.6842 - val_recall: 0.0439\n",
      "Epoch 255/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6788 - binary_accuracy: 0.5554 - precision: 0.6842 - recall: 0.0439 - val_loss: 0.6785 - val_binary_accuracy: 0.5569 - val_precision: 0.6538 - val_recall: 0.0574\n",
      "Epoch 256/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6785 - binary_accuracy: 0.5569 - precision: 0.6538 - recall: 0.0574 - val_loss: 0.6781 - val_binary_accuracy: 0.5600 - val_precision: 0.6786 - val_recall: 0.0642\n",
      "Epoch 257/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 0.6781 - binary_accuracy: 0.5600 - precision: 0.6786 - recall: 0.0642 - val_loss: 0.6776 - val_binary_accuracy: 0.5569 - val_precision: 0.6250 - val_recall: 0.0676\n",
      "Epoch 258/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6776 - binary_accuracy: 0.5569 - precision: 0.6250 - recall: 0.0676 - val_loss: 0.6769 - val_binary_accuracy: 0.5615 - val_precision: 0.6571 - val_recall: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6769 - binary_accuracy: 0.5615 - precision: 0.6571 - recall: 0.0777 - val_loss: 0.6763 - val_binary_accuracy: 0.5662 - val_precision: 0.6944 - val_recall: 0.0845\n",
      "Epoch 260/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6763 - binary_accuracy: 0.5662 - precision: 0.6944 - recall: 0.0845 - val_loss: 0.6769 - val_binary_accuracy: 0.5815 - val_precision: 0.7000 - val_recall: 0.1419\n",
      "Epoch 261/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6769 - binary_accuracy: 0.5815 - precision: 0.7000 - recall: 0.1419 - val_loss: 0.6769 - val_binary_accuracy: 0.5554 - val_precision: 0.5507 - val_recall: 0.1284\n",
      "Epoch 262/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6769 - binary_accuracy: 0.5554 - precision: 0.5507 - recall: 0.1284 - val_loss: 0.6829 - val_binary_accuracy: 0.5462 - val_precision: 0.5028 - val_recall: 0.3007\n",
      "Epoch 263/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6829 - binary_accuracy: 0.5462 - precision: 0.5028 - recall: 0.3007 - val_loss: 0.6788 - val_binary_accuracy: 0.5646 - val_precision: 0.7097 - val_recall: 0.0743\n",
      "Epoch 264/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6788 - binary_accuracy: 0.5646 - precision: 0.7097 - recall: 0.0743 - val_loss: 0.7089 - val_binary_accuracy: 0.4492 - val_precision: 0.4460 - val_recall: 0.8649\n",
      "Epoch 265/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.7089 - binary_accuracy: 0.4492 - precision: 0.4460 - recall: 0.8649 - val_loss: 0.6807 - val_binary_accuracy: 0.5415 - val_precision: 0.4889 - val_recall: 0.1486\n",
      "Epoch 266/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6807 - binary_accuracy: 0.5415 - precision: 0.4889 - recall: 0.1486 - val_loss: 0.6934 - val_binary_accuracy: 0.5677 - val_precision: 0.8947 - val_recall: 0.0574\n",
      "Epoch 267/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6934 - binary_accuracy: 0.5677 - precision: 0.8947 - recall: 0.0574 - val_loss: 0.6847 - val_binary_accuracy: 0.5738 - val_precision: 0.7436 - val_recall: 0.0980\n",
      "Epoch 268/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6847 - binary_accuracy: 0.5738 - precision: 0.7436 - recall: 0.0980 - val_loss: 0.6819 - val_binary_accuracy: 0.5631 - val_precision: 0.5938 - val_recall: 0.1284\n",
      "Epoch 269/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6819 - binary_accuracy: 0.5631 - precision: 0.5938 - recall: 0.1284 - val_loss: 0.6819 - val_binary_accuracy: 0.5662 - val_precision: 0.6167 - val_recall: 0.1250\n",
      "Epoch 270/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6819 - binary_accuracy: 0.5662 - precision: 0.6167 - recall: 0.1250 - val_loss: 0.6879 - val_binary_accuracy: 0.5677 - val_precision: 0.7419 - val_recall: 0.0777\n",
      "Epoch 271/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 0.6879 - binary_accuracy: 0.5677 - precision: 0.7419 - recall: 0.0777 - val_loss: 0.6825 - val_binary_accuracy: 0.5677 - val_precision: 0.8000 - val_recall: 0.0676\n",
      "Epoch 272/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6825 - binary_accuracy: 0.5677 - precision: 0.8000 - recall: 0.0676 - val_loss: 0.6804 - val_binary_accuracy: 0.5662 - val_precision: 0.7692 - val_recall: 0.0676\n",
      "Epoch 273/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5662 - precision: 0.7692 - recall: 0.0676 - val_loss: 0.6804 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 274/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6806 - val_binary_accuracy: 0.5538 - val_precision: 0.8000 - val_recall: 0.0270\n",
      "Epoch 275/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6806 - binary_accuracy: 0.5538 - precision: 0.8000 - recall: 0.0270 - val_loss: 0.6809 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 276/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6809 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6813 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 277/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6813 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 278/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 279/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 280/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 281/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 282/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6818 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 283/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6815 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 284/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6815 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6813 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 285/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6813 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 286/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6811 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6809 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 287/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6809 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6808 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 288/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6808 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6806 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 289/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6806 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 290/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6804 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 291/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 292/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6800 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6798 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/900\n",
      "650/650 [==============================] - 0s 95us/sample - loss: 0.6798 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6797 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 294/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 0.6797 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6796 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 295/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6796 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6795 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 296/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6795 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6794 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 297/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6794 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6793 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 298/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6793 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6792 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 299/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6792 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6792 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 300/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6792 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6791 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 301/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6791 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6788 - val_binary_accuracy: 0.5538 - val_precision: 0.8000 - val_recall: 0.0270\n",
      "Epoch 302/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6788 - binary_accuracy: 0.5538 - precision: 0.8000 - recall: 0.0270 - val_loss: 0.6787 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 303/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6787 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6785 - val_binary_accuracy: 0.5631 - val_precision: 0.8750 - val_recall: 0.0473\n",
      "Epoch 304/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6785 - binary_accuracy: 0.5631 - precision: 0.8750 - recall: 0.0473 - val_loss: 0.6783 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 305/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6783 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6781 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 306/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6781 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6779 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 307/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6779 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6775 - val_binary_accuracy: 0.5677 - val_precision: 0.8261 - val_recall: 0.0642\n",
      "Epoch 308/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6775 - binary_accuracy: 0.5677 - precision: 0.8261 - recall: 0.0642 - val_loss: 0.6771 - val_binary_accuracy: 0.5692 - val_precision: 0.7857 - val_recall: 0.0743\n",
      "Epoch 309/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6771 - binary_accuracy: 0.5692 - precision: 0.7857 - recall: 0.0743 - val_loss: 0.6769 - val_binary_accuracy: 0.5662 - val_precision: 0.6842 - val_recall: 0.0878\n",
      "Epoch 310/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6769 - binary_accuracy: 0.5662 - precision: 0.6842 - recall: 0.0878 - val_loss: 0.6762 - val_binary_accuracy: 0.5662 - val_precision: 0.7059 - val_recall: 0.0811\n",
      "Epoch 311/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6762 - binary_accuracy: 0.5662 - precision: 0.7059 - recall: 0.0811 - val_loss: 0.6757 - val_binary_accuracy: 0.5677 - val_precision: 0.7586 - val_recall: 0.0743\n",
      "Epoch 312/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6757 - binary_accuracy: 0.5677 - precision: 0.7586 - recall: 0.0743 - val_loss: 0.6753 - val_binary_accuracy: 0.5723 - val_precision: 0.8214 - val_recall: 0.0777\n",
      "Epoch 313/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6753 - binary_accuracy: 0.5723 - precision: 0.8214 - recall: 0.0777 - val_loss: 0.6747 - val_binary_accuracy: 0.5600 - val_precision: 0.6316 - val_recall: 0.0811\n",
      "Epoch 314/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 0.6747 - binary_accuracy: 0.5600 - precision: 0.6316 - recall: 0.0811 - val_loss: 0.6743 - val_binary_accuracy: 0.5754 - val_precision: 0.7083 - val_recall: 0.1149\n",
      "Epoch 315/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6743 - binary_accuracy: 0.5754 - precision: 0.7083 - recall: 0.1149 - val_loss: 0.6737 - val_binary_accuracy: 0.5677 - val_precision: 0.6744 - val_recall: 0.0980\n",
      "Epoch 316/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6737 - binary_accuracy: 0.5677 - precision: 0.6744 - recall: 0.0980 - val_loss: 0.6733 - val_binary_accuracy: 0.5646 - val_precision: 0.6585 - val_recall: 0.0912\n",
      "Epoch 317/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6733 - binary_accuracy: 0.5646 - precision: 0.6585 - recall: 0.0912 - val_loss: 0.6726 - val_binary_accuracy: 0.5692 - val_precision: 0.6818 - val_recall: 0.1014\n",
      "Epoch 318/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6726 - binary_accuracy: 0.5692 - precision: 0.6818 - recall: 0.1014 - val_loss: 0.6722 - val_binary_accuracy: 0.5846 - val_precision: 0.7031 - val_recall: 0.1520\n",
      "Epoch 319/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6722 - binary_accuracy: 0.5846 - precision: 0.7031 - recall: 0.1520 - val_loss: 0.6715 - val_binary_accuracy: 0.5862 - val_precision: 0.7368 - val_recall: 0.1419\n",
      "Epoch 320/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6715 - binary_accuracy: 0.5862 - precision: 0.7368 - recall: 0.1419 - val_loss: 0.6710 - val_binary_accuracy: 0.5831 - val_precision: 0.7358 - val_recall: 0.1318\n",
      "Epoch 321/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6710 - binary_accuracy: 0.5831 - precision: 0.7358 - recall: 0.1318 - val_loss: 0.6704 - val_binary_accuracy: 0.5908 - val_precision: 0.7206 - val_recall: 0.1655\n",
      "Epoch 322/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6704 - binary_accuracy: 0.5908 - precision: 0.7206 - recall: 0.1655 - val_loss: 0.6696 - val_binary_accuracy: 0.5862 - val_precision: 0.7077 - val_recall: 0.1554\n",
      "Epoch 323/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6696 - binary_accuracy: 0.5862 - precision: 0.7077 - recall: 0.1554 - val_loss: 0.6690 - val_binary_accuracy: 0.5846 - val_precision: 0.6912 - val_recall: 0.1588\n",
      "Epoch 324/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6690 - binary_accuracy: 0.5846 - precision: 0.6912 - recall: 0.1588 - val_loss: 0.6685 - val_binary_accuracy: 0.5785 - val_precision: 0.6410 - val_recall: 0.1689\n",
      "Epoch 325/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6685 - binary_accuracy: 0.5785 - precision: 0.6410 - recall: 0.1689 - val_loss: 0.6689 - val_binary_accuracy: 0.5662 - val_precision: 0.5946 - val_recall: 0.1486\n",
      "Epoch 326/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6689 - binary_accuracy: 0.5662 - precision: 0.5946 - recall: 0.1486 - val_loss: 0.6717 - val_binary_accuracy: 0.5646 - val_precision: 0.5644 - val_recall: 0.1926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6717 - binary_accuracy: 0.5646 - precision: 0.5644 - recall: 0.1926 - val_loss: 0.6794 - val_binary_accuracy: 0.5523 - val_precision: 0.5126 - val_recall: 0.3446\n",
      "Epoch 328/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6794 - binary_accuracy: 0.5523 - precision: 0.5126 - recall: 0.3446 - val_loss: 0.6763 - val_binary_accuracy: 0.5585 - val_precision: 0.5584 - val_recall: 0.1453\n",
      "Epoch 329/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6763 - binary_accuracy: 0.5585 - precision: 0.5584 - recall: 0.1453 - val_loss: 0.6715 - val_binary_accuracy: 0.5785 - val_precision: 0.6250 - val_recall: 0.1858\n",
      "Epoch 330/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6715 - binary_accuracy: 0.5785 - precision: 0.6250 - recall: 0.1858 - val_loss: 0.6685 - val_binary_accuracy: 0.5708 - val_precision: 0.5714 - val_recall: 0.2297\n",
      "Epoch 331/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6685 - binary_accuracy: 0.5708 - precision: 0.5714 - recall: 0.2297 - val_loss: 0.6747 - val_binary_accuracy: 0.5631 - val_precision: 0.5275 - val_recall: 0.3885\n",
      "Epoch 332/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6747 - binary_accuracy: 0.5631 - precision: 0.5275 - recall: 0.3885 - val_loss: 0.6708 - val_binary_accuracy: 0.5708 - val_precision: 0.6308 - val_recall: 0.1385\n",
      "Epoch 333/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6708 - binary_accuracy: 0.5708 - precision: 0.6308 - recall: 0.1385 - val_loss: 0.6690 - val_binary_accuracy: 0.5846 - val_precision: 0.6757 - val_recall: 0.1689\n",
      "Epoch 334/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6690 - binary_accuracy: 0.5846 - precision: 0.6757 - recall: 0.1689 - val_loss: 0.6734 - val_binary_accuracy: 0.5723 - val_precision: 0.5776 - val_recall: 0.2264\n",
      "Epoch 335/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6734 - binary_accuracy: 0.5723 - precision: 0.5776 - recall: 0.2264 - val_loss: 0.6701 - val_binary_accuracy: 0.5738 - val_precision: 0.6792 - val_recall: 0.1216\n",
      "Epoch 336/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6701 - binary_accuracy: 0.5738 - precision: 0.6792 - recall: 0.1216 - val_loss: 0.6757 - val_binary_accuracy: 0.5538 - val_precision: 0.5294 - val_recall: 0.1824\n",
      "Epoch 337/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6757 - binary_accuracy: 0.5538 - precision: 0.5294 - recall: 0.1824 - val_loss: 0.6728 - val_binary_accuracy: 0.5692 - val_precision: 0.6081 - val_recall: 0.1520\n",
      "Epoch 338/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6728 - binary_accuracy: 0.5692 - precision: 0.6081 - recall: 0.1520 - val_loss: 0.6665 - val_binary_accuracy: 0.5723 - val_precision: 0.6500 - val_recall: 0.1318\n",
      "Epoch 339/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6665 - binary_accuracy: 0.5723 - precision: 0.6500 - recall: 0.1318 - val_loss: 0.6735 - val_binary_accuracy: 0.5754 - val_precision: 0.5893 - val_recall: 0.2230\n",
      "Epoch 340/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6735 - binary_accuracy: 0.5754 - precision: 0.5893 - recall: 0.2230 - val_loss: 0.6674 - val_binary_accuracy: 0.5846 - val_precision: 0.7031 - val_recall: 0.1520\n",
      "Epoch 341/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6674 - binary_accuracy: 0.5846 - precision: 0.7031 - recall: 0.1520 - val_loss: 0.6685 - val_binary_accuracy: 0.5831 - val_precision: 0.8049 - val_recall: 0.1115\n",
      "Epoch 342/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6685 - binary_accuracy: 0.5831 - precision: 0.8049 - recall: 0.1115 - val_loss: 0.6699 - val_binary_accuracy: 0.5692 - val_precision: 0.6600 - val_recall: 0.1115\n",
      "Epoch 343/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6699 - binary_accuracy: 0.5692 - precision: 0.6600 - recall: 0.1115 - val_loss: 0.6692 - val_binary_accuracy: 0.5846 - val_precision: 0.6857 - val_recall: 0.1622\n",
      "Epoch 344/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6692 - binary_accuracy: 0.5846 - precision: 0.6857 - recall: 0.1622 - val_loss: 0.6679 - val_binary_accuracy: 0.5692 - val_precision: 0.5909 - val_recall: 0.1757\n",
      "Epoch 345/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6679 - binary_accuracy: 0.5692 - precision: 0.5909 - recall: 0.1757 - val_loss: 0.6682 - val_binary_accuracy: 0.5769 - val_precision: 0.6235 - val_recall: 0.1791\n",
      "Epoch 346/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6682 - binary_accuracy: 0.5769 - precision: 0.6235 - recall: 0.1791 - val_loss: 0.6667 - val_binary_accuracy: 0.5754 - val_precision: 0.6724 - val_recall: 0.1318\n",
      "Epoch 347/900\n",
      "650/650 [==============================] - 0s 165us/sample - loss: 0.6667 - binary_accuracy: 0.5754 - precision: 0.6724 - recall: 0.1318 - val_loss: 0.6670 - val_binary_accuracy: 0.5923 - val_precision: 0.8444 - val_recall: 0.1284\n",
      "Epoch 348/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6670 - binary_accuracy: 0.5923 - precision: 0.8444 - recall: 0.1284 - val_loss: 0.6651 - val_binary_accuracy: 0.5846 - val_precision: 0.7500 - val_recall: 0.1318\n",
      "Epoch 349/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6651 - binary_accuracy: 0.5846 - precision: 0.7500 - recall: 0.1318 - val_loss: 0.6644 - val_binary_accuracy: 0.5646 - val_precision: 0.5747 - val_recall: 0.1689\n",
      "Epoch 350/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6644 - binary_accuracy: 0.5646 - precision: 0.5747 - recall: 0.1689 - val_loss: 0.6647 - val_binary_accuracy: 0.5646 - val_precision: 0.5565 - val_recall: 0.2162\n",
      "Epoch 351/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6647 - binary_accuracy: 0.5646 - precision: 0.5565 - recall: 0.2162 - val_loss: 0.6633 - val_binary_accuracy: 0.5738 - val_precision: 0.6067 - val_recall: 0.1824\n",
      "Epoch 352/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6633 - binary_accuracy: 0.5738 - precision: 0.6067 - recall: 0.1824 - val_loss: 0.6625 - val_binary_accuracy: 0.5754 - val_precision: 0.6667 - val_recall: 0.1351\n",
      "Epoch 353/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6625 - binary_accuracy: 0.5754 - precision: 0.6667 - recall: 0.1351 - val_loss: 0.6633 - val_binary_accuracy: 0.5877 - val_precision: 0.7917 - val_recall: 0.1284\n",
      "Epoch 354/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6633 - binary_accuracy: 0.5877 - precision: 0.7917 - recall: 0.1284 - val_loss: 0.6622 - val_binary_accuracy: 0.5831 - val_precision: 0.7451 - val_recall: 0.1284\n",
      "Epoch 355/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6622 - binary_accuracy: 0.5831 - precision: 0.7451 - recall: 0.1284 - val_loss: 0.6610 - val_binary_accuracy: 0.5677 - val_precision: 0.6027 - val_recall: 0.1486\n",
      "Epoch 356/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6610 - binary_accuracy: 0.5677 - precision: 0.6027 - recall: 0.1486 - val_loss: 0.6613 - val_binary_accuracy: 0.5708 - val_precision: 0.5825 - val_recall: 0.2027\n",
      "Epoch 357/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6613 - binary_accuracy: 0.5708 - precision: 0.5825 - recall: 0.2027 - val_loss: 0.6610 - val_binary_accuracy: 0.5677 - val_precision: 0.5701 - val_recall: 0.2061\n",
      "Epoch 358/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6610 - binary_accuracy: 0.5677 - precision: 0.5701 - recall: 0.2061 - val_loss: 0.6602 - val_binary_accuracy: 0.5769 - val_precision: 0.6400 - val_recall: 0.1622\n",
      "Epoch 359/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6602 - binary_accuracy: 0.5769 - precision: 0.6400 - recall: 0.1622 - val_loss: 0.6599 - val_binary_accuracy: 0.5800 - val_precision: 0.7018 - val_recall: 0.1351\n",
      "Epoch 360/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6599 - binary_accuracy: 0.5800 - precision: 0.7018 - recall: 0.1351 - val_loss: 0.6601 - val_binary_accuracy: 0.5738 - val_precision: 0.6610 - val_recall: 0.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.6601 - binary_accuracy: 0.5738 - precision: 0.6610 - recall: 0.1318 - val_loss: 0.6592 - val_binary_accuracy: 0.5754 - val_precision: 0.6515 - val_recall: 0.1453\n",
      "Epoch 362/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6592 - binary_accuracy: 0.5754 - precision: 0.6515 - recall: 0.1453 - val_loss: 0.6589 - val_binary_accuracy: 0.5723 - val_precision: 0.6098 - val_recall: 0.1689\n",
      "Epoch 363/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6589 - binary_accuracy: 0.5723 - precision: 0.6098 - recall: 0.1689 - val_loss: 0.6588 - val_binary_accuracy: 0.5723 - val_precision: 0.5918 - val_recall: 0.1959\n",
      "Epoch 364/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.6588 - binary_accuracy: 0.5723 - precision: 0.5918 - recall: 0.1959 - val_loss: 0.6584 - val_binary_accuracy: 0.5677 - val_precision: 0.5862 - val_recall: 0.1723\n",
      "Epoch 365/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6584 - binary_accuracy: 0.5677 - precision: 0.5862 - recall: 0.1723 - val_loss: 0.6578 - val_binary_accuracy: 0.5785 - val_precision: 0.6719 - val_recall: 0.1453\n",
      "Epoch 366/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6578 - binary_accuracy: 0.5785 - precision: 0.6719 - recall: 0.1453 - val_loss: 0.6578 - val_binary_accuracy: 0.5800 - val_precision: 0.6825 - val_recall: 0.1453\n",
      "Epoch 367/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6578 - binary_accuracy: 0.5800 - precision: 0.6825 - recall: 0.1453 - val_loss: 0.6573 - val_binary_accuracy: 0.5785 - val_precision: 0.6719 - val_recall: 0.1453\n",
      "Epoch 368/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6573 - binary_accuracy: 0.5785 - precision: 0.6719 - recall: 0.1453 - val_loss: 0.6569 - val_binary_accuracy: 0.5708 - val_precision: 0.6232 - val_recall: 0.1453\n",
      "Epoch 369/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6569 - binary_accuracy: 0.5708 - precision: 0.6232 - recall: 0.1453 - val_loss: 0.6567 - val_binary_accuracy: 0.5754 - val_precision: 0.6163 - val_recall: 0.1791\n",
      "Epoch 370/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6567 - binary_accuracy: 0.5754 - precision: 0.6163 - recall: 0.1791 - val_loss: 0.6562 - val_binary_accuracy: 0.5785 - val_precision: 0.6250 - val_recall: 0.1858\n",
      "Epoch 371/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6562 - binary_accuracy: 0.5785 - precision: 0.6250 - recall: 0.1858 - val_loss: 0.6557 - val_binary_accuracy: 0.5785 - val_precision: 0.6486 - val_recall: 0.1622\n",
      "Epoch 372/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6557 - binary_accuracy: 0.5785 - precision: 0.6486 - recall: 0.1622 - val_loss: 0.6554 - val_binary_accuracy: 0.5785 - val_precision: 0.6667 - val_recall: 0.1486\n",
      "Epoch 373/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6554 - binary_accuracy: 0.5785 - precision: 0.6667 - recall: 0.1486 - val_loss: 0.6551 - val_binary_accuracy: 0.5785 - val_precision: 0.6486 - val_recall: 0.1622\n",
      "Epoch 374/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6551 - binary_accuracy: 0.5785 - precision: 0.6486 - recall: 0.1622 - val_loss: 0.6546 - val_binary_accuracy: 0.5785 - val_precision: 0.6375 - val_recall: 0.1723\n",
      "Epoch 375/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6546 - binary_accuracy: 0.5785 - precision: 0.6375 - recall: 0.1723 - val_loss: 0.6543 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 376/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6543 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6540 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 377/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6540 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6537 - val_binary_accuracy: 0.5800 - val_precision: 0.6533 - val_recall: 0.1655\n",
      "Epoch 378/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6537 - binary_accuracy: 0.5800 - precision: 0.6533 - recall: 0.1655 - val_loss: 0.6533 - val_binary_accuracy: 0.5738 - val_precision: 0.6338 - val_recall: 0.1520\n",
      "Epoch 379/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6533 - binary_accuracy: 0.5738 - precision: 0.6338 - recall: 0.1520 - val_loss: 0.6530 - val_binary_accuracy: 0.5815 - val_precision: 0.6463 - val_recall: 0.1791\n",
      "Epoch 380/900\n",
      "650/650 [==============================] - 0s 149us/sample - loss: 0.6530 - binary_accuracy: 0.5815 - precision: 0.6463 - recall: 0.1791 - val_loss: 0.6528 - val_binary_accuracy: 0.5800 - val_precision: 0.6353 - val_recall: 0.1824\n",
      "Epoch 381/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6528 - binary_accuracy: 0.5800 - precision: 0.6353 - recall: 0.1824 - val_loss: 0.6525 - val_binary_accuracy: 0.5769 - val_precision: 0.6207 - val_recall: 0.1824\n",
      "Epoch 382/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6525 - binary_accuracy: 0.5769 - precision: 0.6207 - recall: 0.1824 - val_loss: 0.6522 - val_binary_accuracy: 0.5723 - val_precision: 0.6286 - val_recall: 0.1486\n",
      "Epoch 383/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6522 - binary_accuracy: 0.5723 - precision: 0.6286 - recall: 0.1486 - val_loss: 0.6519 - val_binary_accuracy: 0.5723 - val_precision: 0.6286 - val_recall: 0.1486\n",
      "Epoch 384/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6519 - binary_accuracy: 0.5723 - precision: 0.6286 - recall: 0.1486 - val_loss: 0.6515 - val_binary_accuracy: 0.5769 - val_precision: 0.6207 - val_recall: 0.1824\n",
      "Epoch 385/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6515 - binary_accuracy: 0.5769 - precision: 0.6207 - recall: 0.1824 - val_loss: 0.6513 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 386/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6513 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6511 - val_binary_accuracy: 0.5846 - val_precision: 0.6300 - val_recall: 0.2128\n",
      "Epoch 387/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6511 - binary_accuracy: 0.5846 - precision: 0.6300 - recall: 0.2128 - val_loss: 0.6511 - val_binary_accuracy: 0.5815 - val_precision: 0.6622 - val_recall: 0.1655\n",
      "Epoch 388/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6511 - binary_accuracy: 0.5815 - precision: 0.6622 - recall: 0.1655 - val_loss: 0.6529 - val_binary_accuracy: 0.5769 - val_precision: 0.5981 - val_recall: 0.2162\n",
      "Epoch 389/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6529 - binary_accuracy: 0.5769 - precision: 0.5981 - recall: 0.2162 - val_loss: 0.6619 - val_binary_accuracy: 0.5646 - val_precision: 0.5783 - val_recall: 0.1622\n",
      "Epoch 390/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6619 - binary_accuracy: 0.5646 - precision: 0.5783 - recall: 0.1622 - val_loss: 0.6787 - val_binary_accuracy: 0.5462 - val_precision: 0.5021 - val_recall: 0.4122\n",
      "Epoch 391/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6787 - binary_accuracy: 0.5462 - precision: 0.5021 - recall: 0.4122 - val_loss: 0.6927 - val_binary_accuracy: 0.5415 - val_precision: 0.4762 - val_recall: 0.0676\n",
      "Epoch 392/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6927 - binary_accuracy: 0.5415 - precision: 0.4762 - recall: 0.0676 - val_loss: 0.6963 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 393/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6963 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6831 - val_binary_accuracy: 0.5800 - val_precision: 0.7949 - val_recall: 0.1047\n",
      "Epoch 394/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6831 - binary_accuracy: 0.5800 - precision: 0.7949 - recall: 0.1047 - val_loss: 0.6784 - val_binary_accuracy: 0.5569 - val_precision: 0.5217 - val_recall: 0.3243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6784 - binary_accuracy: 0.5569 - precision: 0.5217 - recall: 0.3243 - val_loss: 0.6788 - val_binary_accuracy: 0.5738 - val_precision: 0.5503 - val_recall: 0.3514\n",
      "Epoch 396/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6788 - binary_accuracy: 0.5738 - precision: 0.5503 - recall: 0.3514 - val_loss: 0.6749 - val_binary_accuracy: 0.5877 - val_precision: 0.7333 - val_recall: 0.1486\n",
      "Epoch 397/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6749 - binary_accuracy: 0.5877 - precision: 0.7333 - recall: 0.1486 - val_loss: 0.6740 - val_binary_accuracy: 0.5785 - val_precision: 0.6833 - val_recall: 0.1385\n",
      "Epoch 398/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6740 - binary_accuracy: 0.5785 - precision: 0.6833 - recall: 0.1385 - val_loss: 0.6740 - val_binary_accuracy: 0.5754 - val_precision: 0.6562 - val_recall: 0.1419\n",
      "Epoch 399/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6740 - binary_accuracy: 0.5754 - precision: 0.6562 - recall: 0.1419 - val_loss: 0.6725 - val_binary_accuracy: 0.5785 - val_precision: 0.6833 - val_recall: 0.1385\n",
      "Epoch 400/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6725 - binary_accuracy: 0.5785 - precision: 0.6833 - recall: 0.1385 - val_loss: 0.6701 - val_binary_accuracy: 0.5831 - val_precision: 0.7119 - val_recall: 0.1419\n",
      "Epoch 401/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6701 - binary_accuracy: 0.5831 - precision: 0.7119 - recall: 0.1419 - val_loss: 0.6686 - val_binary_accuracy: 0.5831 - val_precision: 0.6667 - val_recall: 0.1689\n",
      "Epoch 402/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6686 - binary_accuracy: 0.5831 - precision: 0.6667 - recall: 0.1689 - val_loss: 0.6680 - val_binary_accuracy: 0.5708 - val_precision: 0.5876 - val_recall: 0.1926\n",
      "Epoch 403/900\n",
      "650/650 [==============================] - 0s 165us/sample - loss: 0.6680 - binary_accuracy: 0.5708 - precision: 0.5876 - recall: 0.1926 - val_loss: 0.6683 - val_binary_accuracy: 0.5785 - val_precision: 0.6078 - val_recall: 0.2095\n",
      "Epoch 404/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.6683 - binary_accuracy: 0.5785 - precision: 0.6078 - recall: 0.2095 - val_loss: 0.6670 - val_binary_accuracy: 0.5615 - val_precision: 0.5679 - val_recall: 0.1554\n",
      "Epoch 405/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6670 - binary_accuracy: 0.5615 - precision: 0.5679 - recall: 0.1554 - val_loss: 0.6653 - val_binary_accuracy: 0.5815 - val_precision: 0.6818 - val_recall: 0.1520\n",
      "Epoch 406/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6653 - binary_accuracy: 0.5815 - precision: 0.6818 - recall: 0.1520 - val_loss: 0.6679 - val_binary_accuracy: 0.5831 - val_precision: 0.6623 - val_recall: 0.1723\n",
      "Epoch 407/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6679 - binary_accuracy: 0.5831 - precision: 0.6623 - recall: 0.1723 - val_loss: 0.6659 - val_binary_accuracy: 0.5785 - val_precision: 0.6571 - val_recall: 0.1554\n",
      "Epoch 408/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6659 - binary_accuracy: 0.5785 - precision: 0.6571 - recall: 0.1554 - val_loss: 0.6667 - val_binary_accuracy: 0.5615 - val_precision: 0.5632 - val_recall: 0.1655\n",
      "Epoch 409/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6667 - binary_accuracy: 0.5615 - precision: 0.5632 - recall: 0.1655 - val_loss: 0.6649 - val_binary_accuracy: 0.5662 - val_precision: 0.5686 - val_recall: 0.1959\n",
      "Epoch 410/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6649 - binary_accuracy: 0.5662 - precision: 0.5686 - recall: 0.1959 - val_loss: 0.6649 - val_binary_accuracy: 0.5677 - val_precision: 0.5610 - val_recall: 0.2331\n",
      "Epoch 411/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6649 - binary_accuracy: 0.5677 - precision: 0.5610 - recall: 0.2331 - val_loss: 0.6651 - val_binary_accuracy: 0.5954 - val_precision: 0.5873 - val_recall: 0.3750\n",
      "Epoch 412/900\n",
      "650/650 [==============================] - 0s 149us/sample - loss: 0.6651 - binary_accuracy: 0.5954 - precision: 0.5873 - recall: 0.3750 - val_loss: 0.6627 - val_binary_accuracy: 0.5754 - val_precision: 0.5909 - val_recall: 0.2196\n",
      "Epoch 413/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6627 - binary_accuracy: 0.5754 - precision: 0.5909 - recall: 0.2196 - val_loss: 0.6627 - val_binary_accuracy: 0.5769 - val_precision: 0.6105 - val_recall: 0.1959\n",
      "Epoch 414/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6627 - binary_accuracy: 0.5769 - precision: 0.6105 - recall: 0.1959 - val_loss: 0.6629 - val_binary_accuracy: 0.5585 - val_precision: 0.5366 - val_recall: 0.2230\n",
      "Epoch 415/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6629 - binary_accuracy: 0.5585 - precision: 0.5366 - recall: 0.2230 - val_loss: 0.6616 - val_binary_accuracy: 0.5738 - val_precision: 0.6044 - val_recall: 0.1858\n",
      "Epoch 416/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6616 - binary_accuracy: 0.5738 - precision: 0.6044 - recall: 0.1858 - val_loss: 0.6631 - val_binary_accuracy: 0.5815 - val_precision: 0.6395 - val_recall: 0.1858\n",
      "Epoch 417/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6631 - binary_accuracy: 0.5815 - precision: 0.6395 - recall: 0.1858 - val_loss: 0.6617 - val_binary_accuracy: 0.5862 - val_precision: 0.5860 - val_recall: 0.3108\n",
      "Epoch 418/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6617 - binary_accuracy: 0.5862 - precision: 0.5860 - recall: 0.3108 - val_loss: 0.6601 - val_binary_accuracy: 0.5738 - val_precision: 0.5922 - val_recall: 0.2061\n",
      "Epoch 419/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6601 - binary_accuracy: 0.5738 - precision: 0.5922 - recall: 0.2061 - val_loss: 0.6608 - val_binary_accuracy: 0.5785 - val_precision: 0.6100 - val_recall: 0.2061\n",
      "Epoch 420/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.6608 - binary_accuracy: 0.5785 - precision: 0.6100 - recall: 0.2061 - val_loss: 0.6605 - val_binary_accuracy: 0.5892 - val_precision: 0.5819 - val_recall: 0.3480\n",
      "Epoch 421/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6605 - binary_accuracy: 0.5892 - precision: 0.5819 - recall: 0.3480 - val_loss: 0.6582 - val_binary_accuracy: 0.5662 - val_precision: 0.5714 - val_recall: 0.1892\n",
      "Epoch 422/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6582 - binary_accuracy: 0.5662 - precision: 0.5714 - recall: 0.1892 - val_loss: 0.6580 - val_binary_accuracy: 0.5754 - val_precision: 0.6163 - val_recall: 0.1791\n",
      "Epoch 423/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6580 - binary_accuracy: 0.5754 - precision: 0.6163 - recall: 0.1791 - val_loss: 0.6581 - val_binary_accuracy: 0.5646 - val_precision: 0.5489 - val_recall: 0.2466\n",
      "Epoch 424/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6581 - binary_accuracy: 0.5646 - precision: 0.5489 - recall: 0.2466 - val_loss: 0.6569 - val_binary_accuracy: 0.5662 - val_precision: 0.5875 - val_recall: 0.1588\n",
      "Epoch 425/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6569 - binary_accuracy: 0.5662 - precision: 0.5875 - recall: 0.1588 - val_loss: 0.6560 - val_binary_accuracy: 0.5723 - val_precision: 0.6098 - val_recall: 0.1689\n",
      "Epoch 426/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6560 - binary_accuracy: 0.5723 - precision: 0.6098 - recall: 0.1689 - val_loss: 0.6558 - val_binary_accuracy: 0.5754 - val_precision: 0.5746 - val_recall: 0.2601\n",
      "Epoch 427/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6558 - binary_accuracy: 0.5754 - precision: 0.5746 - recall: 0.2601 - val_loss: 0.6563 - val_binary_accuracy: 0.5692 - val_precision: 0.5889 - val_recall: 0.1791\n",
      "Epoch 428/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6563 - binary_accuracy: 0.5692 - precision: 0.5889 - recall: 0.1791 - val_loss: 0.6549 - val_binary_accuracy: 0.5862 - val_precision: 0.5860 - val_recall: 0.3108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6549 - binary_accuracy: 0.5862 - precision: 0.5860 - recall: 0.3108 - val_loss: 0.6545 - val_binary_accuracy: 0.5708 - val_precision: 0.5934 - val_recall: 0.1824\n",
      "Epoch 430/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6545 - binary_accuracy: 0.5708 - precision: 0.5934 - recall: 0.1824 - val_loss: 0.6536 - val_binary_accuracy: 0.5800 - val_precision: 0.5935 - val_recall: 0.2466\n",
      "Epoch 431/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6536 - binary_accuracy: 0.5800 - precision: 0.5935 - recall: 0.2466 - val_loss: 0.6532 - val_binary_accuracy: 0.5800 - val_precision: 0.5891 - val_recall: 0.2568\n",
      "Epoch 432/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6532 - binary_accuracy: 0.5800 - precision: 0.5891 - recall: 0.2568 - val_loss: 0.6532 - val_binary_accuracy: 0.5708 - val_precision: 0.5914 - val_recall: 0.1858\n",
      "Epoch 433/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6532 - binary_accuracy: 0.5708 - precision: 0.5914 - recall: 0.1858 - val_loss: 0.6531 - val_binary_accuracy: 0.5985 - val_precision: 0.6115 - val_recall: 0.3243\n",
      "Epoch 434/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6531 - binary_accuracy: 0.5985 - precision: 0.6115 - recall: 0.3243 - val_loss: 0.6533 - val_binary_accuracy: 0.5754 - val_precision: 0.6190 - val_recall: 0.1757\n",
      "Epoch 435/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6533 - binary_accuracy: 0.5754 - precision: 0.6190 - recall: 0.1757 - val_loss: 0.6527 - val_binary_accuracy: 0.6046 - val_precision: 0.6383 - val_recall: 0.3041\n",
      "Epoch 436/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6527 - binary_accuracy: 0.6046 - precision: 0.6383 - recall: 0.3041 - val_loss: 0.6518 - val_binary_accuracy: 0.5800 - val_precision: 0.6667 - val_recall: 0.1554\n",
      "Epoch 437/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6518 - binary_accuracy: 0.5800 - precision: 0.6667 - recall: 0.1554 - val_loss: 0.6510 - val_binary_accuracy: 0.5785 - val_precision: 0.6310 - val_recall: 0.1791\n",
      "Epoch 438/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6510 - binary_accuracy: 0.5785 - precision: 0.6310 - recall: 0.1791 - val_loss: 0.6514 - val_binary_accuracy: 0.5985 - val_precision: 0.6207 - val_recall: 0.3041\n",
      "Epoch 439/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6514 - binary_accuracy: 0.5985 - precision: 0.6207 - recall: 0.3041 - val_loss: 0.6520 - val_binary_accuracy: 0.5738 - val_precision: 0.6173 - val_recall: 0.1689\n",
      "Epoch 440/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6520 - binary_accuracy: 0.5738 - precision: 0.6173 - recall: 0.1689 - val_loss: 0.6516 - val_binary_accuracy: 0.6062 - val_precision: 0.6333 - val_recall: 0.3209\n",
      "Epoch 441/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6516 - binary_accuracy: 0.6062 - precision: 0.6333 - recall: 0.3209 - val_loss: 0.6510 - val_binary_accuracy: 0.5815 - val_precision: 0.6714 - val_recall: 0.1588\n",
      "Epoch 442/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6510 - binary_accuracy: 0.5815 - precision: 0.6714 - recall: 0.1588 - val_loss: 0.6501 - val_binary_accuracy: 0.5846 - val_precision: 0.6548 - val_recall: 0.1858\n",
      "Epoch 443/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6501 - binary_accuracy: 0.5846 - precision: 0.6548 - recall: 0.1858 - val_loss: 0.6508 - val_binary_accuracy: 0.6062 - val_precision: 0.6266 - val_recall: 0.3345\n",
      "Epoch 444/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6508 - binary_accuracy: 0.6062 - precision: 0.6266 - recall: 0.3345 - val_loss: 0.6536 - val_binary_accuracy: 0.5754 - val_precision: 0.6282 - val_recall: 0.1655\n",
      "Epoch 445/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6536 - binary_accuracy: 0.5754 - precision: 0.6282 - recall: 0.1655 - val_loss: 0.6563 - val_binary_accuracy: 0.5723 - val_precision: 0.5385 - val_recall: 0.4257\n",
      "Epoch 446/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6563 - binary_accuracy: 0.5723 - precision: 0.5385 - recall: 0.4257 - val_loss: 0.6547 - val_binary_accuracy: 0.5862 - val_precision: 0.7547 - val_recall: 0.1351\n",
      "Epoch 447/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6547 - binary_accuracy: 0.5862 - precision: 0.7547 - recall: 0.1351 - val_loss: 0.6507 - val_binary_accuracy: 0.5846 - val_precision: 0.7407 - val_recall: 0.1351\n",
      "Epoch 448/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6507 - binary_accuracy: 0.5846 - precision: 0.7407 - recall: 0.1351 - val_loss: 0.6570 - val_binary_accuracy: 0.5708 - val_precision: 0.5365 - val_recall: 0.4223\n",
      "Epoch 449/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6570 - binary_accuracy: 0.5708 - precision: 0.5365 - recall: 0.4223 - val_loss: 0.6507 - val_binary_accuracy: 0.5800 - val_precision: 0.6667 - val_recall: 0.1554\n",
      "Epoch 450/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6507 - binary_accuracy: 0.5800 - precision: 0.6667 - recall: 0.1554 - val_loss: 0.6512 - val_binary_accuracy: 0.5800 - val_precision: 0.6620 - val_recall: 0.1588\n",
      "Epoch 451/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6512 - binary_accuracy: 0.5800 - precision: 0.6620 - recall: 0.1588 - val_loss: 0.6530 - val_binary_accuracy: 0.6000 - val_precision: 0.6023 - val_recall: 0.3581\n",
      "Epoch 452/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6530 - binary_accuracy: 0.6000 - precision: 0.6023 - recall: 0.3581 - val_loss: 0.6489 - val_binary_accuracy: 0.5831 - val_precision: 0.6506 - val_recall: 0.1824\n",
      "Epoch 453/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6489 - binary_accuracy: 0.5831 - precision: 0.6506 - recall: 0.1824 - val_loss: 0.6526 - val_binary_accuracy: 0.5892 - val_precision: 0.7544 - val_recall: 0.1453\n",
      "Epoch 454/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6526 - binary_accuracy: 0.5892 - precision: 0.7544 - recall: 0.1453 - val_loss: 0.6481 - val_binary_accuracy: 0.5800 - val_precision: 0.6575 - val_recall: 0.1622\n",
      "Epoch 455/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6481 - binary_accuracy: 0.5800 - precision: 0.6575 - recall: 0.1622 - val_loss: 0.6514 - val_binary_accuracy: 0.6000 - val_precision: 0.6071 - val_recall: 0.3446\n",
      "Epoch 456/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6514 - binary_accuracy: 0.6000 - precision: 0.6071 - recall: 0.3446 - val_loss: 0.6481 - val_binary_accuracy: 0.5754 - val_precision: 0.6316 - val_recall: 0.1622\n",
      "Epoch 457/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6481 - binary_accuracy: 0.5754 - precision: 0.6316 - recall: 0.1622 - val_loss: 0.6489 - val_binary_accuracy: 0.5862 - val_precision: 0.6800 - val_recall: 0.1723\n",
      "Epoch 458/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6489 - binary_accuracy: 0.5862 - precision: 0.6800 - recall: 0.1723 - val_loss: 0.6495 - val_binary_accuracy: 0.5969 - val_precision: 0.5977 - val_recall: 0.3514\n",
      "Epoch 459/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6495 - binary_accuracy: 0.5969 - precision: 0.5977 - recall: 0.3514 - val_loss: 0.6464 - val_binary_accuracy: 0.5877 - val_precision: 0.6667 - val_recall: 0.1892\n",
      "Epoch 460/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6464 - binary_accuracy: 0.5877 - precision: 0.6667 - recall: 0.1892 - val_loss: 0.6482 - val_binary_accuracy: 0.5908 - val_precision: 0.7344 - val_recall: 0.1588\n",
      "Epoch 461/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6482 - binary_accuracy: 0.5908 - precision: 0.7344 - recall: 0.1588 - val_loss: 0.6470 - val_binary_accuracy: 0.6062 - val_precision: 0.6266 - val_recall: 0.3345\n",
      "Epoch 462/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6470 - binary_accuracy: 0.6062 - precision: 0.6266 - recall: 0.3345 - val_loss: 0.6450 - val_binary_accuracy: 0.5954 - val_precision: 0.6514 - val_recall: 0.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6450 - binary_accuracy: 0.5954 - precision: 0.6514 - recall: 0.2399 - val_loss: 0.6462 - val_binary_accuracy: 0.5862 - val_precision: 0.6667 - val_recall: 0.1824\n",
      "Epoch 464/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6462 - binary_accuracy: 0.5862 - precision: 0.6667 - recall: 0.1824 - val_loss: 0.6479 - val_binary_accuracy: 0.5908 - val_precision: 0.5758 - val_recall: 0.3851\n",
      "Epoch 465/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6479 - binary_accuracy: 0.5908 - precision: 0.5758 - recall: 0.3851 - val_loss: 0.6493 - val_binary_accuracy: 0.5908 - val_precision: 0.7500 - val_recall: 0.1520\n",
      "Epoch 466/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6493 - binary_accuracy: 0.5908 - precision: 0.7500 - recall: 0.1520 - val_loss: 0.6441 - val_binary_accuracy: 0.5985 - val_precision: 0.6259 - val_recall: 0.2939\n",
      "Epoch 467/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6441 - binary_accuracy: 0.5985 - precision: 0.6259 - recall: 0.2939 - val_loss: 0.6433 - val_binary_accuracy: 0.6031 - val_precision: 0.6418 - val_recall: 0.2905\n",
      "Epoch 468/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6433 - binary_accuracy: 0.6031 - precision: 0.6418 - recall: 0.2905 - val_loss: 0.6464 - val_binary_accuracy: 0.5923 - val_precision: 0.7246 - val_recall: 0.1689\n",
      "Epoch 469/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.6464 - binary_accuracy: 0.5923 - precision: 0.7246 - recall: 0.1689 - val_loss: 0.6455 - val_binary_accuracy: 0.5985 - val_precision: 0.5862 - val_recall: 0.4020\n",
      "Epoch 470/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6455 - binary_accuracy: 0.5985 - precision: 0.5862 - recall: 0.4020 - val_loss: 0.6450 - val_binary_accuracy: 0.5908 - val_precision: 0.7273 - val_recall: 0.1622\n",
      "Epoch 471/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6450 - binary_accuracy: 0.5908 - precision: 0.7273 - recall: 0.1622 - val_loss: 0.6413 - val_binary_accuracy: 0.6077 - val_precision: 0.6589 - val_recall: 0.2872\n",
      "Epoch 472/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6413 - binary_accuracy: 0.6077 - precision: 0.6589 - recall: 0.2872 - val_loss: 0.6404 - val_binary_accuracy: 0.6031 - val_precision: 0.6557 - val_recall: 0.2703\n",
      "Epoch 473/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6404 - binary_accuracy: 0.6031 - precision: 0.6557 - recall: 0.2703 - val_loss: 0.6422 - val_binary_accuracy: 0.5954 - val_precision: 0.7324 - val_recall: 0.1757\n",
      "Epoch 474/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6422 - binary_accuracy: 0.5954 - precision: 0.7324 - recall: 0.1757 - val_loss: 0.6505 - val_binary_accuracy: 0.5877 - val_precision: 0.5515 - val_recall: 0.5068\n",
      "Epoch 475/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6505 - binary_accuracy: 0.5877 - precision: 0.5515 - recall: 0.5068 - val_loss: 0.6707 - val_binary_accuracy: 0.5738 - val_precision: 0.6203 - val_recall: 0.1655\n",
      "Epoch 476/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6707 - binary_accuracy: 0.5738 - precision: 0.6203 - recall: 0.1655 - val_loss: 0.6576 - val_binary_accuracy: 0.5892 - val_precision: 0.8718 - val_recall: 0.1149\n",
      "Epoch 477/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6576 - binary_accuracy: 0.5892 - precision: 0.8718 - recall: 0.1149 - val_loss: 0.6564 - val_binary_accuracy: 0.5954 - val_precision: 0.9459 - val_recall: 0.1182\n",
      "Epoch 478/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6564 - binary_accuracy: 0.5954 - precision: 0.9459 - recall: 0.1182 - val_loss: 0.6623 - val_binary_accuracy: 0.5677 - val_precision: 0.5330 - val_recall: 0.4088\n",
      "Epoch 479/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6623 - binary_accuracy: 0.5677 - precision: 0.5330 - recall: 0.4088 - val_loss: 0.6628 - val_binary_accuracy: 0.5677 - val_precision: 0.5342 - val_recall: 0.3953\n",
      "Epoch 480/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6628 - binary_accuracy: 0.5677 - precision: 0.5342 - recall: 0.3953 - val_loss: 0.6581 - val_binary_accuracy: 0.5831 - val_precision: 0.7907 - val_recall: 0.1149\n",
      "Epoch 481/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6581 - binary_accuracy: 0.5831 - precision: 0.7907 - recall: 0.1149 - val_loss: 0.6558 - val_binary_accuracy: 0.5892 - val_precision: 0.9143 - val_recall: 0.1081\n",
      "Epoch 482/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6558 - binary_accuracy: 0.5892 - precision: 0.9143 - recall: 0.1081 - val_loss: 0.6506 - val_binary_accuracy: 0.5908 - val_precision: 0.8750 - val_recall: 0.1182\n",
      "Epoch 483/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6506 - binary_accuracy: 0.5908 - precision: 0.8750 - recall: 0.1182 - val_loss: 0.6472 - val_binary_accuracy: 0.5938 - val_precision: 0.8077 - val_recall: 0.1419\n",
      "Epoch 484/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6472 - binary_accuracy: 0.5938 - precision: 0.8077 - recall: 0.1419 - val_loss: 0.6642 - val_binary_accuracy: 0.5785 - val_precision: 0.5948 - val_recall: 0.2331\n",
      "Epoch 485/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6642 - binary_accuracy: 0.5785 - precision: 0.5948 - recall: 0.2331 - val_loss: 0.6742 - val_binary_accuracy: 0.5569 - val_precision: 0.5123 - val_recall: 0.5642\n",
      "Epoch 486/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6742 - binary_accuracy: 0.5569 - precision: 0.5123 - recall: 0.5642 - val_loss: 0.6479 - val_binary_accuracy: 0.6062 - val_precision: 0.6471 - val_recall: 0.2973\n",
      "Epoch 487/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6479 - binary_accuracy: 0.6062 - precision: 0.6471 - recall: 0.2973 - val_loss: 0.6554 - val_binary_accuracy: 0.5892 - val_precision: 0.7959 - val_recall: 0.1318\n",
      "Epoch 488/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6554 - binary_accuracy: 0.5892 - precision: 0.7959 - recall: 0.1318 - val_loss: 0.6572 - val_binary_accuracy: 0.5815 - val_precision: 0.7609 - val_recall: 0.1182\n",
      "Epoch 489/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6572 - binary_accuracy: 0.5815 - precision: 0.7609 - recall: 0.1182 - val_loss: 0.6515 - val_binary_accuracy: 0.5923 - val_precision: 0.8444 - val_recall: 0.1284\n",
      "Epoch 490/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6515 - binary_accuracy: 0.5923 - precision: 0.8444 - recall: 0.1284 - val_loss: 0.6503 - val_binary_accuracy: 0.6000 - val_precision: 0.7432 - val_recall: 0.1858\n",
      "Epoch 491/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6503 - binary_accuracy: 0.6000 - precision: 0.7432 - recall: 0.1858 - val_loss: 0.6506 - val_binary_accuracy: 0.6015 - val_precision: 0.6135 - val_recall: 0.3378\n",
      "Epoch 492/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6506 - binary_accuracy: 0.6015 - precision: 0.6135 - recall: 0.3378 - val_loss: 0.6518 - val_binary_accuracy: 0.5908 - val_precision: 0.5758 - val_recall: 0.3851\n",
      "Epoch 493/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6518 - binary_accuracy: 0.5908 - precision: 0.5758 - recall: 0.3851 - val_loss: 0.6508 - val_binary_accuracy: 0.6031 - val_precision: 0.5913 - val_recall: 0.4155\n",
      "Epoch 494/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6508 - binary_accuracy: 0.6031 - precision: 0.5913 - recall: 0.4155 - val_loss: 0.6479 - val_binary_accuracy: 0.5908 - val_precision: 0.5652 - val_recall: 0.4392\n",
      "Epoch 495/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6479 - binary_accuracy: 0.5908 - precision: 0.5652 - recall: 0.4392 - val_loss: 0.6449 - val_binary_accuracy: 0.6169 - val_precision: 0.6391 - val_recall: 0.3649\n",
      "Epoch 496/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6449 - binary_accuracy: 0.6169 - precision: 0.6391 - recall: 0.3649 - val_loss: 0.6437 - val_binary_accuracy: 0.5862 - val_precision: 0.6627 - val_recall: 0.1858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6437 - binary_accuracy: 0.5862 - precision: 0.6627 - recall: 0.1858 - val_loss: 0.6440 - val_binary_accuracy: 0.5985 - val_precision: 0.7869 - val_recall: 0.1622\n",
      "Epoch 498/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6440 - binary_accuracy: 0.5985 - precision: 0.7869 - recall: 0.1622 - val_loss: 0.6440 - val_binary_accuracy: 0.6031 - val_precision: 0.7375 - val_recall: 0.1993\n",
      "Epoch 499/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6440 - binary_accuracy: 0.6031 - precision: 0.7375 - recall: 0.1993 - val_loss: 0.6432 - val_binary_accuracy: 0.6123 - val_precision: 0.7157 - val_recall: 0.2466\n",
      "Epoch 500/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6432 - binary_accuracy: 0.6123 - precision: 0.7157 - recall: 0.2466 - val_loss: 0.6412 - val_binary_accuracy: 0.6077 - val_precision: 0.7253 - val_recall: 0.2230\n",
      "Epoch 501/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6412 - binary_accuracy: 0.6077 - precision: 0.7253 - recall: 0.2230 - val_loss: 0.6404 - val_binary_accuracy: 0.6077 - val_precision: 0.6990 - val_recall: 0.2432\n",
      "Epoch 502/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6404 - binary_accuracy: 0.6077 - precision: 0.6990 - recall: 0.2432 - val_loss: 0.6394 - val_binary_accuracy: 0.6262 - val_precision: 0.6587 - val_recall: 0.3716\n",
      "Epoch 503/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6394 - binary_accuracy: 0.6262 - precision: 0.6587 - recall: 0.3716 - val_loss: 0.6372 - val_binary_accuracy: 0.6046 - val_precision: 0.6585 - val_recall: 0.2736\n",
      "Epoch 504/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6372 - binary_accuracy: 0.6046 - precision: 0.6585 - recall: 0.2736 - val_loss: 0.6357 - val_binary_accuracy: 0.6108 - val_precision: 0.6807 - val_recall: 0.2736\n",
      "Epoch 505/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6357 - binary_accuracy: 0.6108 - precision: 0.6807 - recall: 0.2736 - val_loss: 0.6352 - val_binary_accuracy: 0.6092 - val_precision: 0.6479 - val_recall: 0.3108\n",
      "Epoch 506/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6352 - binary_accuracy: 0.6092 - precision: 0.6479 - recall: 0.3108 - val_loss: 0.6346 - val_binary_accuracy: 0.6092 - val_precision: 0.6641 - val_recall: 0.2872\n",
      "Epoch 507/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6346 - binary_accuracy: 0.6092 - precision: 0.6641 - recall: 0.2872 - val_loss: 0.6337 - val_binary_accuracy: 0.6138 - val_precision: 0.6667 - val_recall: 0.3041\n",
      "Epoch 508/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6337 - binary_accuracy: 0.6138 - precision: 0.6667 - recall: 0.3041 - val_loss: 0.6328 - val_binary_accuracy: 0.6092 - val_precision: 0.6346 - val_recall: 0.3345\n",
      "Epoch 509/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6328 - binary_accuracy: 0.6092 - precision: 0.6346 - recall: 0.3345 - val_loss: 0.6330 - val_binary_accuracy: 0.6169 - val_precision: 0.6850 - val_recall: 0.2939\n",
      "Epoch 510/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6330 - binary_accuracy: 0.6169 - precision: 0.6850 - recall: 0.2939 - val_loss: 0.6312 - val_binary_accuracy: 0.6138 - val_precision: 0.6301 - val_recall: 0.3682\n",
      "Epoch 511/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6312 - binary_accuracy: 0.6138 - precision: 0.6301 - recall: 0.3682 - val_loss: 0.6354 - val_binary_accuracy: 0.6031 - val_precision: 0.6979 - val_recall: 0.2264\n",
      "Epoch 512/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6354 - binary_accuracy: 0.6031 - precision: 0.6979 - recall: 0.2264 - val_loss: 0.6527 - val_binary_accuracy: 0.5754 - val_precision: 0.5355 - val_recall: 0.5101\n",
      "Epoch 513/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6527 - binary_accuracy: 0.5754 - precision: 0.5355 - recall: 0.5101 - val_loss: 0.6929 - val_binary_accuracy: 0.5692 - val_precision: 0.5816 - val_recall: 0.1926\n",
      "Epoch 514/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6929 - binary_accuracy: 0.5692 - precision: 0.5816 - recall: 0.1926 - val_loss: 0.6658 - val_binary_accuracy: 0.5800 - val_precision: 0.6949 - val_recall: 0.1385\n",
      "Epoch 515/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6658 - binary_accuracy: 0.5800 - precision: 0.6949 - recall: 0.1385 - val_loss: 0.6633 - val_binary_accuracy: 0.5892 - val_precision: 0.9394 - val_recall: 0.1047\n",
      "Epoch 516/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6633 - binary_accuracy: 0.5892 - precision: 0.9394 - recall: 0.1047 - val_loss: 0.6661 - val_binary_accuracy: 0.5862 - val_precision: 0.9091 - val_recall: 0.1014\n",
      "Epoch 517/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6661 - binary_accuracy: 0.5862 - precision: 0.9091 - recall: 0.1014 - val_loss: 0.6623 - val_binary_accuracy: 0.5862 - val_precision: 0.9355 - val_recall: 0.0980\n",
      "Epoch 518/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6623 - binary_accuracy: 0.5862 - precision: 0.9355 - recall: 0.0980 - val_loss: 0.6591 - val_binary_accuracy: 0.5954 - val_precision: 0.9459 - val_recall: 0.1182\n",
      "Epoch 519/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6591 - binary_accuracy: 0.5954 - precision: 0.9459 - recall: 0.1182 - val_loss: 0.6549 - val_binary_accuracy: 0.5985 - val_precision: 0.7108 - val_recall: 0.1993\n",
      "Epoch 520/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6549 - binary_accuracy: 0.5985 - precision: 0.7108 - recall: 0.1993 - val_loss: 0.6506 - val_binary_accuracy: 0.5954 - val_precision: 0.5912 - val_recall: 0.3615\n",
      "Epoch 521/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6506 - binary_accuracy: 0.5954 - precision: 0.5912 - recall: 0.3615 - val_loss: 0.6546 - val_binary_accuracy: 0.6092 - val_precision: 0.6082 - val_recall: 0.3986\n",
      "Epoch 522/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6546 - binary_accuracy: 0.6092 - precision: 0.6082 - recall: 0.3986 - val_loss: 0.6462 - val_binary_accuracy: 0.5954 - val_precision: 0.5721 - val_recall: 0.4426\n",
      "Epoch 523/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6462 - binary_accuracy: 0.5954 - precision: 0.5721 - recall: 0.4426 - val_loss: 0.6439 - val_binary_accuracy: 0.5938 - val_precision: 0.5714 - val_recall: 0.4324\n",
      "Epoch 524/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6439 - binary_accuracy: 0.5938 - precision: 0.5714 - recall: 0.4324 - val_loss: 0.6384 - val_binary_accuracy: 0.6154 - val_precision: 0.7396 - val_recall: 0.2399\n",
      "Epoch 525/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6384 - binary_accuracy: 0.6154 - precision: 0.7396 - recall: 0.2399 - val_loss: 0.6426 - val_binary_accuracy: 0.6046 - val_precision: 0.8545 - val_recall: 0.1588\n",
      "Epoch 526/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6426 - binary_accuracy: 0.6046 - precision: 0.8545 - recall: 0.1588 - val_loss: 0.6429 - val_binary_accuracy: 0.6031 - val_precision: 0.8519 - val_recall: 0.1554\n",
      "Epoch 527/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6429 - binary_accuracy: 0.6031 - precision: 0.8519 - recall: 0.1554 - val_loss: 0.6375 - val_binary_accuracy: 0.6108 - val_precision: 0.7945 - val_recall: 0.1959\n",
      "Epoch 528/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6375 - binary_accuracy: 0.6108 - precision: 0.7945 - recall: 0.1959 - val_loss: 0.6369 - val_binary_accuracy: 0.6169 - val_precision: 0.6621 - val_recall: 0.3243\n",
      "Epoch 529/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6369 - binary_accuracy: 0.6169 - precision: 0.6621 - recall: 0.3243 - val_loss: 0.6332 - val_binary_accuracy: 0.6200 - val_precision: 0.6788 - val_recall: 0.3142\n",
      "Epoch 530/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6332 - binary_accuracy: 0.6200 - precision: 0.6788 - recall: 0.3142 - val_loss: 0.6352 - val_binary_accuracy: 0.6185 - val_precision: 0.6935 - val_recall: 0.2905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6352 - binary_accuracy: 0.6185 - precision: 0.6935 - recall: 0.2905 - val_loss: 0.6337 - val_binary_accuracy: 0.6215 - val_precision: 0.6603 - val_recall: 0.3480\n",
      "Epoch 532/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6337 - binary_accuracy: 0.6215 - precision: 0.6603 - recall: 0.3480 - val_loss: 0.6344 - val_binary_accuracy: 0.6231 - val_precision: 0.6409 - val_recall: 0.3919\n",
      "Epoch 533/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6344 - binary_accuracy: 0.6231 - precision: 0.6409 - recall: 0.3919 - val_loss: 0.6319 - val_binary_accuracy: 0.6246 - val_precision: 0.6912 - val_recall: 0.3176\n",
      "Epoch 534/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6319 - binary_accuracy: 0.6246 - precision: 0.6912 - recall: 0.3176 - val_loss: 0.6326 - val_binary_accuracy: 0.6231 - val_precision: 0.7297 - val_recall: 0.2736\n",
      "Epoch 535/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6326 - binary_accuracy: 0.6231 - precision: 0.7297 - recall: 0.2736 - val_loss: 0.6308 - val_binary_accuracy: 0.6185 - val_precision: 0.7000 - val_recall: 0.2838\n",
      "Epoch 536/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6308 - binary_accuracy: 0.6185 - precision: 0.7000 - recall: 0.2838 - val_loss: 0.6319 - val_binary_accuracy: 0.6308 - val_precision: 0.6818 - val_recall: 0.3547\n",
      "Epoch 537/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6319 - binary_accuracy: 0.6308 - precision: 0.6818 - recall: 0.3547 - val_loss: 0.6291 - val_binary_accuracy: 0.6231 - val_precision: 0.7040 - val_recall: 0.2973\n",
      "Epoch 538/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6291 - binary_accuracy: 0.6231 - precision: 0.7040 - recall: 0.2973 - val_loss: 0.6292 - val_binary_accuracy: 0.6231 - val_precision: 0.7073 - val_recall: 0.2939\n",
      "Epoch 539/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6292 - binary_accuracy: 0.6231 - precision: 0.7073 - recall: 0.2939 - val_loss: 0.6279 - val_binary_accuracy: 0.6323 - val_precision: 0.6629 - val_recall: 0.3919\n",
      "Epoch 540/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6279 - binary_accuracy: 0.6323 - precision: 0.6629 - recall: 0.3919 - val_loss: 0.6262 - val_binary_accuracy: 0.6246 - val_precision: 0.6605 - val_recall: 0.3615\n",
      "Epoch 541/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6262 - binary_accuracy: 0.6246 - precision: 0.6605 - recall: 0.3615 - val_loss: 0.6255 - val_binary_accuracy: 0.6338 - val_precision: 0.7231 - val_recall: 0.3176\n",
      "Epoch 542/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6255 - binary_accuracy: 0.6338 - precision: 0.7231 - recall: 0.3176 - val_loss: 0.6238 - val_binary_accuracy: 0.6354 - val_precision: 0.7185 - val_recall: 0.3277\n",
      "Epoch 543/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6238 - binary_accuracy: 0.6354 - precision: 0.7185 - recall: 0.3277 - val_loss: 0.6239 - val_binary_accuracy: 0.6277 - val_precision: 0.6667 - val_recall: 0.3649\n",
      "Epoch 544/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6239 - binary_accuracy: 0.6277 - precision: 0.6667 - recall: 0.3649 - val_loss: 0.6221 - val_binary_accuracy: 0.6292 - val_precision: 0.7099 - val_recall: 0.3142\n",
      "Epoch 545/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6221 - binary_accuracy: 0.6292 - precision: 0.7099 - recall: 0.3142 - val_loss: 0.6211 - val_binary_accuracy: 0.6323 - val_precision: 0.7317 - val_recall: 0.3041\n",
      "Epoch 546/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6211 - binary_accuracy: 0.6323 - precision: 0.7317 - recall: 0.3041 - val_loss: 0.6200 - val_binary_accuracy: 0.6354 - val_precision: 0.6903 - val_recall: 0.3615\n",
      "Epoch 547/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6200 - binary_accuracy: 0.6354 - precision: 0.6903 - recall: 0.3615 - val_loss: 0.6189 - val_binary_accuracy: 0.6446 - val_precision: 0.7559 - val_recall: 0.3243\n",
      "Epoch 548/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6189 - binary_accuracy: 0.6446 - precision: 0.7559 - recall: 0.3243 - val_loss: 0.6174 - val_binary_accuracy: 0.6308 - val_precision: 0.6918 - val_recall: 0.3412\n",
      "Epoch 549/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6174 - binary_accuracy: 0.6308 - precision: 0.6918 - recall: 0.3412 - val_loss: 0.6160 - val_binary_accuracy: 0.6323 - val_precision: 0.6913 - val_recall: 0.3480\n",
      "Epoch 550/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6160 - binary_accuracy: 0.6323 - precision: 0.6913 - recall: 0.3480 - val_loss: 0.6158 - val_binary_accuracy: 0.6385 - val_precision: 0.7607 - val_recall: 0.3007\n",
      "Epoch 551/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6158 - binary_accuracy: 0.6385 - precision: 0.7607 - recall: 0.3007 - val_loss: 0.6152 - val_binary_accuracy: 0.6369 - val_precision: 0.6899 - val_recall: 0.3682\n",
      "Epoch 552/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6152 - binary_accuracy: 0.6369 - precision: 0.6899 - recall: 0.3682 - val_loss: 0.6151 - val_binary_accuracy: 0.6415 - val_precision: 0.7788 - val_recall: 0.2973\n",
      "Epoch 553/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6151 - binary_accuracy: 0.6415 - precision: 0.7788 - recall: 0.2973 - val_loss: 0.6138 - val_binary_accuracy: 0.6246 - val_precision: 0.6461 - val_recall: 0.3885\n",
      "Epoch 554/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6138 - binary_accuracy: 0.6246 - precision: 0.6461 - recall: 0.3885 - val_loss: 0.6177 - val_binary_accuracy: 0.6338 - val_precision: 0.7636 - val_recall: 0.2838\n",
      "Epoch 555/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6177 - binary_accuracy: 0.6338 - precision: 0.7636 - recall: 0.2838 - val_loss: 0.6190 - val_binary_accuracy: 0.6262 - val_precision: 0.6293 - val_recall: 0.4358\n",
      "Epoch 556/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6190 - binary_accuracy: 0.6262 - precision: 0.6293 - recall: 0.4358 - val_loss: 0.6492 - val_binary_accuracy: 0.6000 - val_precision: 0.7093 - val_recall: 0.2061\n",
      "Epoch 557/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6492 - binary_accuracy: 0.6000 - precision: 0.7093 - recall: 0.2061 - val_loss: 0.6429 - val_binary_accuracy: 0.6092 - val_precision: 0.7917 - val_recall: 0.1926\n",
      "Epoch 558/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6429 - binary_accuracy: 0.6092 - precision: 0.7917 - recall: 0.1926 - val_loss: 0.6288 - val_binary_accuracy: 0.6246 - val_precision: 0.7407 - val_recall: 0.2703\n",
      "Epoch 559/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6288 - binary_accuracy: 0.6246 - precision: 0.7407 - recall: 0.2703 - val_loss: 0.6522 - val_binary_accuracy: 0.5538 - val_precision: 0.5110 - val_recall: 0.4696\n",
      "Epoch 560/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6522 - binary_accuracy: 0.5538 - precision: 0.5110 - recall: 0.4696 - val_loss: 0.6255 - val_binary_accuracy: 0.6123 - val_precision: 0.7895 - val_recall: 0.2027\n",
      "Epoch 561/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6255 - binary_accuracy: 0.6123 - precision: 0.7895 - recall: 0.2027 - val_loss: 0.6374 - val_binary_accuracy: 0.6169 - val_precision: 0.7374 - val_recall: 0.2466\n",
      "Epoch 562/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6374 - binary_accuracy: 0.6169 - precision: 0.7374 - recall: 0.2466 - val_loss: 0.6290 - val_binary_accuracy: 0.6154 - val_precision: 0.7674 - val_recall: 0.2230\n",
      "Epoch 563/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6290 - binary_accuracy: 0.6154 - precision: 0.7674 - recall: 0.2230 - val_loss: 0.6102 - val_binary_accuracy: 0.6262 - val_precision: 0.7431 - val_recall: 0.2736\n",
      "Epoch 564/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6102 - binary_accuracy: 0.6262 - precision: 0.7431 - recall: 0.2736 - val_loss: 0.6484 - val_binary_accuracy: 0.5877 - val_precision: 0.5680 - val_recall: 0.3953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6484 - binary_accuracy: 0.5877 - precision: 0.5680 - recall: 0.3953 - val_loss: 0.6289 - val_binary_accuracy: 0.6138 - val_precision: 0.7103 - val_recall: 0.2568\n",
      "Epoch 566/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6289 - binary_accuracy: 0.6138 - precision: 0.7103 - recall: 0.2568 - val_loss: 0.6136 - val_binary_accuracy: 0.6431 - val_precision: 0.9324 - val_recall: 0.2331\n",
      "Epoch 567/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6136 - binary_accuracy: 0.6431 - precision: 0.9324 - recall: 0.2331 - val_loss: 0.6166 - val_binary_accuracy: 0.6292 - val_precision: 0.8986 - val_recall: 0.2095\n",
      "Epoch 568/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6166 - binary_accuracy: 0.6292 - precision: 0.8986 - recall: 0.2095 - val_loss: 0.6249 - val_binary_accuracy: 0.6231 - val_precision: 0.8923 - val_recall: 0.1959\n",
      "Epoch 569/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6249 - binary_accuracy: 0.6231 - precision: 0.8923 - recall: 0.1959 - val_loss: 0.6117 - val_binary_accuracy: 0.6292 - val_precision: 0.8767 - val_recall: 0.2162\n",
      "Epoch 570/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6117 - binary_accuracy: 0.6292 - precision: 0.8767 - recall: 0.2162 - val_loss: 0.6072 - val_binary_accuracy: 0.6431 - val_precision: 0.8333 - val_recall: 0.2703\n",
      "Epoch 571/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6072 - binary_accuracy: 0.6431 - precision: 0.8333 - recall: 0.2703 - val_loss: 0.6077 - val_binary_accuracy: 0.6215 - val_precision: 0.6736 - val_recall: 0.3277\n",
      "Epoch 572/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6077 - binary_accuracy: 0.6215 - precision: 0.6736 - recall: 0.3277 - val_loss: 0.6097 - val_binary_accuracy: 0.6369 - val_precision: 0.6485 - val_recall: 0.4426\n",
      "Epoch 573/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6097 - binary_accuracy: 0.6369 - precision: 0.6485 - recall: 0.4426 - val_loss: 0.5999 - val_binary_accuracy: 0.6354 - val_precision: 0.6595 - val_recall: 0.4122\n",
      "Epoch 574/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5999 - binary_accuracy: 0.6354 - precision: 0.6595 - recall: 0.4122 - val_loss: 0.5994 - val_binary_accuracy: 0.6569 - val_precision: 0.7355 - val_recall: 0.3851\n",
      "Epoch 575/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.5994 - binary_accuracy: 0.6569 - precision: 0.7355 - recall: 0.3851 - val_loss: 0.5935 - val_binary_accuracy: 0.6431 - val_precision: 0.7222 - val_recall: 0.3514\n",
      "Epoch 576/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.5935 - binary_accuracy: 0.6431 - precision: 0.7222 - recall: 0.3514 - val_loss: 0.5938 - val_binary_accuracy: 0.6446 - val_precision: 0.7372 - val_recall: 0.3412\n",
      "Epoch 577/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.5938 - binary_accuracy: 0.6446 - precision: 0.7372 - recall: 0.3412 - val_loss: 0.5916 - val_binary_accuracy: 0.6431 - val_precision: 0.7424 - val_recall: 0.3311\n",
      "Epoch 578/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5916 - binary_accuracy: 0.6431 - precision: 0.7424 - recall: 0.3311 - val_loss: 0.5893 - val_binary_accuracy: 0.6385 - val_precision: 0.7480 - val_recall: 0.3108\n",
      "Epoch 579/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.5893 - binary_accuracy: 0.6385 - precision: 0.7480 - recall: 0.3108 - val_loss: 0.5875 - val_binary_accuracy: 0.6492 - val_precision: 0.7073 - val_recall: 0.3919\n",
      "Epoch 580/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5875 - binary_accuracy: 0.6492 - precision: 0.7073 - recall: 0.3919 - val_loss: 0.5886 - val_binary_accuracy: 0.6523 - val_precision: 0.6768 - val_recall: 0.4527\n",
      "Epoch 581/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5886 - binary_accuracy: 0.6523 - precision: 0.6768 - recall: 0.4527 - val_loss: 0.5824 - val_binary_accuracy: 0.6354 - val_precision: 0.6311 - val_recall: 0.4797\n",
      "Epoch 582/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.5824 - binary_accuracy: 0.6354 - precision: 0.6311 - recall: 0.4797 - val_loss: 0.5858 - val_binary_accuracy: 0.6400 - val_precision: 0.6615 - val_recall: 0.4291\n",
      "Epoch 583/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.5858 - binary_accuracy: 0.6400 - precision: 0.6615 - recall: 0.4291 - val_loss: 0.5790 - val_binary_accuracy: 0.6554 - val_precision: 0.6714 - val_recall: 0.4764\n",
      "Epoch 584/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5790 - binary_accuracy: 0.6554 - precision: 0.6714 - recall: 0.4764 - val_loss: 0.5803 - val_binary_accuracy: 0.6431 - val_precision: 0.6280 - val_recall: 0.5304\n",
      "Epoch 585/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5803 - binary_accuracy: 0.6431 - precision: 0.6280 - recall: 0.5304 - val_loss: 0.5814 - val_binary_accuracy: 0.6600 - val_precision: 0.7419 - val_recall: 0.3885\n",
      "Epoch 586/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5814 - binary_accuracy: 0.6600 - precision: 0.7419 - recall: 0.3885 - val_loss: 0.5723 - val_binary_accuracy: 0.6400 - val_precision: 0.6598 - val_recall: 0.4324\n",
      "Epoch 587/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5723 - binary_accuracy: 0.6400 - precision: 0.6598 - recall: 0.4324 - val_loss: 0.5772 - val_binary_accuracy: 0.6600 - val_precision: 0.6271 - val_recall: 0.6250\n",
      "Epoch 588/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5772 - binary_accuracy: 0.6600 - precision: 0.6271 - recall: 0.6250 - val_loss: 0.5670 - val_binary_accuracy: 0.6462 - val_precision: 0.6241 - val_recall: 0.5608\n",
      "Epoch 589/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5670 - binary_accuracy: 0.6462 - precision: 0.6241 - recall: 0.5608 - val_loss: 0.5812 - val_binary_accuracy: 0.6369 - val_precision: 0.6786 - val_recall: 0.3851\n",
      "Epoch 590/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5812 - binary_accuracy: 0.6369 - precision: 0.6786 - recall: 0.3851 - val_loss: 0.5897 - val_binary_accuracy: 0.6446 - val_precision: 0.6836 - val_recall: 0.4088\n",
      "Epoch 591/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5897 - binary_accuracy: 0.6446 - precision: 0.6836 - recall: 0.4088 - val_loss: 0.6308 - val_binary_accuracy: 0.6277 - val_precision: 0.5860 - val_recall: 0.6216\n",
      "Epoch 592/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6308 - binary_accuracy: 0.6277 - precision: 0.5860 - recall: 0.6216 - val_loss: 0.6527 - val_binary_accuracy: 0.6015 - val_precision: 0.6947 - val_recall: 0.2230\n",
      "Epoch 593/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6527 - binary_accuracy: 0.6015 - precision: 0.6947 - recall: 0.2230 - val_loss: 0.6344 - val_binary_accuracy: 0.6077 - val_precision: 0.7253 - val_recall: 0.2230\n",
      "Epoch 594/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6344 - binary_accuracy: 0.6077 - precision: 0.7253 - recall: 0.2230 - val_loss: 0.6242 - val_binary_accuracy: 0.6354 - val_precision: 0.6497 - val_recall: 0.4324\n",
      "Epoch 595/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6242 - binary_accuracy: 0.6354 - precision: 0.6497 - recall: 0.4324 - val_loss: 0.6326 - val_binary_accuracy: 0.6369 - val_precision: 0.6079 - val_recall: 0.5709\n",
      "Epoch 596/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6326 - binary_accuracy: 0.6369 - precision: 0.6079 - recall: 0.5709 - val_loss: 0.6207 - val_binary_accuracy: 0.6569 - val_precision: 0.6229 - val_recall: 0.6250\n",
      "Epoch 597/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6207 - binary_accuracy: 0.6569 - precision: 0.6229 - recall: 0.6250 - val_loss: 0.6202 - val_binary_accuracy: 0.6492 - val_precision: 0.6241 - val_recall: 0.5777\n",
      "Epoch 598/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6202 - binary_accuracy: 0.6492 - precision: 0.6241 - recall: 0.5777 - val_loss: 0.6201 - val_binary_accuracy: 0.6400 - val_precision: 0.6115 - val_recall: 0.5743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6201 - binary_accuracy: 0.6400 - precision: 0.6115 - recall: 0.5743 - val_loss: 0.6068 - val_binary_accuracy: 0.6492 - val_precision: 0.6269 - val_recall: 0.5676\n",
      "Epoch 600/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.6068 - binary_accuracy: 0.6492 - precision: 0.6269 - recall: 0.5676 - val_loss: 0.6077 - val_binary_accuracy: 0.6338 - val_precision: 0.6074 - val_recall: 0.5541\n",
      "Epoch 601/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6077 - binary_accuracy: 0.6338 - precision: 0.6074 - recall: 0.5541 - val_loss: 0.6060 - val_binary_accuracy: 0.6508 - val_precision: 0.6273 - val_recall: 0.5743\n",
      "Epoch 602/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6060 - binary_accuracy: 0.6508 - precision: 0.6273 - recall: 0.5743 - val_loss: 0.6008 - val_binary_accuracy: 0.6323 - val_precision: 0.6135 - val_recall: 0.5203\n",
      "Epoch 603/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6008 - binary_accuracy: 0.6323 - precision: 0.6135 - recall: 0.5203 - val_loss: 0.6001 - val_binary_accuracy: 0.6123 - val_precision: 0.6000 - val_recall: 0.4459\n",
      "Epoch 604/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6001 - binary_accuracy: 0.6123 - precision: 0.6000 - recall: 0.4459 - val_loss: 0.5981 - val_binary_accuracy: 0.6046 - val_precision: 0.6242 - val_recall: 0.3311\n",
      "Epoch 605/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5981 - binary_accuracy: 0.6046 - precision: 0.6242 - recall: 0.3311 - val_loss: 0.5945 - val_binary_accuracy: 0.5985 - val_precision: 0.6159 - val_recall: 0.3142\n",
      "Epoch 606/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5945 - binary_accuracy: 0.5985 - precision: 0.6159 - recall: 0.3142 - val_loss: 0.5896 - val_binary_accuracy: 0.6415 - val_precision: 0.6493 - val_recall: 0.4628\n",
      "Epoch 607/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5896 - binary_accuracy: 0.6415 - precision: 0.6493 - recall: 0.4628 - val_loss: 0.5872 - val_binary_accuracy: 0.6446 - val_precision: 0.6360 - val_recall: 0.5135\n",
      "Epoch 608/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.5872 - binary_accuracy: 0.6446 - precision: 0.6360 - recall: 0.5135 - val_loss: 0.5835 - val_binary_accuracy: 0.6600 - val_precision: 0.6448 - val_recall: 0.5642\n",
      "Epoch 609/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5835 - binary_accuracy: 0.6600 - precision: 0.6448 - recall: 0.5642 - val_loss: 0.5773 - val_binary_accuracy: 0.6492 - val_precision: 0.6269 - val_recall: 0.5676\n",
      "Epoch 610/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5773 - binary_accuracy: 0.6492 - precision: 0.6269 - recall: 0.5676 - val_loss: 0.5742 - val_binary_accuracy: 0.6415 - val_precision: 0.6226 - val_recall: 0.5405\n",
      "Epoch 611/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5742 - binary_accuracy: 0.6415 - precision: 0.6226 - recall: 0.5405 - val_loss: 0.5705 - val_binary_accuracy: 0.6385 - val_precision: 0.6151 - val_recall: 0.5507\n",
      "Epoch 612/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5705 - binary_accuracy: 0.6385 - precision: 0.6151 - recall: 0.5507 - val_loss: 0.5687 - val_binary_accuracy: 0.6569 - val_precision: 0.6263 - val_recall: 0.6115\n",
      "Epoch 613/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5687 - binary_accuracy: 0.6569 - precision: 0.6263 - recall: 0.6115 - val_loss: 0.5638 - val_binary_accuracy: 0.6585 - val_precision: 0.6225 - val_recall: 0.6351\n",
      "Epoch 614/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5638 - binary_accuracy: 0.6585 - precision: 0.6225 - recall: 0.6351 - val_loss: 0.5623 - val_binary_accuracy: 0.6815 - val_precision: 0.6488 - val_recall: 0.6554\n",
      "Epoch 615/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5623 - binary_accuracy: 0.6815 - precision: 0.6488 - recall: 0.6554 - val_loss: 0.5571 - val_binary_accuracy: 0.6646 - val_precision: 0.6309 - val_recall: 0.6351\n",
      "Epoch 616/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5571 - binary_accuracy: 0.6646 - precision: 0.6309 - recall: 0.6351 - val_loss: 0.5551 - val_binary_accuracy: 0.6692 - val_precision: 0.6392 - val_recall: 0.6284\n",
      "Epoch 617/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5551 - binary_accuracy: 0.6692 - precision: 0.6392 - recall: 0.6284 - val_loss: 0.5527 - val_binary_accuracy: 0.6908 - val_precision: 0.6599 - val_recall: 0.6622\n",
      "Epoch 618/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5527 - binary_accuracy: 0.6908 - precision: 0.6599 - recall: 0.6622 - val_loss: 0.5483 - val_binary_accuracy: 0.6769 - val_precision: 0.6424 - val_recall: 0.6554\n",
      "Epoch 619/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5483 - binary_accuracy: 0.6769 - precision: 0.6424 - recall: 0.6554 - val_loss: 0.5467 - val_binary_accuracy: 0.6815 - val_precision: 0.6584 - val_recall: 0.6250\n",
      "Epoch 620/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5467 - binary_accuracy: 0.6815 - precision: 0.6584 - recall: 0.6250 - val_loss: 0.5432 - val_binary_accuracy: 0.6831 - val_precision: 0.6596 - val_recall: 0.6284\n",
      "Epoch 621/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5432 - binary_accuracy: 0.6831 - precision: 0.6596 - recall: 0.6284 - val_loss: 0.5384 - val_binary_accuracy: 0.6846 - val_precision: 0.6522 - val_recall: 0.6588\n",
      "Epoch 622/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5384 - binary_accuracy: 0.6846 - precision: 0.6522 - recall: 0.6588 - val_loss: 0.5360 - val_binary_accuracy: 0.6877 - val_precision: 0.6620 - val_recall: 0.6419\n",
      "Epoch 623/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5360 - binary_accuracy: 0.6877 - precision: 0.6620 - recall: 0.6419 - val_loss: 0.5320 - val_binary_accuracy: 0.7015 - val_precision: 0.6747 - val_recall: 0.6655\n",
      "Epoch 624/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5320 - binary_accuracy: 0.7015 - precision: 0.6747 - recall: 0.6655 - val_loss: 0.5279 - val_binary_accuracy: 0.6985 - val_precision: 0.6603 - val_recall: 0.6959\n",
      "Epoch 625/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5279 - binary_accuracy: 0.6985 - precision: 0.6603 - recall: 0.6959 - val_loss: 0.5252 - val_binary_accuracy: 0.6985 - val_precision: 0.6773 - val_recall: 0.6453\n",
      "Epoch 626/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5252 - binary_accuracy: 0.6985 - precision: 0.6773 - recall: 0.6453 - val_loss: 0.5223 - val_binary_accuracy: 0.7015 - val_precision: 0.6614 - val_recall: 0.7061\n",
      "Epoch 627/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5223 - binary_accuracy: 0.7015 - precision: 0.6614 - recall: 0.7061 - val_loss: 0.5181 - val_binary_accuracy: 0.7138 - val_precision: 0.7200 - val_recall: 0.6081\n",
      "Epoch 628/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5181 - binary_accuracy: 0.7138 - precision: 0.7200 - recall: 0.6081 - val_loss: 0.5141 - val_binary_accuracy: 0.7169 - val_precision: 0.6830 - val_recall: 0.7061\n",
      "Epoch 629/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5141 - binary_accuracy: 0.7169 - precision: 0.6830 - recall: 0.7061 - val_loss: 0.5095 - val_binary_accuracy: 0.7138 - val_precision: 0.7099 - val_recall: 0.6284\n",
      "Epoch 630/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.5095 - binary_accuracy: 0.7138 - precision: 0.7099 - recall: 0.6284 - val_loss: 0.5074 - val_binary_accuracy: 0.7108 - val_precision: 0.6667 - val_recall: 0.7297\n",
      "Epoch 631/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5074 - binary_accuracy: 0.7108 - precision: 0.6667 - recall: 0.7297 - val_loss: 0.5103 - val_binary_accuracy: 0.7154 - val_precision: 0.7817 - val_recall: 0.5203\n",
      "Epoch 632/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5103 - binary_accuracy: 0.7154 - precision: 0.7817 - recall: 0.5203 - val_loss: 0.5588 - val_binary_accuracy: 0.6769 - val_precision: 0.5964 - val_recall: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5588 - binary_accuracy: 0.6769 - precision: 0.5964 - recall: 0.8986 - val_loss: 0.6146 - val_binary_accuracy: 0.6600 - val_precision: 0.6923 - val_recall: 0.4561\n",
      "Epoch 634/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6146 - binary_accuracy: 0.6600 - precision: 0.6923 - recall: 0.4561 - val_loss: 0.6028 - val_binary_accuracy: 0.6369 - val_precision: 0.6648 - val_recall: 0.4088\n",
      "Epoch 635/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6028 - binary_accuracy: 0.6369 - precision: 0.6648 - recall: 0.4088 - val_loss: 0.5909 - val_binary_accuracy: 0.6262 - val_precision: 0.5917 - val_recall: 0.5777\n",
      "Epoch 636/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5909 - binary_accuracy: 0.6262 - precision: 0.5917 - recall: 0.5777 - val_loss: 0.6125 - val_binary_accuracy: 0.6323 - val_precision: 0.6014 - val_recall: 0.5709\n",
      "Epoch 637/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6125 - binary_accuracy: 0.6323 - precision: 0.6014 - recall: 0.5709 - val_loss: 0.5634 - val_binary_accuracy: 0.6708 - val_precision: 0.6952 - val_recall: 0.4932\n",
      "Epoch 638/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5634 - binary_accuracy: 0.6708 - precision: 0.6952 - recall: 0.4932 - val_loss: 0.5784 - val_binary_accuracy: 0.6600 - val_precision: 0.7095 - val_recall: 0.4291\n",
      "Epoch 639/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5784 - binary_accuracy: 0.6600 - precision: 0.7095 - recall: 0.4291 - val_loss: 0.5600 - val_binary_accuracy: 0.7015 - val_precision: 0.7161 - val_recall: 0.5709\n",
      "Epoch 640/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5600 - binary_accuracy: 0.7015 - precision: 0.7161 - recall: 0.5709 - val_loss: 0.5860 - val_binary_accuracy: 0.6969 - val_precision: 0.7089 - val_recall: 0.5676\n",
      "Epoch 641/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.5860 - binary_accuracy: 0.6969 - precision: 0.7089 - recall: 0.5676 - val_loss: 0.5525 - val_binary_accuracy: 0.6938 - val_precision: 0.7046 - val_recall: 0.5642\n",
      "Epoch 642/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5525 - binary_accuracy: 0.6938 - precision: 0.7046 - recall: 0.5642 - val_loss: 0.5266 - val_binary_accuracy: 0.7277 - val_precision: 0.7820 - val_recall: 0.5574\n",
      "Epoch 643/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.5266 - binary_accuracy: 0.7277 - precision: 0.7820 - recall: 0.5574 - val_loss: 0.5414 - val_binary_accuracy: 0.7308 - val_precision: 0.7763 - val_recall: 0.5743\n",
      "Epoch 644/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.5414 - binary_accuracy: 0.7308 - precision: 0.7763 - recall: 0.5743 - val_loss: 0.5383 - val_binary_accuracy: 0.7031 - val_precision: 0.6988 - val_recall: 0.6115\n",
      "Epoch 645/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5383 - binary_accuracy: 0.7031 - precision: 0.6988 - recall: 0.6115 - val_loss: 0.5228 - val_binary_accuracy: 0.7215 - val_precision: 0.6936 - val_recall: 0.6959\n",
      "Epoch 646/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5228 - binary_accuracy: 0.7215 - precision: 0.6936 - recall: 0.6959 - val_loss: 0.5157 - val_binary_accuracy: 0.7215 - val_precision: 0.7309 - val_recall: 0.6149\n",
      "Epoch 647/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5157 - binary_accuracy: 0.7215 - precision: 0.7309 - recall: 0.6149 - val_loss: 0.5084 - val_binary_accuracy: 0.7277 - val_precision: 0.7390 - val_recall: 0.6216\n",
      "Epoch 648/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.5084 - binary_accuracy: 0.7277 - precision: 0.7390 - recall: 0.6216 - val_loss: 0.5050 - val_binary_accuracy: 0.7277 - val_precision: 0.7228 - val_recall: 0.6520\n",
      "Epoch 649/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5050 - binary_accuracy: 0.7277 - precision: 0.7228 - recall: 0.6520 - val_loss: 0.5032 - val_binary_accuracy: 0.7323 - val_precision: 0.6943 - val_recall: 0.7365\n",
      "Epoch 650/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5032 - binary_accuracy: 0.7323 - precision: 0.6943 - recall: 0.7365 - val_loss: 0.4888 - val_binary_accuracy: 0.7585 - val_precision: 0.7324 - val_recall: 0.7399\n",
      "Epoch 651/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4888 - binary_accuracy: 0.7585 - precision: 0.7324 - recall: 0.7399 - val_loss: 0.4956 - val_binary_accuracy: 0.7462 - val_precision: 0.7631 - val_recall: 0.6419\n",
      "Epoch 652/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.4956 - binary_accuracy: 0.7462 - precision: 0.7631 - recall: 0.6419 - val_loss: 0.4843 - val_binary_accuracy: 0.7662 - val_precision: 0.7590 - val_recall: 0.7128\n",
      "Epoch 653/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.4843 - binary_accuracy: 0.7662 - precision: 0.7590 - recall: 0.7128 - val_loss: 0.4812 - val_binary_accuracy: 0.7538 - val_precision: 0.7615 - val_recall: 0.6689\n",
      "Epoch 654/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4812 - binary_accuracy: 0.7538 - precision: 0.7615 - recall: 0.6689 - val_loss: 0.4849 - val_binary_accuracy: 0.7600 - val_precision: 0.7632 - val_recall: 0.6858\n",
      "Epoch 655/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4849 - binary_accuracy: 0.7600 - precision: 0.7632 - recall: 0.6858 - val_loss: 0.4726 - val_binary_accuracy: 0.7508 - val_precision: 0.7376 - val_recall: 0.7027\n",
      "Epoch 656/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4726 - binary_accuracy: 0.7508 - precision: 0.7376 - recall: 0.7027 - val_loss: 0.4709 - val_binary_accuracy: 0.7708 - val_precision: 0.8155 - val_recall: 0.6419\n",
      "Epoch 657/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4709 - binary_accuracy: 0.7708 - precision: 0.8155 - recall: 0.6419 - val_loss: 0.4853 - val_binary_accuracy: 0.7400 - val_precision: 0.7343 - val_recall: 0.6723\n",
      "Epoch 658/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4853 - binary_accuracy: 0.7400 - precision: 0.7343 - recall: 0.6723 - val_loss: 0.4643 - val_binary_accuracy: 0.7831 - val_precision: 0.7627 - val_recall: 0.7601\n",
      "Epoch 659/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4643 - binary_accuracy: 0.7831 - precision: 0.7627 - recall: 0.7601 - val_loss: 0.4649 - val_binary_accuracy: 0.7585 - val_precision: 0.7791 - val_recall: 0.6554\n",
      "Epoch 660/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4649 - binary_accuracy: 0.7585 - precision: 0.7791 - recall: 0.6554 - val_loss: 0.4861 - val_binary_accuracy: 0.7431 - val_precision: 0.7768 - val_recall: 0.6115\n",
      "Epoch 661/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.4861 - binary_accuracy: 0.7431 - precision: 0.7768 - recall: 0.6115 - val_loss: 0.4740 - val_binary_accuracy: 0.7600 - val_precision: 0.7482 - val_recall: 0.7128\n",
      "Epoch 662/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.4740 - binary_accuracy: 0.7600 - precision: 0.7482 - recall: 0.7128 - val_loss: 0.4813 - val_binary_accuracy: 0.7354 - val_precision: 0.6802 - val_recall: 0.7905\n",
      "Epoch 663/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4813 - binary_accuracy: 0.7354 - precision: 0.6802 - recall: 0.7905 - val_loss: 0.5091 - val_binary_accuracy: 0.7092 - val_precision: 0.9213 - val_recall: 0.3953\n",
      "Epoch 664/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.5091 - binary_accuracy: 0.7092 - precision: 0.9213 - recall: 0.3953 - val_loss: 0.5221 - val_binary_accuracy: 0.7108 - val_precision: 0.6607 - val_recall: 0.7500\n",
      "Epoch 665/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.5221 - binary_accuracy: 0.7108 - precision: 0.6607 - recall: 0.7500 - val_loss: 0.5204 - val_binary_accuracy: 0.7123 - val_precision: 0.6677 - val_recall: 0.7331\n",
      "Epoch 666/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.5204 - binary_accuracy: 0.7123 - precision: 0.6677 - recall: 0.7331 - val_loss: 0.4654 - val_binary_accuracy: 0.7585 - val_precision: 0.7491 - val_recall: 0.7061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4654 - binary_accuracy: 0.7585 - precision: 0.7491 - recall: 0.7061 - val_loss: 0.4732 - val_binary_accuracy: 0.7615 - val_precision: 0.8190 - val_recall: 0.6115\n",
      "Epoch 668/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4732 - binary_accuracy: 0.7615 - precision: 0.8190 - recall: 0.6115 - val_loss: 0.4837 - val_binary_accuracy: 0.7262 - val_precision: 0.8598 - val_recall: 0.4764\n",
      "Epoch 669/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.4837 - binary_accuracy: 0.7262 - precision: 0.8598 - recall: 0.4764 - val_loss: 0.4464 - val_binary_accuracy: 0.7662 - val_precision: 0.7400 - val_recall: 0.7500\n",
      "Epoch 670/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4464 - binary_accuracy: 0.7662 - precision: 0.7400 - recall: 0.7500 - val_loss: 0.4539 - val_binary_accuracy: 0.7492 - val_precision: 0.6873 - val_recall: 0.8243\n",
      "Epoch 671/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4539 - binary_accuracy: 0.7492 - precision: 0.6873 - recall: 0.8243 - val_loss: 0.4595 - val_binary_accuracy: 0.7769 - val_precision: 0.7397 - val_recall: 0.7872\n",
      "Epoch 672/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4595 - binary_accuracy: 0.7769 - precision: 0.7397 - recall: 0.7872 - val_loss: 0.4375 - val_binary_accuracy: 0.7938 - val_precision: 0.8045 - val_recall: 0.7230\n",
      "Epoch 673/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.4375 - binary_accuracy: 0.7938 - precision: 0.8045 - recall: 0.7230 - val_loss: 0.4775 - val_binary_accuracy: 0.7492 - val_precision: 0.8446 - val_recall: 0.5507\n",
      "Epoch 674/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4775 - binary_accuracy: 0.7492 - precision: 0.8446 - recall: 0.5507 - val_loss: 0.4418 - val_binary_accuracy: 0.8015 - val_precision: 0.8249 - val_recall: 0.7162\n",
      "Epoch 675/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.4418 - binary_accuracy: 0.8015 - precision: 0.8249 - recall: 0.7162 - val_loss: 0.4471 - val_binary_accuracy: 0.7662 - val_precision: 0.7483 - val_recall: 0.7331\n",
      "Epoch 676/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.4471 - binary_accuracy: 0.7662 - precision: 0.7483 - recall: 0.7331 - val_loss: 0.4454 - val_binary_accuracy: 0.7785 - val_precision: 0.7436 - val_recall: 0.7838\n",
      "Epoch 677/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4454 - binary_accuracy: 0.7785 - precision: 0.7436 - recall: 0.7838 - val_loss: 0.4206 - val_binary_accuracy: 0.7985 - val_precision: 0.7570 - val_recall: 0.8209\n",
      "Epoch 678/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4206 - binary_accuracy: 0.7985 - precision: 0.7570 - recall: 0.8209 - val_loss: 0.4355 - val_binary_accuracy: 0.7646 - val_precision: 0.8265 - val_recall: 0.6115\n",
      "Epoch 679/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4355 - binary_accuracy: 0.7646 - precision: 0.8265 - recall: 0.6115 - val_loss: 0.4165 - val_binary_accuracy: 0.7908 - val_precision: 0.8125 - val_recall: 0.7027\n",
      "Epoch 680/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4165 - binary_accuracy: 0.7908 - precision: 0.8125 - recall: 0.7027 - val_loss: 0.4110 - val_binary_accuracy: 0.8046 - val_precision: 0.8051 - val_recall: 0.7534\n",
      "Epoch 681/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4110 - binary_accuracy: 0.8046 - precision: 0.8051 - recall: 0.7534 - val_loss: 0.4113 - val_binary_accuracy: 0.7969 - val_precision: 0.7789 - val_recall: 0.7736\n",
      "Epoch 682/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4113 - binary_accuracy: 0.7969 - precision: 0.7789 - recall: 0.7736 - val_loss: 0.4027 - val_binary_accuracy: 0.7862 - val_precision: 0.7524 - val_recall: 0.7905\n",
      "Epoch 683/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4027 - binary_accuracy: 0.7862 - precision: 0.7524 - recall: 0.7905 - val_loss: 0.3972 - val_binary_accuracy: 0.8077 - val_precision: 0.8251 - val_recall: 0.7331\n",
      "Epoch 684/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3972 - binary_accuracy: 0.8077 - precision: 0.8251 - recall: 0.7331 - val_loss: 0.4000 - val_binary_accuracy: 0.8000 - val_precision: 0.8487 - val_recall: 0.6824\n",
      "Epoch 685/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.4000 - binary_accuracy: 0.8000 - precision: 0.8487 - recall: 0.6824 - val_loss: 0.3953 - val_binary_accuracy: 0.8185 - val_precision: 0.8371 - val_recall: 0.7466\n",
      "Epoch 686/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3953 - binary_accuracy: 0.8185 - precision: 0.8371 - recall: 0.7466 - val_loss: 0.3805 - val_binary_accuracy: 0.8046 - val_precision: 0.7717 - val_recall: 0.8108\n",
      "Epoch 687/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.3805 - binary_accuracy: 0.8046 - precision: 0.7717 - recall: 0.8108 - val_loss: 0.3778 - val_binary_accuracy: 0.8169 - val_precision: 0.8062 - val_recall: 0.7872\n",
      "Epoch 688/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3778 - binary_accuracy: 0.8169 - precision: 0.8062 - recall: 0.7872 - val_loss: 0.3931 - val_binary_accuracy: 0.8185 - val_precision: 0.8870 - val_recall: 0.6892\n",
      "Epoch 689/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.3931 - binary_accuracy: 0.8185 - precision: 0.8870 - recall: 0.6892 - val_loss: 0.4121 - val_binary_accuracy: 0.7908 - val_precision: 0.8175 - val_recall: 0.6959\n",
      "Epoch 690/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.4121 - binary_accuracy: 0.7908 - precision: 0.8175 - recall: 0.6959 - val_loss: 0.4912 - val_binary_accuracy: 0.7585 - val_precision: 0.7235 - val_recall: 0.7601\n",
      "Epoch 691/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.4912 - binary_accuracy: 0.7585 - precision: 0.7235 - recall: 0.7601 - val_loss: 0.5503 - val_binary_accuracy: 0.7123 - val_precision: 0.6430 - val_recall: 0.8277\n",
      "Epoch 692/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5503 - binary_accuracy: 0.7123 - precision: 0.6430 - recall: 0.8277 - val_loss: 0.6911 - val_binary_accuracy: 0.6492 - val_precision: 0.7152 - val_recall: 0.3818\n",
      "Epoch 693/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6911 - binary_accuracy: 0.6492 - precision: 0.7152 - recall: 0.3818 - val_loss: 0.4595 - val_binary_accuracy: 0.7554 - val_precision: 0.8374 - val_recall: 0.5743\n",
      "Epoch 694/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.4595 - binary_accuracy: 0.7554 - precision: 0.8374 - recall: 0.5743 - val_loss: 0.5756 - val_binary_accuracy: 0.6862 - val_precision: 0.6369 - val_recall: 0.7230\n",
      "Epoch 695/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5756 - binary_accuracy: 0.6862 - precision: 0.6369 - recall: 0.7230 - val_loss: 0.5512 - val_binary_accuracy: 0.6862 - val_precision: 0.6292 - val_recall: 0.7568\n",
      "Epoch 696/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5512 - binary_accuracy: 0.6862 - precision: 0.6292 - recall: 0.7568 - val_loss: 0.4608 - val_binary_accuracy: 0.7862 - val_precision: 0.7985 - val_recall: 0.7095\n",
      "Epoch 697/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4608 - binary_accuracy: 0.7862 - precision: 0.7985 - recall: 0.7095 - val_loss: 0.5338 - val_binary_accuracy: 0.7369 - val_precision: 0.7753 - val_recall: 0.5946\n",
      "Epoch 698/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5338 - binary_accuracy: 0.7369 - precision: 0.7753 - recall: 0.5946 - val_loss: 0.5298 - val_binary_accuracy: 0.7123 - val_precision: 0.8759 - val_recall: 0.4291\n",
      "Epoch 699/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5298 - binary_accuracy: 0.7123 - precision: 0.8759 - recall: 0.4291 - val_loss: 0.4626 - val_binary_accuracy: 0.7631 - val_precision: 0.8515 - val_recall: 0.5811\n",
      "Epoch 700/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.4626 - binary_accuracy: 0.7631 - precision: 0.8515 - recall: 0.5811 - val_loss: 0.4761 - val_binary_accuracy: 0.7431 - val_precision: 0.6949 - val_recall: 0.7770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4761 - binary_accuracy: 0.7431 - precision: 0.6949 - recall: 0.7770 - val_loss: 0.5093 - val_binary_accuracy: 0.7215 - val_precision: 0.6567 - val_recall: 0.8142\n",
      "Epoch 702/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5093 - binary_accuracy: 0.7215 - precision: 0.6567 - recall: 0.8142 - val_loss: 0.4473 - val_binary_accuracy: 0.7677 - val_precision: 0.7231 - val_recall: 0.7939\n",
      "Epoch 703/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4473 - binary_accuracy: 0.7677 - precision: 0.7231 - recall: 0.7939 - val_loss: 0.4368 - val_binary_accuracy: 0.7677 - val_precision: 0.7778 - val_recall: 0.6858\n",
      "Epoch 704/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4368 - binary_accuracy: 0.7677 - precision: 0.7778 - recall: 0.6858 - val_loss: 0.4617 - val_binary_accuracy: 0.7477 - val_precision: 0.8511 - val_recall: 0.5405\n",
      "Epoch 705/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.4617 - binary_accuracy: 0.7477 - precision: 0.8511 - recall: 0.5405 - val_loss: 0.4263 - val_binary_accuracy: 0.7754 - val_precision: 0.8989 - val_recall: 0.5709\n",
      "Epoch 706/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4263 - binary_accuracy: 0.7754 - precision: 0.8989 - recall: 0.5709 - val_loss: 0.4347 - val_binary_accuracy: 0.7877 - val_precision: 0.8591 - val_recall: 0.6385\n",
      "Epoch 707/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4347 - binary_accuracy: 0.7877 - precision: 0.8591 - recall: 0.6385 - val_loss: 0.4339 - val_binary_accuracy: 0.7738 - val_precision: 0.7614 - val_recall: 0.7331\n",
      "Epoch 708/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4339 - binary_accuracy: 0.7738 - precision: 0.7614 - recall: 0.7331 - val_loss: 0.4140 - val_binary_accuracy: 0.7769 - val_precision: 0.7214 - val_recall: 0.8311\n",
      "Epoch 709/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.4140 - binary_accuracy: 0.7769 - precision: 0.7214 - recall: 0.8311 - val_loss: 0.4105 - val_binary_accuracy: 0.7969 - val_precision: 0.7515 - val_recall: 0.8277\n",
      "Epoch 710/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.4105 - binary_accuracy: 0.7969 - precision: 0.7515 - recall: 0.8277 - val_loss: 0.4074 - val_binary_accuracy: 0.7800 - val_precision: 0.7802 - val_recall: 0.7196\n",
      "Epoch 711/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4074 - binary_accuracy: 0.7800 - precision: 0.7802 - recall: 0.7196 - val_loss: 0.3898 - val_binary_accuracy: 0.8031 - val_precision: 0.8784 - val_recall: 0.6588\n",
      "Epoch 712/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3898 - binary_accuracy: 0.8031 - precision: 0.8784 - recall: 0.6588 - val_loss: 0.4013 - val_binary_accuracy: 0.7908 - val_precision: 0.8846 - val_recall: 0.6216\n",
      "Epoch 713/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4013 - binary_accuracy: 0.7908 - precision: 0.8846 - recall: 0.6216 - val_loss: 0.3840 - val_binary_accuracy: 0.8231 - val_precision: 0.8787 - val_recall: 0.7095\n",
      "Epoch 714/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3840 - binary_accuracy: 0.8231 - precision: 0.8787 - recall: 0.7095 - val_loss: 0.3697 - val_binary_accuracy: 0.8277 - val_precision: 0.8194 - val_recall: 0.7973\n",
      "Epoch 715/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3697 - binary_accuracy: 0.8277 - precision: 0.8194 - recall: 0.7973 - val_loss: 0.3840 - val_binary_accuracy: 0.8000 - val_precision: 0.7712 - val_recall: 0.7973\n",
      "Epoch 716/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3840 - binary_accuracy: 0.8000 - precision: 0.7712 - recall: 0.7973 - val_loss: 0.3680 - val_binary_accuracy: 0.8046 - val_precision: 0.7864 - val_recall: 0.7838\n",
      "Epoch 717/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3680 - binary_accuracy: 0.8046 - precision: 0.7864 - recall: 0.7838 - val_loss: 0.3573 - val_binary_accuracy: 0.8338 - val_precision: 0.8672 - val_recall: 0.7500\n",
      "Epoch 718/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3573 - binary_accuracy: 0.8338 - precision: 0.8672 - recall: 0.7500 - val_loss: 0.3661 - val_binary_accuracy: 0.8215 - val_precision: 0.9091 - val_recall: 0.6757\n",
      "Epoch 719/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3661 - binary_accuracy: 0.8215 - precision: 0.9091 - recall: 0.6757 - val_loss: 0.3451 - val_binary_accuracy: 0.8415 - val_precision: 0.9142 - val_recall: 0.7196\n",
      "Epoch 720/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3451 - binary_accuracy: 0.8415 - precision: 0.9142 - recall: 0.7196 - val_loss: 0.3519 - val_binary_accuracy: 0.8308 - val_precision: 0.8444 - val_recall: 0.7703\n",
      "Epoch 721/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3519 - binary_accuracy: 0.8308 - precision: 0.8444 - recall: 0.7703 - val_loss: 0.3406 - val_binary_accuracy: 0.8523 - val_precision: 0.8497 - val_recall: 0.8209\n",
      "Epoch 722/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3406 - binary_accuracy: 0.8523 - precision: 0.8497 - recall: 0.8209 - val_loss: 0.3465 - val_binary_accuracy: 0.8323 - val_precision: 0.8351 - val_recall: 0.7872\n",
      "Epoch 723/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3465 - binary_accuracy: 0.8323 - precision: 0.8351 - recall: 0.7872 - val_loss: 0.3342 - val_binary_accuracy: 0.8292 - val_precision: 0.8339 - val_recall: 0.7804\n",
      "Epoch 724/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3342 - binary_accuracy: 0.8292 - precision: 0.8339 - recall: 0.7804 - val_loss: 0.3336 - val_binary_accuracy: 0.8369 - val_precision: 0.8958 - val_recall: 0.7264\n",
      "Epoch 725/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3336 - binary_accuracy: 0.8369 - precision: 0.8958 - recall: 0.7264 - val_loss: 0.3198 - val_binary_accuracy: 0.8462 - val_precision: 0.8952 - val_recall: 0.7500\n",
      "Epoch 726/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3198 - binary_accuracy: 0.8462 - precision: 0.8952 - recall: 0.7500 - val_loss: 0.3250 - val_binary_accuracy: 0.8400 - val_precision: 0.8453 - val_recall: 0.7939\n",
      "Epoch 727/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3250 - binary_accuracy: 0.8400 - precision: 0.8453 - recall: 0.7939 - val_loss: 0.3295 - val_binary_accuracy: 0.8415 - val_precision: 0.8434 - val_recall: 0.8007\n",
      "Epoch 728/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3295 - binary_accuracy: 0.8415 - precision: 0.8434 - recall: 0.8007 - val_loss: 0.3056 - val_binary_accuracy: 0.8538 - val_precision: 0.8681 - val_recall: 0.8007\n",
      "Epoch 729/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3056 - binary_accuracy: 0.8538 - precision: 0.8681 - recall: 0.8007 - val_loss: 0.3083 - val_binary_accuracy: 0.8538 - val_precision: 0.8972 - val_recall: 0.7669\n",
      "Epoch 730/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3083 - binary_accuracy: 0.8538 - precision: 0.8972 - recall: 0.7669 - val_loss: 0.3017 - val_binary_accuracy: 0.8646 - val_precision: 0.9228 - val_recall: 0.7669\n",
      "Epoch 731/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3017 - binary_accuracy: 0.8646 - precision: 0.9228 - recall: 0.7669 - val_loss: 0.2926 - val_binary_accuracy: 0.8723 - val_precision: 0.9019 - val_recall: 0.8074\n",
      "Epoch 732/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2926 - binary_accuracy: 0.8723 - precision: 0.9019 - recall: 0.8074 - val_loss: 0.2954 - val_binary_accuracy: 0.8677 - val_precision: 0.8671 - val_recall: 0.8378\n",
      "Epoch 733/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2954 - binary_accuracy: 0.8677 - precision: 0.8671 - recall: 0.8378 - val_loss: 0.2809 - val_binary_accuracy: 0.8831 - val_precision: 0.9297 - val_recall: 0.8041\n",
      "Epoch 734/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2809 - binary_accuracy: 0.8831 - precision: 0.9297 - recall: 0.8041 - val_loss: 0.2795 - val_binary_accuracy: 0.8769 - val_precision: 0.9463 - val_recall: 0.7736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2795 - binary_accuracy: 0.8769 - precision: 0.9463 - recall: 0.7736 - val_loss: 0.2817 - val_binary_accuracy: 0.8692 - val_precision: 0.8809 - val_recall: 0.8243\n",
      "Epoch 736/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2817 - binary_accuracy: 0.8692 - precision: 0.8809 - recall: 0.8243 - val_loss: 0.2889 - val_binary_accuracy: 0.8692 - val_precision: 0.9042 - val_recall: 0.7973\n",
      "Epoch 737/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2889 - binary_accuracy: 0.8692 - precision: 0.9042 - recall: 0.7973 - val_loss: 0.3103 - val_binary_accuracy: 0.8323 - val_precision: 0.8400 - val_recall: 0.7804\n",
      "Epoch 738/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.3103 - binary_accuracy: 0.8323 - precision: 0.8400 - recall: 0.7804 - val_loss: 0.3910 - val_binary_accuracy: 0.8154 - val_precision: 0.8761 - val_recall: 0.6926\n",
      "Epoch 739/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.3910 - binary_accuracy: 0.8154 - precision: 0.8761 - recall: 0.6926 - val_loss: 0.3113 - val_binary_accuracy: 0.8523 - val_precision: 0.8378 - val_recall: 0.8378\n",
      "Epoch 740/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.3113 - binary_accuracy: 0.8523 - precision: 0.8378 - recall: 0.8378 - val_loss: 0.3985 - val_binary_accuracy: 0.7969 - val_precision: 0.7808 - val_recall: 0.7703\n",
      "Epoch 741/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.3985 - binary_accuracy: 0.7969 - precision: 0.7808 - recall: 0.7703 - val_loss: 0.4236 - val_binary_accuracy: 0.7985 - val_precision: 0.9188 - val_recall: 0.6115\n",
      "Epoch 742/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4236 - binary_accuracy: 0.7985 - precision: 0.9188 - recall: 0.6115 - val_loss: 0.4225 - val_binary_accuracy: 0.7831 - val_precision: 0.7719 - val_recall: 0.7432\n",
      "Epoch 743/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4225 - binary_accuracy: 0.7831 - precision: 0.7719 - recall: 0.7432 - val_loss: 0.3405 - val_binary_accuracy: 0.8231 - val_precision: 0.7768 - val_recall: 0.8581\n",
      "Epoch 744/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.3405 - binary_accuracy: 0.8231 - precision: 0.7768 - recall: 0.8581 - val_loss: 0.3594 - val_binary_accuracy: 0.7985 - val_precision: 0.8767 - val_recall: 0.6486\n",
      "Epoch 745/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.3594 - binary_accuracy: 0.7985 - precision: 0.8767 - recall: 0.6486 - val_loss: 0.3806 - val_binary_accuracy: 0.7969 - val_precision: 0.9059 - val_recall: 0.6182\n",
      "Epoch 746/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.3806 - binary_accuracy: 0.7969 - precision: 0.9059 - recall: 0.6182 - val_loss: 0.3004 - val_binary_accuracy: 0.8662 - val_precision: 0.9130 - val_recall: 0.7804\n",
      "Epoch 747/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3004 - binary_accuracy: 0.8662 - precision: 0.9130 - recall: 0.7804 - val_loss: 0.3394 - val_binary_accuracy: 0.8154 - val_precision: 0.7514 - val_recall: 0.8885\n",
      "Epoch 748/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.3394 - binary_accuracy: 0.8154 - precision: 0.7514 - recall: 0.8885 - val_loss: 0.3263 - val_binary_accuracy: 0.8492 - val_precision: 0.8694 - val_recall: 0.7872\n",
      "Epoch 749/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3263 - binary_accuracy: 0.8492 - precision: 0.8694 - recall: 0.7872 - val_loss: 0.2858 - val_binary_accuracy: 0.8615 - val_precision: 0.9087 - val_recall: 0.7736\n",
      "Epoch 750/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2858 - binary_accuracy: 0.8615 - precision: 0.9087 - recall: 0.7736 - val_loss: 0.3176 - val_binary_accuracy: 0.8338 - val_precision: 0.8701 - val_recall: 0.7466\n",
      "Epoch 751/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3176 - binary_accuracy: 0.8338 - precision: 0.8701 - recall: 0.7466 - val_loss: 0.2791 - val_binary_accuracy: 0.8785 - val_precision: 0.9189 - val_recall: 0.8041\n",
      "Epoch 752/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2791 - binary_accuracy: 0.8785 - precision: 0.9189 - recall: 0.8041 - val_loss: 0.2898 - val_binary_accuracy: 0.8662 - val_precision: 0.8746 - val_recall: 0.8243\n",
      "Epoch 753/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2898 - binary_accuracy: 0.8662 - precision: 0.8746 - recall: 0.8243 - val_loss: 0.2811 - val_binary_accuracy: 0.8738 - val_precision: 0.8963 - val_recall: 0.8176\n",
      "Epoch 754/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.2811 - binary_accuracy: 0.8738 - precision: 0.8963 - recall: 0.8176 - val_loss: 0.2642 - val_binary_accuracy: 0.8754 - val_precision: 0.8938 - val_recall: 0.8243\n",
      "Epoch 755/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2642 - binary_accuracy: 0.8754 - precision: 0.8938 - recall: 0.8243 - val_loss: 0.2701 - val_binary_accuracy: 0.8677 - val_precision: 0.8889 - val_recall: 0.8108\n",
      "Epoch 756/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2701 - binary_accuracy: 0.8677 - precision: 0.8889 - recall: 0.8108 - val_loss: 0.2603 - val_binary_accuracy: 0.8800 - val_precision: 0.9160 - val_recall: 0.8108\n",
      "Epoch 757/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2603 - binary_accuracy: 0.8800 - precision: 0.9160 - recall: 0.8108 - val_loss: 0.2588 - val_binary_accuracy: 0.8754 - val_precision: 0.8938 - val_recall: 0.8243\n",
      "Epoch 758/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2588 - binary_accuracy: 0.8754 - precision: 0.8938 - recall: 0.8243 - val_loss: 0.2411 - val_binary_accuracy: 0.9169 - val_precision: 0.9416 - val_recall: 0.8716\n",
      "Epoch 759/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2411 - binary_accuracy: 0.9169 - precision: 0.9416 - recall: 0.8716 - val_loss: 0.2530 - val_binary_accuracy: 0.8862 - val_precision: 0.9173 - val_recall: 0.8243\n",
      "Epoch 760/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2530 - binary_accuracy: 0.8862 - precision: 0.9173 - recall: 0.8243 - val_loss: 0.2345 - val_binary_accuracy: 0.9062 - val_precision: 0.9401 - val_recall: 0.8480\n",
      "Epoch 761/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2345 - binary_accuracy: 0.9062 - precision: 0.9401 - recall: 0.8480 - val_loss: 0.2484 - val_binary_accuracy: 0.8908 - val_precision: 0.8893 - val_recall: 0.8682\n",
      "Epoch 762/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2484 - binary_accuracy: 0.8908 - precision: 0.8893 - recall: 0.8682 - val_loss: 0.2196 - val_binary_accuracy: 0.9154 - val_precision: 0.9382 - val_recall: 0.8716\n",
      "Epoch 763/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2196 - binary_accuracy: 0.9154 - precision: 0.9382 - recall: 0.8716 - val_loss: 0.2360 - val_binary_accuracy: 0.8938 - val_precision: 0.9283 - val_recall: 0.8311\n",
      "Epoch 764/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2360 - binary_accuracy: 0.8938 - precision: 0.9283 - recall: 0.8311 - val_loss: 0.2228 - val_binary_accuracy: 0.9046 - val_precision: 0.9366 - val_recall: 0.8480\n",
      "Epoch 765/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2228 - binary_accuracy: 0.9046 - precision: 0.9366 - recall: 0.8480 - val_loss: 0.2498 - val_binary_accuracy: 0.8954 - val_precision: 0.9014 - val_recall: 0.8649\n",
      "Epoch 766/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2498 - binary_accuracy: 0.8954 - precision: 0.9014 - recall: 0.8649 - val_loss: 0.3387 - val_binary_accuracy: 0.8477 - val_precision: 0.8689 - val_recall: 0.7838\n",
      "Epoch 767/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3387 - binary_accuracy: 0.8477 - precision: 0.8689 - recall: 0.7838 - val_loss: 0.3251 - val_binary_accuracy: 0.8385 - val_precision: 0.8215 - val_recall: 0.8243\n",
      "Epoch 768/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3251 - binary_accuracy: 0.8385 - precision: 0.8215 - recall: 0.8243 - val_loss: 0.3006 - val_binary_accuracy: 0.8600 - val_precision: 0.9253 - val_recall: 0.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.3006 - binary_accuracy: 0.8600 - precision: 0.9253 - recall: 0.7534 - val_loss: 0.2953 - val_binary_accuracy: 0.8785 - val_precision: 0.8511 - val_recall: 0.8885\n",
      "Epoch 770/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2953 - binary_accuracy: 0.8785 - precision: 0.8511 - recall: 0.8885 - val_loss: 0.2828 - val_binary_accuracy: 0.8677 - val_precision: 0.8918 - val_recall: 0.8074\n",
      "Epoch 771/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2828 - binary_accuracy: 0.8677 - precision: 0.8918 - recall: 0.8074 - val_loss: 0.2745 - val_binary_accuracy: 0.8708 - val_precision: 0.9649 - val_recall: 0.7432\n",
      "Epoch 772/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2745 - binary_accuracy: 0.8708 - precision: 0.9649 - recall: 0.7432 - val_loss: 0.2868 - val_binary_accuracy: 0.8631 - val_precision: 0.8462 - val_recall: 0.8547\n",
      "Epoch 773/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2868 - binary_accuracy: 0.8631 - precision: 0.8462 - recall: 0.8547 - val_loss: 0.2392 - val_binary_accuracy: 0.8708 - val_precision: 0.8354 - val_recall: 0.8919\n",
      "Epoch 774/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2392 - binary_accuracy: 0.8708 - precision: 0.8354 - recall: 0.8919 - val_loss: 0.2467 - val_binary_accuracy: 0.8862 - val_precision: 0.9336 - val_recall: 0.8074\n",
      "Epoch 775/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2467 - binary_accuracy: 0.8862 - precision: 0.9336 - recall: 0.8074 - val_loss: 0.2441 - val_binary_accuracy: 0.8877 - val_precision: 0.9514 - val_recall: 0.7939\n",
      "Epoch 776/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2441 - binary_accuracy: 0.8877 - precision: 0.9514 - recall: 0.7939 - val_loss: 0.2403 - val_binary_accuracy: 0.8862 - val_precision: 0.8964 - val_recall: 0.8480\n",
      "Epoch 777/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2403 - binary_accuracy: 0.8862 - precision: 0.8964 - recall: 0.8480 - val_loss: 0.2333 - val_binary_accuracy: 0.8892 - val_precision: 0.8613 - val_recall: 0.9020\n",
      "Epoch 778/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2333 - binary_accuracy: 0.8892 - precision: 0.8613 - recall: 0.9020 - val_loss: 0.2175 - val_binary_accuracy: 0.9092 - val_precision: 0.9341 - val_recall: 0.8615\n",
      "Epoch 779/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2175 - binary_accuracy: 0.9092 - precision: 0.9341 - recall: 0.8615 - val_loss: 0.2283 - val_binary_accuracy: 0.9046 - val_precision: 0.9795 - val_recall: 0.8074\n",
      "Epoch 780/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2283 - binary_accuracy: 0.9046 - precision: 0.9795 - recall: 0.8074 - val_loss: 0.2025 - val_binary_accuracy: 0.9092 - val_precision: 0.9405 - val_recall: 0.8547\n",
      "Epoch 781/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2025 - binary_accuracy: 0.9092 - precision: 0.9405 - recall: 0.8547 - val_loss: 0.2189 - val_binary_accuracy: 0.8923 - val_precision: 0.8717 - val_recall: 0.8953\n",
      "Epoch 782/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2189 - binary_accuracy: 0.8923 - precision: 0.8717 - recall: 0.8953 - val_loss: 0.1928 - val_binary_accuracy: 0.9231 - val_precision: 0.9590 - val_recall: 0.8682\n",
      "Epoch 783/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1928 - binary_accuracy: 0.9231 - precision: 0.9590 - recall: 0.8682 - val_loss: 0.1981 - val_binary_accuracy: 0.9185 - val_precision: 0.9728 - val_recall: 0.8446\n",
      "Epoch 784/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1981 - binary_accuracy: 0.9185 - precision: 0.9728 - recall: 0.8446 - val_loss: 0.1934 - val_binary_accuracy: 0.9123 - val_precision: 0.9509 - val_recall: 0.8514\n",
      "Epoch 785/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1934 - binary_accuracy: 0.9123 - precision: 0.9509 - recall: 0.8514 - val_loss: 0.1876 - val_binary_accuracy: 0.9200 - val_precision: 0.8910 - val_recall: 0.9392\n",
      "Epoch 786/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1876 - binary_accuracy: 0.9200 - precision: 0.8910 - recall: 0.9392 - val_loss: 0.1842 - val_binary_accuracy: 0.9200 - val_precision: 0.9388 - val_recall: 0.8818\n",
      "Epoch 787/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1842 - binary_accuracy: 0.9200 - precision: 0.9388 - recall: 0.8818 - val_loss: 0.1852 - val_binary_accuracy: 0.9262 - val_precision: 0.9844 - val_recall: 0.8514\n",
      "Epoch 788/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1852 - binary_accuracy: 0.9262 - precision: 0.9844 - recall: 0.8514 - val_loss: 0.1797 - val_binary_accuracy: 0.9308 - val_precision: 0.9631 - val_recall: 0.8818\n",
      "Epoch 789/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1797 - binary_accuracy: 0.9308 - precision: 0.9631 - recall: 0.8818 - val_loss: 0.1743 - val_binary_accuracy: 0.9200 - val_precision: 0.8935 - val_recall: 0.9358\n",
      "Epoch 790/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1743 - binary_accuracy: 0.9200 - precision: 0.8935 - recall: 0.9358 - val_loss: 0.1689 - val_binary_accuracy: 0.9277 - val_precision: 0.9278 - val_recall: 0.9122\n",
      "Epoch 791/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1689 - binary_accuracy: 0.9277 - precision: 0.9278 - recall: 0.9122 - val_loss: 0.1686 - val_binary_accuracy: 0.9308 - val_precision: 0.9846 - val_recall: 0.8615\n",
      "Epoch 792/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1686 - binary_accuracy: 0.9308 - precision: 0.9846 - recall: 0.8615 - val_loss: 0.1643 - val_binary_accuracy: 0.9308 - val_precision: 0.9564 - val_recall: 0.8885\n",
      "Epoch 793/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1643 - binary_accuracy: 0.9308 - precision: 0.9564 - recall: 0.8885 - val_loss: 0.1572 - val_binary_accuracy: 0.9446 - val_precision: 0.9514 - val_recall: 0.9257\n",
      "Epoch 794/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1572 - binary_accuracy: 0.9446 - precision: 0.9514 - recall: 0.9257 - val_loss: 0.1649 - val_binary_accuracy: 0.9308 - val_precision: 0.9254 - val_recall: 0.9223\n",
      "Epoch 795/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1649 - binary_accuracy: 0.9308 - precision: 0.9254 - recall: 0.9223 - val_loss: 0.1589 - val_binary_accuracy: 0.9323 - val_precision: 0.9701 - val_recall: 0.8784\n",
      "Epoch 796/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1589 - binary_accuracy: 0.9323 - precision: 0.9701 - recall: 0.8784 - val_loss: 0.1565 - val_binary_accuracy: 0.9400 - val_precision: 0.9606 - val_recall: 0.9054\n",
      "Epoch 797/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1565 - binary_accuracy: 0.9400 - precision: 0.9606 - recall: 0.9054 - val_loss: 0.1640 - val_binary_accuracy: 0.9292 - val_precision: 0.9195 - val_recall: 0.9257\n",
      "Epoch 798/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1640 - binary_accuracy: 0.9292 - precision: 0.9195 - recall: 0.9257 - val_loss: 0.1558 - val_binary_accuracy: 0.9385 - val_precision: 0.9672 - val_recall: 0.8953\n",
      "Epoch 799/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1558 - binary_accuracy: 0.9385 - precision: 0.9672 - recall: 0.8953 - val_loss: 0.1357 - val_binary_accuracy: 0.9492 - val_precision: 0.9550 - val_recall: 0.9324\n",
      "Epoch 800/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1357 - binary_accuracy: 0.9492 - precision: 0.9550 - recall: 0.9324 - val_loss: 0.1338 - val_binary_accuracy: 0.9554 - val_precision: 0.9890 - val_recall: 0.9122\n",
      "Epoch 801/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1338 - binary_accuracy: 0.9554 - precision: 0.9890 - recall: 0.9122 - val_loss: 0.1425 - val_binary_accuracy: 0.9415 - val_precision: 0.9574 - val_recall: 0.9122\n",
      "Epoch 802/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1425 - binary_accuracy: 0.9415 - precision: 0.9574 - recall: 0.9122 - val_loss: 0.2056 - val_binary_accuracy: 0.8923 - val_precision: 0.8951 - val_recall: 0.8649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2056 - binary_accuracy: 0.8923 - precision: 0.8951 - recall: 0.8649 - val_loss: 0.5463 - val_binary_accuracy: 0.7908 - val_precision: 0.7837 - val_recall: 0.7466\n",
      "Epoch 804/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5463 - binary_accuracy: 0.7908 - precision: 0.7837 - recall: 0.7466 - val_loss: 0.3425 - val_binary_accuracy: 0.8508 - val_precision: 0.8373 - val_recall: 0.8345\n",
      "Epoch 805/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3425 - binary_accuracy: 0.8508 - precision: 0.8373 - recall: 0.8345 - val_loss: 0.4688 - val_binary_accuracy: 0.7969 - val_precision: 0.7908 - val_recall: 0.7534\n",
      "Epoch 806/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4688 - binary_accuracy: 0.7969 - precision: 0.7908 - recall: 0.7534 - val_loss: 0.2704 - val_binary_accuracy: 0.8662 - val_precision: 0.9197 - val_recall: 0.7736\n",
      "Epoch 807/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.2704 - binary_accuracy: 0.8662 - precision: 0.9197 - recall: 0.7736 - val_loss: 0.4423 - val_binary_accuracy: 0.7600 - val_precision: 0.6741 - val_recall: 0.9155\n",
      "Epoch 808/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4423 - binary_accuracy: 0.7600 - precision: 0.6741 - recall: 0.9155 - val_loss: 0.2874 - val_binary_accuracy: 0.8754 - val_precision: 0.9909 - val_recall: 0.7331\n",
      "Epoch 809/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2874 - binary_accuracy: 0.8754 - precision: 0.9909 - recall: 0.7331 - val_loss: 0.3856 - val_binary_accuracy: 0.8262 - val_precision: 0.8327 - val_recall: 0.7736\n",
      "Epoch 810/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3856 - binary_accuracy: 0.8262 - precision: 0.8327 - recall: 0.7736 - val_loss: 0.2278 - val_binary_accuracy: 0.8938 - val_precision: 0.8348 - val_recall: 0.9561\n",
      "Epoch 811/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2278 - binary_accuracy: 0.8938 - precision: 0.8348 - recall: 0.9561 - val_loss: 0.3366 - val_binary_accuracy: 0.8292 - val_precision: 0.8715 - val_recall: 0.7331\n",
      "Epoch 812/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.3366 - binary_accuracy: 0.8292 - precision: 0.8715 - recall: 0.7331 - val_loss: 0.1978 - val_binary_accuracy: 0.9123 - val_precision: 0.9314 - val_recall: 0.8716\n",
      "Epoch 813/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1978 - binary_accuracy: 0.9123 - precision: 0.9314 - recall: 0.8716 - val_loss: 0.2760 - val_binary_accuracy: 0.8585 - val_precision: 0.8493 - val_recall: 0.8378\n",
      "Epoch 814/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.2760 - binary_accuracy: 0.8585 - precision: 0.8493 - recall: 0.8378 - val_loss: 0.2028 - val_binary_accuracy: 0.9123 - val_precision: 0.9314 - val_recall: 0.8716\n",
      "Epoch 815/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2028 - binary_accuracy: 0.9123 - precision: 0.9314 - recall: 0.8716 - val_loss: 0.2031 - val_binary_accuracy: 0.9108 - val_precision: 0.9440 - val_recall: 0.8547\n",
      "Epoch 816/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2031 - binary_accuracy: 0.9108 - precision: 0.9440 - recall: 0.8547 - val_loss: 0.2281 - val_binary_accuracy: 0.8954 - val_precision: 0.9014 - val_recall: 0.8649\n",
      "Epoch 817/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2281 - binary_accuracy: 0.8954 - precision: 0.9014 - recall: 0.8649 - val_loss: 0.1821 - val_binary_accuracy: 0.9246 - val_precision: 0.9103 - val_recall: 0.9257\n",
      "Epoch 818/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.1821 - binary_accuracy: 0.9246 - precision: 0.9103 - recall: 0.9257 - val_loss: 0.1921 - val_binary_accuracy: 0.9246 - val_precision: 0.9427 - val_recall: 0.8885\n",
      "Epoch 819/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.1921 - binary_accuracy: 0.9246 - precision: 0.9427 - recall: 0.8885 - val_loss: 0.1996 - val_binary_accuracy: 0.9108 - val_precision: 0.9648 - val_recall: 0.8345\n",
      "Epoch 820/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1996 - binary_accuracy: 0.9108 - precision: 0.9648 - recall: 0.8345 - val_loss: 0.1823 - val_binary_accuracy: 0.9231 - val_precision: 0.9393 - val_recall: 0.8885\n",
      "Epoch 821/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1823 - binary_accuracy: 0.9231 - precision: 0.9393 - recall: 0.8885 - val_loss: 0.1768 - val_binary_accuracy: 0.9292 - val_precision: 0.9371 - val_recall: 0.9054\n",
      "Epoch 822/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1768 - binary_accuracy: 0.9292 - precision: 0.9371 - recall: 0.9054 - val_loss: 0.1602 - val_binary_accuracy: 0.9415 - val_precision: 0.9674 - val_recall: 0.9020\n",
      "Epoch 823/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1602 - binary_accuracy: 0.9415 - precision: 0.9674 - recall: 0.9020 - val_loss: 0.1577 - val_binary_accuracy: 0.9385 - val_precision: 0.9604 - val_recall: 0.9020\n",
      "Epoch 824/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1577 - binary_accuracy: 0.9385 - precision: 0.9604 - recall: 0.9020 - val_loss: 0.1519 - val_binary_accuracy: 0.9354 - val_precision: 0.9504 - val_recall: 0.9054\n",
      "Epoch 825/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1519 - binary_accuracy: 0.9354 - precision: 0.9504 - recall: 0.9054 - val_loss: 0.1429 - val_binary_accuracy: 0.9554 - val_precision: 0.9751 - val_recall: 0.9257\n",
      "Epoch 826/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.1429 - binary_accuracy: 0.9554 - precision: 0.9751 - recall: 0.9257 - val_loss: 0.1488 - val_binary_accuracy: 0.9400 - val_precision: 0.9573 - val_recall: 0.9088\n",
      "Epoch 827/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1488 - binary_accuracy: 0.9400 - precision: 0.9573 - recall: 0.9088 - val_loss: 0.1364 - val_binary_accuracy: 0.9569 - val_precision: 0.9786 - val_recall: 0.9257\n",
      "Epoch 828/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1364 - binary_accuracy: 0.9569 - precision: 0.9786 - recall: 0.9257 - val_loss: 0.1292 - val_binary_accuracy: 0.9538 - val_precision: 0.9854 - val_recall: 0.9122\n",
      "Epoch 829/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1292 - binary_accuracy: 0.9538 - precision: 0.9854 - recall: 0.9122 - val_loss: 0.1367 - val_binary_accuracy: 0.9523 - val_precision: 0.9492 - val_recall: 0.9459\n",
      "Epoch 830/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1367 - binary_accuracy: 0.9523 - precision: 0.9492 - recall: 0.9459 - val_loss: 0.1238 - val_binary_accuracy: 0.9538 - val_precision: 0.9586 - val_recall: 0.9392\n",
      "Epoch 831/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1238 - binary_accuracy: 0.9538 - precision: 0.9586 - recall: 0.9392 - val_loss: 0.1256 - val_binary_accuracy: 0.9523 - val_precision: 0.9749 - val_recall: 0.9189\n",
      "Epoch 832/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.1256 - binary_accuracy: 0.9523 - precision: 0.9749 - recall: 0.9189 - val_loss: 0.1217 - val_binary_accuracy: 0.9585 - val_precision: 0.9821 - val_recall: 0.9257\n",
      "Epoch 833/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1217 - binary_accuracy: 0.9585 - precision: 0.9821 - recall: 0.9257 - val_loss: 0.1130 - val_binary_accuracy: 0.9600 - val_precision: 0.9754 - val_recall: 0.9358\n",
      "Epoch 834/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.1130 - binary_accuracy: 0.9600 - precision: 0.9754 - recall: 0.9358 - val_loss: 0.1175 - val_binary_accuracy: 0.9585 - val_precision: 0.9686 - val_recall: 0.9392\n",
      "Epoch 835/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1175 - binary_accuracy: 0.9585 - precision: 0.9686 - recall: 0.9392 - val_loss: 0.1064 - val_binary_accuracy: 0.9692 - val_precision: 0.9894 - val_recall: 0.9426\n",
      "Epoch 836/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1064 - binary_accuracy: 0.9692 - precision: 0.9894 - recall: 0.9426 - val_loss: 0.1080 - val_binary_accuracy: 0.9692 - val_precision: 0.9894 - val_recall: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1080 - binary_accuracy: 0.9692 - precision: 0.9894 - recall: 0.9426 - val_loss: 0.1044 - val_binary_accuracy: 0.9677 - val_precision: 0.9758 - val_recall: 0.9527\n",
      "Epoch 838/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1044 - binary_accuracy: 0.9677 - precision: 0.9758 - recall: 0.9527 - val_loss: 0.0976 - val_binary_accuracy: 0.9692 - val_precision: 0.9726 - val_recall: 0.9595\n",
      "Epoch 839/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0976 - binary_accuracy: 0.9692 - precision: 0.9726 - recall: 0.9595 - val_loss: 0.1002 - val_binary_accuracy: 0.9723 - val_precision: 0.9860 - val_recall: 0.9527\n",
      "Epoch 840/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1002 - binary_accuracy: 0.9723 - precision: 0.9860 - recall: 0.9527 - val_loss: 0.0951 - val_binary_accuracy: 0.9615 - val_precision: 0.9927 - val_recall: 0.9223\n",
      "Epoch 841/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.0951 - binary_accuracy: 0.9615 - precision: 0.9927 - recall: 0.9223 - val_loss: 0.0933 - val_binary_accuracy: 0.9769 - val_precision: 0.9828 - val_recall: 0.9662\n",
      "Epoch 842/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.0933 - binary_accuracy: 0.9769 - precision: 0.9828 - recall: 0.9662 - val_loss: 0.0915 - val_binary_accuracy: 0.9815 - val_precision: 0.9931 - val_recall: 0.9662\n",
      "Epoch 843/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.0915 - binary_accuracy: 0.9815 - precision: 0.9931 - recall: 0.9662 - val_loss: 0.0871 - val_binary_accuracy: 0.9723 - val_precision: 0.9894 - val_recall: 0.9493\n",
      "Epoch 844/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.0871 - binary_accuracy: 0.9723 - precision: 0.9894 - recall: 0.9493 - val_loss: 0.0832 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 845/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.0832 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0823 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 846/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.0823 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0837 - val_binary_accuracy: 0.9738 - val_precision: 0.9861 - val_recall: 0.9561\n",
      "Epoch 847/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0837 - binary_accuracy: 0.9738 - precision: 0.9861 - recall: 0.9561 - val_loss: 0.0784 - val_binary_accuracy: 0.9800 - val_precision: 0.9930 - val_recall: 0.9628\n",
      "Epoch 848/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0784 - binary_accuracy: 0.9800 - precision: 0.9930 - recall: 0.9628 - val_loss: 0.0774 - val_binary_accuracy: 0.9862 - val_precision: 0.9832 - val_recall: 0.9865\n",
      "Epoch 849/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0774 - binary_accuracy: 0.9862 - precision: 0.9832 - recall: 0.9865 - val_loss: 0.0829 - val_binary_accuracy: 0.9723 - val_precision: 0.9964 - val_recall: 0.9426\n",
      "Epoch 850/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0829 - binary_accuracy: 0.9723 - precision: 0.9964 - recall: 0.9426 - val_loss: 0.0857 - val_binary_accuracy: 0.9738 - val_precision: 0.9574 - val_recall: 0.9865\n",
      "Epoch 851/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.0857 - binary_accuracy: 0.9738 - precision: 0.9574 - recall: 0.9865 - val_loss: 0.1015 - val_binary_accuracy: 0.9569 - val_precision: 0.9855 - val_recall: 0.9189\n",
      "Epoch 852/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1015 - binary_accuracy: 0.9569 - precision: 0.9855 - recall: 0.9189 - val_loss: 0.1187 - val_binary_accuracy: 0.9492 - val_precision: 0.9071 - val_recall: 0.9899\n",
      "Epoch 853/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1187 - binary_accuracy: 0.9492 - precision: 0.9071 - recall: 0.9899 - val_loss: 0.1656 - val_binary_accuracy: 0.9200 - val_precision: 0.9552 - val_recall: 0.8649\n",
      "Epoch 854/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1656 - binary_accuracy: 0.9200 - precision: 0.9552 - recall: 0.8649 - val_loss: 0.3733 - val_binary_accuracy: 0.8508 - val_precision: 0.8241 - val_recall: 0.8547\n",
      "Epoch 855/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3733 - binary_accuracy: 0.8508 - precision: 0.8241 - recall: 0.8547 - val_loss: 0.7544 - val_binary_accuracy: 0.7369 - val_precision: 0.6972 - val_recall: 0.7466\n",
      "Epoch 856/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.7544 - binary_accuracy: 0.7369 - precision: 0.6972 - recall: 0.7466 - val_loss: 0.2921 - val_binary_accuracy: 0.8754 - val_precision: 0.9249 - val_recall: 0.7905\n",
      "Epoch 857/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2921 - binary_accuracy: 0.8754 - precision: 0.9249 - recall: 0.7905 - val_loss: 0.6249 - val_binary_accuracy: 0.7477 - val_precision: 0.6813 - val_recall: 0.8378\n",
      "Epoch 858/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.6249 - binary_accuracy: 0.7477 - precision: 0.6813 - recall: 0.8378 - val_loss: 0.4036 - val_binary_accuracy: 0.8492 - val_precision: 0.8837 - val_recall: 0.7703\n",
      "Epoch 859/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4036 - binary_accuracy: 0.8492 - precision: 0.8837 - recall: 0.7703 - val_loss: 0.3974 - val_binary_accuracy: 0.8385 - val_precision: 0.8259 - val_recall: 0.8176\n",
      "Epoch 860/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3974 - binary_accuracy: 0.8385 - precision: 0.8259 - recall: 0.8176 - val_loss: 0.3430 - val_binary_accuracy: 0.8646 - val_precision: 0.8562 - val_recall: 0.8446\n",
      "Epoch 861/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.3430 - binary_accuracy: 0.8646 - precision: 0.8562 - recall: 0.8446 - val_loss: 0.2538 - val_binary_accuracy: 0.8969 - val_precision: 0.9288 - val_recall: 0.8378\n",
      "Epoch 862/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2538 - binary_accuracy: 0.8969 - precision: 0.9288 - recall: 0.8378 - val_loss: 0.3044 - val_binary_accuracy: 0.8415 - val_precision: 0.8249 - val_recall: 0.8277\n",
      "Epoch 863/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3044 - binary_accuracy: 0.8415 - precision: 0.8249 - recall: 0.8277 - val_loss: 0.2697 - val_binary_accuracy: 0.8769 - val_precision: 0.8750 - val_recall: 0.8514\n",
      "Epoch 864/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2697 - binary_accuracy: 0.8769 - precision: 0.8750 - recall: 0.8514 - val_loss: 0.1848 - val_binary_accuracy: 0.9169 - val_precision: 0.9231 - val_recall: 0.8919\n",
      "Epoch 865/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1848 - binary_accuracy: 0.9169 - precision: 0.9231 - recall: 0.8919 - val_loss: 0.2501 - val_binary_accuracy: 0.8923 - val_precision: 0.9065 - val_recall: 0.8514\n",
      "Epoch 866/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2501 - binary_accuracy: 0.8923 - precision: 0.9065 - recall: 0.8514 - val_loss: 0.2155 - val_binary_accuracy: 0.9108 - val_precision: 0.8993 - val_recall: 0.9054\n",
      "Epoch 867/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2155 - binary_accuracy: 0.9108 - precision: 0.8993 - recall: 0.9054 - val_loss: 0.1688 - val_binary_accuracy: 0.9323 - val_precision: 0.9375 - val_recall: 0.9122\n",
      "Epoch 868/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1688 - binary_accuracy: 0.9323 - precision: 0.9375 - recall: 0.9122 - val_loss: 0.2072 - val_binary_accuracy: 0.9062 - val_precision: 0.9502 - val_recall: 0.8378\n",
      "Epoch 869/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.2072 - binary_accuracy: 0.9062 - precision: 0.9502 - recall: 0.8378 - val_loss: 0.1704 - val_binary_accuracy: 0.9262 - val_precision: 0.9493 - val_recall: 0.8851\n",
      "Epoch 870/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.1704 - binary_accuracy: 0.9262 - precision: 0.9493 - recall: 0.8851 - val_loss: 0.1501 - val_binary_accuracy: 0.9431 - val_precision: 0.9246 - val_recall: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1501 - binary_accuracy: 0.9431 - precision: 0.9246 - recall: 0.9527 - val_loss: 0.1620 - val_binary_accuracy: 0.9415 - val_precision: 0.9607 - val_recall: 0.9088\n",
      "Epoch 872/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1620 - binary_accuracy: 0.9415 - precision: 0.9607 - recall: 0.9088 - val_loss: 0.1567 - val_binary_accuracy: 0.9323 - val_precision: 0.9737 - val_recall: 0.8750\n",
      "Epoch 873/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1567 - binary_accuracy: 0.9323 - precision: 0.9737 - recall: 0.8750 - val_loss: 0.1443 - val_binary_accuracy: 0.9400 - val_precision: 0.9477 - val_recall: 0.9189\n",
      "Epoch 874/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1443 - binary_accuracy: 0.9400 - precision: 0.9477 - recall: 0.9189 - val_loss: 0.1457 - val_binary_accuracy: 0.9400 - val_precision: 0.9241 - val_recall: 0.9459\n",
      "Epoch 875/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 0.1457 - binary_accuracy: 0.9400 - precision: 0.9241 - recall: 0.9459 - val_loss: 0.1216 - val_binary_accuracy: 0.9569 - val_precision: 0.9558 - val_recall: 0.9493\n",
      "Epoch 876/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1216 - binary_accuracy: 0.9569 - precision: 0.9558 - recall: 0.9493 - val_loss: 0.1284 - val_binary_accuracy: 0.9492 - val_precision: 0.9817 - val_recall: 0.9054\n",
      "Epoch 877/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1284 - binary_accuracy: 0.9492 - precision: 0.9817 - recall: 0.9054 - val_loss: 0.1293 - val_binary_accuracy: 0.9446 - val_precision: 0.9610 - val_recall: 0.9155\n",
      "Epoch 878/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.1293 - binary_accuracy: 0.9446 - precision: 0.9610 - recall: 0.9155 - val_loss: 0.1105 - val_binary_accuracy: 0.9585 - val_precision: 0.9529 - val_recall: 0.9561\n",
      "Epoch 879/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1105 - binary_accuracy: 0.9585 - precision: 0.9529 - recall: 0.9561 - val_loss: 0.1087 - val_binary_accuracy: 0.9631 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 880/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1087 - binary_accuracy: 0.9631 - precision: 0.9595 - recall: 0.9595 - val_loss: 0.1101 - val_binary_accuracy: 0.9585 - val_precision: 0.9786 - val_recall: 0.9291\n",
      "Epoch 881/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1101 - binary_accuracy: 0.9585 - precision: 0.9786 - recall: 0.9291 - val_loss: 0.1022 - val_binary_accuracy: 0.9631 - val_precision: 0.9857 - val_recall: 0.9324\n",
      "Epoch 882/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1022 - binary_accuracy: 0.9631 - precision: 0.9857 - recall: 0.9324 - val_loss: 0.0972 - val_binary_accuracy: 0.9738 - val_precision: 0.9761 - val_recall: 0.9662\n",
      "Epoch 883/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0972 - binary_accuracy: 0.9738 - precision: 0.9761 - recall: 0.9662 - val_loss: 0.0991 - val_binary_accuracy: 0.9615 - val_precision: 0.9472 - val_recall: 0.9696\n",
      "Epoch 884/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0991 - binary_accuracy: 0.9615 - precision: 0.9472 - recall: 0.9696 - val_loss: 0.0906 - val_binary_accuracy: 0.9800 - val_precision: 0.9930 - val_recall: 0.9628\n",
      "Epoch 885/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.0906 - binary_accuracy: 0.9800 - precision: 0.9930 - recall: 0.9628 - val_loss: 0.0928 - val_binary_accuracy: 0.9662 - val_precision: 0.9928 - val_recall: 0.9324\n",
      "Epoch 886/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0928 - binary_accuracy: 0.9662 - precision: 0.9928 - recall: 0.9324 - val_loss: 0.0864 - val_binary_accuracy: 0.9723 - val_precision: 0.9860 - val_recall: 0.9527\n",
      "Epoch 887/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.0864 - binary_accuracy: 0.9723 - precision: 0.9860 - recall: 0.9527 - val_loss: 0.0846 - val_binary_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9797\n",
      "Epoch 888/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0846 - binary_accuracy: 0.9831 - precision: 0.9831 - recall: 0.9797 - val_loss: 0.0826 - val_binary_accuracy: 0.9800 - val_precision: 0.9863 - val_recall: 0.9696\n",
      "Epoch 889/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0826 - binary_accuracy: 0.9800 - precision: 0.9863 - recall: 0.9696 - val_loss: 0.0791 - val_binary_accuracy: 0.9785 - val_precision: 0.9930 - val_recall: 0.9595\n",
      "Epoch 890/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0791 - binary_accuracy: 0.9785 - precision: 0.9930 - recall: 0.9595 - val_loss: 0.0757 - val_binary_accuracy: 0.9815 - val_precision: 0.9863 - val_recall: 0.9730\n",
      "Epoch 891/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0757 - binary_accuracy: 0.9815 - precision: 0.9863 - recall: 0.9730 - val_loss: 0.0745 - val_binary_accuracy: 0.9800 - val_precision: 0.9764 - val_recall: 0.9797\n",
      "Epoch 892/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0745 - binary_accuracy: 0.9800 - precision: 0.9764 - recall: 0.9797 - val_loss: 0.0713 - val_binary_accuracy: 0.9831 - val_precision: 0.9897 - val_recall: 0.9730\n",
      "Epoch 893/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.0713 - binary_accuracy: 0.9831 - precision: 0.9897 - recall: 0.9730 - val_loss: 0.0681 - val_binary_accuracy: 0.9815 - val_precision: 0.9965 - val_recall: 0.9628\n",
      "Epoch 894/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.0681 - binary_accuracy: 0.9815 - precision: 0.9965 - recall: 0.9628 - val_loss: 0.0673 - val_binary_accuracy: 0.9800 - val_precision: 0.9896 - val_recall: 0.9662\n",
      "Epoch 895/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0673 - binary_accuracy: 0.9800 - precision: 0.9896 - recall: 0.9662 - val_loss: 0.0658 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 896/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0658 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0615 - val_binary_accuracy: 0.9877 - val_precision: 0.9966 - val_recall: 0.9764\n",
      "Epoch 897/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0615 - binary_accuracy: 0.9877 - precision: 0.9966 - recall: 0.9764 - val_loss: 0.0608 - val_binary_accuracy: 0.9862 - val_precision: 0.9965 - val_recall: 0.9730\n",
      "Epoch 898/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0608 - binary_accuracy: 0.9862 - precision: 0.9965 - recall: 0.9730 - val_loss: 0.0586 - val_binary_accuracy: 0.9892 - val_precision: 0.9932 - val_recall: 0.9831\n",
      "Epoch 899/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.0586 - binary_accuracy: 0.9892 - precision: 0.9932 - recall: 0.9831 - val_loss: 0.0577 - val_binary_accuracy: 0.9877 - val_precision: 0.9898 - val_recall: 0.9831\n",
      "Epoch 900/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.0577 - binary_accuracy: 0.9877 - precision: 0.9898 - recall: 0.9831 - val_loss: 0.0546 - val_binary_accuracy: 0.9877 - val_precision: 0.9932 - val_recall: 0.9797\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model for classification\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_5)\n",
    "\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "print(model.summary())\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  \\\n",
       "0 2019-10-22                   0.003166   \n",
       "1 2019-10-21                   0.009758   \n",
       "2 2019-10-18                   0.007230   \n",
       "3 2019-10-17                   0.000403   \n",
       "4 2019-10-16                  -0.010431   \n",
       "5 2019-10-15                   0.016905   \n",
       "6 2019-10-14                   0.001219   \n",
       "7 2019-10-11                   0.011445   \n",
       "\n",
       "                                            docs_WFC  \\\n",
       "0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "   log_adj_daily_returns_JPM  \\\n",
       "0                   0.009986   \n",
       "1                   0.024498   \n",
       "2                   0.001743   \n",
       "3                   0.005583   \n",
       "4                  -0.002337   \n",
       "5                   0.029696   \n",
       "6                   0.002666   \n",
       "7                   0.016758   \n",
       "\n",
       "                                            docs_JPM  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "\n",
       "   log_adj_daily_returns_BAC  \\\n",
       "0                   0.005786   \n",
       "1                   0.021836   \n",
       "2                   0.002970   \n",
       "3                   0.002979   \n",
       "4                   0.014691   \n",
       "5                   0.020045   \n",
       "6                   0.007924   \n",
       "7                   0.016039   \n",
       "\n",
       "                                            docs_BAC  log_adj_daily_returns_C  \\\n",
       "0                                                 []                 0.003475   \n",
       "1                                                 []                 0.029250   \n",
       "2                                                 []                 0.002009   \n",
       "3                                                 []                 0.001438   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...                -0.024447   \n",
       "5                                                 []                 0.013856   \n",
       "6                                                 []                 0.001995   \n",
       "7                                                 []                 0.021339   \n",
       "\n",
       "                                              docs_C  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "6                                                 []  \n",
       "7                                                 []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 10\n",
    "batch_size = 4\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns', 'docs']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>docs_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>docs_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>docs_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>docs_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>docs_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>docs_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>docs_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>docs_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "      <th>docs_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "                                       docs_WFC(t-5)  \\\n",
       "1                                                 []   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5) docs_JPM(t-5)  \\\n",
       "1                        0.002666            []   \n",
       "2                        0.016758            []   \n",
       "3                        0.013931            []   \n",
       "4                        0.007218            []   \n",
       "5                       -0.022548            []   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-5) docs_BAC(t-5)  log_adj_daily_returns_C(t-5)  \\\n",
       "1                        0.007924            []                      0.001995   \n",
       "2                        0.016039            []                      0.021339   \n",
       "3                        0.019880            []                      0.017494   \n",
       "4                        0.009366            []                      0.015393   \n",
       "5                       -0.024313            []                     -0.026014   \n",
       "\n",
       "  docs_C(t-5) timestamp(t-4)  ...  \\\n",
       "1          []     2019-10-15  ...   \n",
       "2          []     2019-10-14  ...   \n",
       "3          []     2019-10-11  ...   \n",
       "4          []     2019-10-10  ...   \n",
       "5          []     2019-10-09  ...   \n",
       "\n",
       "                                         docs_C(t+0) timestamp(t+1)  \\\n",
       "1                                                 []     2019-10-22   \n",
       "2                                                 []     2019-10-21   \n",
       "3                                                 []     2019-10-18   \n",
       "4                                                 []     2019-10-17   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  \\\n",
       "1                        0.003166   \n",
       "2                        0.009758   \n",
       "3                        0.007230   \n",
       "4                        0.000403   \n",
       "5                       -0.010431   \n",
       "\n",
       "                                       docs_WFC(t+1)  \\\n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "5                                                 []   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+1) docs_JPM(t+1)  \\\n",
       "1                        0.009986            []   \n",
       "2                        0.024498            []   \n",
       "3                        0.001743            []   \n",
       "4                        0.005583            []   \n",
       "5                       -0.002337            []   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  \\\n",
       "1                        0.005786   \n",
       "2                        0.021836   \n",
       "3                        0.002970   \n",
       "4                        0.002979   \n",
       "5                        0.014691   \n",
       "\n",
       "                                       docs_BAC(t+1)  \\\n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "  log_adj_daily_returns_C(t+1)  docs_C(t+1)  \n",
       "1                     0.003475           []  \n",
       "2                     0.029250           []  \n",
       "3                     0.002009           []  \n",
       "4                     0.001438           []  \n",
       "5                    -0.024447           []  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'log_adj_daily_returns': ['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], 'docs': ['docs_WFC(t-5)', 'docs_WFC(t-4)', 'docs_WFC(t-3)', 'docs_WFC(t-2)', 'docs_WFC(t-1)', 'docs_WFC(t+0)', 'docs_WFC(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], 'docs': ['docs_JPM(t-5)', 'docs_JPM(t-4)', 'docs_JPM(t-3)', 'docs_JPM(t-2)', 'docs_JPM(t-1)', 'docs_JPM(t+0)', 'docs_JPM(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], 'docs': ['docs_BAC(t-5)', 'docs_BAC(t-4)', 'docs_BAC(t-3)', 'docs_BAC(t-2)', 'docs_BAC(t-1)', 'docs_BAC(t+0)', 'docs_BAC(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)'], 'docs': ['docs_C(t-5)', 'docs_C(t-4)', 'docs_C(t-3)', 'docs_C(t-2)', 'docs_C(t-1)', 'docs_C(t+0)', 'docs_C(t+1)']}]\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['log_adj_daily_returns', 'docs']\n",
    "col_names_obj = [{fn: [name for name in df.columns if '_'.join([fn, t]) in name] for fn in feature_names}\n",
    "             for t in tickers]\n",
    "print(col_names_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_adj_daily_returns features\n",
      "\n",
      "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
      "1                        0.001219                        0.016905   \n",
      "2                        0.011445                        0.001219   \n",
      "3                        0.010331                        0.011445   \n",
      "4                        0.006877                        0.010331   \n",
      "5                       -0.020491                        0.006877   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
      "1                       -0.010431                        0.000403   \n",
      "2                        0.016905                       -0.010431   \n",
      "3                        0.001219                        0.016905   \n",
      "4                        0.011445                        0.001219   \n",
      "5                        0.010331                        0.011445   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
      "1                        0.007230                        0.009758   \n",
      "2                        0.000403                        0.007230   \n",
      "3                       -0.010431                        0.000403   \n",
      "4                        0.016905                       -0.010431   \n",
      "5                        0.001219                        0.016905   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t+1)  \n",
      "1                        0.003166  \n",
      "2                        0.009758  \n",
      "3                        0.007230  \n",
      "4                        0.000403  \n",
      "5                       -0.010431  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_JPM(t-4)  \\\n",
      "1                        0.002666                        0.029696   \n",
      "2                        0.016758                        0.002666   \n",
      "3                        0.013931                        0.016758   \n",
      "4                        0.007218                        0.013931   \n",
      "5                       -0.022548                        0.007218   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-3)  log_adj_daily_returns_JPM(t-2)  \\\n",
      "1                       -0.002337                        0.005583   \n",
      "2                        0.029696                       -0.002337   \n",
      "3                        0.002666                        0.029696   \n",
      "4                        0.016758                        0.002666   \n",
      "5                        0.013931                        0.016758   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-1)  log_adj_daily_returns_JPM(t+0)  \\\n",
      "1                        0.001743                        0.024498   \n",
      "2                        0.005583                        0.001743   \n",
      "3                       -0.002337                        0.005583   \n",
      "4                        0.029696                       -0.002337   \n",
      "5                        0.002666                        0.029696   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t+1)  \n",
      "1                        0.009986  \n",
      "2                        0.024498  \n",
      "3                        0.001743  \n",
      "4                        0.005583  \n",
      "5                       -0.002337  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_BAC(t-5)  log_adj_daily_returns_BAC(t-4)  \\\n",
      "1                        0.007924                        0.020045   \n",
      "2                        0.016039                        0.007924   \n",
      "3                        0.019880                        0.016039   \n",
      "4                        0.009366                        0.019880   \n",
      "5                       -0.024313                        0.009366   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-3)  log_adj_daily_returns_BAC(t-2)  \\\n",
      "1                        0.014691                        0.002979   \n",
      "2                        0.020045                        0.014691   \n",
      "3                        0.007924                        0.020045   \n",
      "4                        0.016039                        0.007924   \n",
      "5                        0.019880                        0.016039   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-1)  log_adj_daily_returns_BAC(t+0)  \\\n",
      "1                        0.002970                        0.021836   \n",
      "2                        0.002979                        0.002970   \n",
      "3                        0.014691                        0.002979   \n",
      "4                        0.020045                        0.014691   \n",
      "5                        0.007924                        0.020045   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t+1)  \n",
      "1                        0.005786  \n",
      "2                        0.021836  \n",
      "3                        0.002970  \n",
      "4                        0.002979  \n",
      "5                        0.014691  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_C(t-5)  log_adj_daily_returns_C(t-4)  \\\n",
      "1                      0.001995                      0.013856   \n",
      "2                      0.021339                      0.001995   \n",
      "3                      0.017494                      0.021339   \n",
      "4                      0.015393                      0.017494   \n",
      "5                     -0.026014                      0.015393   \n",
      "\n",
      "   log_adj_daily_returns_C(t-3)  log_adj_daily_returns_C(t-2)  \\\n",
      "1                     -0.024447                      0.001438   \n",
      "2                      0.013856                     -0.024447   \n",
      "3                      0.001995                      0.013856   \n",
      "4                      0.021339                      0.001995   \n",
      "5                      0.017494                      0.021339   \n",
      "\n",
      "   log_adj_daily_returns_C(t-1)  log_adj_daily_returns_C(t+0)  \\\n",
      "1                      0.002009                      0.029250   \n",
      "2                      0.001438                      0.002009   \n",
      "3                     -0.024447                      0.001438   \n",
      "4                      0.013856                     -0.024447   \n",
      "5                      0.001995                      0.013856   \n",
      "\n",
      "   log_adj_daily_returns_C(t+1)  \n",
      "1                      0.003475  \n",
      "2                      0.029250  \n",
      "3                      0.002009  \n",
      "4                      0.001438  \n",
      "5                     -0.024447  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "docs features\n",
      "\n",
      "                                       docs_WFC(t-5)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t-4)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t-2)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t-1)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t+0)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t+1)  \n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "5                                                 []  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_JPM(t-5)                                      docs_JPM(t-4)  \\\n",
      "1            []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2            []                                                 []   \n",
      "3            []                                                 []   \n",
      "4            []                                                 []   \n",
      "5            []                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-2)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t+0) docs_JPM(t+1)  \n",
      "1                                                 []            []  \n",
      "2                                                 []            []  \n",
      "3                                                 []            []  \n",
      "4                                                 []            []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...            []  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_BAC(t-5) docs_BAC(t-4)  \\\n",
      "1            []            []   \n",
      "2            []            []   \n",
      "3            []            []   \n",
      "4            []            []   \n",
      "5            []            []   \n",
      "\n",
      "                                       docs_BAC(t-3)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t-2)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t+0)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t+1)  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3                                                 []  \n",
      "4                                                 []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_C(t-5)                                        docs_C(t-4)  \\\n",
      "1          []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2          []                                                 []   \n",
      "3          []                                                 []   \n",
      "4          []                                                 []   \n",
      "5          []                                                 []   \n",
      "\n",
      "                                         docs_C(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t-2)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t+0) docs_C(t+1)  \n",
      "1                                                 []          []  \n",
      "2                                                 []          []  \n",
      "3                                                 []          []  \n",
      "4                                                 []          []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...          []  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = [{key: df[d[key]] for key in d} for d in col_names_obj]\n",
    "\n",
    "print('log_adj_daily_returns features')\n",
    "print()\n",
    "for i in range(len(tickers)):\n",
    "    print(dfs[i]['log_adj_daily_returns'].head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "print()\n",
    "print('docs features')\n",
    "print()\n",
    "for i in range(len(tickers)):\n",
    "    print(dfs[i]['docs'].head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [{key: d[key].values for key in d} for d in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset's features: ['log_adj_daily_returns', 'docs']\n",
      "Testing if each of test_dataset's features have the same length\n",
      "Test passed, test dataset's shape: (5024, 7)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets[0] # JPM's dataset\n",
    "print('dataset\\'s features: {}'.format(list(dataset.keys())))\n",
    "print('Testing if each of test_dataset\\'s features have the same length')\n",
    "dataset_shape = dataset[list(dataset.keys())[0]].shape\n",
    "assert (dataset[key].shape == dataset_shape for key in dataset.keys())\n",
    "print('Test passed, test dataset\\'s shape: {}'.format(dataset_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of features of test_dataset with labels included: {'log_adj_daily_returns': (5024, 7), 'docs': (5024, 7)}\n",
      "Shapes of features of test_dataset with labels extracted: {'log_adj_daily_returns': (5024, 6), 'docs': (5024, 6)}\n",
      "Shapes of extracted labels from test_dataset: {'log_adj_daily_returns': (5024,)}\n",
      "Testing if the extracted labels match the last column (the final timestep) of the test_dataset\n",
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(dataset, label_names):\n",
    "    labels = {fname: dataset[fname][:, -1] for fname in dataset.keys() if fname in label_names}\n",
    "    features = {fname: dataset[fname][:, :-1] for fname in dataset.keys()}\n",
    "    return features, labels\n",
    "\n",
    "test_dataset_with_labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "test_features, test_labels = test_dataset_with_labels[0], test_dataset_with_labels[1]\n",
    "print('Shapes of features of test_dataset with labels included: {}'.format({fn: dataset[fn].shape for fn in dataset}))\n",
    "print('Shapes of features of test_dataset with labels extracted: {}'.format({fn: test_features[fn].shape for fn in test_features}))\n",
    "print('Shapes of extracted labels from test_dataset: {}'.format({fn: test_labels[fn].shape for fn in test_labels}))\n",
    "print('Testing if the extracted labels match the last column (the final timestep) of the test_dataset')\n",
    "assert np.array_equal(dataset['log_adj_daily_returns'][:, -1], test_labels['log_adj_daily_returns'])\n",
    "print('Test passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_docs_feature's shape:(7,)\n",
      "sample_docs_feature\n",
      "['[]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000383.pickle\"]'\n",
      " '[]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000393.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007742.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007757.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007803.pickle\"]']\n"
     ]
    }
   ],
   "source": [
    "test_sample_docs_feature = dataset['docs'][0] # sample 0's docs features of WFC's dataset\n",
    "print('sample_docs_feature\\'s shape:{}'.format(test_sample_docs_feature.shape))\n",
    "print('sample_docs_feature')\n",
    "print(test_sample_docs_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000383.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000393.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007742.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007757.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007803.pickle']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_docs_feature(docs_feature):\n",
    "    docs = []\n",
    "    for timestep in docs_feature:\n",
    "        docs_list = json.loads(timestep)\n",
    "        docs.extend(docs_list)\n",
    "    return docs\n",
    "\n",
    "flatten_docs_feature(test_sample_docs_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: [491   6   1 ...  94 172 271]\n",
      "Testing if each timestep contains the same document that was sampled randomly from the original window\n",
      "Test passed\n",
      "window's shape: (7, 1301)\n",
      "window:\n",
      "[[491   6   1 ...  94 172 271]\n",
      " [491   6   1 ...  94 172 271]\n",
      " [491   6   1 ...  94 172 271]\n",
      " ...\n",
      " [491   6   1 ...  94 172 271]\n",
      " [491   6   1 ...  94 172 271]\n",
      " [491   6   1 ...  94 172 271]]\n"
     ]
    }
   ],
   "source": [
    "def decode_docs_feature(docs_feature, seed):\n",
    "    np.random.seed(seed)\n",
    "    docs_names = flatten_docs_feature(docs_feature)\n",
    "    if len(docs_names) != 0:\n",
    "        windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "        with open(windows_doc_name, 'rb') as f:\n",
    "            windows_doc = pickle.load(f)\n",
    "        window = [windows_doc for _ in range(len(docs_feature))]\n",
    "    else:\n",
    "        window = [[] for _ in range(len(docs_feature))]\n",
    "    return np.stack(window, axis=0)\n",
    "\n",
    "test_window = decode_docs_feature(test_sample_docs_feature, None)\n",
    "test_windows_doc = test_window[0]\n",
    "print('document: {}'.format(test_windows_doc))\n",
    "print('Testing if each timestep contains the same document that was sampled randomly from the original window')\n",
    "assert all(np.array_equal(test_window[i], test_windows_doc) for i in range(len(test_window)))\n",
    "print('Test passed')\n",
    "print('window\\'s shape: {}'.format(test_window.shape))\n",
    "print('window:')\n",
    "print(test_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding features and extracting labels\n",
    "features, labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "features_decoded = {key: (value if key != 'docs'\n",
    "                         else list(map(lambda docf: decode_docs_feature(docf, seed), value)))\n",
    "                   for key, value in features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out samples with no document feature\n",
    "mask = [(sample.shape[1] != 0) for sample in features_decoded['docs']]\n",
    "\n",
    "features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                           else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                     for key, value in features_decoded.items()}\n",
    "\n",
    "labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "\n",
    "assert (features_filtered['log_adj_daily_returns'].shape[0] == len(features_filtered['docs']) == labels_filtered['log_adj_daily_returns'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Dataset\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\n",
    "\n",
    "features_shuffled = {key: (value[shuffled_indices] if key != 'docs'\n",
    "                           else [value[i] for i in shuffled_indices])\n",
    "                     for key, value in features_filtered.items()}\n",
    "\n",
    "labels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\n",
    "\n",
    "assert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_documents(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, 0), (0, longest_doc_len-arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "# Padding Document Features to the max length of a document\n",
    "X = {key: (pad_documents(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\n",
    "y = labels_shuffled['log_adj_daily_returns']\n",
    "print(X['log_adj_daily_returns'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct model layers\n",
    "\n",
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                     weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                     input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                     embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                     activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                     mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00045633 -0.01149596  0.01969069  0.00474809 -0.00474809 -0.01346608]\n",
      " [ 0.0141506   0.01302592  0.00030917  0.0152854  -0.00456189 -0.01442841]\n",
      " [ 0.03178836  0.00458189 -0.01178251 -0.01280198  0.00525521  0.03491873]\n",
      " [-0.01209899  0.00020629  0.01494551 -0.00816164 -0.02049125  0.00687718]\n",
      " [ 0.00085727  0.00855687 -0.0088398   0.00628368 -0.00772012 -0.00460225]\n",
      " [-0.0061644  -0.01210329  0.00640596 -0.00979273 -0.01332685  0.00890427]\n",
      " [-0.00109299 -0.01302126  0.00184483  0.01445182 -0.00272874 -0.00364798]\n",
      " [-0.00214616  0.00526068  0.00213717 -0.00427665 -0.00370793  0.0056529 ]\n",
      " [ 0.00865937 -0.008473    0.00055299 -0.00259111  0.02958504  0.01977823]\n",
      " [ 0.00537348 -0.00268212 -0.00394967 -0.00577167 -0.00108578  0.00307298]]\n",
      "Shape of num features: (10, 6)\n",
      "\n",
      "[-0.00045874  0.01442841  0.01618508  0.01033067  0.00173142  0.\n",
      " -0.02611114  0.00252574 -0.00371114 -0.00525013]\n",
      "Shape of labels: (10,)\n",
      "[[[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]]\n",
      "Shapes of docs features: (10, 6, 1619)\n",
      "Testing if each document at each timestep for all samples in docs feature is equal each other\n",
      "Test past\n"
     ]
    }
   ],
   "source": [
    "# Inspecting Dataset\n",
    "print(X['log_adj_daily_returns'])\n",
    "print('Shape of num features: {}'.format(X['log_adj_daily_returns'].shape))\n",
    "print()\n",
    "print(y)\n",
    "print('Shape of labels: {}'.format(y.shape))\n",
    "print(X['docs'])\n",
    "print('Shapes of docs features: {}'.format(X['docs'].shape))\n",
    "print('Testing if each document at each timestep for all samples in docs feature is equal each other')\n",
    "assert all(np.array_equal(X['docs'][s, i], X['docs'][s, j]) for s in range(dataset_size) for i in range(6) for j in range(6))\n",
    "print('Test past')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "                                                                 embedding[4][0]                  \n",
      "                                                                 embedding[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " 4/10 [===========>..................] - ETA: 8s"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function len> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_num_elements\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`grad` not a Tensor or IndexedSlices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7335a7449b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    596\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No gradients to aggregate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "#word_embedding_layers = [word_embedding(timeslice_layers[timestep]) for timestep in range(6)]\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "#document_embedding_layers = [document_embedding(word_embedding_layers[timestep]) for timestep in range(6)]\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_5])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigating crash of regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears from the above cell that the model is crashing somewhere in its backpropagation step. From inspection of the source code it seems like there are some issues with the shapes of gradients when slicing the docs input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 629ms/sample - loss: 0.0358 - val_loss: 0.0505\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 22ms/sample - loss: 0.0449 - val_loss: 0.0110\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 20ms/sample - loss: 0.0194 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0048 - val_loss: 6.3182e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 3.1893e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 16ms/sample - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0017 - val_loss: 6.6464e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cell it appears that if we take only one slice layer and copy it multiple times then apply our stack layer, the model seems to backpropagate fine. This implies maybe there might be something up with the stack layer: doc_features_layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 15s 1s/sample - loss: 0.0482 - val_loss: 0.0527\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0360 - val_loss: 0.0182\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 60ms/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 0.0015 - val_loss: 4.3584e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 9.8736e-04 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 57ms/sample - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 63ms/sample - loss: 0.0016 - val_loss: 4.9223e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "                                                                 embedding[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " 4/10 [===========>..................] - ETA: 8s"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "PyEval_EvalFrameEx returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_num_elements\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`grad` not a Tensor or IndexedSlices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0c497bc01f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: PyEval_EvalFrameEx returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "#word_embedding_layers = [word_embedding(timeslice_layers[timestep]) for timestep in range(6)]\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "#document_embedding_layers = [document_embedding(word_embedding_layers[timestep]) for timestep in range(6)]\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above to cells we find that the backpropagation crashes when we try to apply our stack layer to a list of more than 3 unique slice layers (as opposed to a list of contains less than 3 unique slice layers where the empty slots are filled with copies of already included slice layers). This further supports that maybe the stacking layer is the cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, None)      0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, None)         0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_14[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 571ms/sample - loss: 0.0310 - val_loss: 0.0210\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0359 - val_loss: 0.0099\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 20ms/sample - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0020 - val_loss: 6.8931e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "timeslice_layer_0 = timeslice_layers[0]\n",
    "timeslice_layer_1 = timeslice_layers[1]\n",
    "timeslice_layer_2 = timeslice_layers[2]\n",
    "timeslice_layer_3 = timeslice_layers[3]\n",
    "timeslice_layer_4 = timeslice_layers[4]\n",
    "timeslice_layer_5 = timeslice_layers[5]\n",
    "\n",
    "# Rebuilding Original Input from Time Slices\n",
    "rebuilt_input_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)), \n",
    "                                    output_shape=(6, None))([timeslice_layer_0,\n",
    "                                                            timeslice_layer_1,\n",
    "                                                            timeslice_layer_2,\n",
    "                                                            timeslice_layer_3,\n",
    "                                                            timeslice_layer_4,\n",
    "                                                            timeslice_layer_5])\n",
    "                                    \n",
    "doc_layer_0 = layers.Lambda((lambda x: x[:, 0, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_1 = layers.Lambda((lambda x: x[:, 1, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_2 = layers.Lambda((lambda x: x[:, 2, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_3 = layers.Lambda((lambda x: x[:, 3, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_4 = layers.Lambda((lambda x: x[:, 4, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_5 = layers.Lambda((lambda x: x[:, 5, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(doc_layer_0)\n",
    "word_embedding_layer_1 = word_embedding(doc_layer_1)\n",
    "word_embedding_layer_2 = word_embedding(doc_layer_2)\n",
    "word_embedding_layer_3 = word_embedding(doc_layer_3)\n",
    "word_embedding_layer_4 = word_embedding(doc_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(doc_layer_5)\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to test our stacking layer, by slicing the input_docs layer, and immediately stacking all unique slices of it, then applying a sequence of layers we know backpropagation doesn't break on. The results show that our stacking layer isn't at fault. This implies that there is something up with the layers that we apply to each slice (word_embedding, and doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2747100     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    2747100     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 300)    2747100     lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 300)    2747100     lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 300)    2747100     lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 300)    2747100     lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          160400      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100)          160400      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 100)          160400      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 100)          160400      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 100)          160400      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,462,185\n",
      "Trainable params: 979,585\n",
      "Non-trainable params: 16,482,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 23s 2s/sample - loss: 0.0108 - val_loss: 0.0158\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 0.0220 - val_loss: 0.0066\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 85ms/sample - loss: 0.0015 - val_loss: 4.0027e-04\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 2.8220e-04 - val_loss: 4.5561e-04\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 87ms/sample - loss: 6.0313e-04 - val_loss: 6.8137e-04\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 84ms/sample - loss: 7.0505e-04 - val_loss: 7.7796e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 8.3631e-04 - val_loss: 5.7608e-04\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 5.4261e-04 - val_loss: 3.1418e-04\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 83ms/sample - loss: 2.8344e-04 - val_loss: 1.4857e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[0])\n",
    "word_embedding_layer_1 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[1])\n",
    "word_embedding_layer_2 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[2])\n",
    "word_embedding_layer_3 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[3])\n",
    "word_embedding_layer_4 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding_layer_0 = layers.LSTM(100)(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = layers.LSTM(100)(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = layers.LSTM(100)(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = layers.LSTM(100)(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = layers.LSTM(100)(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = layers.LSTM(100)(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_5])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created seperate word_embedding_layers and document_embedding_layers for each slice layer ie the document and word embedding layers are seperated for each slice, and do not share weights between each slice. Backpropagation seems to work which implies that the error is raised because of the logic of sharing weights between slice layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuilding Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/900\n",
      "10/10 [==============================] - 8s 842ms/sample - loss: 0.0358 - val_loss: 0.0505\n",
      "Epoch 2/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 0.0449 - val_loss: 0.0110\n",
      "Epoch 3/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 4/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 0.0194 - val_loss: 0.0034\n",
      "Epoch 5/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 6/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 7/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 0.0048 - val_loss: 6.3182e-04\n",
      "Epoch 8/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.1893e-04 - val_loss: 0.0011\n",
      "Epoch 9/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 0.0017 - val_loss: 6.6464e-04\n",
      "Epoch 11/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 6.4518e-04 - val_loss: 4.7101e-04\n",
      "Epoch 12/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.7638e-04 - val_loss: 6.2687e-04\n",
      "Epoch 13/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.2094e-04 - val_loss: 3.2000e-04\n",
      "Epoch 14/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.9116e-04 - val_loss: 3.5164e-04\n",
      "Epoch 15/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7532e-04 - val_loss: 3.8079e-04\n",
      "Epoch 16/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.5840e-04 - val_loss: 1.7039e-04\n",
      "Epoch 17/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.3688e-04 - val_loss: 1.0550e-04\n",
      "Epoch 18/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.3066e-04 - val_loss: 2.0107e-04\n",
      "Epoch 19/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.0013e-04 - val_loss: 1.4366e-04\n",
      "Epoch 20/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.0725e-04 - val_loss: 6.1923e-05\n",
      "Epoch 21/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.3544e-05 - val_loss: 8.1996e-05\n",
      "Epoch 22/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.0159e-04 - val_loss: 9.1769e-05\n",
      "Epoch 23/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 9.0776e-05 - val_loss: 6.2538e-05\n",
      "Epoch 24/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 5.3938e-05 - val_loss: 5.3051e-05\n",
      "Epoch 25/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.4469e-05 - val_loss: 5.6125e-05\n",
      "Epoch 26/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.6133e-05 - val_loss: 4.3520e-05\n",
      "Epoch 27/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.3008e-05 - val_loss: 4.4900e-05\n",
      "Epoch 28/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.3716e-05 - val_loss: 3.4659e-05\n",
      "Epoch 29/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.3303e-05 - val_loss: 3.0644e-05\n",
      "Epoch 30/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 3.4183e-05 - val_loss: 3.1211e-05\n",
      "Epoch 31/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 3.5756e-05 - val_loss: 3.3655e-05\n",
      "Epoch 32/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 3.2725e-05 - val_loss: 2.6359e-05\n",
      "Epoch 33/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.5409e-05 - val_loss: 2.3132e-05\n",
      "Epoch 34/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.2562e-05 - val_loss: 2.4250e-05\n",
      "Epoch 35/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.5299e-05 - val_loss: 2.6237e-05\n",
      "Epoch 36/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.6366e-05 - val_loss: 2.1622e-05\n",
      "Epoch 37/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.1415e-05 - val_loss: 1.7930e-05\n",
      "Epoch 38/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.2145e-05 - val_loss: 1.9619e-05\n",
      "Epoch 39/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.8670e-05 - val_loss: 1.5916e-05\n",
      "Epoch 40/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.5808e-05 - val_loss: 1.6071e-05\n",
      "Epoch 41/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.6936e-05 - val_loss: 1.3745e-05\n",
      "Epoch 42/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.3348e-05 - val_loss: 1.2193e-05\n",
      "Epoch 43/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.3205e-05 - val_loss: 1.2082e-05\n",
      "Epoch 44/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.3129e-05 - val_loss: 1.1053e-05\n",
      "Epoch 45/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 1.0468e-05 - val_loss: 1.0648e-05\n",
      "Epoch 46/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.1004e-05 - val_loss: 1.0208e-05\n",
      "Epoch 47/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.0727e-05 - val_loss: 8.4830e-06\n",
      "Epoch 48/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 9.4678e-06 - val_loss: 1.0115e-05\n",
      "Epoch 49/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 9.7639e-06 - val_loss: 7.6752e-06\n",
      "Epoch 50/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 7.6919e-06 - val_loss: 7.6211e-06\n",
      "Epoch 51/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 8.4667e-06 - val_loss: 7.5778e-06\n",
      "Epoch 52/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 6.8896e-06 - val_loss: 6.1057e-06\n",
      "Epoch 53/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 6.8168e-06 - val_loss: 6.5572e-06\n",
      "Epoch 54/900\n",
      "10/10 [==============================] - 0s 41ms/sample - loss: 6.5051e-06 - val_loss: 5.2797e-06\n",
      "Epoch 55/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 5.5989e-06 - val_loss: 5.1235e-06\n",
      "Epoch 56/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 6.0392e-06 - val_loss: 4.7826e-06\n",
      "Epoch 57/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 39ms/sample - loss: 4.7141e-06 - val_loss: 4.2057e-06\n",
      "Epoch 58/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 4.8748e-06 - val_loss: 4.0736e-06\n",
      "Epoch 59/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 4.0100e-06 - val_loss: 3.7937e-06\n",
      "Epoch 60/900\n",
      "10/10 [==============================] - 0s 41ms/sample - loss: 3.9797e-06 - val_loss: 4.7842e-06\n",
      "Epoch 61/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.6915e-06 - val_loss: 3.5451e-06\n",
      "Epoch 62/900\n",
      "10/10 [==============================] - 0s 41ms/sample - loss: 4.0350e-06 - val_loss: 3.5385e-06\n",
      "Epoch 63/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 3.6853e-06 - val_loss: 2.9376e-06\n",
      "Epoch 64/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 3.5060e-06 - val_loss: 3.3506e-06\n",
      "Epoch 65/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 3.6008e-06 - val_loss: 2.6531e-06\n",
      "Epoch 66/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 2.8299e-06 - val_loss: 2.5259e-06\n",
      "Epoch 67/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.6367e-06 - val_loss: 2.3132e-06\n",
      "Epoch 68/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 2.3916e-06 - val_loss: 2.2048e-06\n",
      "Epoch 69/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.9353e-06 - val_loss: 2.0765e-06\n",
      "Epoch 70/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 3.4712e-06 - val_loss: 2.3619e-06\n",
      "Epoch 71/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 2.6473e-06 - val_loss: 2.1201e-06\n",
      "Epoch 72/900\n",
      "10/10 [==============================] - 0s 41ms/sample - loss: 2.1428e-06 - val_loss: 1.8290e-06\n",
      "Epoch 73/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.9801e-06 - val_loss: 1.5184e-06\n",
      "Epoch 74/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.6589e-06 - val_loss: 1.5559e-06\n",
      "Epoch 75/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.4739e-06 - val_loss: 1.3366e-06\n",
      "Epoch 76/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.4491e-06 - val_loss: 1.5390e-06\n",
      "Epoch 77/900\n",
      "10/10 [==============================] - 0s 41ms/sample - loss: 1.6513e-06 - val_loss: 1.2311e-06\n",
      "Epoch 78/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.3135e-06 - val_loss: 1.1698e-06\n",
      "Epoch 79/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.2503e-06 - val_loss: 1.1168e-06\n",
      "Epoch 80/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 1.4154e-06 - val_loss: 1.0917e-06\n",
      "Epoch 81/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.0330e-06 - val_loss: 1.3332e-06\n",
      "Epoch 82/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 1.3422e-06 - val_loss: 1.0556e-06\n",
      "Epoch 83/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 9.3073e-07 - val_loss: 1.1452e-06\n",
      "Epoch 84/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 1.1883e-06 - val_loss: 1.0013e-06\n",
      "Epoch 85/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 8.9911e-07 - val_loss: 9.5451e-07\n",
      "Epoch 86/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.0718e-06 - val_loss: 8.5370e-07\n",
      "Epoch 87/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 8.4934e-07 - val_loss: 1.2063e-06\n",
      "Epoch 88/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.3581e-06 - val_loss: 8.3717e-07\n",
      "Epoch 89/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 7.9782e-07 - val_loss: 7.7697e-07\n",
      "Epoch 90/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 8.5716e-07 - val_loss: 8.6142e-07\n",
      "Epoch 91/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.2046e-06 - val_loss: 7.2106e-07\n",
      "Epoch 92/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 9.6809e-07 - val_loss: 8.8744e-07\n",
      "Epoch 93/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 8.5228e-07 - val_loss: 7.0022e-07\n",
      "Epoch 94/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 7.1883e-07 - val_loss: 6.7879e-07\n",
      "Epoch 95/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 7.8294e-07 - val_loss: 5.6451e-07\n",
      "Epoch 96/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 6.6468e-07 - val_loss: 6.2859e-07\n",
      "Epoch 97/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.8926e-07 - val_loss: 5.2613e-07\n",
      "Epoch 98/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 5.6500e-07 - val_loss: 5.5622e-07\n",
      "Epoch 99/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.4613e-07 - val_loss: 4.6556e-07\n",
      "Epoch 100/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.9045e-07 - val_loss: 4.8686e-07\n",
      "Epoch 101/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.3278e-07 - val_loss: 4.2806e-07\n",
      "Epoch 102/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.2861e-07 - val_loss: 4.1508e-07\n",
      "Epoch 103/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.6265e-07 - val_loss: 4.0762e-07\n",
      "Epoch 104/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 5.2800e-07 - val_loss: 6.3233e-07\n",
      "Epoch 105/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.0809e-07 - val_loss: 4.7706e-07\n",
      "Epoch 106/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 7.9091e-07 - val_loss: 4.5886e-07\n",
      "Epoch 107/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.2540e-07 - val_loss: 7.7333e-07\n",
      "Epoch 108/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 7.0001e-07 - val_loss: 3.1427e-07\n",
      "Epoch 109/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.8085e-07 - val_loss: 5.6426e-07\n",
      "Epoch 110/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 5.3381e-07 - val_loss: 2.8504e-07\n",
      "Epoch 111/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.6797e-07 - val_loss: 3.3806e-07\n",
      "Epoch 112/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.4830e-07 - val_loss: 2.6475e-07\n",
      "Epoch 113/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 4.0012e-07 - val_loss: 4.7581e-07\n",
      "Epoch 114/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.0917e-07 - val_loss: 2.4736e-07\n",
      "Epoch 115/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.8281e-07 - val_loss: 2.8367e-07\n",
      "Epoch 116/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.5327e-07 - val_loss: 2.5566e-07\n",
      "Epoch 117/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.6901e-07 - val_loss: 2.3728e-07\n",
      "Epoch 118/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.4464e-07 - val_loss: 2.1706e-07\n",
      "Epoch 119/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4204e-07 - val_loss: 2.3933e-07\n",
      "Epoch 120/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 4.3148e-07 - val_loss: 1.9313e-07\n",
      "Epoch 121/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 4.3467e-07 - val_loss: 5.1202e-07\n",
      "Epoch 122/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.5776e-07 - val_loss: 2.1892e-07\n",
      "Epoch 123/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.7344e-07 - val_loss: 2.2075e-07\n",
      "Epoch 124/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.0876e-07 - val_loss: 1.6812e-07\n",
      "Epoch 125/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.6739e-07 - val_loss: 1.7225e-07\n",
      "Epoch 126/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.1321e-07 - val_loss: 1.4891e-07\n",
      "Epoch 127/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.4327e-07 - val_loss: 1.7189e-07\n",
      "Epoch 128/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 2.0763e-07 - val_loss: 1.3338e-07\n",
      "Epoch 129/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.4270e-07 - val_loss: 1.2986e-07\n",
      "Epoch 130/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.3804e-07 - val_loss: 1.2679e-07\n",
      "Epoch 131/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.3785e-07 - val_loss: 1.3028e-07\n",
      "Epoch 132/900\n",
      "10/10 [==============================] - ETA: 0s - loss: 9.8787e-0 - 0s 38ms/sample - loss: 1.2537e-07 - val_loss: 1.8637e-07\n",
      "Epoch 133/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.9033e-07 - val_loss: 1.1275e-07\n",
      "Epoch 134/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.0556e-07 - val_loss: 1.4709e-07\n",
      "Epoch 135/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.4840e-07 - val_loss: 9.8628e-08\n",
      "Epoch 136/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.2666e-07 - val_loss: 1.1849e-07\n",
      "Epoch 137/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 9.7186e-08 - val_loss: 1.0593e-07\n",
      "Epoch 138/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.4140e-07 - val_loss: 9.1958e-08\n",
      "Epoch 139/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.0956e-07 - val_loss: 1.1370e-07\n",
      "Epoch 140/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.0922e-07 - val_loss: 8.3385e-08\n",
      "Epoch 141/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.0443e-07 - val_loss: 7.8272e-08\n",
      "Epoch 142/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 7.9937e-08 - val_loss: 1.0884e-07\n",
      "Epoch 143/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.1258e-07 - val_loss: 7.0016e-08\n",
      "Epoch 144/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 7.3808e-08 - val_loss: 1.0416e-07\n",
      "Epoch 145/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.0790e-07 - val_loss: 7.0274e-08\n",
      "Epoch 146/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 7.6810e-08 - val_loss: 5.9452e-08\n",
      "Epoch 147/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 7.7567e-08 - val_loss: 5.9715e-08\n",
      "Epoch 148/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 6.7056e-08 - val_loss: 5.4918e-08\n",
      "Epoch 149/900\n",
      "10/10 [==============================] - 0s 40ms/sample - loss: 6.8959e-08 - val_loss: 5.0039e-08\n",
      "Epoch 150/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 6.0783e-08 - val_loss: 5.8044e-08\n",
      "Epoch 151/900\n",
      "10/10 [==============================] - 0s 39ms/sample - loss: 5.6395e-08 - val_loss: 5.1955e-08\n",
      "Epoch 152/900\n",
      "10/10 [==============================] - 0s 41ms/sample - loss: 6.6360e-08 - val_loss: 4.8194e-08\n",
      "Epoch 153/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.4477e-08 - val_loss: 5.8918e-08\n",
      "Epoch 154/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.9768e-08 - val_loss: 4.0211e-08\n",
      "Epoch 155/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.7958e-08 - val_loss: 4.2460e-08\n",
      "Epoch 156/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.0270e-08 - val_loss: 3.8036e-08\n",
      "Epoch 157/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.6184e-08 - val_loss: 1.0204e-07\n",
      "Epoch 158/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 8.9828e-08 - val_loss: 3.6549e-08\n",
      "Epoch 159/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 6.7771e-08 - val_loss: 5.0542e-08\n",
      "Epoch 160/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 9.5162e-08 - val_loss: 6.2870e-08\n",
      "Epoch 161/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.4201e-08 - val_loss: 4.5398e-08\n",
      "Epoch 162/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 5.1408e-08 - val_loss: 3.0896e-08\n",
      "Epoch 163/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.1967e-08 - val_loss: 2.3805e-08\n",
      "Epoch 164/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.3786e-08 - val_loss: 2.7906e-08\n",
      "Epoch 165/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.2975e-08 - val_loss: 2.1502e-08\n",
      "Epoch 166/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.4043e-08 - val_loss: 2.0475e-08\n",
      "Epoch 167/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.3189e-08 - val_loss: 1.9221e-08\n",
      "Epoch 168/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.6571e-08 - val_loss: 1.8138e-08\n",
      "Epoch 169/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.8007e-08 - val_loss: 2.2737e-08\n",
      "Epoch 170/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.6406e-08 - val_loss: 1.7965e-08\n",
      "Epoch 171/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 3.2559e-08 - val_loss: 4.7274e-08\n",
      "Epoch 172/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.0741e-08 - val_loss: 2.3172e-08\n",
      "Epoch 173/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6269e-08 - val_loss: 1.9134e-08\n",
      "Epoch 174/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.5061e-08 - val_loss: 2.1030e-08\n",
      "Epoch 175/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 2.1818e-08 - val_loss: 2.6679e-08\n",
      "Epoch 176/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.7231e-08 - val_loss: 2.3264e-08\n",
      "Epoch 177/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 5.3732e-08 - val_loss: 1.4218e-08\n",
      "Epoch 178/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.5583e-09 - val_loss: 6.8228e-08\n",
      "Epoch 179/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.4625e-08 - val_loss: 1.9634e-08\n",
      "Epoch 180/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.9487e-08 - val_loss: 5.5097e-08\n",
      "Epoch 181/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 5.7876e-08 - val_loss: 3.7564e-08\n",
      "Epoch 182/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.1250e-08 - val_loss: 1.8549e-08\n",
      "Epoch 183/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.0315e-08 - val_loss: 8.4204e-09\n",
      "Epoch 184/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 8.7262e-09 - val_loss: 1.2507e-08\n",
      "Epoch 185/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 1.1726e-08 - val_loss: 6.7192e-09\n",
      "Epoch 186/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.3666e-09 - val_loss: 5.8594e-09\n",
      "Epoch 187/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 6.8343e-09 - val_loss: 5.9198e-09\n",
      "Epoch 188/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 7.6982e-09 - val_loss: 5.3980e-09\n",
      "Epoch 189/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 6.5316e-09 - val_loss: 5.5796e-09\n",
      "Epoch 190/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 4.9895e-09 - val_loss: 6.4703e-09\n",
      "Epoch 191/900\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 6.7778e-09 - val_loss: 4.3055e-09\n",
      "Epoch 192/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.9215e-09 - val_loss: 5.6457e-09\n",
      "Epoch 193/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.1807e-09 - val_loss: 4.4988e-09\n",
      "Epoch 194/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 6.4210e-09 - val_loss: 3.9479e-09\n",
      "Epoch 195/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.8051e-09 - val_loss: 7.7171e-09\n",
      "Epoch 196/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 4.2911e-09 - val_loss: 9.4630e-09\n",
      "Epoch 197/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 8.7935e-09 - val_loss: 3.2961e-09\n",
      "Epoch 198/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.4933e-09 - val_loss: 3.8371e-09\n",
      "Epoch 199/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 3.6717e-09 - val_loss: 3.3554e-09\n",
      "Epoch 200/900\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 3.4207e-09 - val_loss: 2.6059e-09\n",
      "Epoch 201/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 2.6988e-09 - val_loss: 2.5869e-09\n",
      "Epoch 202/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 2.9878e-09 - val_loss: 2.4515e-09\n",
      "Epoch 203/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 79ms/sample - loss: 5.9000e-09 - val_loss: 2.0072e-09\n",
      "Epoch 204/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 3.7538e-09 - val_loss: 5.0610e-09\n",
      "Epoch 205/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 5.2058e-09 - val_loss: 5.1455e-09\n",
      "Epoch 206/900\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 4.3313e-09 - val_loss: 4.4786e-09\n",
      "Epoch 207/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 5.4101e-09 - val_loss: 2.2362e-09\n",
      "Epoch 208/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 3.9539e-09 - val_loss: 3.1043e-09\n",
      "Epoch 209/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.4441e-09 - val_loss: 3.9604e-09\n",
      "Epoch 210/900\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 4.5441e-09 - val_loss: 2.5146e-09\n",
      "Epoch 211/900\n",
      "10/10 [==============================] - 1s 83ms/sample - loss: 3.4342e-09 - val_loss: 8.4966e-09\n",
      "Epoch 212/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.9300e-09 - val_loss: 5.0912e-09\n",
      "Epoch 213/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 5.2155e-09 - val_loss: 1.5965e-09\n",
      "Epoch 214/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.4130e-09 - val_loss: 4.4904e-09\n",
      "Epoch 215/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 3.4772e-09 - val_loss: 2.6822e-09\n",
      "Epoch 216/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 3.3998e-09 - val_loss: 1.7891e-09\n",
      "Epoch 217/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 6.3993e-09 - val_loss: 1.2087e-09\n",
      "Epoch 218/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 6.1006e-09 - val_loss: 5.2739e-09\n",
      "Epoch 219/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 4.0276e-09 - val_loss: 4.9699e-09\n",
      "Epoch 220/900\n",
      "10/10 [==============================] - 1s 81ms/sample - loss: 3.3707e-09 - val_loss: 3.5936e-09\n",
      "Epoch 221/900\n",
      "10/10 [==============================] - 1s 83ms/sample - loss: 5.6653e-09 - val_loss: 1.1662e-09\n",
      "Epoch 222/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 3.3552e-09 - val_loss: 3.4231e-09\n",
      "Epoch 223/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 1.7197e-09 - val_loss: 2.9765e-09\n",
      "Epoch 224/900\n",
      "10/10 [==============================] - 1s 81ms/sample - loss: 3.0871e-09 - val_loss: 9.4207e-10\n",
      "Epoch 225/900\n",
      "10/10 [==============================] - 1s 89ms/sample - loss: 2.5167e-09 - val_loss: 1.4083e-09\n",
      "Epoch 226/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 1.6124e-09 - val_loss: 1.8713e-09\n",
      "Epoch 227/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.6578e-09 - val_loss: 1.2156e-09\n",
      "Epoch 228/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.2185e-09 - val_loss: 5.2869e-10\n",
      "Epoch 229/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 8.7608e-10 - val_loss: 8.3949e-10\n",
      "Epoch 230/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.4016e-09 - val_loss: 6.1982e-10\n",
      "Epoch 231/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.5158e-10 - val_loss: 8.0263e-10\n",
      "Epoch 232/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.6783e-10 - val_loss: 4.3294e-10\n",
      "Epoch 233/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 7.0385e-10 - val_loss: 3.2454e-10\n",
      "Epoch 234/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 2.9342e-10 - val_loss: 4.9109e-10\n",
      "Epoch 235/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.6105e-10 - val_loss: 2.4083e-10\n",
      "Epoch 236/900\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 3.9519e-10 - val_loss: 1.8935e-10\n",
      "Epoch 237/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.0938e-10 - val_loss: 3.1269e-10\n",
      "Epoch 238/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.5673e-10 - val_loss: 4.4137e-10\n",
      "Epoch 239/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.8545e-10 - val_loss: 5.2242e-10\n",
      "Epoch 240/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.1695e-10 - val_loss: 2.2700e-10\n",
      "Epoch 241/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.2077e-10 - val_loss: 1.6655e-10\n",
      "Epoch 242/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.3467e-10 - val_loss: 4.0998e-10\n",
      "Epoch 243/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.6947e-10 - val_loss: 2.5479e-10\n",
      "Epoch 244/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.2041e-10 - val_loss: 1.3069e-10\n",
      "Epoch 245/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.5588e-10 - val_loss: 3.6467e-10\n",
      "Epoch 246/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.7551e-10 - val_loss: 1.8098e-10\n",
      "Epoch 247/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.9432e-10 - val_loss: 1.0904e-10\n",
      "Epoch 248/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.1053e-10 - val_loss: 1.9764e-10\n",
      "Epoch 249/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.5320e-10 - val_loss: 1.2593e-10\n",
      "Epoch 250/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 1.2176e-10 - val_loss: 6.0570e-11\n",
      "Epoch 251/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 6.7511e-11 - val_loss: 1.0535e-10\n",
      "Epoch 252/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 8.1163e-11 - val_loss: 7.1646e-11\n",
      "Epoch 253/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 8.1029e-11 - val_loss: 5.7255e-11\n",
      "Epoch 254/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.9190e-11 - val_loss: 8.0545e-11\n",
      "Epoch 255/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.4024e-11 - val_loss: 5.3854e-11\n",
      "Epoch 256/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.0794e-11 - val_loss: 4.3420e-11\n",
      "Epoch 257/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.3810e-11 - val_loss: 4.3756e-11\n",
      "Epoch 258/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.5701e-11 - val_loss: 5.1650e-11\n",
      "Epoch 259/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.7090e-11 - val_loss: 4.7042e-11\n",
      "Epoch 260/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 4.2720e-11 - val_loss: 3.6337e-11\n",
      "Epoch 261/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.9108e-11 - val_loss: 3.3188e-11\n",
      "Epoch 262/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.9968e-11 - val_loss: 3.9479e-11\n",
      "Epoch 263/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.8839e-11 - val_loss: 2.9990e-11\n",
      "Epoch 264/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.3954e-11 - val_loss: 3.5981e-11\n",
      "Epoch 265/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.8566e-11 - val_loss: 2.1547e-11\n",
      "Epoch 266/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.3173e-11 - val_loss: 2.2819e-11\n",
      "Epoch 267/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.4255e-11 - val_loss: 1.7430e-11\n",
      "Epoch 268/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.0392e-11 - val_loss: 3.4627e-11\n",
      "Epoch 269/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.8503e-11 - val_loss: 4.6829e-11\n",
      "Epoch 270/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.3335e-11 - val_loss: 2.5386e-11\n",
      "Epoch 271/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.9975e-11 - val_loss: 1.8583e-11\n",
      "Epoch 272/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.4010e-11 - val_loss: 2.7189e-11\n",
      "Epoch 273/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.4965e-11 - val_loss: 3.5258e-11\n",
      "Epoch 274/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 3.3141e-11 - val_loss: 2.7001e-11\n",
      "Epoch 275/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.8708e-11 - val_loss: 1.8106e-11\n",
      "Epoch 276/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.4799e-11 - val_loss: 3.5212e-11\n",
      "Epoch 277/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.7806e-11 - val_loss: 3.4540e-11\n",
      "Epoch 278/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 1.3653e-11 - val_loss: 4.5384e-11\n",
      "Epoch 279/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 5.2689e-11 - val_loss: 1.2073e-11\n",
      "Epoch 280/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.0298e-11 - val_loss: 2.6696e-11\n",
      "Epoch 281/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 4.8762e-11 - val_loss: 1.9201e-10\n",
      "Epoch 282/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.1300e-10 - val_loss: 1.4768e-10\n",
      "Epoch 283/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 2.1973e-10 - val_loss: 2.9309e-11\n",
      "Epoch 284/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.6457e-10 - val_loss: 1.3892e-10\n",
      "Epoch 285/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.8654e-10 - val_loss: 2.5226e-10\n",
      "Epoch 286/900\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 2.0809e-10 - val_loss: 2.5574e-10\n",
      "Epoch 287/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.2438e-10 - val_loss: 8.9062e-11\n",
      "Epoch 288/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.1266e-10 - val_loss: 4.3558e-11\n",
      "Epoch 289/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.6704e-10 - val_loss: 2.4255e-10\n",
      "Epoch 290/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.4910e-10 - val_loss: 4.7806e-10\n",
      "Epoch 291/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.7652e-10 - val_loss: 4.3280e-10\n",
      "Epoch 292/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.3559e-10 - val_loss: 1.7872e-10\n",
      "Epoch 293/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.7496e-10 - val_loss: 1.1097e-10\n",
      "Epoch 294/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 5.8824e-11 - val_loss: 2.9732e-10\n",
      "Epoch 295/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.9733e-10 - val_loss: 2.3088e-10\n",
      "Epoch 296/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.5883e-10 - val_loss: 2.2140e-10\n",
      "Epoch 297/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.8455e-10 - val_loss: 1.1047e-10\n",
      "Epoch 298/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 6.4407e-11 - val_loss: 6.3041e-10\n",
      "Epoch 299/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 6.0765e-10 - val_loss: 1.5765e-10\n",
      "Epoch 300/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 8.4483e-11 - val_loss: 1.9783e-10\n",
      "Epoch 301/900\n",
      "10/10 [==============================] - 1s 83ms/sample - loss: 2.2285e-10 - val_loss: 1.1060e-10\n",
      "Epoch 302/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 1.8681e-10 - val_loss: 1.3048e-10\n",
      "Epoch 303/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.1236e-10 - val_loss: 1.9475e-10\n",
      "Epoch 304/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 8.7692e-11 - val_loss: 1.6944e-10\n",
      "Epoch 305/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.6898e-10 - val_loss: 3.9186e-11\n",
      "Epoch 306/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 5.4821e-11 - val_loss: 2.1050e-11\n",
      "Epoch 307/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.2833e-11 - val_loss: 3.0027e-11\n",
      "Epoch 308/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.7076e-11 - val_loss: 2.7694e-11\n",
      "Epoch 309/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.7184e-11 - val_loss: 1.8887e-11\n",
      "Epoch 310/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.7908e-11 - val_loss: 9.8045e-12\n",
      "Epoch 311/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.4500e-11 - val_loss: 1.7668e-11\n",
      "Epoch 312/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.5119e-11 - val_loss: 9.5960e-12\n",
      "Epoch 313/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.8707e-11 - val_loss: 5.2479e-12\n",
      "Epoch 314/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.1968e-11 - val_loss: 4.8925e-12\n",
      "Epoch 315/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.7474e-11 - val_loss: 5.8964e-12\n",
      "Epoch 316/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 9.3110e-12 - val_loss: 3.0224e-11\n",
      "Epoch 317/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.0819e-11 - val_loss: 2.7524e-11\n",
      "Epoch 318/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.8738e-11 - val_loss: 8.4019e-12\n",
      "Epoch 319/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 9.3269e-12 - val_loss: 2.0967e-12\n",
      "Epoch 320/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 4.9021e-12 - val_loss: 1.0456e-12\n",
      "Epoch 321/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 4.1547e-12 - val_loss: 5.6481e-12\n",
      "Epoch 322/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.5154e-12 - val_loss: 3.8568e-12\n",
      "Epoch 323/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.6148e-12 - val_loss: 4.0748e-12\n",
      "Epoch 324/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.0144e-12 - val_loss: 5.8821e-12\n",
      "Epoch 325/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 8.8682e-12 - val_loss: 2.3295e-13\n",
      "Epoch 326/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.1783e-12 - val_loss: 6.3954e-12\n",
      "Epoch 327/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 9.8099e-12 - val_loss: 1.3475e-11\n",
      "Epoch 328/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 9.7895e-12 - val_loss: 1.9698e-11\n",
      "Epoch 329/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.3576e-11 - val_loss: 7.4348e-12\n",
      "Epoch 330/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 9.1965e-12 - val_loss: 7.7959e-12\n",
      "Epoch 331/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.3201e-11 - val_loss: 4.7813e-13\n",
      "Epoch 332/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.9626e-12 - val_loss: 1.5135e-11\n",
      "Epoch 333/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 8.6516e-12 - val_loss: 1.5667e-11\n",
      "Epoch 334/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 9.8332e-12 - val_loss: 5.8695e-12\n",
      "Epoch 335/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.9356e-12 - val_loss: 7.9154e-13\n",
      "Epoch 336/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.7832e-12 - val_loss: 7.5787e-12\n",
      "Epoch 337/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.1741e-12 - val_loss: 5.4349e-12\n",
      "Epoch 338/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.1713e-12 - val_loss: 4.4953e-12\n",
      "Epoch 339/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.1258e-12 - val_loss: 9.5295e-13\n",
      "Epoch 340/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.8184e-12 - val_loss: 3.0000e-12\n",
      "Epoch 341/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 4.3146e-12 - val_loss: 1.0968e-12\n",
      "Epoch 342/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.1809e-12 - val_loss: 1.7891e-12\n",
      "Epoch 343/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.3776e-12 - val_loss: 3.3328e-12\n",
      "Epoch 344/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.4916e-12 - val_loss: 7.4084e-12\n",
      "Epoch 345/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.3114e-12 - val_loss: 6.8350e-12\n",
      "Epoch 346/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.0075e-11 - val_loss: 7.4565e-13\n",
      "Epoch 347/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 7.2678e-12 - val_loss: 8.4398e-12\n",
      "Epoch 348/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 6.4015e-12 - val_loss: 4.7299e-12\n",
      "Epoch 349/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.8962e-12 - val_loss: 4.6614e-12\n",
      "Epoch 350/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.7660e-12 - val_loss: 1.5271e-11\n",
      "Epoch 351/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.3145e-11 - val_loss: 5.0282e-12\n",
      "Epoch 352/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.5321e-12 - val_loss: 8.2391e-12\n",
      "Epoch 353/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.2811e-12 - val_loss: 1.9033e-12\n",
      "Epoch 354/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.8772e-12 - val_loss: 4.3149e-12\n",
      "Epoch 355/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.3741e-12 - val_loss: 2.3675e-12\n",
      "Epoch 356/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.2851e-12 - val_loss: 7.6845e-12\n",
      "Epoch 357/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.2580e-12 - val_loss: 4.4684e-12\n",
      "Epoch 358/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 8.4983e-12 - val_loss: 1.8076e-12\n",
      "Epoch 359/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 1.8351e-12 - val_loss: 1.1175e-11\n",
      "Epoch 360/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 1.9154e-11 - val_loss: 6.6580e-12\n",
      "Epoch 361/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.4684e-11 - val_loss: 3.4810e-11\n",
      "Epoch 362/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.6677e-11 - val_loss: 1.9581e-12\n",
      "Epoch 363/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2943e-11 - val_loss: 1.0562e-11\n",
      "Epoch 364/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 9.6964e-12 - val_loss: 2.5425e-11\n",
      "Epoch 365/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.7848e-11 - val_loss: 1.9616e-12\n",
      "Epoch 366/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.5805e-12 - val_loss: 2.0985e-11\n",
      "Epoch 367/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.3542e-11 - val_loss: 1.7955e-12\n",
      "Epoch 368/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.7093e-11 - val_loss: 9.9730e-12\n",
      "Epoch 369/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.5832e-11 - val_loss: 5.5580e-11\n",
      "Epoch 370/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.3404e-10 - val_loss: 8.5908e-11\n",
      "Epoch 371/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.8768e-10 - val_loss: 2.2684e-10\n",
      "Epoch 372/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.5921e-10 - val_loss: 2.0884e-10\n",
      "Epoch 373/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6273e-10 - val_loss: 1.6785e-11\n",
      "Epoch 374/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 9.9527e-11 - val_loss: 5.6957e-10\n",
      "Epoch 375/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 7.1357e-10 - val_loss: 5.4878e-11\n",
      "Epoch 376/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 3.7693e-10 - val_loss: 3.9954e-10\n",
      "Epoch 377/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 3.3233e-10 - val_loss: 1.0252e-10\n",
      "Epoch 378/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.8306e-10 - val_loss: 5.3038e-10\n",
      "Epoch 379/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 4.8021e-10 - val_loss: 1.7180e-10\n",
      "Epoch 380/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.5408e-10 - val_loss: 2.5056e-10\n",
      "Epoch 381/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.3213e-10 - val_loss: 1.0205e-10\n",
      "Epoch 382/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.9648e-10 - val_loss: 2.3127e-10\n",
      "Epoch 383/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.7625e-10 - val_loss: 5.0579e-10\n",
      "Epoch 384/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.2213e-09 - val_loss: 7.0640e-10\n",
      "Epoch 385/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 9.5941e-10 - val_loss: 4.8659e-10\n",
      "Epoch 386/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.7380e-09 - val_loss: 2.6853e-10\n",
      "Epoch 387/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.3076e-09 - val_loss: 6.9695e-10\n",
      "Epoch 388/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.9085e-09 - val_loss: 2.5808e-09\n",
      "Epoch 389/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.0507e-09 - val_loss: 9.7765e-09\n",
      "Epoch 390/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 7.6991e-09 - val_loss: 3.9127e-09\n",
      "Epoch 391/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.5698e-09 - val_loss: 5.4953e-09\n",
      "Epoch 392/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 7.1349e-09 - val_loss: 3.9277e-09\n",
      "Epoch 393/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.2183e-09 - val_loss: 9.5521e-10\n",
      "Epoch 394/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.2039e-09 - val_loss: 2.4285e-09\n",
      "Epoch 395/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.1997e-09 - val_loss: 1.8076e-09\n",
      "Epoch 396/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.1716e-09 - val_loss: 7.3622e-10\n",
      "Epoch 397/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.4503e-09 - val_loss: 2.4495e-09\n",
      "Epoch 398/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.1438e-09 - val_loss: 3.2571e-09\n",
      "Epoch 399/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 4.4573e-09 - val_loss: 5.8782e-09\n",
      "Epoch 400/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.7214e-09 - val_loss: 4.5967e-09\n",
      "Epoch 401/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.9997e-09 - val_loss: 3.1561e-09\n",
      "Epoch 402/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 6.4373e-09 - val_loss: 2.2610e-09\n",
      "Epoch 403/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 7.5139e-09 - val_loss: 1.8880e-09\n",
      "Epoch 404/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.7356e-09 - val_loss: 2.4511e-09\n",
      "Epoch 405/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.4116e-09 - val_loss: 2.1446e-09\n",
      "Epoch 406/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.9414e-09 - val_loss: 1.9219e-09\n",
      "Epoch 407/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.4234e-09 - val_loss: 1.2465e-08\n",
      "Epoch 408/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.4994e-08 - val_loss: 1.1544e-08\n",
      "Epoch 409/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.0743e-08 - val_loss: 6.9504e-09\n",
      "Epoch 410/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.0921e-09 - val_loss: 1.1688e-09\n",
      "Epoch 411/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.6464e-09 - val_loss: 6.1156e-09\n",
      "Epoch 412/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 7.2369e-09 - val_loss: 1.3471e-08\n",
      "Epoch 413/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.0925e-08 - val_loss: 3.0689e-09\n",
      "Epoch 414/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 5.0779e-09 - val_loss: 3.4485e-09\n",
      "Epoch 415/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 6.8317e-09 - val_loss: 3.9173e-09\n",
      "Epoch 416/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.7107e-09 - val_loss: 2.9424e-10\n",
      "Epoch 417/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.0678e-09 - val_loss: 3.1541e-09\n",
      "Epoch 418/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.7048e-09 - val_loss: 9.8248e-10\n",
      "Epoch 419/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 8.5543e-10 - val_loss: 3.2283e-09\n",
      "Epoch 420/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.0750e-09 - val_loss: 8.3442e-10\n",
      "Epoch 421/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 8.3272e-10 - val_loss: 3.8617e-09\n",
      "Epoch 422/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 75ms/sample - loss: 4.3634e-09 - val_loss: 8.6402e-10\n",
      "Epoch 423/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.3104e-09 - val_loss: 9.6134e-09\n",
      "Epoch 424/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.7390e-09 - val_loss: 8.6431e-09\n",
      "Epoch 425/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.0152e-08 - val_loss: 6.6549e-09\n",
      "Epoch 426/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.6885e-08 - val_loss: 2.1440e-08\n",
      "Epoch 427/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.4789e-08 - val_loss: 1.0287e-08\n",
      "Epoch 428/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.2417e-08 - val_loss: 5.0240e-09\n",
      "Epoch 429/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.4264e-08 - val_loss: 3.9967e-09\n",
      "Epoch 430/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.6132e-08 - val_loss: 1.4614e-08\n",
      "Epoch 431/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.1444e-08 - val_loss: 1.4040e-08\n",
      "Epoch 432/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.9369e-09 - val_loss: 1.9115e-08\n",
      "Epoch 433/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.7123e-08 - val_loss: 3.7255e-08\n",
      "Epoch 434/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.0673e-08 - val_loss: 1.6288e-07\n",
      "Epoch 435/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5759e-07 - val_loss: 1.5133e-07\n",
      "Epoch 436/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.0363e-07 - val_loss: 1.3547e-08\n",
      "Epoch 437/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.0539e-08 - val_loss: 5.8136e-08\n",
      "Epoch 438/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.0542e-07 - val_loss: 3.4847e-08\n",
      "Epoch 439/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.0887e-08 - val_loss: 3.1248e-07\n",
      "Epoch 440/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.2248e-07 - val_loss: 1.0441e-07\n",
      "Epoch 441/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6023e-07 - val_loss: 9.8871e-08\n",
      "Epoch 442/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 9.4034e-08 - val_loss: 6.5995e-07\n",
      "Epoch 443/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 8.5737e-07 - val_loss: 3.0879e-07\n",
      "Epoch 444/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.0018e-06 - val_loss: 3.9309e-07\n",
      "Epoch 445/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.8769e-07 - val_loss: 6.9303e-07\n",
      "Epoch 446/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.4303e-06 - val_loss: 1.9714e-07\n",
      "Epoch 447/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.5719e-06 - val_loss: 7.4419e-07\n",
      "Epoch 448/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.5584e-06 - val_loss: 2.7719e-06\n",
      "Epoch 449/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.8879e-06 - val_loss: 1.5672e-06\n",
      "Epoch 450/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.5569e-06 - val_loss: 1.2973e-05\n",
      "Epoch 451/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 9.5204e-06 - val_loss: 1.1078e-05\n",
      "Epoch 452/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.6861e-05 - val_loss: 2.6167e-05\n",
      "Epoch 453/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.0477e-05 - val_loss: 2.0832e-05\n",
      "Epoch 454/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.7121e-05 - val_loss: 2.1607e-05\n",
      "Epoch 455/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.0101e-05 - val_loss: 1.7549e-05\n",
      "Epoch 456/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.0814e-05 - val_loss: 2.1895e-05\n",
      "Epoch 457/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.5385e-05 - val_loss: 1.6424e-05\n",
      "Epoch 458/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.5452e-05 - val_loss: 4.6925e-06\n",
      "Epoch 459/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.0536e-06 - val_loss: 9.8409e-06\n",
      "Epoch 460/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 7.2837e-06 - val_loss: 3.8433e-06\n",
      "Epoch 461/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 5.2880e-06 - val_loss: 4.3640e-06\n",
      "Epoch 462/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.5031e-06 - val_loss: 3.8709e-06\n",
      "Epoch 463/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.6700e-06 - val_loss: 4.4983e-06\n",
      "Epoch 464/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.3615e-06 - val_loss: 2.8842e-06\n",
      "Epoch 465/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.1029e-06 - val_loss: 6.7720e-06\n",
      "Epoch 466/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.9756e-06 - val_loss: 2.9559e-06\n",
      "Epoch 467/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.5649e-05 - val_loss: 2.9594e-06\n",
      "Epoch 468/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 7.5052e-06 - val_loss: 2.7792e-05\n",
      "Epoch 469/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.8219e-05 - val_loss: 3.5432e-05\n",
      "Epoch 470/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.4783e-05 - val_loss: 2.0392e-05\n",
      "Epoch 471/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.6688e-05 - val_loss: 4.0727e-05\n",
      "Epoch 472/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.4762e-05 - val_loss: 2.5274e-05\n",
      "Epoch 473/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 1.8626e-05 - val_loss: 9.2356e-06\n",
      "Epoch 474/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.2041e-05 - val_loss: 1.2359e-05\n",
      "Epoch 475/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.2735e-05 - val_loss: 8.9242e-06\n",
      "Epoch 476/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.4951e-06 - val_loss: 8.1991e-06\n",
      "Epoch 477/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 7.0513e-06 - val_loss: 6.5398e-06\n",
      "Epoch 478/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.9816e-06 - val_loss: 1.4741e-06\n",
      "Epoch 479/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.6515e-06 - val_loss: 1.5933e-06\n",
      "Epoch 480/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.1550e-06 - val_loss: 9.3922e-06\n",
      "Epoch 481/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.1662e-05 - val_loss: 1.3231e-06\n",
      "Epoch 482/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 9.7117e-06 - val_loss: 2.4632e-06\n",
      "Epoch 483/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.1302e-06 - val_loss: 2.6895e-06\n",
      "Epoch 484/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.6385e-06 - val_loss: 1.6267e-06\n",
      "Epoch 485/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.7593e-06 - val_loss: 1.4197e-06\n",
      "Epoch 486/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.7645e-06 - val_loss: 1.8229e-05\n",
      "Epoch 487/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.2301e-05 - val_loss: 1.2959e-05\n",
      "Epoch 488/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.7511e-05 - val_loss: 1.3757e-05\n",
      "Epoch 489/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 9.7742e-06 - val_loss: 1.9237e-05\n",
      "Epoch 490/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 1.7016e-05 - val_loss: 1.0426e-05\n",
      "Epoch 491/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.1178e-05 - val_loss: 2.2013e-05\n",
      "Epoch 492/900\n",
      "10/10 [==============================] - 1s 78ms/sample - loss: 2.8475e-05 - val_loss: 2.1694e-05\n",
      "Epoch 493/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 2.8340e-05 - val_loss: 2.1113e-05\n",
      "Epoch 494/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 2.9156e-05 - val_loss: 1.0295e-05\n",
      "Epoch 495/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.1199e-05 - val_loss: 2.2860e-05\n",
      "Epoch 496/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.4977e-05 - val_loss: 1.3363e-05\n",
      "Epoch 497/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.4579e-05 - val_loss: 9.3525e-06\n",
      "Epoch 498/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.8921e-05 - val_loss: 9.8328e-06\n",
      "Epoch 499/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.7007e-05 - val_loss: 6.2174e-05\n",
      "Epoch 500/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.0625e-04 - val_loss: 3.4482e-05\n",
      "Epoch 501/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3101e-04 - val_loss: 7.5796e-05\n",
      "Epoch 502/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.7373e-05 - val_loss: 2.2339e-04\n",
      "Epoch 503/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.7307e-04 - val_loss: 2.5157e-05\n",
      "Epoch 504/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.5283e-04 - val_loss: 4.8524e-04\n",
      "Epoch 505/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 5.9641e-04 - val_loss: 3.5579e-04\n",
      "Epoch 506/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.9653e-04 - val_loss: 4.6493e-05\n",
      "Epoch 507/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.6774e-04 - val_loss: 1.0564e-04\n",
      "Epoch 508/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 5.6269e-05 - val_loss: 1.1258e-04\n",
      "Epoch 509/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.0970e-04 - val_loss: 4.6323e-05\n",
      "Epoch 510/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.9578e-05 - val_loss: 2.2776e-05\n",
      "Epoch 511/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 4.9382e-05 - val_loss: 2.8681e-05\n",
      "Epoch 512/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 4.4776e-05 - val_loss: 1.9186e-05\n",
      "Epoch 513/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.1152e-05 - val_loss: 5.8724e-06\n",
      "Epoch 514/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.4997e-05 - val_loss: 1.8181e-05\n",
      "Epoch 515/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.4124e-05 - val_loss: 3.6257e-05\n",
      "Epoch 516/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.2423e-05 - val_loss: 1.1299e-05\n",
      "Epoch 517/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.3804e-05 - val_loss: 2.0127e-05\n",
      "Epoch 518/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.8654e-05 - val_loss: 1.0378e-05\n",
      "Epoch 519/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.5532e-05 - val_loss: 2.6978e-05\n",
      "Epoch 520/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.4137e-05 - val_loss: 3.4471e-05\n",
      "Epoch 521/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.9658e-05 - val_loss: 3.8364e-05\n",
      "Epoch 522/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.1821e-05 - val_loss: 1.6295e-05\n",
      "Epoch 523/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 1.7108e-05 - val_loss: 3.7933e-06\n",
      "Epoch 524/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.5401e-06 - val_loss: 7.1110e-06\n",
      "Epoch 525/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.9011e-06 - val_loss: 3.5405e-06\n",
      "Epoch 526/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.9918e-06 - val_loss: 4.2078e-06\n",
      "Epoch 527/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.5752e-06 - val_loss: 2.1829e-06\n",
      "Epoch 528/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.2983e-06 - val_loss: 1.4747e-06\n",
      "Epoch 529/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.1226e-06 - val_loss: 1.0693e-06\n",
      "Epoch 530/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.3739e-06 - val_loss: 1.3150e-06\n",
      "Epoch 531/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.2559e-07 - val_loss: 1.6785e-06\n",
      "Epoch 532/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3295e-06 - val_loss: 7.3832e-07\n",
      "Epoch 533/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 9.6682e-07 - val_loss: 6.0285e-07\n",
      "Epoch 534/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.8403e-07 - val_loss: 2.3466e-07\n",
      "Epoch 535/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.5951e-07 - val_loss: 1.9687e-07\n",
      "Epoch 536/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.9518e-07 - val_loss: 3.3706e-07\n",
      "Epoch 537/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.3808e-07 - val_loss: 4.1303e-07\n",
      "Epoch 538/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.6164e-07 - val_loss: 2.1149e-07\n",
      "Epoch 539/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.5527e-07 - val_loss: 6.4733e-08\n",
      "Epoch 540/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.9913e-07 - val_loss: 1.1236e-07\n",
      "Epoch 541/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.7251e-07 - val_loss: 1.9372e-07\n",
      "Epoch 542/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.4538e-07 - val_loss: 1.1583e-07\n",
      "Epoch 543/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 9.5915e-08 - val_loss: 4.1835e-08\n",
      "Epoch 544/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.3115e-08 - val_loss: 3.2770e-08\n",
      "Epoch 545/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.2600e-08 - val_loss: 3.9841e-08\n",
      "Epoch 546/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 6.0091e-08 - val_loss: 3.5540e-08\n",
      "Epoch 547/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.9291e-08 - val_loss: 3.0756e-08\n",
      "Epoch 548/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.2987e-08 - val_loss: 2.8005e-08\n",
      "Epoch 549/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.3539e-08 - val_loss: 1.4598e-08\n",
      "Epoch 550/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.8493e-08 - val_loss: 1.5761e-08\n",
      "Epoch 551/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.4534e-08 - val_loss: 1.9846e-08\n",
      "Epoch 552/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.8465e-08 - val_loss: 1.5336e-08\n",
      "Epoch 553/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.6243e-08 - val_loss: 8.5867e-09\n",
      "Epoch 554/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.1583e-09 - val_loss: 6.8958e-09\n",
      "Epoch 555/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.0033e-09 - val_loss: 5.2889e-09\n",
      "Epoch 556/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2144e-08 - val_loss: 6.3740e-09\n",
      "Epoch 557/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.8771e-08 - val_loss: 6.4550e-09\n",
      "Epoch 558/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.4631e-08 - val_loss: 9.4503e-09\n",
      "Epoch 559/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.9556e-09 - val_loss: 2.7331e-08\n",
      "Epoch 560/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.2611e-08 - val_loss: 3.3909e-08\n",
      "Epoch 561/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.0420e-08 - val_loss: 1.1082e-08\n",
      "Epoch 562/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.4313e-08 - val_loss: 3.2211e-09\n",
      "Epoch 563/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.5735e-09 - val_loss: 1.1560e-08\n",
      "Epoch 564/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.4360e-09 - val_loss: 1.4124e-08\n",
      "Epoch 565/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.6089e-08 - val_loss: 1.0516e-08\n",
      "Epoch 566/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.4168e-09 - val_loss: 3.5504e-09\n",
      "Epoch 567/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.0392e-09 - val_loss: 2.7657e-09\n",
      "Epoch 568/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.9975e-09 - val_loss: 5.1787e-09\n",
      "Epoch 569/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.8846e-09 - val_loss: 2.2242e-09\n",
      "Epoch 570/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.1042e-09 - val_loss: 2.4574e-09\n",
      "Epoch 571/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.5581e-09 - val_loss: 1.6062e-09\n",
      "Epoch 572/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.0756e-09 - val_loss: 2.4319e-09\n",
      "Epoch 573/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.6740e-09 - val_loss: 1.0364e-09\n",
      "Epoch 574/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.8172e-09 - val_loss: 9.3463e-10\n",
      "Epoch 575/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.2111e-09 - val_loss: 9.8406e-10\n",
      "Epoch 576/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 9.2862e-10 - val_loss: 7.5258e-10\n",
      "Epoch 577/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 7.1402e-10 - val_loss: 6.4544e-10\n",
      "Epoch 578/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 6.5426e-10 - val_loss: 5.0197e-10\n",
      "Epoch 579/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.3159e-10 - val_loss: 6.5958e-10\n",
      "Epoch 580/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.6008e-09 - val_loss: 7.2265e-10\n",
      "Epoch 581/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6357e-09 - val_loss: 4.7726e-10\n",
      "Epoch 582/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.5392e-10 - val_loss: 1.5152e-09\n",
      "Epoch 583/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3157e-09 - val_loss: 1.9133e-09\n",
      "Epoch 584/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.8738e-09 - val_loss: 1.7763e-09\n",
      "Epoch 585/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2306e-09 - val_loss: 1.5076e-09\n",
      "Epoch 586/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.3862e-09 - val_loss: 9.2850e-10\n",
      "Epoch 587/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.1564e-09 - val_loss: 8.4379e-10\n",
      "Epoch 588/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.3817e-09 - val_loss: 4.1359e-10\n",
      "Epoch 589/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.8560e-10 - val_loss: 2.0136e-09\n",
      "Epoch 590/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.4101e-09 - val_loss: 1.1144e-09\n",
      "Epoch 591/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.7041e-09 - val_loss: 3.5811e-09\n",
      "Epoch 592/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.2767e-09 - val_loss: 7.7553e-10\n",
      "Epoch 593/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.1302e-09 - val_loss: 2.8841e-09\n",
      "Epoch 594/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.8053e-09 - val_loss: 3.3828e-09\n",
      "Epoch 595/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.5286e-09 - val_loss: 3.8804e-09\n",
      "Epoch 596/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.4659e-09 - val_loss: 2.6372e-09\n",
      "Epoch 597/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 5.1066e-09 - val_loss: 7.8244e-10\n",
      "Epoch 598/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.1169e-09 - val_loss: 6.3821e-10\n",
      "Epoch 599/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.4110e-09 - val_loss: 9.7430e-10\n",
      "Epoch 600/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.6263e-10 - val_loss: 2.4301e-09\n",
      "Epoch 601/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.3034e-09 - val_loss: 2.1762e-09\n",
      "Epoch 602/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.9975e-09 - val_loss: 1.1939e-09\n",
      "Epoch 603/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.3530e-09 - val_loss: 4.8490e-10\n",
      "Epoch 604/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3397e-09 - val_loss: 1.9916e-10\n",
      "Epoch 605/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 9.4246e-10 - val_loss: 4.0697e-10\n",
      "Epoch 606/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.1018e-09 - val_loss: 1.1150e-09\n",
      "Epoch 607/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.0085e-09 - val_loss: 1.4535e-09\n",
      "Epoch 608/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 6.2562e-10 - val_loss: 1.8732e-09\n",
      "Epoch 609/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.8181e-09 - val_loss: 3.0745e-09\n",
      "Epoch 610/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 3.3162e-09 - val_loss: 3.2746e-09\n",
      "Epoch 611/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.5694e-09 - val_loss: 8.1449e-10\n",
      "Epoch 612/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 2.5538e-09 - val_loss: 9.2128e-10\n",
      "Epoch 613/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 4.7089e-09 - val_loss: 9.6517e-10\n",
      "Epoch 614/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 5.7565e-09 - val_loss: 1.6556e-10\n",
      "Epoch 615/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.8656e-09 - val_loss: 2.7000e-09\n",
      "Epoch 616/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.2180e-09 - val_loss: 6.3763e-09\n",
      "Epoch 617/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.8895e-09 - val_loss: 3.9484e-09\n",
      "Epoch 618/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.8447e-09 - val_loss: 2.5664e-09\n",
      "Epoch 619/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.6367e-09 - val_loss: 1.1046e-09\n",
      "Epoch 620/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.4242e-09 - val_loss: 6.0812e-09\n",
      "Epoch 621/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.5489e-09 - val_loss: 2.4829e-09\n",
      "Epoch 622/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.1102e-09 - val_loss: 1.3439e-09\n",
      "Epoch 623/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.0521e-09 - val_loss: 1.3537e-09\n",
      "Epoch 624/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.5649e-09 - val_loss: 4.4354e-10\n",
      "Epoch 625/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.1226e-09 - val_loss: 1.1771e-09\n",
      "Epoch 626/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.9692e-09 - val_loss: 2.9343e-09\n",
      "Epoch 627/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 5.1352e-09 - val_loss: 2.2672e-09\n",
      "Epoch 628/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.1081e-09 - val_loss: 2.4283e-09\n",
      "Epoch 629/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6710e-09 - val_loss: 9.7432e-10\n",
      "Epoch 630/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.1903e-09 - val_loss: 1.3725e-09\n",
      "Epoch 631/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.9238e-09 - val_loss: 4.8985e-10\n",
      "Epoch 632/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.5434e-09 - val_loss: 1.0467e-09\n",
      "Epoch 633/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.3851e-09 - val_loss: 5.4864e-10\n",
      "Epoch 634/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5404e-09 - val_loss: 6.4557e-10\n",
      "Epoch 635/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6123e-09 - val_loss: 4.2157e-10\n",
      "Epoch 636/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.2501e-09 - val_loss: 2.1968e-09\n",
      "Epoch 637/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.7118e-09 - val_loss: 2.5057e-09\n",
      "Epoch 638/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.4370e-09 - val_loss: 3.1816e-09\n",
      "Epoch 639/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.4779e-09 - val_loss: 8.4617e-09\n",
      "Epoch 640/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.2723e-09 - val_loss: 2.4983e-09\n",
      "Epoch 641/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.2356e-09 - val_loss: 2.3394e-09\n",
      "Epoch 642/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.5133e-09 - val_loss: 1.4194e-09\n",
      "Epoch 643/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.7253e-09 - val_loss: 8.5761e-10\n",
      "Epoch 644/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 8.9673e-10 - val_loss: 3.8339e-10\n",
      "Epoch 645/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.6015e-10 - val_loss: 8.2540e-10\n",
      "Epoch 646/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.8101e-09 - val_loss: 7.6830e-10\n",
      "Epoch 647/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.5040e-09 - val_loss: 2.9433e-10\n",
      "Epoch 648/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.1546e-09 - val_loss: 3.2465e-10\n",
      "Epoch 649/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.4587e-09 - val_loss: 5.2230e-10\n",
      "Epoch 650/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.3924e-09 - val_loss: 9.7521e-10\n",
      "Epoch 651/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 1.9460e-09 - val_loss: 7.0711e-10\n",
      "Epoch 652/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.8393e-09 - val_loss: 1.1207e-09\n",
      "Epoch 653/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.3358e-09 - val_loss: 1.7334e-09\n",
      "Epoch 654/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 9.9602e-10 - val_loss: 2.0380e-09\n",
      "Epoch 655/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.3168e-09 - val_loss: 3.3016e-10\n",
      "Epoch 656/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 9.6008e-10 - val_loss: 6.4411e-10\n",
      "Epoch 657/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.3328e-09 - val_loss: 2.5475e-10\n",
      "Epoch 658/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.7694e-09 - val_loss: 4.8003e-10\n",
      "Epoch 659/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.4747e-10 - val_loss: 2.2640e-09\n",
      "Epoch 660/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 9.1724e-10 - val_loss: 2.9971e-09\n",
      "Epoch 661/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.0767e-09 - val_loss: 2.0505e-09\n",
      "Epoch 662/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.8105e-09 - val_loss: 1.2105e-09\n",
      "Epoch 663/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.7678e-09 - val_loss: 5.2955e-10\n",
      "Epoch 664/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 9.7449e-10 - val_loss: 1.7274e-10\n",
      "Epoch 665/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.7242e-10 - val_loss: 2.7433e-10\n",
      "Epoch 666/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.9552e-10 - val_loss: 5.2284e-10\n",
      "Epoch 667/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.2391e-10 - val_loss: 2.7371e-10\n",
      "Epoch 668/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.5797e-10 - val_loss: 8.3785e-10\n",
      "Epoch 669/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.3395e-10 - val_loss: 7.1247e-10\n",
      "Epoch 670/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 7.4031e-10 - val_loss: 3.6386e-10\n",
      "Epoch 671/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.0572e-10 - val_loss: 4.7158e-10\n",
      "Epoch 672/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 5.8210e-10 - val_loss: 5.6774e-10\n",
      "Epoch 673/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 6.4381e-10 - val_loss: 1.9702e-10\n",
      "Epoch 674/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.2534e-10 - val_loss: 3.0871e-10\n",
      "Epoch 675/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 8.0785e-10 - val_loss: 1.3737e-10\n",
      "Epoch 676/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 9.8716e-10 - val_loss: 1.9455e-10\n",
      "Epoch 677/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.0857e-09 - val_loss: 3.3935e-10\n",
      "Epoch 678/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.0350e-09 - val_loss: 2.3429e-10\n",
      "Epoch 679/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.4156e-09 - val_loss: 4.9561e-10\n",
      "Epoch 680/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.0553e-09 - val_loss: 4.6428e-10\n",
      "Epoch 681/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 9.7616e-10 - val_loss: 1.9661e-09\n",
      "Epoch 682/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.3966e-09 - val_loss: 1.2587e-09\n",
      "Epoch 683/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 9.8924e-10 - val_loss: 1.6558e-09\n",
      "Epoch 684/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.3990e-09 - val_loss: 5.4431e-10\n",
      "Epoch 685/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.0310e-10 - val_loss: 1.2529e-09\n",
      "Epoch 686/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.1931e-09 - val_loss: 1.7691e-09\n",
      "Epoch 687/900\n",
      "10/10 [==============================] - 1s 79ms/sample - loss: 1.7542e-09 - val_loss: 8.2442e-10\n",
      "Epoch 688/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 9.1126e-10 - val_loss: 7.3106e-10\n",
      "Epoch 689/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 9.5889e-10 - val_loss: 8.5313e-10\n",
      "Epoch 690/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.0539e-09 - val_loss: 7.9792e-10\n",
      "Epoch 691/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 1.0221e-09 - val_loss: 4.8174e-10\n",
      "Epoch 692/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.2057e-09 - val_loss: 4.9080e-10\n",
      "Epoch 693/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.1703e-09 - val_loss: 3.6828e-10\n",
      "Epoch 694/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.7070e-09 - val_loss: 3.1220e-10\n",
      "Epoch 695/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.1637e-09 - val_loss: 1.8293e-10\n",
      "Epoch 696/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.9372e-10 - val_loss: 5.8675e-10\n",
      "Epoch 697/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 9.2600e-10 - val_loss: 1.7732e-09\n",
      "Epoch 698/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.7009e-09 - val_loss: 7.9897e-10\n",
      "Epoch 699/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.0902e-09 - val_loss: 8.6909e-09\n",
      "Epoch 700/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.7161e-09 - val_loss: 4.9029e-09\n",
      "Epoch 701/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.2020e-09 - val_loss: 7.7432e-09\n",
      "Epoch 702/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.3011e-09 - val_loss: 9.3648e-09\n",
      "Epoch 703/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2597e-08 - val_loss: 8.7747e-09\n",
      "Epoch 704/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3184e-08 - val_loss: 6.4675e-09\n",
      "Epoch 705/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 9.2959e-09 - val_loss: 3.3792e-09\n",
      "Epoch 706/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.5236e-08 - val_loss: 4.7689e-09\n",
      "Epoch 707/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.0541e-09 - val_loss: 1.1730e-09\n",
      "Epoch 708/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.2969e-09 - val_loss: 3.0834e-10\n",
      "Epoch 709/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.8480e-09 - val_loss: 7.1724e-10\n",
      "Epoch 710/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.7237e-09 - val_loss: 1.1092e-09\n",
      "Epoch 711/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.2561e-09 - val_loss: 1.5529e-09\n",
      "Epoch 712/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 5.0483e-09 - val_loss: 7.0398e-10\n",
      "Epoch 713/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 4.9095e-09 - val_loss: 7.3312e-10\n",
      "Epoch 714/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.2818e-09 - val_loss: 1.0704e-09\n",
      "Epoch 715/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.0013e-09 - val_loss: 2.1813e-09\n",
      "Epoch 716/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 4.7751e-09 - val_loss: 2.3902e-09\n",
      "Epoch 717/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.0862e-09 - val_loss: 8.6740e-10\n",
      "Epoch 718/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 5.9353e-10 - val_loss: 2.7826e-09\n",
      "Epoch 719/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 3.0125e-09 - val_loss: 8.9959e-10\n",
      "Epoch 720/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.5608e-09 - val_loss: 3.1021e-09\n",
      "Epoch 721/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.4464e-09 - val_loss: 1.2577e-09\n",
      "Epoch 722/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.4287e-10 - val_loss: 4.5016e-09\n",
      "Epoch 723/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.8532e-09 - val_loss: 3.3600e-09\n",
      "Epoch 724/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.7626e-09 - val_loss: 4.8521e-09\n",
      "Epoch 725/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 5.0025e-09 - val_loss: 5.3827e-09\n",
      "Epoch 726/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 5.9551e-09 - val_loss: 5.0402e-09\n",
      "Epoch 727/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.5970e-09 - val_loss: 5.2707e-09\n",
      "Epoch 728/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 4.2968e-09 - val_loss: 2.6884e-09\n",
      "Epoch 729/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 3.2293e-09 - val_loss: 1.9206e-09\n",
      "Epoch 730/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.0758e-09 - val_loss: 2.2655e-09\n",
      "Epoch 731/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.3626e-09 - val_loss: 2.5554e-09\n",
      "Epoch 732/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.4982e-09 - val_loss: 2.7374e-09\n",
      "Epoch 733/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.5783e-09 - val_loss: 5.6778e-09\n",
      "Epoch 734/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 7.0175e-09 - val_loss: 8.2569e-09\n",
      "Epoch 735/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.3993e-09 - val_loss: 1.0309e-08\n",
      "Epoch 736/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 1.0120e-08 - val_loss: 1.4682e-08\n",
      "Epoch 737/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.5610e-08 - val_loss: 1.4771e-08\n",
      "Epoch 738/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.0098e-08 - val_loss: 2.5919e-08\n",
      "Epoch 739/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.8497e-08 - val_loss: 5.0889e-08\n",
      "Epoch 740/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 5.1129e-08 - val_loss: 5.3156e-08\n",
      "Epoch 741/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 5.7829e-08 - val_loss: 6.6763e-08\n",
      "Epoch 742/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 7.2074e-08 - val_loss: 1.4357e-07\n",
      "Epoch 743/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.0156e-07 - val_loss: 2.0065e-07\n",
      "Epoch 744/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.2894e-07 - val_loss: 2.0407e-07\n",
      "Epoch 745/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.0156e-07 - val_loss: 5.3372e-07\n",
      "Epoch 746/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 4.2476e-07 - val_loss: 5.7488e-07\n",
      "Epoch 747/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.1982e-07 - val_loss: 7.0422e-07\n",
      "Epoch 748/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 4.8673e-07 - val_loss: 8.8848e-07\n",
      "Epoch 749/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 8.5999e-07 - val_loss: 1.6344e-06\n",
      "Epoch 750/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.3330e-06 - val_loss: 1.6923e-06\n",
      "Epoch 751/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.1436e-06 - val_loss: 3.3662e-06\n",
      "Epoch 752/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.6890e-06 - val_loss: 6.1508e-06\n",
      "Epoch 753/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.8505e-06 - val_loss: 5.6139e-06\n",
      "Epoch 754/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 5.6285e-06 - val_loss: 4.2265e-06\n",
      "Epoch 755/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.7304e-06 - val_loss: 3.9869e-06\n",
      "Epoch 756/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.8326e-06 - val_loss: 6.3287e-06\n",
      "Epoch 757/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 5.4137e-06 - val_loss: 7.2431e-06\n",
      "Epoch 758/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.8250e-06 - val_loss: 1.0428e-05\n",
      "Epoch 759/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 9.6663e-06 - val_loss: 1.3659e-05\n",
      "Epoch 760/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.6759e-06 - val_loss: 1.1157e-05\n",
      "Epoch 761/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 7.3658e-06 - val_loss: 2.1660e-05\n",
      "Epoch 762/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.7021e-05 - val_loss: 1.9942e-05\n",
      "Epoch 763/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.5089e-05 - val_loss: 2.0199e-05\n",
      "Epoch 764/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.8539e-05 - val_loss: 1.0460e-05\n",
      "Epoch 765/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.0035e-05 - val_loss: 7.1634e-06\n",
      "Epoch 766/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.6721e-06 - val_loss: 1.9198e-05\n",
      "Epoch 767/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.2647e-05 - val_loss: 1.1472e-05\n",
      "Epoch 768/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.7576e-06 - val_loss: 5.9072e-06\n",
      "Epoch 769/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.8441e-06 - val_loss: 9.2298e-06\n",
      "Epoch 770/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 7.8366e-06 - val_loss: 1.0367e-05\n",
      "Epoch 771/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 7.2148e-06 - val_loss: 1.2451e-05\n",
      "Epoch 772/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.1178e-05 - val_loss: 8.9892e-06\n",
      "Epoch 773/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 5.4432e-06 - val_loss: 3.8149e-05\n",
      "Epoch 774/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.1585e-05 - val_loss: 4.5968e-05\n",
      "Epoch 775/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.5154e-05 - val_loss: 3.4548e-05\n",
      "Epoch 776/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5756e-05 - val_loss: 7.3471e-05\n",
      "Epoch 777/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 5.8122e-05 - val_loss: 4.5845e-05\n",
      "Epoch 778/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 3.5747e-05 - val_loss: 6.0244e-05\n",
      "Epoch 779/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.5281e-05 - val_loss: 8.9834e-06\n",
      "Epoch 780/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.1208e-05 - val_loss: 3.7027e-05\n",
      "Epoch 781/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.3873e-05 - val_loss: 5.3947e-05\n",
      "Epoch 782/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.3589e-05 - val_loss: 5.3286e-05\n",
      "Epoch 783/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.9074e-05 - val_loss: 4.6462e-05\n",
      "Epoch 784/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 8.4273e-05 - val_loss: 4.3514e-05\n",
      "Epoch 785/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 4.4529e-05 - val_loss: 9.3318e-05\n",
      "Epoch 786/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.1710e-04 - val_loss: 5.1932e-05\n",
      "Epoch 787/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.1329e-04 - val_loss: 8.8911e-05\n",
      "Epoch 788/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.1050e-05 - val_loss: 2.7676e-05\n",
      "Epoch 789/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5798e-05 - val_loss: 2.2604e-05\n",
      "Epoch 790/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.0212e-05 - val_loss: 3.2449e-06\n",
      "Epoch 791/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.0605e-05 - val_loss: 1.3355e-05\n",
      "Epoch 792/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.0685e-05 - val_loss: 1.4748e-05\n",
      "Epoch 793/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.5325e-05 - val_loss: 7.6445e-06\n",
      "Epoch 794/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.1405e-05 - val_loss: 6.3508e-06\n",
      "Epoch 795/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 4.8813e-06 - val_loss: 3.7655e-06\n",
      "Epoch 796/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.6249e-06 - val_loss: 2.1516e-06\n",
      "Epoch 797/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.7649e-06 - val_loss: 2.6675e-06\n",
      "Epoch 798/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.4194e-06 - val_loss: 1.9701e-06\n",
      "Epoch 799/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.4293e-06 - val_loss: 1.9647e-06\n",
      "Epoch 800/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.4571e-06 - val_loss: 1.6462e-06\n",
      "Epoch 801/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 2.5974e-06 - val_loss: 2.2332e-06\n",
      "Epoch 802/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 2.2641e-06 - val_loss: 2.0257e-06\n",
      "Epoch 803/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.9733e-06 - val_loss: 2.3038e-06\n",
      "Epoch 804/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 3.9914e-06 - val_loss: 3.1655e-06\n",
      "Epoch 805/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.8321e-06 - val_loss: 1.4235e-06\n",
      "Epoch 806/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.5308e-06 - val_loss: 8.0085e-07\n",
      "Epoch 807/900\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 2.4584e-06 - val_loss: 9.2832e-07\n",
      "Epoch 808/900\n",
      "10/10 [==============================] - 1s 77ms/sample - loss: 5.3604e-06 - val_loss: 7.6149e-07\n",
      "Epoch 809/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.4054e-06 - val_loss: 6.3866e-06\n",
      "Epoch 810/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 5.7742e-06 - val_loss: 4.3798e-06\n",
      "Epoch 811/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 4.9653e-06 - val_loss: 1.2562e-05\n",
      "Epoch 812/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.7229e-05 - val_loss: 6.2246e-06\n",
      "Epoch 813/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 1.7773e-05 - val_loss: 1.1779e-05\n",
      "Epoch 814/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.2222e-05 - val_loss: 2.6220e-05\n",
      "Epoch 815/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 4.1445e-05 - val_loss: 1.9608e-05\n",
      "Epoch 816/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.1152e-05 - val_loss: 1.4454e-05\n",
      "Epoch 817/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.4760e-05 - val_loss: 6.6892e-06\n",
      "Epoch 818/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.3176e-05 - val_loss: 1.2925e-04\n",
      "Epoch 819/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.2468e-04 - val_loss: 4.7325e-05\n",
      "Epoch 820/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 1.3594e-04 - val_loss: 1.1993e-04\n",
      "Epoch 821/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.4090e-04 - val_loss: 2.9352e-05\n",
      "Epoch 822/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 1.4564e-04 - val_loss: 2.7037e-05\n",
      "Epoch 823/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.8281e-05 - val_loss: 3.8487e-05\n",
      "Epoch 824/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 6.7838e-05 - val_loss: 3.6459e-05\n",
      "Epoch 825/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 6.5457e-05 - val_loss: 6.3191e-06\n",
      "Epoch 826/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 3.9763e-05 - val_loss: 1.3460e-05\n",
      "Epoch 827/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 5.6776e-05 - val_loss: 3.7325e-05\n",
      "Epoch 828/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 5.9037e-05 - val_loss: 5.5767e-05\n",
      "Epoch 829/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 6.5780e-05 - val_loss: 4.2113e-05\n",
      "Epoch 830/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.9909e-05 - val_loss: 7.4348e-05\n",
      "Epoch 831/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 6.0382e-05 - val_loss: 6.3411e-05\n",
      "Epoch 832/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 5.5336e-05 - val_loss: 1.7412e-05\n",
      "Epoch 833/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.7254e-05 - val_loss: 1.6435e-05\n",
      "Epoch 834/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.2207e-05 - val_loss: 1.6055e-05\n",
      "Epoch 835/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.0291e-05 - val_loss: 1.0284e-05\n",
      "Epoch 836/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 9.7108e-06 - val_loss: 1.4839e-05\n",
      "Epoch 837/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5779e-05 - val_loss: 1.4579e-05\n",
      "Epoch 838/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 2.6339e-05 - val_loss: 7.8171e-06\n",
      "Epoch 839/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 8.7552e-06 - val_loss: 9.6402e-06\n",
      "Epoch 840/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.7271e-05 - val_loss: 9.7127e-06\n",
      "Epoch 841/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.1163e-06 - val_loss: 6.8967e-06\n",
      "Epoch 842/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 9.3177e-06 - val_loss: 1.2596e-05\n",
      "Epoch 843/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6359e-05 - val_loss: 7.7824e-06\n",
      "Epoch 844/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6144e-05 - val_loss: 2.6075e-06\n",
      "Epoch 845/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.0394e-05 - val_loss: 1.2139e-05\n",
      "Epoch 846/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.6801e-05 - val_loss: 2.2517e-05\n",
      "Epoch 847/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.0057e-05 - val_loss: 7.7364e-05\n",
      "Epoch 848/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 7.3332e-05 - val_loss: 5.9571e-05\n",
      "Epoch 849/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 6.6624e-05 - val_loss: 2.6178e-05\n",
      "Epoch 850/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 6.6714e-05 - val_loss: 2.3296e-05\n",
      "Epoch 851/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.5962e-05 - val_loss: 4.3756e-05\n",
      "Epoch 852/900\n",
      "10/10 [==============================] - 1s 75ms/sample - loss: 3.7440e-05 - val_loss: 5.5863e-05\n",
      "Epoch 853/900\n",
      "10/10 [==============================] - 1s 81ms/sample - loss: 4.4981e-05 - val_loss: 3.3305e-05\n",
      "Epoch 854/900\n",
      "10/10 [==============================] - 1s 76ms/sample - loss: 2.0935e-05 - val_loss: 1.5759e-05\n",
      "Epoch 855/900\n",
      "10/10 [==============================] - 1s 72ms/sample - loss: 2.5474e-05 - val_loss: 1.0930e-05\n",
      "Epoch 856/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3611e-05 - val_loss: 1.2833e-05\n",
      "Epoch 857/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.2995e-05 - val_loss: 9.5447e-06\n",
      "Epoch 858/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 6.4473e-06 - val_loss: 6.0868e-06\n",
      "Epoch 859/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 5.9645e-06 - val_loss: 6.8108e-06\n",
      "Epoch 860/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 71ms/sample - loss: 8.6820e-06 - val_loss: 2.7944e-06\n",
      "Epoch 861/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.7340e-06 - val_loss: 3.8936e-06\n",
      "Epoch 862/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 5.9892e-06 - val_loss: 2.2364e-06\n",
      "Epoch 863/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.9728e-06 - val_loss: 3.3687e-06\n",
      "Epoch 864/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.8678e-06 - val_loss: 3.1220e-06\n",
      "Epoch 865/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 2.9053e-06 - val_loss: 1.9906e-06\n",
      "Epoch 866/900\n",
      "10/10 [==============================] - 1s 67ms/sample - loss: 3.6781e-06 - val_loss: 1.6952e-06\n",
      "Epoch 867/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2850e-06 - val_loss: 3.9315e-06\n",
      "Epoch 868/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.2795e-06 - val_loss: 1.6170e-06\n",
      "Epoch 869/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2948e-06 - val_loss: 9.0467e-07\n",
      "Epoch 870/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 1.2114e-06 - val_loss: 5.7404e-07\n",
      "Epoch 871/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 7.1826e-07 - val_loss: 1.0245e-06\n",
      "Epoch 872/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.3509e-06 - val_loss: 6.1018e-07\n",
      "Epoch 873/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 4.9793e-07 - val_loss: 2.1348e-07\n",
      "Epoch 874/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.1749e-07 - val_loss: 2.8106e-07\n",
      "Epoch 875/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 4.2716e-07 - val_loss: 2.5304e-07\n",
      "Epoch 876/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.1465e-07 - val_loss: 1.7669e-07\n",
      "Epoch 877/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.0074e-07 - val_loss: 2.1505e-07\n",
      "Epoch 878/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5718e-07 - val_loss: 3.3278e-07\n",
      "Epoch 879/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.9746e-07 - val_loss: 1.4974e-07\n",
      "Epoch 880/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.5500e-07 - val_loss: 9.7220e-08\n",
      "Epoch 881/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 7.9240e-08 - val_loss: 3.1810e-08\n",
      "Epoch 882/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 6.5887e-08 - val_loss: 7.4368e-08\n",
      "Epoch 883/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.2896e-07 - val_loss: 4.5284e-08\n",
      "Epoch 884/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 1.4901e-07 - val_loss: 3.6876e-08\n",
      "Epoch 885/900\n",
      "10/10 [==============================] - 1s 73ms/sample - loss: 7.1341e-08 - val_loss: 1.4652e-07\n",
      "Epoch 886/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.6598e-07 - val_loss: 5.8960e-08\n",
      "Epoch 887/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 9.5019e-08 - val_loss: 8.0197e-08\n",
      "Epoch 888/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.3105e-07 - val_loss: 1.1989e-07\n",
      "Epoch 889/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.1161e-07 - val_loss: 8.1631e-08\n",
      "Epoch 890/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 8.3971e-08 - val_loss: 3.1955e-08\n",
      "Epoch 891/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 3.3086e-08 - val_loss: 3.5390e-08\n",
      "Epoch 892/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 3.7017e-08 - val_loss: 5.1308e-08\n",
      "Epoch 893/900\n",
      "10/10 [==============================] - 1s 69ms/sample - loss: 7.4051e-08 - val_loss: 2.3961e-08\n",
      "Epoch 894/900\n",
      "10/10 [==============================] - 1s 68ms/sample - loss: 2.8461e-08 - val_loss: 1.2451e-08\n",
      "Epoch 895/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 2.2416e-08 - val_loss: 1.8543e-08\n",
      "Epoch 896/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.8772e-08 - val_loss: 1.9485e-08\n",
      "Epoch 897/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 2.5405e-08 - val_loss: 1.3082e-08\n",
      "Epoch 898/900\n",
      "10/10 [==============================] - 1s 71ms/sample - loss: 1.4233e-08 - val_loss: 3.2493e-09\n",
      "Epoch 899/900\n",
      "10/10 [==============================] - 1s 74ms/sample - loss: 2.9960e-09 - val_loss: 7.2075e-09\n",
      "Epoch 900/900\n",
      "10/10 [==============================] - 1s 70ms/sample - loss: 1.3863e-08 - val_loss: 6.5835e-09\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.5\n",
      "Probability of sampling a 0: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/900\n",
      "10/10 [==============================] - 9s 931ms/sample - loss: 0.7232 - binary_accuracy: 0.4000 - precision: 0.4444 - recall: 0.8000 - val_loss: 0.6295 - val_binary_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.6247 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.5701 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.5637 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.5005 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4850 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.4236 - val_binary_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4067 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.3399 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.3082 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.1929 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.2051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.1055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0878 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0811 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0553 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0464 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0359 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0340 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0291 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0283 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0228 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0173 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0148 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0124 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0121 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0107 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0103 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9966e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9281e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7411e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4426e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2621e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2054e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0421e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.9851e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7769e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6302e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.5853e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4349e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.3829e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2519e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2021e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0748e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9037e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.8589e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7370e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6948e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5338e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4239e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3872e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.2373e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0947e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9945e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8377e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7343e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.7029e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6128e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5798e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4651e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3824e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.3501e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2733e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2459e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1667e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1396e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0647e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 6.0375e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9670e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.9406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8726e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.8479e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7810e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.7583e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6928e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.6716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6077e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.5861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5256e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.5047e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4458e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4245e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.3498e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2936e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2740e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2215e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2052e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1507e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1344e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0827e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0174e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0007e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9531e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8908e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 101/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8760e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8296e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 102/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7709e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 103/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7546e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7135e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 104/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.6983e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6571e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 105/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.6431e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 106/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.5876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 107/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.5349e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4964e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 108/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.4840e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4452e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 109/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4329e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 110/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 111/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3010e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 112/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.2893e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2545e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 113/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2428e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 114/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1986e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1653e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 115/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1222e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 116/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0803e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 117/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.0695e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0390e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 118/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0277e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9985e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 119/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9873e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 120/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9473e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9187e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 121/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9077e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8797e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 122/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.8700e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 123/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8043e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 124/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7676e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 125/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7585e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7316e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 126/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7222e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6965e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.6880e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6620e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 128/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.6530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6286e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 129/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6206e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 130/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5868e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 131/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5547e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5317e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 132/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5233e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 133/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4918e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4695e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 134/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4613e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4392e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 135/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4310e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 136/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4010e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 137/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3508e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 138/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3220e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 139/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3148e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2940e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 140/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 141/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2586e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 142/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2313e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2126e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 143/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2048e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1859e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 144/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1779e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 145/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1519e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1333e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 146/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1074e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 147/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1011e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0820e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 148/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0758e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0575e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 149/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0512e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0334e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 150/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0274e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0098e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 151/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9865e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 152/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9803e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9637e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 153/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9578e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 154/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9352e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9190e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 155/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9130e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8969e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 156/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8751e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 157/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 158/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8478e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 159/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8258e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 161/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7849e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7692e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 162/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7639e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 163/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 164/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7242e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7090e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 165/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7039e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 166/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6847e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6704e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 167/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6515e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 168/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6471e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 169/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6272e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 170/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6094e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 171/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 172/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5719e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 173/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.5542e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5412e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 174/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 175/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5189e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5055e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 176/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5009e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4881e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 177/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.4838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4710e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 178/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4663e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4541e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 179/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4373e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 180/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.4331e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4207e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 181/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.4161e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4044e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 182/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3883e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 183/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 184/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3679e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3560e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 185/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.3522e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3401e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 186/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3244e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 187/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 188/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.3053e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2942e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 189/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 190/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2756e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2649e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 191/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2611e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2506e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 192/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.2468e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2363e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2330e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2221e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 194/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2185e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2082e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 195/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.2041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1944e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 196/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1805e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 197/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1773e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1668e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 198/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.1633e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 199/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1499e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1402e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 200/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1366e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 201/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1240e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 202/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1011e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 203/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.0976e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0886e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 204/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0854e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 205/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0730e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0638e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 206/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0605e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0516e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 207/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0485e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 208/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0359e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0274e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 209/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0248e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0152e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 210/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0033e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 211/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0000e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9916e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 212/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.9888e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 213/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9766e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9683e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 214/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9654e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 215/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9539e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9456e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 216/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9424e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 217/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9316e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 218/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.9204e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9122e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 219/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.9093e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9012e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 220/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.8982e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8903e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 221/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 222/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.8767e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 223/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.8658e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8581e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 224/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8552e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 225/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8447e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8372e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.8341e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8268e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 227/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 228/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 229/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8035e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 230/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7936e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7860e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 231/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 232/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7735e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 233/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7642e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 234/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7544e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7475e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 235/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7450e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 236/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7357e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 237/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7196e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 238/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7170e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7106e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 239/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7082e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 240/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6989e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6927e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 241/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6902e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 242/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6812e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6749e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 243/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6727e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6661e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 244/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6636e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6574e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 245/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6550e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6488e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 246/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6462e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6403e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 247/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6382e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 248/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6299e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 249/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6215e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 250/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6076e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 251/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6056e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5998e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 252/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5921e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 253/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5901e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5845e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 254/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5825e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5769e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 255/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5748e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 256/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5673e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5619e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 257/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5544e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 258/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5524e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5470e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5453e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5397e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 260/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5379e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 261/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.5306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5254e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 262/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5184e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 263/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5164e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5115e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 264/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5096e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5045e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 265/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5027e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4977e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 266/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4958e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4909e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 267/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4891e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4841e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 268/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4823e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4774e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 269/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4757e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4707e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 270/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4642e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 271/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4625e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4578e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 272/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4560e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4514e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 273/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4450e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 274/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4386e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 275/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 276/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4307e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4260e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 277/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.4243e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4199e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 278/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4183e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4137e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 279/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4120e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4075e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 280/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.4060e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4015e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 281/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 282/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 283/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3881e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 284/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3779e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 285/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3763e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 286/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3663e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 287/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3648e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3605e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 288/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3590e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3549e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 289/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3533e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3493e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 290/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3477e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3437e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 291/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3423e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3367e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 293/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3311e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 294/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3256e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3216e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 295/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3162e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 296/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3149e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 297/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3095e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3056e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 298/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3042e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 299/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2990e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2951e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 300/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2937e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 301/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2885e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2847e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 302/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2833e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2795e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 303/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2782e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 304/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2731e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 305/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2680e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2643e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 306/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 307/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2580e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2543e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 308/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2494e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 309/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2481e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2445e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 310/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2396e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 311/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2383e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2347e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 312/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2299e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 313/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2286e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2251e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 314/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2239e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2204e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 315/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 316/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2144e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 317/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2097e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 318/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2049e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 319/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2004e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1970e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 320/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1957e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1924e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 321/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1912e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1879e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 322/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1833e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 323/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1788e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 324/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1777e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1733e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1699e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 326/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1687e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1655e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 327/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1645e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1612e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 328/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.1600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 329/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1557e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1526e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 330/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1515e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1483e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 331/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1472e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1440e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 332/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1429e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1398e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 333/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1388e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1356e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 334/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 335/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1304e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1273e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 336/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1263e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 337/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1221e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1191e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 338/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1181e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1151e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 339/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1140e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1110e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 340/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1099e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1070e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 341/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1059e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1030e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 342/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1019e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0990e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 343/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0950e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 344/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0940e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0910e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 345/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0900e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0871e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 346/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0832e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 347/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0822e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0793e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 348/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0783e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0754e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 349/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0744e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0716e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 350/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0677e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 351/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0668e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0639e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 352/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0601e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 353/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0592e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0564e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 354/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0554e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0527e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 355/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0517e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0490e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 356/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0480e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0453e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 357/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0443e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0416e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0380e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 359/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0371e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 360/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0308e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 361/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0298e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0272e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 362/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 363/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0227e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0201e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 364/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 365/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0156e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0130e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 366/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 367/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0086e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0060e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 368/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0025e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 369/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0016e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 370/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.9817e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9563e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 371/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9471e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9222e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 372/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9135e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 373/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8544e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 374/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8455e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8209e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 375/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.8119e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7875e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 376/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7788e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 377/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7454e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7212e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 378/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6883e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 379/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6554e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 380/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6464e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6229e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 381/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.6143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5904e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 382/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 383/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5260e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 384/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5176e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 385/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4855e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4622e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 386/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4542e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4305e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 387/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 9.4226e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3992e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 388/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 389/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3603e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 390/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.3291e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3065e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2984e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2760e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 392/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.2677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 393/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2372e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2152e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 394/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.2073e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1848e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 395/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.1769e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1547e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 396/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.1468e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1248e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 397/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0951e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 398/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.0870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0654e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 399/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0575e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0278e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0064e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 401/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9983e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9770e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 402/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.9689e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9476e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 403/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 404/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.9108e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8895e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 405/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 406/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8533e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 407/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8249e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 408/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7959e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7752e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 409/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7471e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 410/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7394e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7190e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 411/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7117e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6910e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 412/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6835e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6633e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 413/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6561e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 414/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6284e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 415/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.6010e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5807e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 416/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5535e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 417/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5463e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5264e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 418/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5192e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4995e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 419/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4922e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 420/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.4655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4461e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 421/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4390e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 422/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3929e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 423/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3859e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.3593e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 425/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 426/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2879e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 427/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2807e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2618e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 428/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2546e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 429/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2293e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2101e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 430/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.2032e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 431/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1591e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 432/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1521e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1337e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 433/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1269e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 434/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.1019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0831e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 435/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 436/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0519e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0335e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 437/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0268e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0090e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 438/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 439/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.9778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 440/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9535e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9353e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9110e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9046e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8867e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.8799e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8626e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 444/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8385e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8146e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8083e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7841e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7607e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.7371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7199e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 450/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.7138e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6965e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 451/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6904e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6732e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 452/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.6674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6501e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6043e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5981e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5816e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5757e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5527e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5302e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4911e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.4852e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.4631e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4466e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.4408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4245e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.4186e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4025e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3966e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3806e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3746e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3370e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3313e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3153e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3095e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2937e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2722e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 471/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.2235e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1657e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1447e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1391e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1239e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1183e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.0772e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0620e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0364e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0161e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0012e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9958e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9811e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9758e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9610e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9410e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9210e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.9155e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.8960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8812e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8419e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.8369e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8223e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8169e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8028e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7641e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7589e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7398e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7257e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7205e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7066e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7015e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6876e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6633e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6496e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6443e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6307e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6118e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.6066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5930e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.5881e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 505/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5694e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5557e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.5507e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5189e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5006e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4957e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4775e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4462e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4414e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4282e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4236e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4055e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3925e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3748e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.3701e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3571e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3523e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3395e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.3348e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3219e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3174e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3044e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2998e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2870e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2697e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2652e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2525e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.2480e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2310e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2139e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2014e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1968e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1845e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1632e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1339e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1172e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1126e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1005e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0837e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0627e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0341e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.0298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0177e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0015e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9853e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 539/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9810e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9692e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9648e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9531e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9488e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9371e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9328e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9211e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9009e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8893e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.8851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8692e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8577e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8420e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8263e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8223e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7952e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7334e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7181e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.7140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7029e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6989e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6877e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6838e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6726e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6685e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6575e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6537e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6425e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6386e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6277e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6237e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6129e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6089e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5944e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.5796e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5503e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5397e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5213e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5069e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4963e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4926e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4819e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4677e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 573/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4640e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4393e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4355e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4214e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4112e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3971e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.3934e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3832e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3656e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3278e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3242e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3103e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2865e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2827e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2691e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2592e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2420e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2151e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2054e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2018e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1920e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1885e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1750e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1655e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1620e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1522e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1391e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1259e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1225e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1128e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1094e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0998e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0834e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0739e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0704e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0611e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0482e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 607/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0064e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9970e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.9937e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9686e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9593e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9560e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9469e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9435e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9345e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9312e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9220e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9187e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8973e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8941e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8851e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8818e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8607e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8574e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8485e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8452e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8331e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7971e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7762e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7731e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7644e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7612e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7494e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7408e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7376e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7290e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7259e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7173e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7026e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6909e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6709e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6679e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6594e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.6564e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6478e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6449e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6250e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6219e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 641/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.5992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5909e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5574e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5544e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5463e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5433e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5352e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5131e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5101e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4993e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4912e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4664e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.4448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4369e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4341e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4261e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4154e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4125e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3913e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3835e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3808e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3702e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3625e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3597e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3520e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3415e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3387e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3311e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3283e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3208e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3180e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3104e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3077e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2973e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2898e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2795e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2590e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2460e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2387e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 675/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2285e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.2157e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2056e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1856e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1783e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1684e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1658e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1559e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1487e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1461e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1389e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1363e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1292e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1267e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1072e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0903e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0808e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0687e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0521e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0426e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0331e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0306e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0237e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0142e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0118e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0023e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9955e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9931e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9862e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.9837e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9769e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9744e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9651e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9558e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9466e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9398e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9373e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9306e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9281e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9191e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 709/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.9098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9006e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8916e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8759e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8669e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8467e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8378e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8290e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8025e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7961e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7939e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7873e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7764e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7700e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7614e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7528e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7442e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7334e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7250e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7102e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7079e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7018e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6995e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6934e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6765e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6743e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6659e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6598e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6515e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6432e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6410e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6349e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6327e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6267e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6245e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6185e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 743/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6163e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6081e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6021e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5999e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5939e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5918e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5858e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5836e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5777e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5755e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5696e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5512e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5454e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5035e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4977e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4821e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4722e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4511e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4491e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4413e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4337e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4281e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4261e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4184e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4127e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4107e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4031e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3975e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3955e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3749e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3728e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3674e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3579e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3524e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 777/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3449e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3430e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3375e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3302e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3282e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3228e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3155e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3082e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3063e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3009e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2990e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2936e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2917e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2864e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2844e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2791e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2700e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2647e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2576e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2433e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2415e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2343e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2291e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2221e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2132e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2080e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2062e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1923e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1871e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1853e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1784e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1733e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1715e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1664e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.1645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1508e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1457e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1388e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1301e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1251e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1183e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1115e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 811/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1029e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0980e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0962e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0913e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0895e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0779e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0761e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0646e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0629e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0514e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0382e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0365e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0317e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0300e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0234e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0057e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0040e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9993e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9928e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9863e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9846e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9799e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9783e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9719e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9545e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9481e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9465e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9418e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9402e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9356e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9339e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9293e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9277e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9231e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9215e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9169e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9152e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.9090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9045e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8983e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8921e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 845/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8905e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8860e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8843e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8798e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8737e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8721e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8660e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8600e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8539e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8494e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8478e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8418e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8314e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8254e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8238e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8195e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8179e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8120e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8076e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8060e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8017e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8001e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7958e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7942e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7840e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7782e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.7767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7724e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7708e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7666e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7550e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7492e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7477e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7377e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7362e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7304e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7262e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7247e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7205e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7148e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7091e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7020e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6978e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6922e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 879/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6907e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6866e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6810e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6754e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6739e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6698e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6683e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6643e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6587e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6573e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6532e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6422e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6367e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6258e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6244e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6096e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6082e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6042e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5988e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5935e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5921e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5867e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5827e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5813e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5774e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5721e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
