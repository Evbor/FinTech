{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RERUN ALL EXPERIREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data's Vocabulary\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Loading Training Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def gen_print_model_stats(model, path):\n",
    "    m = model()\n",
    "    if not os.path.exists(os.path.join(path, model.__name__)):\n",
    "        os.makedirs(os.path.join(path, model.__name__))\n",
    "    fname = os.path.join(path, model.__name__, model.__name__)\n",
    "    tf.keras.utils.plot_model(m, fname + '.png', show_shapes=True, expand_nested=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "8-k_WFC (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "8-k_JPM (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "8-k_BAC (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "8-k_C (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "document_embedder (Model)       (None, 100)          1994300     8-k_WFC[0][0]                    \n",
      "                                                                 8-k_JPM[0][0]                    \n",
      "                                                                 8-k_BAC[0][0]                    \n",
      "                                                                 8-k_C[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_WFC (InputLayer) [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_JPM (InputLayer) [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_BAC (InputLayer) [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_C (InputLayer)   [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 5, 100)       0           document_embedder[1][0]          \n",
      "                                                                 document_embedder[2][0]          \n",
      "                                                                 document_embedder[3][0]          \n",
      "                                                                 document_embedder[4][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 1)         0           adjusted_close_WFC[0][0]         \n",
      "                                                                 adjusted_close_JPM[0][0]         \n",
      "                                                                 adjusted_close_BAC[0][0]         \n",
      "                                                                 adjusted_close_C[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 404)       0           lambda[0][0]                     \n",
      "                                                                 lambda[1][0]                     \n",
      "                                                                 lambda[2][0]                     \n",
      "                                                                 lambda[3][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_1[1][0]                   \n",
      "                                                                 lambda_1[2][0]                   \n",
      "                                                                 lambda_1[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           55936       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_target_WFC (Dens (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,050,269\n",
      "Trainable params: 216,369\n",
      "Non-trainable params: 1,833,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "gen_print_model_stats(model_0, os.path.join('logs', 'models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of Model:\n",
    "![title](logs/models/model_0/model_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talks about model, what loss functione etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Testing if when initialized properly, the model is equivalent to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel in order to fully clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=3000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def baseline_model(output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64)\n",
    "             }\n",
    "    \n",
    "    features = tf.keras.layers.Concatenate()([inputs[fname] for fname in inputs.keys() if '8-k' not in fname])\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, \n",
    "                                         name='adjusted_close_target_WFC')\n",
    "    \n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(features)\n",
    "              }\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='baseline_model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(time_series_lstm)\n",
    "              }\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing baseline equivalence of model when initialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import build_compiled_model\n",
    "\n",
    "def test_baseline_equivalence(model, baseline_model, batch_size, X, y):\n",
    "    '''\n",
    "    Tests baseline equivalence with baseline\n",
    "    '''\n",
    "    \n",
    "    print('Testing if the untrained model when initialized properly is equivalent to the baseline model')\n",
    "    \n",
    "    output_bias_init = {key: y[key].mean() for key in y}\n",
    "    \n",
    "    loss = tf.keras.losses.MeanSquaredError\n",
    "    \n",
    "    hyperparameters_b = {\n",
    "                         'model_parameters': {'output_bias_init': output_bias_init}, \n",
    "                         'training_parameters': {},\n",
    "                         'loss': loss, \n",
    "                         'optimizer': tf.keras.optimizers.Adam, \n",
    "                         'optimizer_parameters': {},\n",
    "                         'version': None\n",
    "                        }\n",
    "    \n",
    "    baseline_m, initial_epoch = build_compiled_model(baseline_model, hyperparameters_b, metrics=[], run_number=None)\n",
    "    baseline_results = baseline_m.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    model_params = {'output_kernel_init': 'zeros', 'output_bias_init': output_bias_init}\n",
    "    \n",
    "    hyperparameters = {\n",
    "                       'model_parameters': model_params, \n",
    "                       'training_parameters': {},\n",
    "                       'loss': loss, \n",
    "                       'optimizer': tf.keras.optimizers.Adam, \n",
    "                       'optimizer_parameters': {}, \n",
    "                       'version': None\n",
    "                      }\n",
    "    \n",
    "    m1, initial_epoch = build_compiled_model(model, hyperparameters, metrics=[], run_number=None)\n",
    "    m1_results = m1.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    assert m1_results == baseline_results\n",
    "    \n",
    "    return print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if the untrained model when initialized properly is equivalent to the baseline model\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "test_baseline_equivalence(model_0, baseline_model, batch_size=4, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Testing if the model trained on real data performs better than the model trained on null data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Null Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def null_feature(feature_name, feature):\n",
    "    if 'adjusted_close' in feature_name:\n",
    "        null_feature = np.zeros(shape=feature.shape, dtype=feature.dtype)\n",
    "    elif '8-k' in feature_name:\n",
    "        null_feature = np.ones(shape=feature.shape, dtype=feature.dtype)\n",
    "    return null_feature\n",
    "\n",
    "def null_features(features):\n",
    "    return {fname: null_feature(fname, features[fname]) for fname in features.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(time_series_lstm)\n",
    "              }\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on null features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 13s 819ms/sample - loss: 23.4841\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 9s 564ms/sample - loss: 21.4231\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import train\n",
    "\n",
    "# Sampling Data and Nulling Features\n",
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "X_null = null_features(X)\n",
    "\n",
    "# Defining Hyperparameters\n",
    "output_bias_init = {key: y[key].mean() for key in y}\n",
    "model_params = {'output_bias_init': output_bias_init}\n",
    "training_params = {'epochs': 2, 'batch_size': 6}\n",
    "\n",
    "hyperparameters = {\n",
    "                   'model_parameters': model_params, \n",
    "                   'training_parameters': training_params,\n",
    "                   'loss': tf.keras.losses.MeanSquaredError,\n",
    "                   'optimizer': tf.keras.optimizers.Adam, \n",
    "                   'optimizer_parameters': {}, \n",
    "                   'version': None\n",
    "                  }\n",
    "\n",
    "# Training Model\n",
    "model, model_history = train(model_0, hyperparameters, metrics=[], run_number=None, X=X_null, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model.evaluate(X, y, batch_size=training_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on zeroed features.\n",
      "\n",
      "Loss for Model: 20.801743984222412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on zeroed features.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(model_results))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(time_series_lstm)\n",
    "              }\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 13s 806ms/sample - loss: 20.9907\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 9s 574ms/sample - loss: 20.4879\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import train\n",
    "\n",
    "# Sampling Data\n",
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "\n",
    "# Defining Hyperparameters\n",
    "output_bias_init = {key: y[key].mean() for key in y}\n",
    "model_params = {'output_bias_init': output_bias_init}\n",
    "training_params = {'epochs': 2, 'batch_size': 6}\n",
    "\n",
    "hyperparameters = {\n",
    "                   'model_parameters': model_params, \n",
    "                   'training_parameters': training_params,\n",
    "                   'loss': tf.keras.losses.MeanSquaredError,\n",
    "                   'optimizer': tf.keras.optimizers.Adam, \n",
    "                   'optimizer_parameters': {}, \n",
    "                   'version': None\n",
    "                  }\n",
    "\n",
    "# Training Model\n",
    "model, model_history = train(model_0, hyperparameters, metrics=[], run_number=None, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model.evaluate(X, y, batch_size=training_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on actual data.\n",
      "\n",
      "Loss for Model: 20.055744647979736\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on actual data.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(model_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out. The model when trained on actual data has a smaller loss than when trained on the null features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Testing if the model can overfit on a small sample of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        #print(list(range(len(true_labels.keys()))))\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    name = ts_fname.split('_')\n",
    "    ticker = name.pop()\n",
    "    name = '_'.join(name)\n",
    "    target = targets['_'.join([name, 'target', ticker])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([name, 'target', ticker]):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history[metric], label='Train')\n",
    "    if 'val_' + metric in history:\n",
    "        ax.plot(history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(time_series_lstm)\n",
    "              }\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtraining model on a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import build_compiled_model\n",
    "\n",
    "def overfit_small_sample(model, batch_size, epochs, X_small, y_small, verbose):\n",
    "    print('Testing if model can overfit on a small sample of data')\n",
    "    \n",
    "    # Defining Model Hyperparameters for Test\n",
    "    output_bias_init = {key: y_small[key].mean() for key in y_small}\n",
    "    model_params = {'output_bias_init': output_bias_init}\n",
    "    training_params = {'epochs': epochs, 'batch_size': batch_size}\n",
    "    hyperparameters = {\n",
    "                       'model_parameters': model_params, \n",
    "                       'training_parameters': training_params,\n",
    "                       'loss': tf.keras.losses.MeanSquaredError, \n",
    "                       'optimizer': tf.keras.optimizers.Adam,\n",
    "                       'optimizer_parameters': {},\n",
    "                       'version': None\n",
    "                      }\n",
    "    \n",
    "    m, initial_epoch = build_compiled_model(model, hyperparameters, metrics=[], run_number=None)\n",
    "    m_pred_untrained = m.predict(X_small, batch_size=batch_size)\n",
    "    m_history = m.fit(X_small, y_small, **training_params, initial_epoch=initial_epoch, verbose=verbose)\n",
    "    m_pred_trained = m.predict(X_small, batch_size=batch_size)\n",
    "    \n",
    "    print()\n",
    "    print('Plotting Error against Sample for Before Training, and After Training on the Small Dataset')\n",
    "    plot_outputs_errors(m_pred_untrained, y_small, 'Before Training')\n",
    "    plot_outputs_errors(m_pred_trained, y_small, 'After Training')\n",
    "    print()\n",
    "    \n",
    "    print('Plotting Each Sample\\'s Time Series')\n",
    "    plot_ts_samples_ba(X_small, y_small, m_pred_untrained, m_pred_trained, 'adjusted_close_WFC')\n",
    "    \n",
    "    metrics = m.metrics_names\n",
    "    for met in metrics:\n",
    "        plot_metric(m_history.history, metric=met)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if model can overfit on a small sample of data\n",
      "Train on 2 samples\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 7s 4s/sample - loss: 21.8624\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 4s 2s/sample - loss: 21.5307\n",
      "Plotting Error against Sample for Before Training, and After Training on the Small Dataset\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYQklEQVR4nO3debhkdX3n8fen2VtQorQKNHSriIK4BFvURxMRiBKi4BjXNKMoTucx6qghISqOg4k4yTiJWVywExWNrYBxScdlFKPIiKI2gsoiisgqSIOyaLsh3/njnCvV13tvV3ffW9X3/t6v56nn1lnqnO/vVN3zqXN+VadSVUiS2rNo3AVIksbDAJCkRhkAktQoA0CSGmUASFKjDABJapQBMA8kOS7JFwaGf5zk/mOu6dAk127B405O8r65qGmhS+fdSX6U5CuzvOw3JLkpyQ2zudzZluTiJIfO9rytMgDGKMnZ/T/zTpvzuKrataqu2Mp1n5bkDVuzjPlgS4NqlmuoJPvNwqIeD/wesLSqDpmF5QGQZF/gBODAqrpvkuV9zdvP4jpmZZlV9ZCqOnu2522VATAmSZYDvwMUcPRYi9G0ZnMnOAuWAVdW1U9mebn7AjdX1Y2zsbAt3Wbb2LZuggEwPs8DzgNOA54/OCHJvZKsTXJbf6j/gEnTf/2Osj+KeNHAtF+fLupPGbw5yY39sr6Z5KAkq4CVwIn96aT/6OffK8mHkqxP8r0k/31gubv0Rw0/SnIJ8KiZGpfkIUnOSvLDJD9I8ppp5ju6P1S/pW/LAQPT/iLJdUluT3JZksP78YuSvCrJd5PcnOTMJPecYtl3Az4J7NW388d9Gw9J8qV+ndcneUuSHSdt35ck+Q7wnX7ck/oabk3ytiSfn7TdX5jk0n77fCrJsn78Of0sX+/X/+wp6rwqySP7+yv79T+kHz4+yUeTHA/8C/DYfjmv76cfk+TC/vn9bpIjp9nOE9vr9iSXJPkv/fgjgLMGttFpwETNt/TjHjtTG6fbZpP8xjL71+q5/Wv0ZuDkJA9I8tn+eb0pyZokuw+s58q+5onTiWcmeW/frouTrNjCeQ9OckE/7YNJzkgDR8hUlbcx3IDLgT8BHgn8ErjPwLTTgTOBuwEHAdcBXxiYXsB+/f2zgRcNTDtuYl7gycD5wO5AgAOAPftppwFvGHjcon7e1wE7AvcHrgCe3E//a+D/AfcE9gEuAq6dpm27AdfTnVbYuR9+dD/tZOB9/f39gZ/QndbYATix3y47Ag8CrgH26uddDjygv/9yuvBcCuwEvAP4wDS1HDq5zn6bPwbYvl/upcArJm3fs/q27gLsAdwGPL1/zMv75+xF/fzH9HUf0E9/LfDFqZ6vaWp8L3BCf3818F3gxQPTXjn5ue2HDwFu7bffImBv4MHTrOOZwF79fM/ut/ueU22jfpsUsP3AuGHa+OttNsX6p1rmccAdwMv6Ze4C7Ne3ZydgCV1w/P3AY64Ejhh4Lf0MOArYDvhfwHmbOy/d6+2q/nndoX+ef8HA/8dCvY29gBZvdOdyfwns0Q9/a+CffLt+2oMH5n8jWxYAhwHfptvZLZpUw2lsHACPBq6eNM+rgXf3968AjhyYtorpA+C5wAXTTDuZuwLgfwBnDkxbRBd2h/Y7ghuBI4AdJi3jUuDwgeE9+222/RTrO3S6OgfmeQXwkUnb97CB4ecBXxoYDl04TQTAJ4HjJ7VjA7Bs8vM1zfqPB9YOtO1FwOn98FXAwZOf2374HcCbt/A1eCFwzFTbiKl31sO08bAZ1jfVMo+b/Jqb4nFPG3wt8Zs79c8MTDsQ+Onmzgv8bv+6y8D0L9BAAHgKaDyeD3y6qm7qh9/PXaeBltC9G7pmYP6rtmQlVfVZ4C3AW4Ebk6xOcvdpZl9Gdxrglokb8BrgPv30vTajpn3o3sVuyl6Dy6mqO/t17F1Vl9PtmE/uaz89yV4DtX5koM5LgV8N1DqjJPsn+ViSG5LcRhewe0yabbCtG7W9uj3EYMfyMuAfBur5IV1I7D1MPcDngd9JsifdG4Azgcel6ye6B93OeirDbmeSPK8/VTRR40H8ZptnMkwbr5nykTPb6DFJ7tM/19f1z837NlHn4KeWNgA7Z/q+hOnm3Qu4rn9ep6xroTIARizJLsCzgCf0O6AbgFcCD0/ycGA93WHxPgMP23eGRf4EWDwwfN/BiVX1j1X1SLp3PPsDfz4xadJyrgG+V1W7D9x2q6qj+unXb0ZN19CdQtqU79PtWICuz6Jfx3V97e+vqsf38xTwNwPL//1Jte5cVddNsY6pLnf7drqjrgdW1d3pgi4zPO56utNNg3UuHZh+DfDHk+rZpaq+uKkN0Lfzcrod0suAc6rqNrqd1Sq6d/x3TvPQa5jUPzSV/lz9PwMvBe5VVbvTncKb3OZflzTNujbVxpkuLTzdtMnj39iPe2j/3Bw7Q52z5Xpg7/55nbDPdDMvJAbA6D2N7t3qgcAj+tsBdOfXn1dVvwI+TNchtjjJgUzqJJ7kQuDp/bz70Z1OACDJo5I8OskOdEHxM2BiZ/IDNt5JfwW4PV3H6y5JtkvXYTzR2Xsm8Ookv5VkKd3OajofA/ZM8ookOyXZLcmjp5jvTOAPkhze13gC8HPgi0kelOSwdB+R/Rnw04HaTwVOyV0drUuSHDNNLT8A7pXkHgPjdqM7p//jJA8GXjxDWwA+Djw0ydP6d4wvYeOgPZVu20x03N4jyTMn1bCpQPw83Q768/3w2ZOGp/JO4AX99luUZO++PZPdjW6nur6v7wV0RwDTWU+3rQdr3lQbN2WqZU5lN+DHwK1J9uauNyxz6Ut0/5MvTbJ9/1qatY/ZbssMgNF7Pt159aur6oaJG92pmpX9DualwK507wJPA949w/LeTNdh9QPgPcCagWl3p3vn9yO6Uy03A2/qp70TOLA/pP9oHzxPoQuk7wE30X3qZGLH+fp+Gd8DPg3863QFVdXtdB15T+3b8B3giVPMdxndO7x/6tf3VOCpVfULuk7Av+7H3wDcm65PAuAfgLXAp5PcTtchPFXAUFXfAj4AXNG3dS/gz4A/Am7vt88Z07WlX8ZNdJ2o/5tuGx4IrKMLK6rqI3RHJ6f3py0uAn5/YBEnA+/p1/+saVbzebqd3znTDE9V11eAF9C9Bm7tH7NsivkuAf6Wbkf3A+ChwLkzLHcDcApwbl/zY4Zo44ymWuY0s74eOLhvz8fp3gzNqf719nS6N0+30L0mP0b//C5k2fi0l7Z1SRbRvVtZVlVXj7ueFvXPwbXAyqr63Ljr0exL8mXg1Kqa6c3XvOcRwPxzEN0pkW36K/sLTZInJ9m9PyU10Wdw3pjL0ixJ8oQk9+1PAT0feBjwf8dd11zzm3fzSJI/pPuc+F/0h60ancfSfVprR+AS4GlV9dPxlqRZ9CDu+u7NFcAzqur68ZY09zwFJEmN8hSQJDVqXp0C2mOPPWr58uXjLkOS5pXzzz//pqpaMnn8vAqA5cuXs27dunGXIUnzSpIpv7nvKSBJapQBIEmNMgAkqVEGgCQ1ygCQpEYt+ABYswaWL4dFi7q/a9Zs6hGS1IZ59THQzbVmDaxaBRs2dMNXXdUNA6xcOb66JGlbsKCPAE466a6d/4QNG7rxktS6BR0AV09zseTpxktSSxZ0AOw7zY8WTjdeklqyoAPglFNg8eKNxy1e3I2XpNYt6ABYuRJWr4ZlyyDp/q5ebQewJMEC/xQQdDt7d/iS9JsW9BGAJGl6BoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJatTYAyDJdkkuSPKxcdciSS0ZewAALwcuHXcRktSasQZAkqXAHwD/Ms46JKlF4z4C+HvgRODO6WZIsirJuiTr1q9fP7rKJGmBG1sAJHkKcGNVnT/TfFW1uqpWVNWKJUuWjKg6SVr4xnkE8Djg6CRXAqcDhyV53xjrkaSmjC0AqurVVbW0qpYDzwE+W1XHjqseSWrNuPsAJEljsv24CwCoqrOBs8dchiQ1xSMASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0aWwAk2SfJ55JckuTiJC8fVy2S1KLtx7juO4ATquprSXYDzk9yVlVdMsaaJKkZYzsCqKrrq+pr/f3bgUuBvcdVjyS1ZpvoA0iyHPht4MtTTFuVZF2SdevXrx91aZK0YI09AJLsCnwIeEVV3TZ5elWtrqoVVbViyZIloy9QkhaosQZAkh3odv5rqurD46xFklozzk8BBXgncGlV/d246pCkVo3zCOBxwH8FDktyYX87aoz1SFJTxvYx0Kr6ApBxrV+SWjf2TmBJ0ngYAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRm0yAJJsl+T/jKIYSdLobDIAqupXwONHUIskaYSG/U3gC5KsBT4I/GRiZFV9eE6qkiTNuWEDYGfgZuCwgXEFGACSNE8NFQBV9YK5LkSSNFpDfQooydIkH0lyY3/7UJKlc12cJGnuDPsx0HcDa4G9+tt/9OMkSfPUsAGwpKreXVV39LfTgCVzWJckaY4NGwA3Jzm2/07AdkmOpesUliTNU8MGwAuBZwE3ANcDzwDsGJakeWyTnwJKsh3w9Ko6egT1SJJGZNhvAj93BLVIkkZo2C+CnZvkLcAZbPxN4K/NSVWSpDk3bAA8ov/7lwPjio2/GSxJmkeG6QNYBLy9qs4cQT2SpBEZpg/gTuDEEdQiSRqhYT8G+pkkf5ZknyT3nLht7cqTHJnksiSXJ3nV1i5PkjS8YfsAnt3/fcnAuALuv6Ur7j9e+lbg94Brga8mWVtVl2zpMiVJwxv2aqD3m4N1HwJcXlVXACQ5HTgGMAAkaQRmPAWU5MSB+8+cNO2NW7nuvYFrBoav7cdJkkZgU30Azxm4/+pJ046c5VqmlGRVknVJ1q1fv34Uq5SkJmwqADLN/amGN9d1wD4Dw0v7cRupqtVVtaKqVixZ4gVIJWm2bCoAapr7Uw1vrq8CD0xyvyQ70h1trN3KZUqShrSpTuCHJ7mN7t3+Lv19+uGdt2bFVXVHkpcCnwK2A95VVRdvzTIlScObMQCqaru5XHlVfQL4xFyuQ5I0tWG/CCZJWmAMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJatRYAiDJm5J8K8k3knwkye7jqEOSWjauI4CzgIOq6mHAt4FXj6kOSWrWWAKgqj5dVXf0g+cBS8dRhyS1bFvoA3gh8MlxFyFJrdl+rhac5DPAfaeYdFJV/Xs/z0nAHcCaGZazClgFsO+++85BpZLUpjkLgKo6YqbpSY4DngIcXlU1w3JWA6sBVqxYMe18kqTNM2cBMJMkRwInAk+oqg3jqEGSWjeuPoC3ALsBZyW5MMmpY6pDkpo1liOAqtpvHOuVJN1lW/gUkCRpDAwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElq1FgDIMkJSSrJHuOsQ5JaNLYASLIP8CTg6nHVIEktG+cRwJuBE4EaYw2S1KyxBECSY4Drqurr41i/JGkOAyDJZ5JcNMXtGOA1wOuGXM6qJOuSrFu/fv1clStJ26Q1a2D5cli0qPu7Zs3sLTtVoz0Dk+ShwH8CG/pRS4HvA4dU1Q0zPXbFihW1bt26Oa5QkrYNa9bAqlWwYcNd4xYvhtWrYeXK4ZeT5PyqWjF5/MhPAVXVN6vq3lW1vKqWA9cCB29q5y9JrTnppI13/tANn3TS7Czf7wFI0jbq6mk+Iznd+M019gDojwRuGncdkrSt2XffzRu/ucYeAJKkqZ1ySnfOf9Dixd342WAASNI2auXKrsN32TJIur+b2wE8k+1nZzGSpLmwcuXs7fAn8whAkhplAEhSowwASWqUASBJjTIAJKlRI78W0NZIsh64agsfvgfQ2hfObHMbbHMbtqbNy6pqyeSR8yoAtkaSdVNdDGkhs81tsM1tmIs2ewpIkhplAEhSo1oKgNXjLmAMbHMbbHMbZr3NzfQBSJI21tIRgCRpgAEgSY1acAGQ5MgklyW5PMmrppi+U5Iz+ulfTrJ89FXOriHa/KdJLknyjST/mWTZOOqcTZtq88B8f5ikkszrjwwO094kz+qf54uTvH/UNc62IV7X+yb5XJIL+tf2UeOoczYleVeSG5NcNM30JPnHfpt8I8nBW7XCqlowN2A74LvA/YEdga8DB06a50+AU/v7zwHOGHfdI2jzE4HF/f0Xt9Dmfr7dgHOA84AV4657jp/jBwIXAL/VD9973HWPoM2rgRf39w8Erhx33bPQ7t8FDgYummb6UcAngQCPAb68NetbaEcAhwCXV9UVVfUL4HTgmEnzHAO8p7//b8DhSTLCGmfbJttcVZ+rqomflj4PWDriGmfbMM8zwF8BfwP8bJTFzYFh2vvfgLdW1Y8AqurGEdc424ZpcwF37+/fA/j+COubE1V1DvDDGWY5Bnhvdc4Ddk+y55aub6EFwN7ANQPD1/bjppynqu4AbgXuNZLq5sYwbR50PN07iPlsk23uD433qaqPj7KwOTLMc7w/sH+Sc5Ocl+TIkVU3N4Zp88nAsUmuBT4BvGw0pY3V5v6/z8hfBGtIkmOBFcATxl3LXEqyCPg74LgxlzJK29OdBjqU7gjvnCQPrapbxlrV3HoucFpV/W2SxwL/muSgqrpz3IXNFwvtCOA6YJ+B4aX9uCnnSbI93aHjzSOpbm4M02aSHAGcBBxdVT8fUW1zZVNt3g04CDg7yZV050rXzuOO4GGe42uBtVX1y6r6HvBtukCYr4Zp8/HAmQBV9SVgZ7oLpi1kQ/2/D2uhBcBXgQcmuV+SHek6eddOmmct8Pz+/jOAz1bfuzJPbbLNSX4beAfdzn++nxuGTbS5qm6tqj2qanlVLafr9zi6qtaNp9ytNszr+qN07/5JsgfdKaErRlnkLBumzVcDhwMkOYAuANaPtMrRWws8r/800GOAW6vq+i1d2II6BVRVdyR5KfApuk8RvKuqLk7yl8C6qloLvJPuUPFyus6W54yv4q03ZJvfBOwKfLDv7766qo4eW9Fbacg2LxhDtvdTwJOSXAL8Cvjzqpq3R7ZDtvkE4J+TvJKuQ/i4ef5mjiQfoAvyPfq+jf8J7ABQVafS9XUcBVwObABesFXrm+fbS5K0hRbaKSBJ0pAMAElqlAEgSY0yACSpUQaAJDXKAFDzkpzUX0HzG0kuTPLoOVzX2fP4C2laYBbU9wCkzdVfQuApwMFV9fP+S1Q7jrksaSQ8AlDr9gRumrg8RlXdVFXfT/K6JF9NclGS1RNXjO3fwb85yboklyZ5VJIPJ/lOkjf08yxP8q0ka/p5/i3J4skrTvKkJF9K8rUkH0yy60hbruYZAGrdp4F9knw7yduSTFwo7y1V9aiqOgjYhe4oYcIvqmoFcCrw78BL6K49dFySiSvLPgh4W1UdANxG9zsUv9YfabwWOKKqDgbWAX86N02UpmYAqGlV9WPgkcAquuvInJHkOOCJ6X4x7pvAYcBDBh42camJbwIXV9X1/RHEFdx1oa5rqurc/v77gMdPWvVj6H7E5NwkF9Jdn2re/1Kb5hf7ANS8qvoVcDbd1UO/Cfwx8DC6XxG7JsnJdBcamzBxNdU7B+5PDE/8T02+xsrk4QBnVdVzt7oB0hbyCEBNS/KgJIOXTX4EcFl//6b+vPwztmDR+/YdzAB/BHxh0vTzgMcl2a+v425J9t+C9UhbzCMAtW5X4J+S7A7cQXeVxVXALcBFwA10lybeXJcBL0nyLuAS4O2DE6tqfX+q6QNJdupHv5buOv7SSHg1UGmWJVkOfKzvQJa2WZ4CkqRGeQQgSY3yCECSGmUASFKjDABJapQBIEmNMgAkqVH/H+xcWwQ03xAzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting Each Sample's Time Series\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Target Value: 25.3963\n",
      "Predicted Target Value Before Training: 20.42641258239746\n",
      "Predicted Target Value After Training: 20.351648330688477\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Target Value: 16.0382\n",
      "Predicted Target Value Before Training: 20.30572509765625\n",
      "Predicted Target Value After Training: 20.192684173583984\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_small, y_small = sample_dataset(train_dataset, sample_size=2, seed=seed)\n",
    "\n",
    "del y_small['adjusted_close_target_JPM']\n",
    "del y_small['adjusted_close_target_BAC']\n",
    "del y_small['adjusted_close_target_C']\n",
    "\n",
    "overfit_small_sample(model_0, batch_size=1, epochs=2, X_small=X_small, y_small=y_small, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots its clear that our model has overfit on our small sample of the dataset which is the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history[metric], label='Train')\n",
    "    if 'val_' + metric in history:\n",
    "        ax.plot(history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None\n",
    "\n",
    "def plot_print_complete_metrics(model_name, model_version, run_number, metrics_train, metrics_val, metrics_names):\n",
    "    csvlog = os.path.join('logs', 'models', model_name, '_'.join(['version', str(model_version)]), 'runs', str(run_number), 'history.log')\n",
    "    df = pd.read_csv(csvfile).drop_duplicates(subset='epoch', keep='last').set_index('epoch')\n",
    "    plot_print_metrics(df, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=metrics_names)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(time_series_lstm)\n",
    "              }\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting both are training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names and shapes for Training Data:\n",
      "adjusted_close_WFC: (5,)\n",
      "8-k_WFC: (1562,)\n",
      "adjusted_close_JPM: (5,)\n",
      "8-k_JPM: (90363,)\n",
      "adjusted_close_BAC: (5,)\n",
      "8-k_BAC: (15826,)\n",
      "adjusted_close_C: (5,)\n",
      "8-k_C: (53958,)\n",
      "\n",
      "Feature names and shapes for Validation Data:\n",
      "adjusted_close_WFC: (5,)\n",
      "8-k_WFC: (1364,)\n",
      "adjusted_close_JPM: (5,)\n",
      "8-k_JPM: (1706,)\n",
      "adjusted_close_BAC: (5,)\n",
      "8-k_BAC: (2026,)\n",
      "adjusted_close_C: (5,)\n",
      "8-k_C: (2636,)\n",
      "\n",
      "Train set size: 3014\n",
      "Validation set size: 1001\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_dataset\n",
    "X_val, y_val = val_dataset\n",
    "\n",
    "print('Feature names and shapes for Training Data:')\n",
    "for key in X_train:\n",
    "    print('{}: {}'.format(key, X_train[key].shape[1:]))\n",
    "print()\n",
    "print('Feature names and shapes for Validation Data:')\n",
    "for key in X_val:\n",
    "    print('{}: {}'.format(key, X_val[key].shape[1:]))\n",
    "print()\n",
    "print('Train set size: {}'.format(len(y_train['adjusted_close_target_WFC'])))\n",
    "print('Validation set size: {}'.format(len(y_val['adjusted_close_target_WFC'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Defining Hyperparameters\n",
    "output_bias_init = {key: y_train[key].mean() for key in y_train}\n",
    "model_params = {\n",
    "                'output_bias_init': output_bias_init, \n",
    "                'lstm_layer_units': 32\n",
    "               }\n",
    "training_params = {\n",
    "                   'batch_size': 6, \n",
    "                   'epochs': 2\n",
    "                  }\n",
    "loss = tf.keras.losses.MeanSquaredError\n",
    "optimizer = tf.keras.optimizers.Adam\n",
    "optimizer_params = {}\n",
    "\n",
    "model_version = 0\n",
    "hyperparameters = {\n",
    "                   'model_parameters': model_params,\n",
    "                   'training_parameters': training_params,\n",
    "                   'loss': loss, \n",
    "                   'optimizer': optimizer, \n",
    "                   'optimizer_parameters': optimizer_params, \n",
    "                   'version': model_version\n",
    "                  }\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from: logs/models/model_0/version_0/runs/0/checkpoints/cp-1.ckpt\n",
      "Saved hyperparameters to file: logs/models/model_0/version_0\n",
      "Train on 3014 samples, validate on 1001 samples\n",
      "Epoch 1/2\n",
      "  48/3014 [..............................] - ETA: 29:11 - loss: 4.6273\n",
      "Epoch 00001: saving model to logs/models/model_0/version_0/runs/0/checkpoints/cp-1.ckpt\n",
      "  48/3014 [..............................] - ETA: 29:15 - loss: 4.6273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0fa8d0304217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstockanalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/stockanalysis/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(build_model, hparams, metrics, run_number, X, y, validation_data, write_hyperparameters, checkpoint, log)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Training Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtraining_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stockanalysis.train import train\n",
    "\n",
    "model, model_history = train(model_0, hyperparameters, metrics, run_number, X_train, y_train, (X_val, y_val), True, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_params['batch_size'], verbose=0)\n",
    "metrics_val = model.evaluate(X_val, y_val, batch_size=training_params['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_params['batch_size'])\n",
    "m_preds_val = model.predict(X_val, batch_size=training_params['batch_size'])\n",
    "m_preds_up_train = ((m_preds_train[1:, 0] - y_train['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "m_preds_up_val = ((m_preds_val[1:, 0] - y_val['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "labels_up_train = ((y_train['adjusted_close_target_WFC'][1:] - y_train['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "labels_up_val = ((y_val['adjusted_close_target_WFC'][1:] - y_val['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_val = np.mean(np.equal(m_preds_up_val, labels_up_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 1.8115987953122437\n",
      "Loss on validation dataset: 214.70029630479993\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.9193494855625622\n",
      "Accuracy on validation dataset: 0.578\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(model_history.history, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Learning Curves for Metrics: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 1.8115987953122437\n",
      "Loss on validation dataset: 214.70029630479993\n"
     ]
    }
   ],
   "source": [
    "print('Complete Learning Curves for Metrics: ')\n",
    "plot_print_complete_metrics('model_0', model_version, run_number, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=model.metrics_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
