{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we train and evaluate our previous deep learning model for the Wells Fargo stock price time series, except with modifications made to include the 8-K form time series for each of the 4 banks as input features as well. Similarly, the notebook can be broken up into 3 different parts: Model Architecture, Unit Testing Model, and Model Evaluation, with each part performing the same function as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisiting the main goal of this project, suggests that the loss function for our modified model should be mean squared error as well, since our goals have not changed. In the code below we define and print a graph of our modified model architecture as well as justify the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data's Vocabulary\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Loading Training Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_train_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def gen_print_model_stats(model, path):\n",
    "    m = model()\n",
    "    if not os.path.exists(os.path.join(path, model.__name__)):\n",
    "        os.makedirs(os.path.join(path, model.__name__))\n",
    "    fname = os.path.join(path, model.__name__, model.__name__)\n",
    "    tf.keras.utils.plot_model(m, fname + '.png', show_shapes=True, expand_nested=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            config_path = os.expanduser(os.path.join('~', '.stockanalysis', 'config.json'))\n",
    "            with open(config_path, 'r') as f:\n",
    "                configuration = json.load(f)\n",
    "            glove_vec_file = os.path.expanduser(configuration['Model_Resources']['glove'])\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(glove_vec_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_text(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "               output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_text')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_text\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "8-k_WFC (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "8-k_JPM (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "8-k_BAC (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "8-k_C (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "document_embedder (Model)       (None, 100)          1994300     8-k_WFC[0][0]                    \n",
      "                                                                 8-k_JPM[0][0]                    \n",
      "                                                                 8-k_BAC[0][0]                    \n",
      "                                                                 8-k_C[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_WFC (InputLayer) [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_JPM (InputLayer) [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_BAC (InputLayer) [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_C (InputLayer)   [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 5, 100)       0           document_embedder[1][0]          \n",
      "                                                                 document_embedder[2][0]          \n",
      "                                                                 document_embedder[3][0]          \n",
      "                                                                 document_embedder[4][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 1)         0           adjusted_close_WFC[0][0]         \n",
      "                                                                 adjusted_close_JPM[0][0]         \n",
      "                                                                 adjusted_close_BAC[0][0]         \n",
      "                                                                 adjusted_close_C[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 404)       0           lambda[0][0]                     \n",
      "                                                                 lambda[1][0]                     \n",
      "                                                                 lambda[2][0]                     \n",
      "                                                                 lambda[3][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_1[1][0]                   \n",
      "                                                                 lambda_1[2][0]                   \n",
      "                                                                 lambda_1[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           55936       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "adjusted_close_target_WFC (Dens (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,050,269\n",
      "Trainable params: 216,369\n",
      "Non-trainable params: 1,833,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "gen_print_model_stats(model_text, os.path.join('logs', 'models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of Model:\n",
    "\n",
    "<a title=\"Model Graph\" href=\"logs/models/model_text/model_text.png\"><img width=\"5000\" src=\"logs/models/model_text/model_text.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph is a visual depiction of our chosen model architecture. It shows that the input features to our model have been decided to be the lagged 5 days stock prices for each of the stock tickers: WFC, JPM, BAC, and C. Again, this decision was made because these 4 banks are all major competitors with each other, and thus their stock prices should have some correlations baked into their time series. The core of our model architecture is the LSTM (long-short term memory) layer that we feed the stock price time series too. LSTM layers are a type of RNN (recurrent neural network) layer. RNNs are good a learning sequential dependences between data because the network contains inbuilt feedback between its inputs and outputs. This makes RNNs a natural choice when modeling stock price time series because the sequence in which prices occur in time is important to the problem of price prediction. LSTMs are an RNN layer that is specifically designed to learn long-term dependences easier than vanilla RNNs and avoid the vanishing gradient problem. Its because of these reasons that we chose to use an LSTM layer as the core of our time series model. \n",
    "\n",
    "(WEAERRAERA EDFADSSFADF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the Unit Testing Model section in the previous notebook, we plan on running our new model through the same 3 tests before moving to the training and evaluation stage. The first test examines if our model can be initialized to be equivalent to the baseline model. The second, tests whether our dataset can be used to train models on. And the third, tests whether our model can overtrain on a small sample set of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Testing if when initialized properly, the model is equivalent to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel in order to fully clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=3000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_train_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def baseline_model(output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64)\n",
    "             }\n",
    "    \n",
    "    features = tf.keras.layers.Concatenate()([inputs[fname] for fname in inputs.keys() if '8-k' not in fname])\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, \n",
    "                                         name='adjusted_close_target_WFC')\n",
    "    \n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_layer(features)\n",
    "              }\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='baseline_model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            config_path = os.expanduser(os.path.join('~', '.stockanalysis', 'config.json'))\n",
    "            with open(config_path, 'r') as f:\n",
    "                configuration = json.load(f)\n",
    "            glove_vec_file = os.path.expanduser(configuration['Model_Resources']['glove'])\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(glove_vec_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_text(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "               output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_text')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing baseline equivalence of model when initialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import build_compiled_model\n",
    "\n",
    "def test_baseline_equivalence(model, baseline_model, batch_size, X, y):\n",
    "    '''\n",
    "    Tests baseline equivalence with baseline\n",
    "    '''\n",
    "    \n",
    "    print('Testing if the untrained model when initialized properly is equivalent to the baseline model')\n",
    "    \n",
    "    output_bias_init = {key: y[key].mean() for key in y}\n",
    "    \n",
    "    loss = tf.keras.losses.MeanSquaredError\n",
    "    \n",
    "    hyperparameters_b = {\n",
    "                         'model_parameters': {'output_bias_init': output_bias_init}, \n",
    "                         'training_parameters': {},\n",
    "                         'loss': loss, \n",
    "                         'optimizer': tf.keras.optimizers.Adam, \n",
    "                         'optimizer_parameters': {},\n",
    "                         'version': None\n",
    "                        }\n",
    "    \n",
    "    baseline_m, initial_epoch = build_compiled_model(baseline_model, hyperparameters_b, metrics=[], run_number=None)\n",
    "    baseline_results = baseline_m.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    model_params = {'output_kernel_init': 'zeros', 'output_bias_init': output_bias_init}\n",
    "    \n",
    "    hyperparameters = {\n",
    "                       'model_parameters': model_params, \n",
    "                       'training_parameters': {},\n",
    "                       'loss': loss, \n",
    "                       'optimizer': tf.keras.optimizers.Adam, \n",
    "                       'optimizer_parameters': {}, \n",
    "                       'version': None\n",
    "                      }\n",
    "    \n",
    "    m1, initial_epoch = build_compiled_model(model, hyperparameters, metrics=[], run_number=None)\n",
    "    m1_results = m1.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    assert m1_results == baseline_results\n",
    "    \n",
    "    return print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if the untrained model when initialized properly is equivalent to the baseline model\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "test_baseline_equivalence(model_text, baseline_model, batch_size=4, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing if the model trained on real data performs better than the model trained on null data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Null Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_train_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def null_feature(feature_name, feature):\n",
    "    if 'adjusted_close' in feature_name:\n",
    "        null_feature = np.zeros(shape=feature.shape, dtype=feature.dtype)\n",
    "    elif '8-k' in feature_name:\n",
    "        null_feature = np.ones(shape=feature.shape, dtype=feature.dtype)\n",
    "    return null_feature\n",
    "\n",
    "def null_features(features):\n",
    "    return {fname: null_feature(fname, features[fname]) for fname in features.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            config_path = os.expanduser(os.path.join('~', '.stockanalysis', 'config.json'))\n",
    "            with open(config_path, 'r') as f:\n",
    "                configuration = json.load(f)\n",
    "            glove_vec_file = os.path.expanduser(configuration['Model_Resources']['glove'])\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(glove_vec_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_text(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "               output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_text')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on null features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 21s 1s/sample - loss: 23.4841\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 19s 1s/sample - loss: 21.4231\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 19s 1s/sample - loss: 21.8424\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 18s 1s/sample - loss: 21.8074\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 23s 1s/sample - loss: 21.6725\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 23s 1s/sample - loss: 21.4724\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 29s 2s/sample - loss: 21.6153\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 26s 2s/sample - loss: 21.4916\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 23s 1s/sample - loss: 21.4825\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 24s 1s/sample - loss: 21.4765\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 9s 557ms/sample - loss: 21.4920\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 9s 569ms/sample - loss: 21.5273\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 9s 575ms/sample - loss: 21.4525\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 9s 578ms/sample - loss: 21.5833\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 9s 575ms/sample - loss: 21.4360\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 9s 573ms/sample - loss: 21.5206\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 9s 571ms/sample - loss: 21.4324\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 9s 582ms/sample - loss: 21.4890\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 9s 573ms/sample - loss: 21.4359\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 10s 596ms/sample - loss: 21.4924\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 9s 585ms/sample - loss: 21.4577\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 9s 573ms/sample - loss: 21.4474\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 9s 577ms/sample - loss: 21.4641\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 9s 579ms/sample - loss: 21.4772\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 9s 584ms/sample - loss: 21.4361\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 9s 591ms/sample - loss: 21.4912\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 9s 590ms/sample - loss: 21.5206\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 10s 594ms/sample - loss: 21.4311\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 9s 571ms/sample - loss: 21.4349\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 9s 572ms/sample - loss: 21.4749\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import train\n",
    "\n",
    "# Sampling Data and Nulling Features\n",
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "X_null = null_features(X)\n",
    "\n",
    "# Defining Hyperparameters\n",
    "output_bias_init = {key: y[key].mean() for key in y}\n",
    "model_params = {'output_bias_init': output_bias_init}\n",
    "training_params = {'epochs': 30, 'batch_size': 6}\n",
    "\n",
    "hyperparameters = {\n",
    "                   'model_parameters': model_params, \n",
    "                   'training_parameters': training_params,\n",
    "                   'loss': tf.keras.losses.MeanSquaredError,\n",
    "                   'optimizer': tf.keras.optimizers.Adam, \n",
    "                   'optimizer_parameters': {}, \n",
    "                   'version': None\n",
    "                  }\n",
    "\n",
    "# Training Model\n",
    "model, model_history = train(model_text, hyperparameters, metrics=[], run_number=None, X=X_null, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model.evaluate(X, y, batch_size=training_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on zeroed features.\n",
      "\n",
      "Loss for Model: 20.817207098007202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on zeroed features.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(model_results))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_train_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            config_path = os.expanduser(os.path.join('~', '.stockanalysis', 'config.json'))\n",
    "            with open(config_path, 'r') as f:\n",
    "                configuration = json.load(f)\n",
    "            glove_vec_file = os.path.expanduser(configuration['Model_Resources']['glove'])\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(glove_vec_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_text(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "               output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_text')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 13s 828ms/sample - loss: 20.9907\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 9s 555ms/sample - loss: 20.4879\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 9s 552ms/sample - loss: 19.8153\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 9s 568ms/sample - loss: 18.8336\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 9s 563ms/sample - loss: 18.3563\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 9s 583ms/sample - loss: 18.5154\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 9s 577ms/sample - loss: 18.3728\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 9s 568ms/sample - loss: 17.9085\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 9s 579ms/sample - loss: 17.6864\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 9s 564ms/sample - loss: 17.3243\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 9s 585ms/sample - loss: 16.9998\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 9s 577ms/sample - loss: 19.1911\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 9s 588ms/sample - loss: 16.3993\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 9s 586ms/sample - loss: 16.9380\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 9s 573ms/sample - loss: 16.4628\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 9s 575ms/sample - loss: 15.9952\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 9s 587ms/sample - loss: 15.2267\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 9s 584ms/sample - loss: 15.2734\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 9s 568ms/sample - loss: 14.3751\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 9s 556ms/sample - loss: 13.8810\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 9s 585ms/sample - loss: 13.4968\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 9s 575ms/sample - loss: 13.0490\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 9s 572ms/sample - loss: 12.8115\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 9s 587ms/sample - loss: 11.9470\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 9s 572ms/sample - loss: 11.7125\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 9s 578ms/sample - loss: 11.4071\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 9s 577ms/sample - loss: 11.2059\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 9s 582ms/sample - loss: 10.3259\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 9s 580ms/sample - loss: 9.7752\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 9s 580ms/sample - loss: 9.5157\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import train\n",
    "\n",
    "# Sampling Data\n",
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "\n",
    "# Defining Hyperparameters\n",
    "output_bias_init = {key: y[key].mean() for key in y}\n",
    "model_params = {'output_bias_init': output_bias_init}\n",
    "training_params = {'epochs': 30, 'batch_size': 6}\n",
    "\n",
    "hyperparameters = {\n",
    "                   'model_parameters': model_params, \n",
    "                   'training_parameters': training_params,\n",
    "                   'loss': tf.keras.losses.MeanSquaredError,\n",
    "                   'optimizer': tf.keras.optimizers.Adam, \n",
    "                   'optimizer_parameters': {}, \n",
    "                   'version': None\n",
    "                  }\n",
    "\n",
    "# Training Model\n",
    "model, model_history = train(model_text, hyperparameters, metrics=[], run_number=None, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model.evaluate(X, y, batch_size=training_params['batch_size'], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on actual data.\n",
      "\n",
      "Loss for Model: 9.051951050758362\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on actual data.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(model_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out. The model when trained on actual data has a smaller loss than when trained on the null features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testing if the model can overfit on a small sample of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_train_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        #print(list(range(len(true_labels.keys()))))\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    name = ts_fname.split('_')\n",
    "    ticker = name.pop()\n",
    "    name = '_'.join(name)\n",
    "    target = targets['_'.join([name, 'target', ticker])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([name, 'target', ticker]):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history[metric], label='Train')\n",
    "    if 'val_' + metric in history:\n",
    "        ax.plot(history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            config_path = os.expanduser(os.path.join('~', '.stockanalysis', 'config.json'))\n",
    "            with open(config_path, 'r') as f:\n",
    "                configuration = json.load(f)\n",
    "            glove_vec_file = os.path.expanduser(configuration['Model_Resources']['glove'])\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(glove_vec_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_text(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "               output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_text')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtraining model on a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from stockanalysis.train import build_compiled_model\n",
    "\n",
    "def overfit_small_sample(model, batch_size, epochs, X_small, y_small, verbose):\n",
    "    print('Testing if model can overfit on a small sample of data')\n",
    "    \n",
    "    # Defining Model Hyperparameters for Test\n",
    "    output_bias_init = {key: y_small[key].mean() for key in y_small}\n",
    "    model_params = {'output_bias_init': output_bias_init}\n",
    "    training_params = {'epochs': epochs, 'batch_size': batch_size}\n",
    "    hyperparameters = {\n",
    "                       'model_parameters': model_params, \n",
    "                       'training_parameters': training_params,\n",
    "                       'loss': tf.keras.losses.MeanSquaredError, \n",
    "                       'optimizer': tf.keras.optimizers.Adam,\n",
    "                       'optimizer_parameters': {},\n",
    "                       'version': None\n",
    "                      }\n",
    "    \n",
    "    m, initial_epoch = build_compiled_model(model, hyperparameters, metrics=[], run_number=None)\n",
    "    m_pred_untrained = m.predict(X_small, batch_size=batch_size)\n",
    "    m_history = m.fit(X_small, y_small, **training_params, initial_epoch=initial_epoch, verbose=verbose)\n",
    "    m_pred_trained = m.predict(X_small, batch_size=batch_size)\n",
    "    \n",
    "    print()\n",
    "    print('Plotting Error against Sample for Before Training, and After Training on the Small Dataset')\n",
    "    plot_outputs_errors(m_pred_untrained, y_small, 'Before Training')\n",
    "    plot_outputs_errors(m_pred_trained, y_small, 'After Training')\n",
    "    print()\n",
    "    \n",
    "    print('Plotting Each Sample\\'s Time Series')\n",
    "    plot_ts_samples_ba(X_small, y_small, m_pred_untrained, m_pred_trained, 'adjusted_close_WFC')\n",
    "    \n",
    "    metrics = m.metrics_names\n",
    "    for met in metrics:\n",
    "        plot_metric(m_history.history, metric=met)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if model can overfit on a small sample of data\n",
      "Train on 2 samples\n",
      "Epoch 1/1000\n",
      "2/2 [==============================] - 6s 3s/sample - loss: 21.4558\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 21.2582\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 19.2471\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 19.7620\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 19.5867\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.6758\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.6764\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 19.0391\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.4707\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.2191\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.3291\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.3370\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.1924\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.0550\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 18.0587\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.9860\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.7375\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.6313\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.7047\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.6296\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.4595\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.3797\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.3382\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.2183\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.0573\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.9172\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.7912\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.6739\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.4985\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.3346\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.1859\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 15.7859\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.2579\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.3709\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 17.1451\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.8005\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.3398\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.3453\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 16.4102\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 15.5490\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 15.0117\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 15.1964\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 15.4012\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 14.9209\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 14.3328\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 14.0953\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 14.1182\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 14.0223\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 13.4101\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 12.9935\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 12.7853\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 12.6665\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 12.3377\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 11.9649\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 11.5949\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 11.3005\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 11.0162\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 10.7006\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 10.3414\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.9877\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.6070\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.5047\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.2916\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.0244\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.6103\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.4877\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.1657\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.1067\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.7213\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.6355\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.4404\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.2022\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.1149\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.9377\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.7417\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.6435\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.5350\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.3853\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.2710\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.1838\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.0721\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.9581\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.8742\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.7947\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.6948\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.5935\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.5112\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.4353\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.3482\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.2566\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.1770\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.1200\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.0387\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.9576\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.8922\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.8316\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.7645\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6937\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6269\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.5657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.5059\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.4434\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3815\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3246\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.2693\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.2112\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.1527\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.0965\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.0401\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.9804\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.9232\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8703\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8210\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7725\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7226\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6733\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6264\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.5807\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.5349\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4896\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4455\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4023\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3595\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3172\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2759\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2355\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1955\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1558\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1168\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0787\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0412\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0041\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9674\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9312\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8957\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8607\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8262\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7922\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7586\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7254\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6927\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6604\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6286\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5972\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5662\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5355\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5053\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4754\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4459\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4168\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3881\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3597\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3316\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3039\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2766\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2495\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2228\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1964\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1703\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1446\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1191\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0939\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0690\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0444\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0201\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9961\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9724\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9489\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9257\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9027\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8801\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8577\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8355\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8136\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7919\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7705\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7493\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7284\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7077\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6872\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6669\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6469\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6271\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6076\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5882\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5691\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5501\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5314\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5129\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4946\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4765\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4586\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4409\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4234\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4061\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3890\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3721\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3553\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3388\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3062\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2902\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2744\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2587\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2432\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2279\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2128\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1978\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1830\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1684\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1539\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1395\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1254\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1114\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0975\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0838\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0703\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0569\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0437\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0306\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0176\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0048\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9922\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9797\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9673\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9550\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9429\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9310\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9191\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.9075\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8959\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8845\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8732\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8620\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8509\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8400\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8292\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8185\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.8080\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7975\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7872\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7770\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7670\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7570\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7471\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7374\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7278\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7183\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.7089\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6996\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6904\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6813\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6723\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6634\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6547\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6460\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6374\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6290\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6206\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6124\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.6042\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5961\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5881\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5802\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5725\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5648\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5572\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5496\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5422\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5349\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5276\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5205\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5134\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.5064\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4995\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4927\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4859\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4793\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4727\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4662\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4598\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4534\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4471\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4410\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4348\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4288\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4228\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4170\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4111\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.4054\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3997\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3941\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3886\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3831\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3777\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3724\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3671\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3619\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3568\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3467\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3418\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3369\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3321\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3273\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3226\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3180\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3134\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3089\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3044\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.3000\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2957\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2914\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2872\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2830\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2789\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2748\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2708\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2668\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2629\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2590\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2552\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2514\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2477\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2441\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2404\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2369\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2334\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2299\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2264\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2231\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2197\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2164\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2132\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2100\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2068\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2037\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.2006\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1976\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1946\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1916\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1887\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1858\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1830\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1802\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1775\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1747\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1720\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1694\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1668\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1642\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1617\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1592\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1567\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1543\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1519\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1495\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1472\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1449\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1426\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1404\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1382\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1360\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1338\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1317\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1297\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1276\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1256\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1236\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1216\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1197\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1178\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1159\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1140\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1122\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1104\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1086\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1069\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1052\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1035\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1018\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.1001\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0985\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0969\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0953\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0938\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0922\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0907\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0892\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0878\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0863\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0849\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0835\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0821\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0808\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0794\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0781\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0768\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0755\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0730\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0718\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0706\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0694\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0683\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0671\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0660\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0649\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0638\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0627\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0616\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0606\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0596\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0585\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0575\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0566\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0556\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0546\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0537\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0528\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0519\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0510\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0501\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0492\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0484\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0475\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0467\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0459\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0451\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0443\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0435\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0428\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0420\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0413\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0406\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0399\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0392\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0385\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0378\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0371\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0365\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0358\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0352\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0345\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0339\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0333\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0327\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0321\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0316\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0310\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0304\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0299\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0293\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0288\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0283\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0278\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0273\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0268\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0263\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0258\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0253\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0249\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0244\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0240\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0235\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0231\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0227\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0223\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0218\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0214\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0210\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0207\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0203\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0199\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0195\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0192\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0188\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0185\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0181\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0178\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0174\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0171\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0168\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0165\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0162\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0158\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0155\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0153\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0150\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0147\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0144\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0141\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0139\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0136\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0133\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0131\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0128\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0126\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0123\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0119\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0116\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0114\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0112\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0110\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0108\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0105\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0103\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0101\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0099\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0097\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0096\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0094\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0092\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0090\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0088\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0086\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0085\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0083\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0081\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0080\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0078\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0077\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0075\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0074\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0072\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0071\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0069\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0068\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0067\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0065\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0064\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0063\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0061\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0060\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0059\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0058\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0057\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0055\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0054\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0053\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0052\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0051\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0050\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0049\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0048\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0047\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0046\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0045\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0044\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0043\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0042\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0041\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0041\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0040\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0039\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0038\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0037\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0037\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0036\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0035\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0034\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0034\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0033\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0032\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0031\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0031\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0030\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0030\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0029\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0028\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0028\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0027\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0027\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0026\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0025\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0025\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0024\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0024\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0023\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0023\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0022\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0022\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0021\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0021\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0020\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0020\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0020\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0019\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0019\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0018\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0018\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0018\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0017\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0017\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0016\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0016\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0016\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0015\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0015\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0014\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0014\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0014\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0013\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0013\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0013\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0013\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0012\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0012\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0012\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0011\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0011\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0011\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0011\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0010\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0010\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 0.0010\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.7895e-04\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.5688e-04\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.3539e-04\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.1424e-04\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.9351e-04\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.7326e-04\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.5354e-04\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.3414e-04\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.1520e-04\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.9664e-04\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.7854e-04\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.6077e-04\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.4336e-04\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.2641e-04\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.0977e-04\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.9349e-04\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.7760e-04\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.6203e-04\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.4679e-04\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.3187e-04\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.1734e-04\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.0309e-04\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.8916e-04\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.7558e-04\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.6224e-04\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.4917e-04\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.3640e-04\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.2396e-04\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.1178e-04\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.9987e-04\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.8817e-04\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.7674e-04\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6562e-04\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.5473e-04\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.4405e-04\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3366e-04\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.2345e-04\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.1353e-04\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.0374e-04\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.9427e-04\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8497e-04\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7588e-04\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6698e-04\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.5827e-04\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4978e-04\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4148e-04\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3333e-04\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2539e-04\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1769e-04\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1008e-04\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0271e-04\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9543e-04\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8834e-04\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8145e-04\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7471e-04\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6809e-04\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6168e-04\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5536e-04\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4919e-04\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4316e-04\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3732e-04\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3159e-04\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2597e-04\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2050e-04\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1514e-04\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0993e-04\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0479e-04\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9979e-04\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9489e-04\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9016e-04\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8553e-04\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8099e-04\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7658e-04\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7223e-04\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6800e-04\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6386e-04\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5981e-04\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5591e-04\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5204e-04\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4832e-04\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4466e-04\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4108e-04\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3758e-04\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3416e-04\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3085e-04\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2757e-04\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2440e-04\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2130e-04\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1829e-04\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1536e-04\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1246e-04\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0966e-04\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0689e-04\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0422e-04\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0160e-04\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.9022e-05\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.6537e-05\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.4104e-05\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.1726e-05\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.9423e-05\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.7160e-05\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.4969e-05\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.2812e-05\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.0706e-05\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.8656e-05\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.6678e-05\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.4703e-05\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.2804e-05\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.0923e-05\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.9117e-05\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.7350e-05\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.5653e-05\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.3957e-05\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.2330e-05\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.0723e-05\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.9174e-05\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.7653e-05\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.6168e-05\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.4725e-05\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.3302e-05\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.1916e-05\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.0572e-05\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.9259e-05\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.7968e-05\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6748e-05\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.5521e-05\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.4346e-05\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3191e-05\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.2067e-05\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.0979e-05\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.9919e-05\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8875e-05\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7846e-05\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6850e-05\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.5880e-05\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4945e-05\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4016e-05\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3121e-05\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2249e-05\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1378e-05\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0548e-05\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9751e-05\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8971e-05\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8198e-05\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7463e-05\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6727e-05\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6018e-05\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5329e-05\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4648e-05\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4006e-05\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3360e-05\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2732e-05\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2118e-05\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1525e-05\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0949e-05\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0384e-05\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9838e-05\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9303e-05\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8772e-05\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8259e-05\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7765e-05\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7288e-05\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6829e-05\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6376e-05\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5929e-05\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5499e-05\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5087e-05\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4670e-05\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4277e-05\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3894e-05\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3514e-05\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3139e-05\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2781e-05\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2437e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2098e-05\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1756e-05\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1436e-05\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1119e-05\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0809e-05\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0512e-05\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0219e-05\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.9370e-06\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.6605e-06\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.3878e-06\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.1349e-06\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.8699e-06\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.6223e-06\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.3858e-06\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.1544e-06\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.9302e-06\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.7125e-06\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.4978e-06\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.2933e-06\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.0916e-06\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.8943e-06\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.6982e-06\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.5132e-06\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.3324e-06\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.1526e-06\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.9882e-06\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.8133e-06\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.6488e-06\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.4928e-06\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.3389e-06\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.1873e-06\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.0378e-06\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.8963e-06\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.7569e-06\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6194e-06\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.4909e-06\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3615e-06\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.2367e-06\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.1164e-06\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.0003e-06\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8783e-06\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7708e-06\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6624e-06\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.5530e-06\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4490e-06\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3513e-06\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2503e-06\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1555e-06\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0631e-06\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9767e-06\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8860e-06\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8045e-06\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7251e-06\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6469e-06\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5741e-06\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4990e-06\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4251e-06\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3563e-06\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2886e-06\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2266e-06\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1655e-06\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1005e-06\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0374e-06\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9790e-06\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9214e-06\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8682e-06\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8131e-06\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7607e-06\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7106e-06\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6605e-06\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6111e-06\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5657e-06\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5178e-06\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4745e-06\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4304e-06\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3884e-06\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3487e-06\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3072e-06\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2694e-06\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2320e-06\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1953e-06\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1591e-06\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1235e-06\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0911e-06\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0592e-06\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0258e-06\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.9754e-07\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.6708e-07\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.3768e-07\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.0816e-07\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.7968e-07\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.5352e-07\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.2887e-07\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.0347e-07\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.7902e-07\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.5494e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.3124e-07\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.0792e-07\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.8716e-07\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.6619e-07\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.4394e-07\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.2622e-07\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.0417e-07\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.8748e-07\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.6857e-07\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.4998e-07\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.3361e-07\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.1560e-07\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.9975e-07\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.8415e-07\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6880e-07\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.5411e-07\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3884e-07\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.2463e-07\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.1194e-07\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.9779e-07\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8552e-07\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7343e-07\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6034e-07\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4903e-07\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3753e-07\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2623e-07\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1512e-07\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0566e-07\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9525e-07\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8642e-07\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7634e-07\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6748e-07\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5845e-07\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5120e-07\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4406e-07\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3702e-07\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3009e-07\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2326e-07\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1681e-07\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.1046e-07\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.0393e-07\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9777e-07\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.9170e-07\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8598e-07\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.8010e-07\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.7541e-07\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6994e-07\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6457e-07\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.6009e-07\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5591e-07\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.5053e-07\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4625e-07\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.4203e-07\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3712e-07\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.3377e-07\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2996e-07\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2598e-07\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.2206e-07\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1821e-07\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1530e-07\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.1135e-07\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0767e-07\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0490e-07\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 1.0217e-07\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.8649e-08\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.6001e-08\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.2587e-08\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 9.0202e-08\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.7493e-08\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.5174e-08\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 8.1960e-08\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.9548e-08\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.7338e-08\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.5161e-08\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.2851e-08\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 7.0739e-08\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.8498e-08\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.6451e-08\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.4279e-08\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.2801e-08\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 6.0045e-08\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.8764e-08\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.6723e-08\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.5479e-08\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.3496e-08\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.2149e-08\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 5.0364e-08\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.8476e-08\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.7194e-08\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.6059e-08\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.4254e-08\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.3030e-08\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.1946e-08\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 4.0347e-08\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.9177e-08\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.8144e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.7007e-08\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.6003e-08\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.4410e-08\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.3331e-08\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.2378e-08\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.1439e-08\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 3.0408e-08\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.9395e-08\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.8500e-08\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7620e-08\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.7085e-08\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.6226e-08\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.5286e-08\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.4456e-08\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.3641e-08\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 3s 1s/sample - loss: 2.2841e-08\n",
      "\n",
      "Plotting Error against Sample for Before Training, and After Training on the Small Dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting Each Sample's Time Series\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Target Value: 25.3963\n",
      "Predicted Target Value Before Training: 20.42641258239746\n",
      "Predicted Target Value After Training: 25.396093368530273\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Target Value: 16.0382\n",
      "Predicted Target Value Before Training: 20.30572509765625\n",
      "Predicted Target Value After Training: 16.03824806213379\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_small, y_small = sample_dataset(train_dataset, sample_size=2, seed=seed)\n",
    "\n",
    "del y_small['adjusted_close_target_JPM']\n",
    "del y_small['adjusted_close_target_BAC']\n",
    "del y_small['adjusted_close_target_C']\n",
    "\n",
    "overfit_small_sample(model_text, batch_size=6, epochs=1000, X_small=X_small, y_small=y_small, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots its clear that our model has overfit on our small sample of the dataset which is the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final section we train and evaluate our model architecture using a few different sets of hyperparameters. The metrics we will use to evaluate our model are mean squared error, and accuracy at predict daily stock trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Configuring Virtual GPU and Loading Data\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_dataset.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "    \n",
    "# Loading Train Dataset's Vocabulary\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_train_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history[metric], label='Train')\n",
    "    if 'val_' + metric in history:\n",
    "        ax.plot(history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None\n",
    "\n",
    "def plot_print_complete_metrics(model_name, model_version, run_number, metrics_train, metrics_val, metrics_names):\n",
    "    csvlog = os.path.join('logs', 'models', model_name, '_'.join(['version', str(model_version)]), 'runs', str(run_number), 'history.log')\n",
    "    df = pd.read_csv(csvfile).drop_duplicates(subset='epoch', keep='last').set_index('epoch')\n",
    "    plot_print_metrics(df, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=metrics_names)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            config_path = os.expanduser(os.path.join('~', '.stockanalysis', 'config.json'))\n",
    "            with open(config_path, 'r') as f:\n",
    "                configuration = json.load(f)\n",
    "            glove_vec_file = os.path.expanduser(configuration['Model_Resources']['glove'])\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(glove_vec_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_text(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "               output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias = output_bias_init['adjusted_close_target_WFC']\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_text')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting both are training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names and shapes for Training Data:\n",
      "adjusted_close_WFC: (5,)\n",
      "8-k_WFC: (1562,)\n",
      "adjusted_close_JPM: (5,)\n",
      "8-k_JPM: (90363,)\n",
      "adjusted_close_BAC: (5,)\n",
      "8-k_BAC: (15826,)\n",
      "adjusted_close_C: (5,)\n",
      "8-k_C: (53958,)\n",
      "\n",
      "Feature names and shapes for Validation Data:\n",
      "adjusted_close_WFC: (5,)\n",
      "8-k_WFC: (1364,)\n",
      "adjusted_close_JPM: (5,)\n",
      "8-k_JPM: (1706,)\n",
      "adjusted_close_BAC: (5,)\n",
      "8-k_BAC: (2026,)\n",
      "adjusted_close_C: (5,)\n",
      "8-k_C: (2636,)\n",
      "\n",
      "Train set size: 3014\n",
      "Validation set size: 1001\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_dataset\n",
    "X_val, y_val = val_dataset\n",
    "\n",
    "print('Feature names and shapes for Training Data:')\n",
    "for key in X_train:\n",
    "    print('{}: {}'.format(key, X_train[key].shape[1:]))\n",
    "print()\n",
    "print('Feature names and shapes for Validation Data:')\n",
    "for key in X_val:\n",
    "    print('{}: {}'.format(key, X_val[key].shape[1:]))\n",
    "print()\n",
    "print('Train set size: {}'.format(len(y_train['adjusted_close_target_WFC'])))\n",
    "print('Validation set size: {}'.format(len(y_val['adjusted_close_target_WFC'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Defining Hyperparameters\n",
    "output_bias_init = {key: y_train[key].mean() for key in y_train}\n",
    "model_params = {\n",
    "                'output_bias_init': output_bias_init, \n",
    "                'lstm_layer_units': 32\n",
    "               }\n",
    "training_params = {\n",
    "                   'batch_size': 6, \n",
    "                   'epochs': 2\n",
    "                  }\n",
    "loss = tf.keras.losses.MeanSquaredError\n",
    "optimizer = tf.keras.optimizers.Adam\n",
    "optimizer_params = {}\n",
    "\n",
    "model_version = 0\n",
    "hyperparameters = {\n",
    "                   'model_parameters': model_params,\n",
    "                   'training_parameters': training_params,\n",
    "                   'loss': loss, \n",
    "                   'optimizer': optimizer, \n",
    "                   'optimizer_parameters': optimizer_params, \n",
    "                   'version': model_version\n",
    "                  }\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from: logs/models/model_0/version_0/runs/0/checkpoints/cp-1.ckpt\n",
      "Saved hyperparameters to file: logs/models/model_0/version_0\n",
      "Train on 3014 samples, validate on 1001 samples\n",
      "Epoch 1/2\n",
      "  48/3014 [..............................] - ETA: 29:11 - loss: 4.6273\n",
      "Epoch 00001: saving model to logs/models/model_0/version_0/runs/0/checkpoints/cp-1.ckpt\n",
      "  48/3014 [..............................] - ETA: 29:15 - loss: 4.6273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0fa8d0304217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstockanalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/stockanalysis/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(build_model, hparams, metrics, run_number, X, y, validation_data, write_hyperparameters, checkpoint, log)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Training Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtraining_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stockanalysis.train import train\n",
    "\n",
    "model, model_history = train(model_0, hyperparameters, metrics, run_number, X_train, y_train, (X_val, y_val), True, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_params['batch_size'], verbose=0)\n",
    "metrics_val = model.evaluate(X_val, y_val, batch_size=training_params['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_params['batch_size'])\n",
    "m_preds_val = model.predict(X_val, batch_size=training_params['batch_size'])\n",
    "m_preds_up_train = ((m_preds_train[1:, 0] - y_train['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "m_preds_up_val = ((m_preds_val[1:, 0] - y_val['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "labels_up_train = ((y_train['adjusted_close_target_WFC'][1:] - y_train['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "labels_up_val = ((y_val['adjusted_close_target_WFC'][1:] - y_val['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_val = np.mean(np.equal(m_preds_up_val, labels_up_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 1.8115987953122437\n",
      "Loss on validation dataset: 214.70029630479993\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.9193494855625622\n",
      "Accuracy on validation dataset: 0.578\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(model_history.history, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Learning Curves for Metrics: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 1.8115987953122437\n",
      "Loss on validation dataset: 214.70029630479993\n"
     ]
    }
   ],
   "source": [
    "print('Complete Learning Curves for Metrics: ')\n",
    "plot_print_complete_metrics('model_0', model_version, run_number, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Blah blah blah, talk about experiments)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
