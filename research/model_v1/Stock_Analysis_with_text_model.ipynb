{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=4000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_print_model_stats(model, path, model_name):\n",
    "    m = model()\n",
    "    if not os.path.exists(os.path.join(path, model_name)):\n",
    "        os.makedirs(os.path.join(path, model_name))\n",
    "    fname = os.path.join(path, model_name, model_name)\n",
    "    tf.keras.utils.plot_model(m, fname + '.png', show_shapes=True, expand_nested=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of Model:\n",
    "![title](logs/models/model_0/model_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Testing if when initialized properly, the model is equivalent to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel in order to fully clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=3000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def baseline_model(output_bias_init=0):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64)\n",
    "             }\n",
    "    \n",
    "    features = tf.keras.layers.Concatenate()([inputs[fname] for fname in inputs.keys() if '8-k' not in fname])\n",
    "    \n",
    "    output_wfc = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, name='adjusted_close_target_WFC')(features)\n",
    "    #output_jpm = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, name='log_adj_daily_returns_target_JPM')(features)\n",
    "    #output_bac = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, name='log_adj_daily_returns_target_BAC')(features)\n",
    "    #output_c = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, name='log_adj_daily_returns_target_C')(features)\n",
    "    \n",
    "    outputs = {\n",
    "               'adjusted_close_target_WFC': output_wfc, \n",
    "              }\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='baseline_model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing baseline equivalence of model when initialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline_equivalence(model, baseline_model, batch_size, X, y):\n",
    "    print('Testing if the untrained model when initialized properly is equivalent to the baseline model')\n",
    "    output_bias_init = 0\n",
    "    \n",
    "    baseline_m = build_compiled_model(baseline_model, {'output_bias_init': output_bias_init},\n",
    "                                      loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    baseline_results = baseline_m.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    hparams = {'output_kernel_init': 'zeros', 'output_bias_init': output_bias_init}\n",
    "    m1 = build_compiled_model(model, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m1_results = m1.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    assert m1_results == baseline_results\n",
    "    \n",
    "    return print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if the untrained model when initialized properly is equivalent to the baseline model\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "test_baseline_equivalence(model_0, baseline_model, batch_size=4, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Testing if the model trained on real data performs better than the model trained on null data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Null Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def null_feature(feature_name, feature):\n",
    "    if 'adjusted_close' in feature_name:\n",
    "        null_feature = np.zeros(shape=feature.shape, dtype=feature.dtype)\n",
    "    elif '8-k' in feature_name:\n",
    "        null_feature = np.ones(shape=feature.shape, dtype=feature.dtype)\n",
    "    return null_feature\n",
    "\n",
    "def null_features(features):\n",
    "    return {fname: null_feature(fname, features[fname]) for fname in features.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on null features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 17s 1s/sample - loss: 385.3904\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 12s 750ms/sample - loss: 294.7742\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 12s 751ms/sample - loss: 244.9124\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 12s 735ms/sample - loss: 214.6178\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 12s 728ms/sample - loss: 198.9521\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 12s 725ms/sample - loss: 191.5750\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 12s 726ms/sample - loss: 186.8328\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 12s 721ms/sample - loss: 183.2223\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 12s 731ms/sample - loss: 179.5221\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 12s 733ms/sample - loss: 176.0314\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "X_null = null_features(X)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "output_bias_init = 0\n",
    "hparams = {'output_bias_init': output_bias_init}\n",
    "\n",
    "m = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "m_history = m.fit(X_null, y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory issue is weird because I'll reset the kernel (which kills the python process reseting the GPU memory), run the same code, and have the GPU run out of memory about 80% of the time I rerun the same code. The longer I wait between sessions using the GPU, the more likely I won't encounter the issue. *Suprisingly when I train on smaller datasets I encounter the error usually in the first batch, but when I train on larger datasets, it usually doesnt show up in the first batch.* When the error is not raised in the first batch, the batch number it shows up in varies from run to run even when I have all possible random number generators seeded and am using the same dataset. When seeding all possible random number generators running without the GPU, I get reproducible metrics, and the training never crashes, but when introducing the GPU I introduce this memory error. It appears to me that the problem lies with the GPU, since my since my code trains perfectly well on the CPU and produces reproducible results. Hypothesis: Maybe the amount of memory the GPU needs to allocate to perform calculations for my code differs from run to run even when the calculation performed is still the mathematically the same (or very similar). ie run 1: 2+2 requires 1 byte to compute, run 2: 2+2 requires 3.5 bytes to compute. IDK.\n",
    "When I do successfully train the model on GPU I get the same metrics I get when training on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_results = m.evaluate(X, y, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on zeroed features.\n",
      "\n",
      "Loss for Model: 411.3193817138672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on zeroed features.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(m_results))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3014 samples, validate on 1001 samples\n",
      "Epoch 1/100\n",
      " 226/3014 [=>............................] - ETA: 1:08:55 - loss: 248.2337"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-02bc818f0d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mm_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "X, y = train_dataset\n",
    "X_val, y_val = val_dataset\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "output_bias_init = 0\n",
    "hparams = {'output_bias_init': output_bias_init}\n",
    "\n",
    "m = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "m_history = m.fit(X, y, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_results = m.evaluate(X, y, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metrics for model trained on actual data.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(m_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out. The model when trained on actual data has a smaller loss than when trained on the null features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Testing if the model can overfit on a small sample of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        print(list(range(len(true_labels.keys()))))\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    name = ts_fname.split('_')\n",
    "    ticker = name.pop()\n",
    "    name = '_'.join(name)\n",
    "    target = targets['_'.join([name, 'target', ticker])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([name, 'target', ticker]):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtraining model on a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_small_sample(model, batch_size, epochs, X_small, y_small, verbose):\n",
    "    print('Testing if model can overfit on a small sample of data')\n",
    "    output_bias_init = 0\n",
    "    hparams = {'output_bias_init': output_bias_init}\n",
    "    \n",
    "    m = build_compiled_model(model, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m_pred_untrained = m.predict(X_small, batch_size=batch_size)\n",
    "    print(m_pred_untrained.shape)\n",
    "    plot_outputs_errors(m_pred_untrained, y_small, 'Before Training')\n",
    "    m_history = m.fit(X_small, y_small, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "    m_pred_trained = m.predict(X_small, batch_size=batch_size)\n",
    "    print()\n",
    "    \n",
    "    print('Plotting Error against Sample for Before Training, and After Training on the Small Dataset')\n",
    "    plot_outputs_errors(m_pred_untrained, y_small, 'Before Training')\n",
    "    plot_outputs_errors(m_pred_trained, y_small, 'After Training')\n",
    "    print()\n",
    "    \n",
    "    print('Plotting Each Sample\\'s Time Series for Log Adjusted Daily Returns')\n",
    "    plot_ts_samples_ba(X_small, y_small, m_pred_untrained, m_pred_trained, 'log_adj_daily_returns_WFC')\n",
    "    \n",
    "    metrics = ['loss'] + list(map(lambda met: met.name, METRICS))\n",
    "    for met in metrics:\n",
    "        plot_metric(m_history, metric=met)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if model can overfit on a small sample of data\n",
      "(2, 1)\n",
      "[0, 1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5d67b76170bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moverfit_small_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_small\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_small\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-b0567bb1259b>\u001b[0m in \u001b[0;36moverfit_small_sample\u001b[0;34m(model, batch_size, epochs, X_small, y_small, verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mm_pred_untrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_pred_untrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplot_outputs_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_pred_untrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Before Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mm_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mm_pred_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-88fdfdccf5eb>\u001b[0m in \u001b[0;36mplot_outputs_errors\u001b[0;34m(predictions, true_labels, title)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "X_small, y_small = sample_dataset(train_dataset, sample_size=2, seed=seed)\n",
    "overfit_small_sample(model_0, batch_size=1, epochs=500, X_small=X_small, y_small=y_small, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots its clear that our model has overfit on our small sample of the dataset which is the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stockanalysis.train import config_hardware\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU and TensorFlow\n",
    "config_hardware(gpu_memory=7000, seed=seed)\n",
    "\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_datasetp2.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'val_datasetp2.pickle'), 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab_8k_norm_trainp2_WFC_JPM_BAC_C.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    name = ts_fname.split('_')\n",
    "    ticker = name.pop()\n",
    "    name = '_'.join(name)\n",
    "    target = targets['_'.join([name, 'target', ticker])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([name, 'target', ticker]):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init, emb_name):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre-initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, '{}.pickle'.format(emb_name)), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, emb_name,\n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init, emb_name)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, emb_name, doc_embedding_size):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', emb_name=emb_name, mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100, emb_name='current_embedding', \n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, emb_name, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = os.path.join('~', '.stockanalysis', 'model_resources', 'glove')\n",
    "        glove_dir = os.path.expanduser(glove_dir)\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=False, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_1(lstm_layer_units_0=64, lstm_layer_units_1=32, lstm_layer_units_2=16, vocab=vocab, \n",
    "            doc_embedding_size=100, output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {\n",
    "              'adjusted_close_WFC': tf.keras.Input(shape=(5,), name='adjusted_close_WFC', dtype=tf.float32),\n",
    "              '8-k_WFC': tf.keras.Input(shape=(None,), name='8-k_WFC', dtype=tf.int64),\n",
    "              'adjusted_close_JPM': tf.keras.Input(shape=(5,), name='adjusted_close_JPM', dtype=tf.float32),\n",
    "              '8-k_JPM': tf.keras.Input(shape=(None,), name='8-k_JPM', dtype=tf.int64),\n",
    "              'adjusted_close_BAC': tf.keras.Input(shape=(5,), name='adjusted_close_BAC', dtype=tf.float32),\n",
    "              '8-k_BAC': tf.keras.Input(shape=(None,), name='8-k_BAC', dtype=tf.int64),\n",
    "              'adjusted_close_C': tf.keras.Input(shape=(5,), name='adjusted_close_C', dtype=tf.float32),\n",
    "              '8-k_C': tf.keras.Input(shape=(None,), name='8-k_C', dtype=tf.int64),\n",
    "             }\n",
    "    \n",
    "    doc_embedder = document_embedder_model(vocab, doc_embedding_size)\n",
    "    document_embeddings = [doc_embedder(inputs[fname]) for fname in inputs.keys() if '8-k' in fname]\n",
    "    \n",
    "    reshape_doc_embedding = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))\n",
    "    reshaped_doc_embeddings = [reshape_doc_embedding(doc_embedding) for doc_embedding in document_embeddings]\n",
    "    \n",
    "    reshape_price_feature = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))\n",
    "    reshaped_price_features = [reshape_price_feature(inputs[fname]) for fname in inputs.keys() if '8-k' not in fname]\n",
    "    time_series_input = tf.keras.layers.Concatenate()(reshaped_doc_embeddings + reshaped_price_features)\n",
    "    \n",
    "    time_series_lstm_0 = tf.keras.layers.LSTM(lstm_layer_units_0, return_sequences=True)(time_series_input)\n",
    "    time_series_lstm_0 = tf.keras.layers.Dropout(0.2)(time_series_lstm_0)\n",
    "    time_series_lstm_1 = tf.keras.layers.LSTM(lstm_layer_units_1, return_sequences=True)(time_series_lstm_0)\n",
    "    time_series_lstm_1 = tf.keras.layers.Dropout(0.2)(time_series_lstm_1)\n",
    "    time_series_lstm_2 = tf.keras.layers.LSTM(lstm_layer_units_2)(time_series_lstm_1)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='adjusted_close_target_WFC')\n",
    "    outputs = {'adjusted_close_target_WFC': output_layer(time_series_lstm_2)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train dataset into train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X_train, y_train = train_dataset\\nX_val, y_val = val_dataset\\n\\nprint('Train set size: {}'.format(len(y_train['adjusted_close_target_WFC'])))\\nprint('Validation set size: {}'.format(len(y_val['adjusted_close_target_WFC'])))\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_train, y_train = train_dataset\n",
    "X_val, y_val = val_dataset\n",
    "\n",
    "print('Train set size: {}'.format(len(y_train['adjusted_close_target_WFC'])))\n",
    "print('Validation set size: {}'.format(len(y_val['adjusted_close_target_WFC'])))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining and Saving Hyperparameters\n",
    "#LOSS = tf.keras.losses.MeanSquaredError()\n",
    "#OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "#model_params = {'lstm_layer_units': 32, 'vocab': vocab, 'doc_embedding_size': 100, 'output_bias_init': 0}\n",
    "training_params = {'batch_size': 2, 'epochs': 12}\n",
    "#model_version = 0\n",
    "#hyperparameters = {'model_parameters': model_params, 'training_parameters': training_params,\n",
    "#                   'loss': LOSS, 'optimizer': OPTIMIZER, 'version': model_version}\n",
    "#write_hparams('model_0', hyperparameters)\n",
    "\n",
    "# Defining Metrics\n",
    "#METRICS = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "#run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_bias_init = 0\n",
    "#hparams = {'output_bias_init': output_bias_init}\n",
    "#model = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3014 samples, validate on 1001 samples\n",
      "Epoch 1/18\n",
      "  30/3014 [..............................] - ETA: 1:00:26 - loss: 17.9536"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bd4381ac6a40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mm_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''# Setting up callbacks\n",
    "path_to_run = os.path.join('logs', 'models', 'model_0',\n",
    "                            '_'.join(['version', str(hyperparameters['version'])]),\n",
    "                            'runs', str(run_number))\n",
    "path_to_ckpts = os.path.join(path_to_run, 'checkpoints')\n",
    "if not os.path.exists(path_to_ckpts):\n",
    "    os.makedirs(path_to_ckpts)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path_to_ckpts, 'cp-{epoch}.ckpt'),\n",
    "                                                 verbose=1, save_weights_only=True, period=10)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=os.path.join(path_to_run, 'history.log'), append=True)\n",
    "callbacks = [cp_callback, csv_logger]\n",
    "\n",
    "# Unpacking model training parameters\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "\n",
    "# Fetching last trained epoch if the model was reloaded\n",
    "latest_ckpt = tf.train.latest_checkpoint(path_to_ckpts)\n",
    "if latest_ckpt is not None:\n",
    "    initial_epoch = re.findall(r'cp-(\\d+)\\.ckpt', latest_ckpt)[0]\n",
    "    initial_epoch = int(initial_epoch) - 1\n",
    "else:\n",
    "    initial_epoch = 0'''\n",
    "\n",
    "X, y = train_dataset\n",
    "X_val, y_val = val_dataset\n",
    "\n",
    "epochs = 18\n",
    "batch_size = 6\n",
    "output_bias_init = y['adjusted_close_target_WFC'].mean()\n",
    "hparams = {'output_bias_init': output_bias_init, 'lstm_layer_units': 32}\n",
    "\n",
    "m = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "m_history = m.fit(X, y, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "\n",
    "#TODO: CALCULATE TREND ACCURACY METRIC\n",
    "metrics_train = m.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "metrics_val = m.evaluate(X_val, y_val, batch_size=batch_size, verbose=0)\n",
    "m_preds_train = m.predict(X, batch_size=batch_size)\n",
    "m_preds_val = m.predict(X_val, batch_size=batch_size)\n",
    "m_preds_up_train = ((m_preds_train[1:, 0] - y['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "m_preds_up_val = ((m_preds_val[1:, 0] - y_val['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "labels_up_train = ((y['adjusted_close_target_WFC'][1:] - y['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "labels_up_val = ((y_val['adjusted_close_target_WFC'][1:] - y_val['adjusted_close_target_WFC'][:-1]) > 0).astype(int)\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_val = np.mean(np.equal(m_preds_up_val, labels_up_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 0.2743346627187367\n",
      "Loss on validation dataset: 135.92893173454047\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.976435446398938\n",
      "Accuracy on validation dataset: 0.739\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(m_history, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=m.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49615384.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ((m_preds_val[1:, 0] - y_val['adjusted_close_target_WFC'][:-1]) > 0)\n",
    "returns = y_val['adjusted_close_target_WFC'][1:] - y_val['adjusted_close_target_WFC'][:-1]\n",
    "sum(returns[mask]*(300000 / 20))\n",
    "# bullshit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Selected Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions \n",
    "def write_hparams(model_name, hparams, verbose=True):\n",
    "    version_number = hparams['version']\n",
    "    path = os.path.join('logs', 'models', model_name, '_'.join(['version', str(version_number)]))\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'hparams.pickle'), 'wb') as f:\n",
    "        pickle.dump(hparams, f)\n",
    "    if verbose:\n",
    "        return print('Saved hyperparameters to file: {}'.format(path))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def build_compiled_model(build_model, model_name, hparams, metrics, run_number):\n",
    "    hparam_version = hparams['version']\n",
    "    loss = hparams['loss']\n",
    "    optimizer = hparams['optimizer']\n",
    "    model_parameters = hparams['model_parameters']\n",
    "    model = build_model(**model_parameters)\n",
    "    path_to_ckpt = os.path.join('logs', 'models', model_name, '_'.join(['version', str(hparam_version)]),\n",
    "                               'runs', str(run_number), 'checkpoints')\n",
    "    if os.path.exists(path_to_ckpt):\n",
    "        latest = tf.train.latest_checkpoint(path_to_ckpt)\n",
    "        model.load_weights(latest)\n",
    "        print('Restored model from: {}'.format(latest))  \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_dataset\n",
    "X_test, y_test = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    target = targets['_'.join([ts_fname, 'target'])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([ts_fname, 'target']):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        if history != None:\n",
    "            plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hyperparameters to file: logs/models/model_selected/version_final\n"
     ]
    }
   ],
   "source": [
    "# Defining and Saving Hyperparameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "model_params = {'lstm_layer_units': 256, 'vocab': vocab, 'doc_embedding_size': 200, 'output_bias_init': 0}\n",
    "training_params = {'batch_size': 4, 'epochs': 50}\n",
    "model_version = 'final'\n",
    "hyperparameters = {'model_parameters': model_params, 'training_parameters': training_params,\n",
    "                   'loss': LOSS, 'optimizer': OPTIMIZER, 'version': model_version}\n",
    "write_hparams('model_selected', hyperparameters)\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_compiled_model(model_0, 'model_selected', hyperparameters, metrics=metrics, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on full train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7410 samples, validate on 2470 samples\n",
      "Epoch 1/50\n",
      "7410/7410 [==============================] - 402s 54ms/sample - loss: 0.0014 - val_loss: 7.1876e-04\n",
      "Epoch 2/50\n",
      "7410/7410 [==============================] - 405s 55ms/sample - loss: 8.5110e-04 - val_loss: 6.8347e-04\n",
      "Epoch 3/50\n",
      "7410/7410 [==============================] - 412s 56ms/sample - loss: 8.2944e-04 - val_loss: 6.7151e-04\n",
      "Epoch 4/50\n",
      "7410/7410 [==============================] - 407s 55ms/sample - loss: 8.0630e-04 - val_loss: 7.0192e-04\n",
      "Epoch 5/50\n",
      "7410/7410 [==============================] - 416s 56ms/sample - loss: 8.0736e-04 - val_loss: 6.6922e-04\n",
      "Epoch 6/50\n",
      "7410/7410 [==============================] - 411s 56ms/sample - loss: 7.9791e-04 - val_loss: 6.6630e-04\n",
      "Epoch 7/50\n",
      "7410/7410 [==============================] - 422s 57ms/sample - loss: 8.0261e-04 - val_loss: 6.7528e-04\n",
      "Epoch 8/50\n",
      "7410/7410 [==============================] - 413s 56ms/sample - loss: 8.1416e-04 - val_loss: 6.8368e-04\n",
      "Epoch 9/50\n",
      "7410/7410 [==============================] - 416s 56ms/sample - loss: 8.0031e-04 - val_loss: 6.6519e-04\n",
      "Epoch 10/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.9726e-04\n",
      "Epoch 00010: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-10.ckpt\n",
      "7410/7410 [==============================] - 411s 55ms/sample - loss: 7.9705e-04 - val_loss: 6.8684e-04\n",
      "Epoch 11/50\n",
      "7410/7410 [==============================] - 402s 54ms/sample - loss: 7.9468e-04 - val_loss: 7.5967e-04\n",
      "Epoch 12/50\n",
      "7410/7410 [==============================] - 403s 54ms/sample - loss: 7.9707e-04 - val_loss: 6.8248e-04\n",
      "Epoch 13/50\n",
      "7410/7410 [==============================] - 410s 55ms/sample - loss: 7.9599e-04 - val_loss: 6.8404e-04\n",
      "Epoch 14/50\n",
      "7410/7410 [==============================] - 431s 58ms/sample - loss: 7.9341e-04 - val_loss: 6.7407e-04\n",
      "Epoch 15/50\n",
      "7410/7410 [==============================] - 425s 57ms/sample - loss: 7.9170e-04 - val_loss: 6.7336e-04\n",
      "Epoch 16/50\n",
      "7410/7410 [==============================] - 421s 57ms/sample - loss: 7.8469e-04 - val_loss: 6.9698e-04\n",
      "Epoch 17/50\n",
      "7410/7410 [==============================] - 424s 57ms/sample - loss: 7.8349e-04 - val_loss: 6.7608e-04\n",
      "Epoch 18/50\n",
      "7410/7410 [==============================] - 413s 56ms/sample - loss: 7.8290e-04 - val_loss: 6.9322e-04\n",
      "Epoch 19/50\n",
      "7410/7410 [==============================] - 430s 58ms/sample - loss: 7.7870e-04 - val_loss: 7.0318e-04\n",
      "Epoch 20/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.7962e-04\n",
      "Epoch 00020: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-20.ckpt\n",
      "7410/7410 [==============================] - 424s 57ms/sample - loss: 7.7942e-04 - val_loss: 6.7816e-04\n",
      "Epoch 21/50\n",
      "7410/7410 [==============================] - 415s 56ms/sample - loss: 7.7109e-04 - val_loss: 6.9535e-04\n",
      "Epoch 22/50\n",
      "7410/7410 [==============================] - 396s 53ms/sample - loss: 7.7076e-04 - val_loss: 6.7602e-04\n",
      "Epoch 23/50\n",
      "7410/7410 [==============================] - 385s 52ms/sample - loss: 7.6872e-04 - val_loss: 6.9049e-04\n",
      "Epoch 24/50\n",
      "7410/7410 [==============================] - 384s 52ms/sample - loss: 7.6638e-04 - val_loss: 6.7173e-04\n",
      "Epoch 25/50\n",
      "7410/7410 [==============================] - 383s 52ms/sample - loss: 7.6933e-04 - val_loss: 6.7274e-04\n",
      "Epoch 26/50\n",
      "7410/7410 [==============================] - 383s 52ms/sample - loss: 7.6437e-04 - val_loss: 6.7135e-04\n",
      "Epoch 27/50\n",
      "7410/7410 [==============================] - 385s 52ms/sample - loss: 7.6020e-04 - val_loss: 6.9324e-04\n",
      "Epoch 28/50\n",
      "7410/7410 [==============================] - 425s 57ms/sample - loss: 7.6913e-04 - val_loss: 6.8200e-04\n",
      "Epoch 29/50\n",
      "7410/7410 [==============================] - 406s 55ms/sample - loss: 7.6870e-04 - val_loss: 6.7721e-04\n",
      "Epoch 30/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.6483e-04\n",
      "Epoch 00030: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-30.ckpt\n",
      "7410/7410 [==============================] - 405s 55ms/sample - loss: 7.6473e-04 - val_loss: 7.0582e-04\n",
      "Epoch 31/50\n",
      "7410/7410 [==============================] - 493s 66ms/sample - loss: 7.5664e-04 - val_loss: 6.9871e-04\n",
      "Epoch 32/50\n",
      "7410/7410 [==============================] - 443s 60ms/sample - loss: 7.5768e-04 - val_loss: 6.8470e-04\n",
      "Epoch 33/50\n",
      "7410/7410 [==============================] - 434s 59ms/sample - loss: 7.5128e-04 - val_loss: 7.6341e-04\n",
      "Epoch 34/50\n",
      "7410/7410 [==============================] - 412s 56ms/sample - loss: 7.5431e-04 - val_loss: 6.7713e-04\n",
      "Epoch 35/50\n",
      "7410/7410 [==============================] - 396s 53ms/sample - loss: 7.5601e-04 - val_loss: 6.7985e-04\n",
      "Epoch 36/50\n",
      "7410/7410 [==============================] - 390s 53ms/sample - loss: 7.5117e-04 - val_loss: 7.0180e-04\n",
      "Epoch 37/50\n",
      "7410/7410 [==============================] - 400s 54ms/sample - loss: 7.4925e-04 - val_loss: 7.3616e-04\n",
      "Epoch 38/50\n",
      "7410/7410 [==============================] - 399s 54ms/sample - loss: 7.3829e-04 - val_loss: 6.9453e-04\n",
      "Epoch 39/50\n",
      "7410/7410 [==============================] - 409s 55ms/sample - loss: 7.4177e-04 - val_loss: 7.5010e-04\n",
      "Epoch 40/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.3809e-04\n",
      "Epoch 00040: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-40.ckpt\n",
      "7410/7410 [==============================] - 414s 56ms/sample - loss: 7.3790e-04 - val_loss: 7.3695e-04\n",
      "Epoch 41/50\n",
      "7410/7410 [==============================] - 429s 58ms/sample - loss: 7.2971e-04 - val_loss: 7.4988e-04\n",
      "Epoch 42/50\n",
      "7410/7410 [==============================] - 416s 56ms/sample - loss: 7.2515e-04 - val_loss: 7.4372e-04\n",
      "Epoch 43/50\n",
      "7410/7410 [==============================] - 373s 50ms/sample - loss: 7.1235e-04 - val_loss: 7.6756e-04\n",
      "Epoch 44/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 7.0937e-04 - val_loss: 7.8594e-04\n",
      "Epoch 45/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 7.0231e-04 - val_loss: 7.7428e-04\n",
      "Epoch 46/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.9240e-04 - val_loss: 7.4683e-04\n",
      "Epoch 47/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.8276e-04 - val_loss: 8.1758e-04\n",
      "Epoch 48/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.7758e-04 - val_loss: 7.8488e-04\n",
      "Epoch 49/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.9563e-04 - val_loss: 8.2415e-04\n",
      "Epoch 50/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.0262e-04\n",
      "Epoch 00050: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-50.ckpt\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 7.0257e-04 - val_loss: 7.7475e-04\n"
     ]
    }
   ],
   "source": [
    "# Setting up callbacks\n",
    "path_to_run = os.path.join('logs', 'models', 'model_selected',\n",
    "                            '_'.join(['version', str(hyperparameters['version'])]),\n",
    "                            'runs', str(run_number))\n",
    "path_to_ckpts = os.path.join(path_to_run, 'checkpoints')\n",
    "if not os.path.exists(path_to_ckpts):\n",
    "    os.makedirs(path_to_ckpts)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path_to_ckpts, 'cp-{epoch}.ckpt'),\n",
    "                                                 verbose=1, save_weights_only=True, period=10)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=os.path.join(path_to_run, 'history.log'), append=True)\n",
    "callbacks = [cp_callback, csv_logger]\n",
    "\n",
    "# Unpacking model training parameters\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "\n",
    "# Fetching last trained epoch if the model was reloaded\n",
    "latest_ckpt = tf.train.latest_checkpoint(path_to_ckpts)\n",
    "if latest_ckpt is not None:\n",
    "    initial_epoch = re.findall(r'cp-(\\d+)\\.ckpt', latest_ckpt)[0]\n",
    "    initial_epoch = int(initial_epoch) - 1\n",
    "else:\n",
    "    initial_epoch = 0\n",
    "\n",
    "model_history = model.fit(X_train, y_train, **training_parameters, validation_data=(X_test, y_test),\n",
    "                          initial_epoch=initial_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_test = model.evaluate(X_test, y_test, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_test = model.predict(X_test, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_test = (m_preds_test[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_test = y_test['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_test = np.mean(np.equal(m_preds_up_test, labels_up_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 0.0006485506063616562\n",
      "Loss on validation dataset: 0.0007747489441738396\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.5464237516869096\n",
      "Accuracy on validation dataset: 0.5040485829959515\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(model_history, metrics_train=metrics_train, metrics_val=metrics_test, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from: logs/models/model_selected/version_final/runs/0/checkpoints/cp-30.ckpt\n"
     ]
    }
   ],
   "source": [
    "hparam_version = hyperparameters['version']\n",
    "loss = hyperparameters['loss']\n",
    "optimizer = hyperparameters['optimizer']\n",
    "model_parameters = hyperparameters['model_parameters']\n",
    "model = model_0(**model_parameters)\n",
    "path_to_ckpt = os.path.join('logs', 'models', 'model_selected', '_'.join(['version', str(hparam_version)]),\n",
    "                            'runs', str(run_number), 'checkpoints')\n",
    "ckpt = os.path.join(path_to_ckpt, 'cp-30.ckpt')\n",
    "model.load_weights(ckpt)\n",
    "print('Restored model from: {}'.format(ckpt))  \n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_test = model.evaluate(X_test, y_test, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_test = model.predict(X_test, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_test = (m_preds_test[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_test = y_test['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_test = np.mean(np.equal(m_preds_up_test, labels_up_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n",
      "Loss on train dataset: 0.000738731865831522\n",
      "Loss on validation dataset: 0.0007058223036158149\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.525910931174089\n",
      "Accuracy on validation dataset: 0.5101214574898786\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(None, metrics_train=metrics_train, metrics_val=metrics_test, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Saving Model for Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: []\n",
      "Visible GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions \n",
    "def write_hparams(model_name, hparams, verbose=True):\n",
    "    version_number = hparams['version']\n",
    "    path = os.path.join('logs', 'models', model_name, '_'.join(['version', str(version_number)]))\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'hparams.pickle'), 'wb') as f:\n",
    "        pickle.dump(hparams, f)\n",
    "    if verbose:\n",
    "        return print('Saved hyperparameters to file: {}'.format(path))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def build_compiled_model(build_model, model_name, hparams, metrics, run_number):\n",
    "    hparam_version = hparams['version']\n",
    "    loss = hparams['loss']\n",
    "    optimizer = hparams['optimizer']\n",
    "    model_parameters = hparams['model_parameters']\n",
    "    model = build_model(**model_parameters)\n",
    "    path_to_ckpt = os.path.join('logs', 'models', model_name, '_'.join(['version', str(hparam_version)]),\n",
    "                               'runs', str(run_number), 'checkpoints')\n",
    "    if os.path.exists(path_to_ckpt):\n",
    "        latest = tf.train.latest_checkpoint(path_to_ckpt)\n",
    "        model.load_weights(latest)\n",
    "        print('Restored model from: {}'.format(latest))  \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    target = targets['_'.join([ts_fname, 'target'])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([ts_fname, 'target']):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        if history != None:\n",
    "            plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hyperparameters to file: logs/models/model_deployment/version_final\n"
     ]
    }
   ],
   "source": [
    "# Defining and Saving Hyperparameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "model_params = {'lstm_layer_units': 256, 'vocab': vocab, 'doc_embedding_size': 200, 'output_bias_init': 0}\n",
    "training_params = {'batch_size': 4, 'epochs': 30}\n",
    "model_version = 'final'\n",
    "hyperparameters = {'model_parameters': model_params, 'training_parameters': training_params,\n",
    "                   'loss': LOSS, 'optimizer': OPTIMIZER, 'version': model_version}\n",
    "write_hparams('model_deployment', hyperparameters)\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-59e8cae016af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_deployment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-1be5f255ae8d>\u001b[0m in \u001b[0;36mbuild_compiled_model\u001b[0;34m(build_model, model_name, hparams, metrics, run_number)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Restored model from: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \"\"\"\n\u001b[0;32m-> 1139\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m       \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_is_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m   return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n\u001b[0m\u001b[1;32m   1450\u001b[0m           filepath.endswith('.hdf5'))\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "model = build_compiled_model(model_0, 'model_deployment', hyperparameters, metrics=metrics, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on full train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-77858483f678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m model_history = model.fit(X_train, y_train, **training_parameters, validation_data=(X_test, y_test),\n\u001b[0m\u001b[1;32m     25\u001b[0m                           initial_epoch=initial_epoch, callbacks=callbacks)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting up callbacks\n",
    "path_to_run = os.path.join('logs', 'models', 'model_deployment',\n",
    "                            '_'.join(['version', str(hyperparameters['version'])]),\n",
    "                            'runs', str(run_number))\n",
    "path_to_ckpts = os.path.join(path_to_run, 'checkpoints')\n",
    "if not os.path.exists(path_to_ckpts):\n",
    "    os.makedirs(path_to_ckpts)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path_to_ckpts, 'cp-{epoch}.ckpt'),\n",
    "                                                 verbose=1, save_weights_only=True, period=2)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=os.path.join(path_to_run, 'history.log'), append=True)\n",
    "callbacks = [cp_callback, csv_logger]\n",
    "\n",
    "# Unpacking model training parameters\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "\n",
    "# Fetching last trained epoch if the model was reloaded\n",
    "latest_ckpt = tf.train.latest_checkpoint(path_to_ckpts)\n",
    "if latest_ckpt is not None:\n",
    "    initial_epoch = re.findall(r'cp-(\\d+)\\.ckpt', latest_ckpt)[0]\n",
    "    initial_epoch = int(initial_epoch) - 1\n",
    "else:\n",
    "    initial_epoch = 0\n",
    "\n",
    "model_history = model.fit(X, y, **training_parameters, validation_data=(X_test, y_test),\n",
    "                          initial_epoch=initial_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_test = model.evaluate(X_test, y_test, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_test = model.predict(X_test, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_test = (m_preds_test[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_test = y_test['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_test = np.mean(np.equal(m_preds_up_test, labels_up_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 0.0006485506063616562\n",
      "Loss on validation dataset: 0.0007747489441738396\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.5464237516869096\n",
      "Accuracy on validation dataset: 0.5040485829959515\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(model_history, metrics_train=metrics_train, metrics_val=metrics_test, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /media/Data/Programs/FinTech/models/model_0/assets\n"
     ]
    }
   ],
   "source": [
    "m.save(os.path.join(path_to_models, 'model_0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLAH OLD CODE TO REVIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: []\n",
      "Visible GPUs: []\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/Data/Programs/FinTech/data/dataset.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b087cdaee6ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Loading Full Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/Data/Programs/FinTech/data/dataset.pickle'"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_print_model_stats(model, path, model_name):\n",
    "    m = model()\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    fname = os.path.join(path, model_name, model_name)\n",
    "    tf.keras.utils.plot_model(m, fname + '.png', show_shapes=True, expand_nested=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "    return m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "document_embedder (Model)       (None, 100)          2911400     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 5, 100)       0           document_embedder[1][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 101)       0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns_target (D (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,928,585\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,751,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model\n",
    "\n",
    "gen_print_model_stats(model_0, os.path.join('logs', 'models'), 'model_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of Model:\n",
    "![title](logs/models/model_0/model_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Testing if when initialized properly, the model is equivalent to the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel in order to fully clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def baseline_model(output_bias_init):\n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "        \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    output_layer = tf.keras.layers.Dense(1, kernel_initializer='zeros', bias_initializer=output_bias_init, \n",
    "                                         name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(inputs['log_adj_daily_returns'])}\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='baseline_model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing baseline equivalence of model when initialized properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline_equivalence(model, baseline_model, batch_size, X, y):\n",
    "    print('Testing if the untrained model when initialized properly is equivalent to the baseline model')\n",
    "    output_bias_init = 0\n",
    "    \n",
    "    baseline_m = build_compiled_model(baseline_model, {'output_bias_init': output_bias_init},\n",
    "                                      loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    baseline_results = baseline_m.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    hparams = {'output_kernel_init': 'zeros', 'output_bias_init': output_bias_init}\n",
    "    m1 = build_compiled_model(model, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m1_results = m1.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    assert m1_results == baseline_results\n",
    "    \n",
    "    return print('Passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if the untrained model when initialized properly is equivalent to the baseline model\n",
      "Passed\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "test_baseline_equivalence(model_0, baseline_model, batch_size=8, X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Testing if the model trained on real data performs better than the model trained on null data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Null Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Turns On and Off the GPU\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def null_feature(feature_name, feature):\n",
    "    if (feature_name == 'log_adj_daily_returns'):\n",
    "        null_feature = np.zeros(shape=feature.shape, dtype=feature.dtype)\n",
    "    elif (feature_name == 'docs'):\n",
    "        null_feature = np.ones(shape=feature.shape, dtype=feature.dtype)\n",
    "    return null_feature\n",
    "\n",
    "def null_features(features):\n",
    "    return {fname: null_feature(fname, features[fname]) for fname in features.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on null features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 17s 1s/sample - loss: 0.1680\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 0.0705\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 11s 662ms/sample - loss: 0.0228\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 0.0074\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 11s 679ms/sample - loss: 0.0069\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 11s 681ms/sample - loss: 0.0049\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 11s 662ms/sample - loss: 0.0013\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 11s 665ms/sample - loss: 0.0032\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 11s 662ms/sample - loss: 5.0525e-04\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 0.0012\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 6.2191e-04\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 2.8314e-04\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 4.7738e-04\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 11s 670ms/sample - loss: 1.1357e-04\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 2.1562e-04\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 9.2070e-05\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 11s 662ms/sample - loss: 1.5818e-04\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 11s 664ms/sample - loss: 1.5303e-04\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 1.1364e-04\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.0700e-04\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 11s 666ms/sample - loss: 9.3560e-05\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 11s 669ms/sample - loss: 1.1064e-04\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 9.4316e-05\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 1.0429e-04\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 1.0765e-04\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 1.1052e-04\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.0012e-04\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 9.9180e-05\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 9.9605e-05\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 9.5424e-05\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 9.9834e-05\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 11s 666ms/sample - loss: 9.8583e-05\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.2159e-04\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 9.8693e-05\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 1.0421e-04\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 11s 677ms/sample - loss: 9.6019e-05\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.1077e-04\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 9.6628e-05\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 11s 662ms/sample - loss: 1.1066e-04\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 1.1321e-04\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 1.0138e-04\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 11s 656ms/sample - loss: 1.0146e-04\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.0040e-04\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 9.9917e-05\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.1755e-04\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 9.8252e-05\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.0350e-04\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 9.8571e-05\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.0518e-04\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 11s 667ms/sample - loss: 1.0561e-04\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.0119e-04\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.0185e-04\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 11s 670ms/sample - loss: 1.1464e-04\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 11s 669ms/sample - loss: 9.6109e-05\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 1.0694e-04\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.1497e-04\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.0819e-04\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 11s 669ms/sample - loss: 1.1657e-04\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.1464e-04\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.0263e-04\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.0898e-04\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 11s 660ms/sample - loss: 1.2167e-04\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 9.6966e-05\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.1528e-04\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 11s 666ms/sample - loss: 1.2438e-04\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.0383e-04\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 11s 665ms/sample - loss: 1.1103e-04\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 11s 670ms/sample - loss: 1.4039e-04\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 11s 665ms/sample - loss: 1.1665e-04\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.2334e-04\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 10s 655ms/sample - loss: 1.2858e-04\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 8.4309e-05\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.1758e-04\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.1112e-04\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 11s 668ms/sample - loss: 1.3765e-04\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 1.0446e-04\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.1741e-04\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 11s 664ms/sample - loss: 1.2902e-04\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.3790e-04\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 9.8965e-05\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 11s 664ms/sample - loss: 1.3177e-04\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.1830e-04\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.0685e-04\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.2423e-04\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.3833e-04\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 8.9266e-05\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 1.3946e-04\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 11s 664ms/sample - loss: 2.0808e-04\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 11s 659ms/sample - loss: 1.7326e-04\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.3658e-04\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.2803e-04\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 11s 661ms/sample - loss: 1.1496e-04\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 11s 663ms/sample - loss: 1.0008e-04\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 11s 667ms/sample - loss: 9.8268e-05\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 11s 683ms/sample - loss: 1.0947e-04\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 11s 668ms/sample - loss: 9.0863e-05\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.0887e-04\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.4399e-04\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 11s 658ms/sample - loss: 1.0820e-04\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 11s 657ms/sample - loss: 1.0724e-04\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "X_null = null_features(X)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "output_bias_init = 0\n",
    "hparams = {'output_bias_init': output_bias_init}\n",
    "\n",
    "m = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "m_history = m.fit(X_null, y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory issue is weird because I'll reset the kernel (which kills the python process reseting the GPU memory), run the same code, and have the GPU run out of memory about 80% of the time I rerun the same code. The longer I wait between sessions using the GPU, the more likely I won't encounter the issue. *Suprisingly when I train on smaller datasets I encounter the error usually in the first batch, but when I train on larger datasets, it usually doesnt show up in the first batch.* When the error is not raised in the first batch, the batch number it shows up in varies from run to run even when I have all possible random number generators seeded and am using the same dataset. When seeding all possible random number generators running without the GPU, I get reproducible metrics, and the training never crashes, but when introducing the GPU I introduce this memory error. It appears to me that the problem lies with the GPU, since my since my code trains perfectly well on the CPU and produces reproducible results. Hypothesis: Maybe the amount of memory the GPU needs to allocate to perform calculations for my code differs from run to run even when the calculation performed is still the mathematically the same (or very similar). ie run 1: 2+2 requires 1 byte to compute, run 2: 2+2 requires 3.5 bytes to compute. IDK.\n",
    "When I do successfully train the model on GPU I get the same metrics I get when training on the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_results = m.evaluate(X, y, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on zeroed features.\n",
      "\n",
      "Loss for Model: 0.005705256695364369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on zeroed features.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(m_results))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics, callbacks=callbacks)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 6s 403ms/sample - loss: 0.0218\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 38ms/sample - loss: 0.0342\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 0.0128\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 0.0099\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 0.0036\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 0.0048\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 0.0021\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 0.0021\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 0.0012\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 5.5630e-04\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 9.6478e-05\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.5071e-04\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 1.6307e-04\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.4383e-04\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.8784e-05\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.5518e-05\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 4.7594e-05\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 3.2327e-05\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 2.4742e-05\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.9790e-05\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 2.4248e-05\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.3959e-05\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 37ms/sample - loss: 1.4658e-05\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 1.5943e-05\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.2470e-05\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 2.0168e-05\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.9839e-06\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.7413e-05\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.1212e-05\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 9.5130e-06\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 9.9027e-06\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 8.4563e-06\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 9.8316e-06\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 8.3967e-06\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.3948e-06\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 8.1765e-06\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 8.1751e-06\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.1033e-06\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.1980e-06\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 7.6340e-06\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.3185e-06\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 7.9360e-06\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.2373e-06\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.6822e-06\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.1031e-06\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.3988e-06\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.9496e-06\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.7039e-06\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.5580e-06\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.8995e-06\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 1s 37ms/sample - loss: 8.3962e-06\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 5.4952e-06\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 8.8956e-06\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.8822e-06\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.2515e-06\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.3100e-06\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.6963e-06\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.2039e-06\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.1002e-06\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 8.2214e-06\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.2963e-06\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.5227e-06\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.8209e-06\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.7315e-06\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.0719e-05\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 5.8963e-06\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.4583e-06\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.6142e-06\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 7.1302e-06\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.0487e-06\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.1209e-06\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 8.0017e-06\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.0959e-05\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 9.8470e-06\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.8393e-06\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.1091e-06\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 4.9748e-06\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 5.2391e-06\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.2635e-06\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 4.8800e-06\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.6184e-06\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.6246e-06\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 8.1640e-06\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 4.7300e-06\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.2181e-06\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.3677e-06\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.5150e-06\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 5.0972e-06\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.6562e-06\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 9.6998e-06\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 6.0674e-06\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.0924e-06\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 9.5406e-06\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 1.4936e-05\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 1.2389e-05\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 1s 35ms/sample - loss: 7.4368e-06\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 7.6411e-06\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 6.2980e-06\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.4750e-06\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 1s 36ms/sample - loss: 5.2687e-06\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=16, seed=seed)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "output_bias_init = 0\n",
    "hparams = {'output_bias_init': output_bias_init}\n",
    "\n",
    "m = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "m_history = m.fit(X, y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_results = m.evaluate(X, y, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on actual data.\n",
      "\n",
      "Loss for Model: 4.721949103725365e-06\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on actual data.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(m_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks out. The model when trained on actual data has a smaller loss than when trained on the null features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Testing if the model can overfit on a small sample of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions    \n",
    "def build_compiled_model(build_model, hparams, loss, optimizer, metrics):\n",
    "    model = build_model(**hparams)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# Model Agnostic Parameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "METRICS = []\n",
    "CALLBACKS = None\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def sample_dataset(dataset, sample_size, seed=None):\n",
    "    if (isinstance(sample_size, float) and (sample_size == 1)) or (isinstance(sample_size, int) and sample_size == len(dataset[1][next(iter(dataset[1].keys()))])):\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds, not_ds = split_dataset(dataset, train_size=sample_size, random_state=seed)\n",
    "    return ds\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    target = targets['_'.join([ts_fname, 'target'])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([ts_fname, 'target']):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtraining model on a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_small_sample(model, batch_size, epochs, X_small, y_small, verbose):\n",
    "    print('Testing if model can overfit on a small sample of data')\n",
    "    output_bias_init = 0\n",
    "    hparams = {'output_bias_init': output_bias_init}\n",
    "    \n",
    "    m = build_compiled_model(model, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "    m_pred_untrained = m.predict(X_small, batch_size=batch_size)\n",
    "    m_history = m.fit(X_small, y_small, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "    m_pred_trained = m.predict(X_small, batch_size=batch_size)\n",
    "    print()\n",
    "    \n",
    "    print('Plotting Error against Sample for Before Training, and After Training on the Small Dataset')\n",
    "    plot_outputs_errors(m_pred_untrained, y_small, 'Before Training')\n",
    "    plot_outputs_errors(m_pred_trained, y_small, 'After Training')\n",
    "    print()\n",
    "    \n",
    "    print('Plotting Each Sample\\'s Time Series for Log Adjusted Daily Returns')\n",
    "    plot_ts_samples_ba(X_small, y_small, m_pred_untrained, m_pred_trained, 'log_adj_daily_returns')\n",
    "    \n",
    "    metrics = ['loss'] + list(map(lambda met: met.name, METRICS))\n",
    "    for met in metrics:\n",
    "        plot_metric(m_history, metric=met)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if model can overfit on a small sample of data\n",
      "\n",
      "Plotting Error against Sample for Before Training, and After Training on the Small Dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting Each Sample's Time Series for Log Adjusted Daily Returns\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Target Value: -0.0035051436379571754\n",
      "Predicted Target Value Before Training: -0.08434920012950897\n",
      "Predicted Target Value After Training: -0.0035051372833549976\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Target Value: -0.010760221939794423\n",
      "Predicted Target Value Before Training: -0.13711243867874146\n",
      "Predicted Target Value After Training: -0.010760234668850899\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_small, y_small = sample_dataset(train_dataset, sample_size=2, seed=seed)\n",
    "overfit_small_sample(model_0, batch_size=2, epochs=500, X_small=X_small, y_small=y_small, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots its clear that our model has overfit on our small sample of the dataset which is the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = 42\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f) \n",
    "     \n",
    "# Defining Helper Functions \n",
    "def write_hparams(model_name, hparams, verbose=True):\n",
    "    version_number = hparams['version']\n",
    "    path = os.path.join('logs', 'models', model_name, '_'.join(['version', str(version_number)]))\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'hparams.pickle'), 'wb') as f:\n",
    "        pickle.dump(hparams, f)\n",
    "    if verbose:\n",
    "        return print('Saved hyperparameters to file: {}'.format(path))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def build_compiled_model(build_model, model_name, hparams, metrics, run_number):\n",
    "    hparam_version = hparams['version']\n",
    "    loss = hparams['loss']\n",
    "    optimizer = hparams['optimizer']\n",
    "    model_parameters = hparams['model_parameters']\n",
    "    model = build_model(**model_parameters)\n",
    "    path_to_ckpt = os.path.join('logs', 'models', model_name, '_'.join(['version', str(hparam_version)]),\n",
    "                               'runs', str(run_number), 'checkpoints')\n",
    "    if os.path.exists(path_to_ckpt):\n",
    "        latest = tf.train.latest_checkpoint(path_to_ckpt)\n",
    "        model.load_weights(latest)\n",
    "        print('Restored model from: {}'.format(latest))  \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    target = targets['_'.join([ts_fname, 'target'])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([ts_fname, 'target']):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train dataset into train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 5557\n",
      "Validation set size: 1853\n",
      "Test set size: 2470\n"
     ]
    }
   ],
   "source": [
    "train, val = split_dataset(train_dataset, train_size=0.75, random_state=seed)\n",
    "X_train, y_train = train\n",
    "X_val, y_val = val\n",
    "\n",
    "print('Train set size: {}'.format(len(y_train['log_adj_daily_returns_target'])))\n",
    "print('Validation set size: {}'.format(len(y_val['log_adj_daily_returns_target'])))\n",
    "print('Test set size: {}'.format(len(test_dataset[1]['log_adj_daily_returns_target'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hyperparameters to file: logs/models/model_0/version_0\n"
     ]
    }
   ],
   "source": [
    "# Defining and Saving Hyperparameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "model_params = {'lstm_layer_units': 256, 'vocab': vocab, 'doc_embedding_size': 200, 'output_bias_init': 0}\n",
    "training_params = {'batch_size': 4, 'epochs': 1500}\n",
    "model_version = 0\n",
    "hyperparameters = {'model_parameters': model_params, 'training_parameters': training_params,\n",
    "                   'loss': LOSS, 'optimizer': OPTIMIZER, 'version': model_version}\n",
    "write_hparams('model_0', hyperparameters)\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from: logs/models/model_0/version_0/runs/0/checkpoints/cp-100.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = build_compiled_model(model_0, 'model_0', hyperparameters, metrics=metrics, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 5557 samples\n",
      "Epoch 100/1500\n",
      "5557/5557 [==============================] - 252s 45ms/sample - loss: 3.6727e-04\n",
      "Epoch 101/1500\n",
      "5557/5557 [==============================] - 268s 48ms/sample - loss: 3.6627e-04\n",
      "Epoch 102/1500\n",
      "5557/5557 [==============================] - 261s 47ms/sample - loss: 3.6860e-04\n",
      "Epoch 103/1500\n",
      "5557/5557 [==============================] - 268s 48ms/sample - loss: 3.6345e-04\n",
      "Epoch 104/1500\n",
      "5557/5557 [==============================] - 252s 45ms/sample - loss: 3.6142e-04\n",
      "Epoch 105/1500\n",
      "5557/5557 [==============================] - 242s 44ms/sample - loss: 3.5262e-04\n",
      "Epoch 106/1500\n",
      "5557/5557 [==============================] - 242s 44ms/sample - loss: 3.5099e-04\n",
      "Epoch 107/1500\n",
      "5557/5557 [==============================] - 240s 43ms/sample - loss: 3.4022e-04\n",
      "Epoch 108/1500\n",
      "5557/5557 [==============================] - 243s 44ms/sample - loss: 3.4392e-04\n",
      "Epoch 109/1500\n",
      "5556/5557 [============================>.] - ETA: 0s - loss: 3.4236e-04\n",
      "Epoch 00109: saving model to logs/models/model_0/version_0/runs/0/checkpoints/cp-109.ckpt\n",
      "5557/5557 [==============================] - 242s 43ms/sample - loss: 3.4250e-04\n",
      "Epoch 110/1500\n",
      "5557/5557 [==============================] - 241s 43ms/sample - loss: 3.3492e-04\n",
      "Epoch 111/1500\n",
      "5557/5557 [==============================] - 241s 43ms/sample - loss: 3.3205e-04\n",
      "Epoch 112/1500\n",
      "5557/5557 [==============================] - 240s 43ms/sample - loss: 3.2500e-04\n",
      "Epoch 113/1500\n",
      "5557/5557 [==============================] - 239s 43ms/sample - loss: 3.2471e-04\n",
      "Epoch 114/1500\n",
      "5557/5557 [==============================] - 239s 43ms/sample - loss: 3.2305e-04\n",
      "Epoch 115/1500\n",
      "5557/5557 [==============================] - 241s 43ms/sample - loss: 3.2281e-04\n",
      "Epoch 116/1500\n",
      "5557/5557 [==============================] - 248s 45ms/sample - loss: 3.2442e-04\n",
      "Epoch 117/1500\n",
      "5557/5557 [==============================] - 243s 44ms/sample - loss: 3.1100e-04\n",
      "Epoch 118/1500\n",
      "5557/5557 [==============================] - 237s 43ms/sample - loss: 3.1769e-04\n",
      "Epoch 119/1500\n",
      "5556/5557 [============================>.] - ETA: 0s - loss: 3.0880e-04\n",
      "Epoch 00119: saving model to logs/models/model_0/version_0/runs/0/checkpoints/cp-119.ckpt\n",
      "5557/5557 [==============================] - 238s 43ms/sample - loss: 3.0875e-04\n",
      "Epoch 120/1500\n",
      "5557/5557 [==============================] - 238s 43ms/sample - loss: 3.0597e-04\n",
      "Epoch 121/1500\n",
      "5557/5557 [==============================] - 244s 44ms/sample - loss: 3.0172e-04\n",
      "Epoch 122/1500\n",
      "5557/5557 [==============================] - 250s 45ms/sample - loss: 3.0378e-04\n",
      "Epoch 123/1500\n",
      "5557/5557 [==============================] - 249s 45ms/sample - loss: 3.0130e-04\n",
      "Epoch 124/1500\n",
      "5557/5557 [==============================] - 249s 45ms/sample - loss: 3.0039e-04\n",
      "Epoch 125/1500\n",
      "5557/5557 [==============================] - 249s 45ms/sample - loss: 3.0341e-04\n",
      "Epoch 126/1500\n",
      "5557/5557 [==============================] - 251s 45ms/sample - loss: 2.8836e-04\n",
      "Epoch 127/1500\n",
      "5557/5557 [==============================] - 249s 45ms/sample - loss: 2.9415e-04\n",
      "Epoch 128/1500\n",
      "5557/5557 [==============================] - 244s 44ms/sample - loss: 2.8927e-04\n",
      "Epoch 129/1500\n",
      "5556/5557 [============================>.] - ETA: 0s - loss: 2.8481e-04\n",
      "Epoch 00129: saving model to logs/models/model_0/version_0/runs/0/checkpoints/cp-129.ckpt\n",
      "5557/5557 [==============================] - 240s 43ms/sample - loss: 2.8476e-04\n",
      "Epoch 130/1500\n",
      "5557/5557 [==============================] - 239s 43ms/sample - loss: 2.8102e-04\n",
      "Epoch 131/1500\n",
      "5557/5557 [==============================] - 239s 43ms/sample - loss: 2.8303e-04\n",
      "Epoch 132/1500\n",
      "5557/5557 [==============================] - 247s 44ms/sample - loss: 2.7809e-04\n",
      "Epoch 133/1500\n",
      "5557/5557 [==============================] - 244s 44ms/sample - loss: 2.7471e-04\n",
      "Epoch 134/1500\n",
      "5557/5557 [==============================] - 241s 43ms/sample - loss: 2.7443e-04\n",
      "Epoch 135/1500\n",
      "5557/5557 [==============================] - 240s 43ms/sample - loss: 2.7028e-04\n",
      "Epoch 136/1500\n",
      "5557/5557 [==============================] - 239s 43ms/sample - loss: 2.6983e-04\n",
      "Epoch 137/1500\n",
      "5557/5557 [==============================] - 240s 43ms/sample - loss: 2.6372e-04\n",
      "Epoch 138/1500\n",
      "5557/5557 [==============================] - 240s 43ms/sample - loss: 2.6291e-04\n",
      "Epoch 139/1500\n",
      "5556/5557 [============================>.] - ETA: 0s - loss: 2.6652e-04\n",
      "Epoch 00139: saving model to logs/models/model_0/version_0/runs/0/checkpoints/cp-139.ckpt\n",
      "5557/5557 [==============================] - 244s 44ms/sample - loss: 2.6648e-04\n",
      "Epoch 140/1500\n",
      "5557/5557 [==============================] - 239s 43ms/sample - loss: 2.6407e-04\n",
      "Epoch 141/1500\n",
      "5557/5557 [==============================] - 238s 43ms/sample - loss: 2.6351e-04\n",
      "Epoch 142/1500\n",
      "5557/5557 [==============================] - 242s 44ms/sample - loss: 2.5077e-04\n",
      "Epoch 143/1500\n",
      "5557/5557 [==============================] - 242s 44ms/sample - loss: 2.4700e-04\n",
      "Epoch 144/1500\n",
      "5496/5557 [============================>.] - ETA: 2s - loss: 2.5496e-04"
     ]
    }
   ],
   "source": [
    "# Setting up callbacks\n",
    "path_to_run = os.path.join('logs', 'models', 'model_0',\n",
    "                            '_'.join(['version', str(hyperparameters['version'])]),\n",
    "                            'runs', str(run_number))\n",
    "path_to_ckpts = os.path.join(path_to_run, 'checkpoints')\n",
    "if not os.path.exists(path_to_ckpts):\n",
    "    os.makedirs(path_to_ckpts)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path_to_ckpts, 'cp-{epoch}.ckpt'),\n",
    "                                                 verbose=1, save_weights_only=True, period=10)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=os.path.join(path_to_run, 'history.log'), append=True)\n",
    "callbacks = [cp_callback, csv_logger]\n",
    "\n",
    "# Unpacking model training parameters\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "\n",
    "# Fetching last trained epoch if the model was reloaded\n",
    "latest_ckpt = tf.train.latest_checkpoint(path_to_ckpts)\n",
    "if latest_ckpt is not None:\n",
    "    initial_epoch = re.findall(r'cp-(\\d+)\\.ckpt', latest_ckpt)[0]\n",
    "    initial_epoch = int(initial_epoch) - 1\n",
    "else:\n",
    "    initial_epoch = 0\n",
    "\n",
    "model_history = model.fit(X_train, y_train, **training_parameters,\n",
    "                          initial_epoch=initial_epoch, callbacks=callbacks) # validation_data=(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "metrics_train = m.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_val = m.evaluate(X_val, y_val, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = m.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_val = m.predict(X_val, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_val = (m_preds_val[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_val = y_val['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_val = np.mean(np.equal(m_preds_up_val, labels_up_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 4.989523747099156e-06\n",
      "Loss on validation dataset: 0.0013666351001578641\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.953\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(m_history, metrics_train=metrics_train, metrics_val=metrics_val, metrics_names=m.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "#print('Accuracy on validation dataset: {}'.format(up_cls_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.13168225e-03  1.37693441e-03 -2.94649532e-03 -1.56740499e-04\n",
      "  4.42081054e-05 -3.45404711e-04  5.36118984e-03  9.30834364e-04\n",
      "  5.31926171e-04  1.44887850e-03 -2.47901282e-04 -3.65341622e-04\n",
      "  3.56802002e-04  7.11967797e-04 -1.27560368e-03  8.37871121e-04\n",
      " -1.34503763e-04  2.69293435e-03  9.56341079e-04 -1.14950259e-03\n",
      "  2.05272523e-03 -1.90569279e-04  1.02836398e-03  1.51925673e-04\n",
      " -2.43840400e-03  3.17201876e-04  2.14913129e-04  4.67219653e-03\n",
      " -6.07072954e-04  1.27161215e-03 -1.61569804e-04 -2.18755926e-03\n",
      "  5.60527626e-04 -2.99900742e-04 -2.93392637e-03 -1.29017887e-03\n",
      "  1.24451332e-03 -2.86464556e-03  2.10590779e-03  3.58878227e-04\n",
      " -6.47977049e-04  5.22670123e-04  4.18972464e-05  2.25678377e-04\n",
      "  1.22242156e-03 -2.12826496e-03  5.77997468e-04 -8.84464393e-04\n",
      "  6.23337677e-04  1.60486713e-04 -2.85154816e-03  1.06104919e-03\n",
      "  2.38532897e-04  7.96082155e-03  2.11155502e-03 -5.39792498e-03\n",
      "  7.89332936e-04  1.43231601e-04  7.30393749e-03 -1.41602025e-03\n",
      " -1.88576120e-03 -1.42429810e-03  6.49458636e-04  6.37788246e-05\n",
      " -3.69786557e-04 -3.09324344e-03 -1.15777900e-03  1.38011443e-03\n",
      "  6.16462159e-04 -1.21442840e-03  2.57591056e-04  6.03845480e-04\n",
      " -3.36722542e-03 -3.10556482e-05  1.00736777e-04 -2.21509319e-03\n",
      "  1.80203280e-03 -3.34799551e-04 -1.10244216e-03  5.83353028e-04\n",
      "  1.77297513e-03 -1.24924146e-03  1.78444616e-04  6.79544437e-04\n",
      "  1.05300979e-03 -1.30705439e-03 -4.12220491e-04 -5.86154091e-04\n",
      "  1.25110586e-03 -3.70033414e-05 -1.14959892e-04 -2.69315378e-04\n",
      " -4.17032678e-04  1.20571562e-03  1.28871050e-03  4.91739093e-04\n",
      "  5.56761289e-04  3.63470609e-03  1.48962716e-03  1.01311482e-03\n",
      "  1.04369750e-03 -3.02955543e-03 -1.04856082e-03 -1.36942832e-03\n",
      "  1.41923241e-03  6.85254000e-04  1.25808362e-03  1.93990949e-03\n",
      " -6.38294929e-04  9.11616140e-04 -5.08860811e-04  1.22533958e-03\n",
      "  7.76490414e-04 -3.57342275e-04  2.04866067e-04  5.94070211e-04\n",
      "  1.55110284e-03  2.74504789e-03 -3.49379158e-03 -3.88630069e-04\n",
      " -3.61171708e-05  2.28624080e-03  5.47172036e-03  1.21651781e-03\n",
      " -6.83813213e-03  1.79701602e-04 -1.64050353e-03  2.42330213e-04\n",
      "  5.80031133e-04 -6.13868648e-04  1.87487529e-03 -1.42660656e-04\n",
      "  1.77707366e-03 -1.62906917e-04  9.10412606e-04 -1.52732095e-03\n",
      " -3.52673846e-04 -5.07628313e-04 -1.02764039e-04  9.67115791e-04\n",
      "  1.13652593e-03  1.43870066e-03  4.04625457e-04 -1.55627735e-03\n",
      "  1.05875298e-03  5.98375125e-05  1.03022795e-04  1.02832545e-03\n",
      "  1.76371275e-03  2.01409950e-03 -6.76311304e-04 -6.75368921e-04\n",
      " -2.00167986e-03  6.47181692e-05  5.09263458e-04 -7.25146185e-04\n",
      "  2.80400285e-04  2.52836836e-03 -2.40375955e-04  1.54959732e-03\n",
      "  4.79299039e-04  1.08265242e-03  1.24488080e-03 -2.46048302e-03\n",
      "  3.81398384e-04  1.93019492e-03  9.98782777e-04  2.85754784e-03\n",
      " -7.90177056e-03  1.49356742e-03  1.20167782e-03  2.35543163e-03\n",
      " -8.58881312e-05 -1.06223804e-03  5.94216807e-04  6.12194126e-03\n",
      " -9.89366725e-04 -2.12914028e-04  5.93073686e-04 -3.83132187e-04\n",
      "  1.86615019e-03  2.90703793e-03 -2.63833878e-03 -9.44711846e-04\n",
      "  9.78457776e-05 -9.45987389e-04 -1.81395019e-03  1.35212843e-03\n",
      "  3.25699464e-03  1.67655315e-04 -3.26721618e-04  1.91998836e-04\n",
      "  1.05795023e-03 -3.40441518e-04  3.02281175e-04 -7.82273823e-05\n",
      "  5.73194794e-03  1.74988537e-03  4.15575676e-03 -2.05920188e-03\n",
      "  1.54885359e-03 -1.92629103e-03  4.44028306e-04  7.46365560e-04\n",
      "  3.44239125e-03  1.12060051e-03 -3.30125720e-04  1.32169558e-03\n",
      "  1.55728758e-03  1.58011734e-03  6.53255265e-04  3.39510988e-04\n",
      " -7.63733976e-03 -2.22690442e-03  4.17374987e-03 -3.87017754e-03\n",
      "  2.24229102e-03 -2.47935248e-03 -9.21699883e-04 -5.85790748e-05\n",
      "  9.58112349e-04 -8.90847257e-04  1.37532128e-03  1.78560988e-03\n",
      " -1.10965033e-04  3.36967826e-03 -9.45832790e-04 -7.81424138e-04\n",
      " -1.37244267e-03  2.29285741e-03 -9.90345088e-05  1.68694336e-03\n",
      "  1.36359685e-03 -2.56591949e-03 -1.63254982e-03 -1.47790704e-04\n",
      " -2.72691415e-04  7.64232771e-04 -1.98659505e-03 -3.92449717e-04\n",
      "  1.54535156e-03 -3.84412616e-03 -5.72066642e-05  1.36949975e-03\n",
      "  1.21158797e-03 -1.76890981e-03  1.04582496e-03  7.64388078e-04\n",
      "  2.25546444e-03  1.76436710e-04 -1.61851835e-03  2.76410401e-03\n",
      " -1.63303118e-04 -1.81825786e-03  9.83957632e-04 -8.68794684e-04\n",
      " -3.14351981e-04 -2.68210297e-03  3.00594330e-03  4.72985674e-04\n",
      "  1.36128540e-03  2.31093727e-05  2.42182249e-03 -7.53693791e-03\n",
      "  1.42364922e-03  3.20252285e-03  7.74011177e-04 -1.26854352e-03\n",
      " -4.60041955e-03 -7.63136773e-04  1.95166379e-04 -2.76263565e-03\n",
      "  5.73160342e-04  2.69865283e-03  5.58521225e-04 -6.81644685e-04\n",
      "  1.46112208e-04 -3.91212528e-04  7.30429830e-03 -2.37530042e-03\n",
      "  2.58468642e-03  2.86620330e-03  1.94518549e-03  7.54412570e-04\n",
      " -1.33810719e-03 -1.54837821e-03  2.93142091e-04  1.64460044e-03\n",
      "  7.49089497e-05  6.50139495e-04 -2.17192527e-03 -4.43822590e-03\n",
      " -7.49135408e-04  7.57665217e-05 -1.85778428e-03  1.56121962e-03\n",
      " -2.25926667e-04  3.94733488e-04  1.01014137e-03  1.34977516e-03\n",
      "  6.42217817e-04  5.92886634e-04  2.08431321e-03  7.10148909e-03\n",
      "  2.26064471e-03 -4.09048051e-04  2.02406031e-04  2.46309479e-04\n",
      " -3.17292081e-03 -1.38515698e-03  7.25946745e-04 -1.06539717e-03\n",
      " -3.35141199e-03 -1.14854538e-03 -7.62597242e-04 -1.46740350e-03\n",
      "  7.40246797e-04 -1.43129626e-03  7.03319205e-04  3.38857922e-04\n",
      " -1.21015589e-03  9.46770426e-05  4.47277534e-04  4.66653445e-04\n",
      "  3.42729034e-04  6.97402223e-03 -6.25785994e-03 -1.96755439e-04\n",
      " -1.40462875e-03  2.79741779e-03  1.26453015e-03  2.17688105e-04\n",
      "  2.46563047e-04  2.28166059e-04 -9.78679356e-04  2.52464827e-04\n",
      "  1.96573534e-04 -6.79990288e-03 -1.53658324e-03 -5.39179762e-05\n",
      "  1.14056554e-03  4.80440665e-04  2.57937457e-04  2.43244886e-03\n",
      " -1.49367559e-03  2.48305444e-04  3.10260400e-03  7.52279936e-04\n",
      " -9.72978932e-04  7.37354829e-04 -2.46878883e-03  3.68777248e-04\n",
      "  1.13363523e-03  3.07265155e-03  7.74256565e-05  2.29633099e-03\n",
      "  1.69065129e-03 -1.82369779e-04 -1.47765612e-03 -1.12542343e-03\n",
      "  2.03993090e-04 -4.52824983e-04  1.47076533e-04  1.24770952e-03\n",
      " -1.69064084e-03  3.56958859e-03 -3.26106398e-04  1.65959664e-03\n",
      " -7.79402768e-04 -2.69357709e-03  2.56791425e-04 -1.09772796e-03\n",
      "  4.03829054e-04  9.64107138e-05  7.54153073e-04 -6.24074969e-04\n",
      "  1.53362286e-03  2.22914439e-04 -4.97454456e-05 -9.12355832e-04\n",
      " -6.87177816e-04  4.74087679e-03  7.09966354e-04  7.47403813e-04\n",
      "  2.63523671e-03  1.55176317e-04  8.13563411e-04 -1.38531128e-03\n",
      " -2.67687215e-03  1.23234068e-03 -4.64370068e-03  8.48539372e-04\n",
      "  4.69228891e-04 -4.16769845e-03 -7.91839561e-04 -1.74324764e-04\n",
      " -2.13532005e-04 -4.47803128e-04  6.73254702e-04  4.22606642e-04\n",
      " -7.97378090e-04 -2.99244275e-04 -3.08507395e-03  3.18555110e-05\n",
      " -7.38217602e-04  3.24107694e-03  1.62957835e-03  5.49426503e-04\n",
      "  8.98079444e-04 -2.75752136e-04 -3.73362579e-04  8.27120629e-03\n",
      " -1.17326899e-03  3.40660058e-04 -1.03254021e-04 -2.17382449e-04\n",
      "  1.04837283e-03  8.84913125e-03 -5.83182479e-04  8.08053530e-03\n",
      "  2.17427928e-03 -7.13813444e-04  3.93142370e-04  4.25041740e-04\n",
      " -1.05227861e-03 -1.73027595e-03 -1.20685342e-03  1.01285454e-03\n",
      " -1.27042701e-04  2.99704230e-03  3.83380496e-04  3.70921277e-04\n",
      "  3.20683172e-04  1.01739544e-03  5.30313821e-04 -1.92065192e-03\n",
      " -7.02646501e-05  3.18184041e-03  1.43496644e-04  4.64607169e-04\n",
      " -2.27897633e-04 -3.65130320e-04  1.36601683e-03  1.69959959e-03\n",
      "  1.88906609e-03  2.48706823e-03  1.86099259e-03  1.84500457e-04\n",
      "  1.16326975e-03 -6.07301316e-04  7.66754303e-04 -3.47454016e-04\n",
      " -3.05753534e-03 -7.83261770e-04  4.27916286e-04 -6.64841579e-04\n",
      "  2.44115673e-04  6.59700316e-03 -1.35787583e-03 -1.58025554e-03\n",
      " -1.01656284e-03 -1.75602073e-05 -9.03809322e-05 -8.35627709e-03\n",
      " -1.34576642e-03  2.55650209e-03  1.36278329e-03  1.32476213e-02\n",
      " -2.47887340e-04 -9.93046314e-05  6.67926862e-04  4.35816000e-05\n",
      "  4.69015227e-04 -2.91320973e-03  5.71108973e-04 -9.99282122e-04\n",
      "  1.51380481e-03  6.39450430e-04  1.59561427e-05 -3.55290529e-04\n",
      " -3.10348908e-04  4.20642738e-04  1.19924743e-03 -1.21393045e-03\n",
      " -9.52865597e-03  7.34987153e-04  2.22067871e-04 -7.48385857e-04\n",
      " -2.98366747e-04  1.41531978e-03  8.58307704e-04  1.88992989e-03\n",
      " -1.43607131e-05  1.81391904e-03  1.57503143e-03 -5.50144323e-03\n",
      " -8.89084648e-04 -1.10510348e-03  4.67796675e-04 -7.31006662e-04\n",
      " -3.86080290e-03 -7.40715989e-04  1.77074636e-03  7.28522865e-05\n",
      "  1.42162380e-03 -1.41538037e-03  3.82200741e-03  1.74428804e-03\n",
      " -5.74054215e-04  1.51200984e-04 -1.92136604e-03 -1.47951782e-03\n",
      " -7.89511508e-05  1.28528529e-03  8.60875872e-04  9.65860017e-04\n",
      "  8.68336358e-04 -5.61823864e-04 -3.52585152e-03 -7.40271218e-04\n",
      " -3.69691805e-04  5.19940979e-04 -1.58415565e-04  5.48777346e-03\n",
      "  5.16419809e-04 -7.64592853e-04 -4.96961894e-04  1.86544246e-03\n",
      "  2.40621702e-03  4.16203897e-04  1.30837159e-03  1.46803711e-03\n",
      " -1.23583595e-03 -6.59954827e-04  8.99728875e-04 -1.16022943e-04\n",
      "  3.78225943e-03  4.01193601e-04  1.53198061e-03 -2.00305527e-04\n",
      " -2.16074757e-03 -1.92610352e-03  2.68757695e-04  1.16930828e-03\n",
      "  6.09192669e-03 -1.86556654e-03  7.05299865e-04  1.19904473e-03\n",
      "  1.14529759e-03 -1.05922397e-03  1.12018134e-03  9.00023365e-04\n",
      "  1.28201991e-03 -2.69819766e-04  3.11973153e-03 -7.84880953e-04\n",
      "  2.51555185e-03 -2.05186451e-03  6.84360489e-04  1.88847414e-03\n",
      " -5.63041275e-04  3.30305795e-03 -4.20713629e-04 -3.09840186e-03\n",
      " -3.64222222e-03  1.16422964e-03  1.04584727e-03  5.57487031e-04\n",
      "  1.37306104e-03  1.59956684e-03  2.34187499e-04  2.64947234e-03\n",
      " -2.24018112e-04 -1.89138178e-04  6.58680518e-04  9.00693737e-04\n",
      "  1.76676181e-03  1.00413505e-03 -6.63651105e-03  3.61484278e-03\n",
      "  5.93094625e-04 -2.80876966e-03 -9.04604619e-05 -1.44783314e-04\n",
      "  5.62481475e-04  5.41635190e-04 -1.86839239e-03  5.45781346e-04\n",
      "  1.63050837e-04  1.86483444e-03 -8.07782355e-04 -1.04184457e-04\n",
      "  1.11327354e-03  8.15833012e-04  6.05538244e-04  3.40585213e-04\n",
      "  6.45485237e-04 -3.72314658e-04  5.21187797e-04  9.21900862e-04\n",
      "  1.22730567e-03  7.88612966e-04  6.19841999e-04  1.04543181e-03\n",
      "  4.28286907e-04  3.77557133e-04  1.44795378e-03 -2.64390434e-04\n",
      " -1.08607984e-03  6.02467561e-05  4.29682890e-04 -9.53205480e-04\n",
      " -4.85626060e-03 -1.09499733e-03  1.70294886e-03 -5.58648591e-04\n",
      " -1.44512380e-04  2.50079826e-03 -8.22183044e-04 -4.50287007e-04\n",
      " -1.45882882e-03 -9.35858842e-05 -8.13642929e-04 -1.09150256e-03\n",
      "  1.62829646e-03 -3.36754888e-04 -3.87206554e-04  4.52962511e-03\n",
      "  2.08669343e-04  2.69388481e-04 -2.60397272e-03  2.86038162e-03\n",
      "  6.72084143e-03  8.66676336e-06  1.48476686e-04 -9.47771268e-04\n",
      "  9.97196474e-04 -8.46261662e-04  1.33526764e-03  7.34767331e-04\n",
      " -6.56136602e-04 -3.03841321e-03  2.20239150e-03 -4.59042728e-04\n",
      " -3.26626065e-03  8.83524521e-04  9.01308961e-04  6.28532317e-04\n",
      " -1.49239547e-04 -8.24968345e-04  7.76107234e-04 -5.73543720e-03\n",
      "  7.90899554e-04 -2.15674405e-04 -1.71441249e-03  9.60197623e-04\n",
      " -8.55741595e-03 -2.20504306e-04 -3.65131098e-03 -1.12943049e-03\n",
      "  1.20894868e-04 -1.02551935e-03 -1.30231389e-03  1.22375220e-03\n",
      " -2.77672423e-04 -8.33915731e-04  2.30881843e-03 -3.09942352e-04\n",
      " -2.23436152e-03  3.68214148e-05 -8.64134695e-04  6.29979711e-04\n",
      " -8.52846285e-05  2.40523181e-03  5.28792884e-03 -1.85199478e-03\n",
      " -2.53413319e-04  9.23518960e-04  1.74107538e-03 -4.79651121e-03\n",
      "  6.99188013e-04  1.78697195e-03  1.30168359e-03 -2.66206606e-04\n",
      "  1.20589333e-03  1.86090017e-04 -4.29908953e-04 -1.58117017e-03\n",
      "  1.76793739e-03  1.13853881e-04 -3.24150387e-04  1.45856073e-03\n",
      " -9.44801110e-04  1.45210852e-03  1.15214362e-03 -2.09906022e-03\n",
      "  6.85092422e-04 -6.78189017e-03  3.93099091e-03 -1.29117962e-04\n",
      "  1.94702962e-03  4.00883005e-04 -3.75273074e-04 -3.19051853e-04\n",
      " -9.08204429e-04  1.70494531e-04 -1.54011649e-03 -6.88309289e-04\n",
      "  1.86917868e-03 -8.20721795e-04  5.40664685e-03  1.29598871e-03\n",
      "  1.38702304e-03  1.94345627e-04  1.81864357e-03 -1.95020097e-03\n",
      " -7.28732886e-04 -1.12093539e-03  1.89616063e-03 -9.89832443e-04\n",
      " -1.34825815e-03  1.10791492e-03  4.42648993e-03 -6.02109485e-04\n",
      "  1.55294436e-03  6.63049391e-04 -1.88409612e-03  2.85325662e-04\n",
      "  5.10657889e-04  2.67473385e-03 -1.43733297e-03  5.86801803e-04\n",
      "  1.80472392e-03 -2.62122714e-04 -4.70109450e-04  1.33913018e-03\n",
      " -3.28231918e-04  5.77729018e-04 -1.23405268e-03 -5.58590870e-04\n",
      "  1.03405399e-03  1.49504010e-03 -1.15423249e-03 -1.12372552e-03\n",
      "  1.14116372e-03  5.27751495e-03 -1.53706069e-04  3.25286600e-04\n",
      "  1.85329093e-03 -3.06437636e-04  1.54706888e-03  5.99384397e-04\n",
      "  3.01885709e-03  4.08619577e-04  8.39670932e-03 -8.54389595e-04\n",
      " -5.18497272e-04 -3.98736491e-03  3.97014338e-04 -1.89866163e-03\n",
      " -3.44229023e-03  1.31070307e-04  1.23887075e-04 -4.02452647e-04\n",
      "  7.66052637e-04 -1.36023989e-03 -2.84543621e-04 -9.91156708e-04\n",
      "  9.13661768e-04 -2.44141533e-04  3.31234763e-03  3.06542226e-03\n",
      "  1.21793871e-03  1.19200472e-03 -3.61118576e-04 -5.25501311e-04\n",
      " -2.46938123e-03  6.16620515e-04  1.00404001e-03 -3.73034058e-04\n",
      "  4.01494863e-04  2.47315208e-03  1.02291996e-03 -2.87406368e-04\n",
      "  3.70045602e-04 -5.41528250e-04 -3.89249614e-04  1.23445440e-03\n",
      "  7.27914548e-04  5.33552648e-04 -1.89421072e-03  3.44883038e-03\n",
      " -4.76655948e-05  8.29040706e-04 -1.84977011e-03  1.54010668e-04\n",
      "  1.17290183e-03 -5.52095073e-04  2.07996666e-03  3.84423101e-03\n",
      "  1.39105230e-03  1.39432267e-03  1.38704095e-03 -1.09974773e-04\n",
      "  2.98971007e-03  2.33056367e-04  2.31287689e-03 -2.32977793e-04\n",
      "  3.92620760e-04 -2.51778792e-03  1.37909403e-03  6.06322081e-04\n",
      " -2.82695001e-04  1.93100142e-03 -3.38354686e-04 -2.44079587e-03\n",
      "  1.43468396e-03 -4.95156314e-04 -3.37731912e-03 -5.84415936e-04\n",
      " -1.77225735e-03  1.04316703e-03  3.50380751e-03 -2.72079293e-05\n",
      "  3.56057701e-06  7.53617169e-04  9.10299611e-04  2.62017432e-03\n",
      "  1.39620635e-03  5.79819259e-05 -1.08416327e-03  4.29424875e-03\n",
      " -1.66593203e-03  2.90776729e-04 -5.48462510e-04  9.54121104e-04\n",
      "  2.93061865e-03  9.57860187e-04 -1.32357039e-03 -8.48399874e-04\n",
      " -1.47572638e-03  4.54629415e-04  9.08277378e-04  5.94859430e-04\n",
      " -6.18381955e-03 -9.85586734e-04 -2.01452379e-04  4.42817909e-04\n",
      " -1.19617561e-04 -9.16177417e-04 -3.29879875e-04 -3.93896368e-03\n",
      " -1.36988999e-04 -1.83533590e-04  4.35063052e-04  9.23237671e-04\n",
      "  2.90076374e-04  5.43479538e-05 -3.12918442e-03  1.97976915e-05\n",
      "  9.29781249e-05 -3.55174642e-03  9.41056831e-04 -2.43748605e-03\n",
      "  1.72992567e-03 -8.52802980e-03  3.49674713e-04  1.51294480e-03\n",
      " -4.03754867e-04 -2.08007639e-03  4.52443643e-04 -1.81705736e-03\n",
      "  1.33327800e-03 -2.19610836e-03  1.13252919e-03 -5.79542561e-04\n",
      " -2.59508674e-03  3.07698531e-03 -4.73977922e-04  2.92629369e-04\n",
      "  3.53556111e-03  1.35271817e-04 -4.18823304e-04 -4.52580043e-04\n",
      " -6.93552738e-04  1.19601391e-03  1.88581400e-06  1.31181138e-04\n",
      "  1.08507037e-02 -3.47252038e-03  1.08666387e-03 -2.83814266e-04\n",
      "  4.55704593e-04 -1.65504684e-04  1.33043782e-03  1.94804843e-03\n",
      " -2.34291335e-03  7.25861058e-04 -1.16335663e-04  1.27550859e-03\n",
      "  4.77309216e-03 -9.21286120e-04  1.87509838e-03  2.06754495e-04\n",
      " -3.58834933e-05  1.25052314e-03 -7.47331515e-04  4.14198816e-04\n",
      "  1.20438019e-03  6.32861963e-04 -1.55578236e-03 -6.79483437e-05\n",
      "  2.08600733e-03  1.80437614e-04 -1.58870829e-03 -7.89634166e-03\n",
      "  2.91149657e-04 -1.50505714e-03 -5.15580521e-04  1.31197531e-04\n",
      "  1.51731798e-03  2.18130028e-03 -1.94143517e-04 -5.11467474e-05\n",
      " -5.62754455e-04 -1.07710472e-03 -5.35304183e-03  5.08751712e-04\n",
      "  5.05773816e-04 -4.87174017e-03 -1.82000603e-03 -1.42256365e-03\n",
      " -6.93239603e-04  5.23476760e-04 -1.56609869e-04  7.11174303e-04\n",
      "  1.18825565e-03 -9.22761955e-05 -5.20271156e-03  2.78068495e-04\n",
      "  1.17393727e-04  7.51129728e-05 -1.38722447e-03 -1.16360432e-03\n",
      "  2.10185687e-03 -9.74944825e-04  1.32927178e-03 -9.17268386e-04\n",
      "  1.65307841e-03 -3.84743996e-04  1.59482389e-03 -1.00761237e-03\n",
      "  1.01780041e-03 -1.13476942e-04 -4.12874340e-04  2.37558699e-03\n",
      " -6.11274898e-05 -8.18169259e-05  2.50180101e-04  1.67701345e-03\n",
      " -1.13281776e-03  4.69342129e-04  1.41564747e-04 -5.68630541e-05\n",
      "  7.81310212e-04 -1.08543402e-03 -4.06732792e-04  1.54788067e-03\n",
      "  4.15757521e-04 -3.50827829e-04 -9.64467357e-04 -1.83323418e-04\n",
      " -1.35954201e-04  4.87900895e-04 -7.88246801e-04 -7.29594233e-04\n",
      "  2.11497737e-04  3.90671673e-04 -9.85862205e-04 -2.21492472e-03\n",
      "  4.23050089e-04  1.60907456e-03 -2.52241905e-02  1.22778617e-04\n",
      " -2.20888044e-03  1.10823988e-03 -2.93264060e-03  2.81896937e-04\n",
      "  1.66984418e-03  2.26566478e-04 -6.56924166e-04  6.20303512e-04\n",
      " -1.09338012e-03  3.49914213e-03  1.29992039e-03  8.01500332e-04\n",
      "  1.65485204e-03  2.58753626e-03 -2.29340677e-04 -3.57649817e-03]\n"
     ]
    }
   ],
   "source": [
    "print(m_preds_train[:, 0] - y_train['log_adj_daily_returns_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Selected Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Train Dataset\n",
    "with open(os.path.join(path_to_data, 'train_dataset.pickle'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Test Dataset\n",
    "with open(os.path.join(path_to_data, 'test_dataset.pickle'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions \n",
    "def write_hparams(model_name, hparams, verbose=True):\n",
    "    version_number = hparams['version']\n",
    "    path = os.path.join('logs', 'models', model_name, '_'.join(['version', str(version_number)]))\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'hparams.pickle'), 'wb') as f:\n",
    "        pickle.dump(hparams, f)\n",
    "    if verbose:\n",
    "        return print('Saved hyperparameters to file: {}'.format(path))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def build_compiled_model(build_model, model_name, hparams, metrics, run_number):\n",
    "    hparam_version = hparams['version']\n",
    "    loss = hparams['loss']\n",
    "    optimizer = hparams['optimizer']\n",
    "    model_parameters = hparams['model_parameters']\n",
    "    model = build_model(**model_parameters)\n",
    "    path_to_ckpt = os.path.join('logs', 'models', model_name, '_'.join(['version', str(hparam_version)]),\n",
    "                               'runs', str(run_number), 'checkpoints')\n",
    "    if os.path.exists(path_to_ckpt):\n",
    "        latest = tf.train.latest_checkpoint(path_to_ckpt)\n",
    "        model.load_weights(latest)\n",
    "        print('Restored model from: {}'.format(latest))  \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_dataset\n",
    "X_test, y_test = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    target = targets['_'.join([ts_fname, 'target'])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([ts_fname, 'target']):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        if history != None:\n",
    "            plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hyperparameters to file: logs/models/model_selected/version_final\n"
     ]
    }
   ],
   "source": [
    "# Defining and Saving Hyperparameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "model_params = {'lstm_layer_units': 256, 'vocab': vocab, 'doc_embedding_size': 200, 'output_bias_init': 0}\n",
    "training_params = {'batch_size': 4, 'epochs': 50}\n",
    "model_version = 'final'\n",
    "hyperparameters = {'model_parameters': model_params, 'training_parameters': training_params,\n",
    "                   'loss': LOSS, 'optimizer': OPTIMIZER, 'version': model_version}\n",
    "write_hparams('model_selected', hyperparameters)\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_compiled_model(model_0, 'model_selected', hyperparameters, metrics=metrics, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on full train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 7410 samples, validate on 2470 samples\n",
      "Epoch 1/50\n",
      "7410/7410 [==============================] - 402s 54ms/sample - loss: 0.0014 - val_loss: 7.1876e-04\n",
      "Epoch 2/50\n",
      "7410/7410 [==============================] - 405s 55ms/sample - loss: 8.5110e-04 - val_loss: 6.8347e-04\n",
      "Epoch 3/50\n",
      "7410/7410 [==============================] - 412s 56ms/sample - loss: 8.2944e-04 - val_loss: 6.7151e-04\n",
      "Epoch 4/50\n",
      "7410/7410 [==============================] - 407s 55ms/sample - loss: 8.0630e-04 - val_loss: 7.0192e-04\n",
      "Epoch 5/50\n",
      "7410/7410 [==============================] - 416s 56ms/sample - loss: 8.0736e-04 - val_loss: 6.6922e-04\n",
      "Epoch 6/50\n",
      "7410/7410 [==============================] - 411s 56ms/sample - loss: 7.9791e-04 - val_loss: 6.6630e-04\n",
      "Epoch 7/50\n",
      "7410/7410 [==============================] - 422s 57ms/sample - loss: 8.0261e-04 - val_loss: 6.7528e-04\n",
      "Epoch 8/50\n",
      "7410/7410 [==============================] - 413s 56ms/sample - loss: 8.1416e-04 - val_loss: 6.8368e-04\n",
      "Epoch 9/50\n",
      "7410/7410 [==============================] - 416s 56ms/sample - loss: 8.0031e-04 - val_loss: 6.6519e-04\n",
      "Epoch 10/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.9726e-04\n",
      "Epoch 00010: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-10.ckpt\n",
      "7410/7410 [==============================] - 411s 55ms/sample - loss: 7.9705e-04 - val_loss: 6.8684e-04\n",
      "Epoch 11/50\n",
      "7410/7410 [==============================] - 402s 54ms/sample - loss: 7.9468e-04 - val_loss: 7.5967e-04\n",
      "Epoch 12/50\n",
      "7410/7410 [==============================] - 403s 54ms/sample - loss: 7.9707e-04 - val_loss: 6.8248e-04\n",
      "Epoch 13/50\n",
      "7410/7410 [==============================] - 410s 55ms/sample - loss: 7.9599e-04 - val_loss: 6.8404e-04\n",
      "Epoch 14/50\n",
      "7410/7410 [==============================] - 431s 58ms/sample - loss: 7.9341e-04 - val_loss: 6.7407e-04\n",
      "Epoch 15/50\n",
      "7410/7410 [==============================] - 425s 57ms/sample - loss: 7.9170e-04 - val_loss: 6.7336e-04\n",
      "Epoch 16/50\n",
      "7410/7410 [==============================] - 421s 57ms/sample - loss: 7.8469e-04 - val_loss: 6.9698e-04\n",
      "Epoch 17/50\n",
      "7410/7410 [==============================] - 424s 57ms/sample - loss: 7.8349e-04 - val_loss: 6.7608e-04\n",
      "Epoch 18/50\n",
      "7410/7410 [==============================] - 413s 56ms/sample - loss: 7.8290e-04 - val_loss: 6.9322e-04\n",
      "Epoch 19/50\n",
      "7410/7410 [==============================] - 430s 58ms/sample - loss: 7.7870e-04 - val_loss: 7.0318e-04\n",
      "Epoch 20/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.7962e-04\n",
      "Epoch 00020: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-20.ckpt\n",
      "7410/7410 [==============================] - 424s 57ms/sample - loss: 7.7942e-04 - val_loss: 6.7816e-04\n",
      "Epoch 21/50\n",
      "7410/7410 [==============================] - 415s 56ms/sample - loss: 7.7109e-04 - val_loss: 6.9535e-04\n",
      "Epoch 22/50\n",
      "7410/7410 [==============================] - 396s 53ms/sample - loss: 7.7076e-04 - val_loss: 6.7602e-04\n",
      "Epoch 23/50\n",
      "7410/7410 [==============================] - 385s 52ms/sample - loss: 7.6872e-04 - val_loss: 6.9049e-04\n",
      "Epoch 24/50\n",
      "7410/7410 [==============================] - 384s 52ms/sample - loss: 7.6638e-04 - val_loss: 6.7173e-04\n",
      "Epoch 25/50\n",
      "7410/7410 [==============================] - 383s 52ms/sample - loss: 7.6933e-04 - val_loss: 6.7274e-04\n",
      "Epoch 26/50\n",
      "7410/7410 [==============================] - 383s 52ms/sample - loss: 7.6437e-04 - val_loss: 6.7135e-04\n",
      "Epoch 27/50\n",
      "7410/7410 [==============================] - 385s 52ms/sample - loss: 7.6020e-04 - val_loss: 6.9324e-04\n",
      "Epoch 28/50\n",
      "7410/7410 [==============================] - 425s 57ms/sample - loss: 7.6913e-04 - val_loss: 6.8200e-04\n",
      "Epoch 29/50\n",
      "7410/7410 [==============================] - 406s 55ms/sample - loss: 7.6870e-04 - val_loss: 6.7721e-04\n",
      "Epoch 30/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.6483e-04\n",
      "Epoch 00030: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-30.ckpt\n",
      "7410/7410 [==============================] - 405s 55ms/sample - loss: 7.6473e-04 - val_loss: 7.0582e-04\n",
      "Epoch 31/50\n",
      "7410/7410 [==============================] - 493s 66ms/sample - loss: 7.5664e-04 - val_loss: 6.9871e-04\n",
      "Epoch 32/50\n",
      "7410/7410 [==============================] - 443s 60ms/sample - loss: 7.5768e-04 - val_loss: 6.8470e-04\n",
      "Epoch 33/50\n",
      "7410/7410 [==============================] - 434s 59ms/sample - loss: 7.5128e-04 - val_loss: 7.6341e-04\n",
      "Epoch 34/50\n",
      "7410/7410 [==============================] - 412s 56ms/sample - loss: 7.5431e-04 - val_loss: 6.7713e-04\n",
      "Epoch 35/50\n",
      "7410/7410 [==============================] - 396s 53ms/sample - loss: 7.5601e-04 - val_loss: 6.7985e-04\n",
      "Epoch 36/50\n",
      "7410/7410 [==============================] - 390s 53ms/sample - loss: 7.5117e-04 - val_loss: 7.0180e-04\n",
      "Epoch 37/50\n",
      "7410/7410 [==============================] - 400s 54ms/sample - loss: 7.4925e-04 - val_loss: 7.3616e-04\n",
      "Epoch 38/50\n",
      "7410/7410 [==============================] - 399s 54ms/sample - loss: 7.3829e-04 - val_loss: 6.9453e-04\n",
      "Epoch 39/50\n",
      "7410/7410 [==============================] - 409s 55ms/sample - loss: 7.4177e-04 - val_loss: 7.5010e-04\n",
      "Epoch 40/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.3809e-04\n",
      "Epoch 00040: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-40.ckpt\n",
      "7410/7410 [==============================] - 414s 56ms/sample - loss: 7.3790e-04 - val_loss: 7.3695e-04\n",
      "Epoch 41/50\n",
      "7410/7410 [==============================] - 429s 58ms/sample - loss: 7.2971e-04 - val_loss: 7.4988e-04\n",
      "Epoch 42/50\n",
      "7410/7410 [==============================] - 416s 56ms/sample - loss: 7.2515e-04 - val_loss: 7.4372e-04\n",
      "Epoch 43/50\n",
      "7410/7410 [==============================] - 373s 50ms/sample - loss: 7.1235e-04 - val_loss: 7.6756e-04\n",
      "Epoch 44/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 7.0937e-04 - val_loss: 7.8594e-04\n",
      "Epoch 45/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 7.0231e-04 - val_loss: 7.7428e-04\n",
      "Epoch 46/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.9240e-04 - val_loss: 7.4683e-04\n",
      "Epoch 47/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.8276e-04 - val_loss: 8.1758e-04\n",
      "Epoch 48/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.7758e-04 - val_loss: 7.8488e-04\n",
      "Epoch 49/50\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 6.9563e-04 - val_loss: 8.2415e-04\n",
      "Epoch 50/50\n",
      "7408/7410 [============================>.] - ETA: 0s - loss: 7.0262e-04\n",
      "Epoch 00050: saving model to logs/models/model_selected/version_final/runs/0/checkpoints/cp-50.ckpt\n",
      "7410/7410 [==============================] - 368s 50ms/sample - loss: 7.0257e-04 - val_loss: 7.7475e-04\n"
     ]
    }
   ],
   "source": [
    "# Setting up callbacks\n",
    "path_to_run = os.path.join('logs', 'models', 'model_selected',\n",
    "                            '_'.join(['version', str(hyperparameters['version'])]),\n",
    "                            'runs', str(run_number))\n",
    "path_to_ckpts = os.path.join(path_to_run, 'checkpoints')\n",
    "if not os.path.exists(path_to_ckpts):\n",
    "    os.makedirs(path_to_ckpts)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path_to_ckpts, 'cp-{epoch}.ckpt'),\n",
    "                                                 verbose=1, save_weights_only=True, period=10)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=os.path.join(path_to_run, 'history.log'), append=True)\n",
    "callbacks = [cp_callback, csv_logger]\n",
    "\n",
    "# Unpacking model training parameters\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "\n",
    "# Fetching last trained epoch if the model was reloaded\n",
    "latest_ckpt = tf.train.latest_checkpoint(path_to_ckpts)\n",
    "if latest_ckpt is not None:\n",
    "    initial_epoch = re.findall(r'cp-(\\d+)\\.ckpt', latest_ckpt)[0]\n",
    "    initial_epoch = int(initial_epoch) - 1\n",
    "else:\n",
    "    initial_epoch = 0\n",
    "\n",
    "model_history = model.fit(X_train, y_train, **training_parameters, validation_data=(X_test, y_test),\n",
    "                          initial_epoch=initial_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_test = model.evaluate(X_test, y_test, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_test = model.predict(X_test, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_test = (m_preds_test[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_test = y_test['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_test = np.mean(np.equal(m_preds_up_test, labels_up_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 0.0006485506063616562\n",
      "Loss on validation dataset: 0.0007747489441738396\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.5464237516869096\n",
      "Accuracy on validation dataset: 0.5040485829959515\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(model_history, metrics_train=metrics_train, metrics_val=metrics_test, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from: logs/models/model_selected/version_final/runs/0/checkpoints/cp-30.ckpt\n"
     ]
    }
   ],
   "source": [
    "hparam_version = hyperparameters['version']\n",
    "loss = hyperparameters['loss']\n",
    "optimizer = hyperparameters['optimizer']\n",
    "model_parameters = hyperparameters['model_parameters']\n",
    "model = model_0(**model_parameters)\n",
    "path_to_ckpt = os.path.join('logs', 'models', 'model_selected', '_'.join(['version', str(hparam_version)]),\n",
    "                            'runs', str(run_number), 'checkpoints')\n",
    "ckpt = os.path.join(path_to_ckpt, 'cp-30.ckpt')\n",
    "model.load_weights(ckpt)\n",
    "print('Restored model from: {}'.format(ckpt))  \n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_test = model.evaluate(X_test, y_test, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_test = model.predict(X_test, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_test = (m_preds_test[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_test = y_test['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_test = np.mean(np.equal(m_preds_up_test, labels_up_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n",
      "Loss on train dataset: 0.000738731865831522\n",
      "Loss on validation dataset: 0.0007058223036158149\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.525910931174089\n",
      "Accuracy on validation dataset: 0.5101214574898786\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(None, metrics_train=metrics_train, metrics_val=metrics_test, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Saving Model for Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel to clear GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: []\n",
      "Visible GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project Paths\n",
    "project_dir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "path_to_data = os.path.join(project_dir, 'data')\n",
    "path_to_docs = os.path.join(path_to_data, 'documents')\n",
    "path_to_models = os.path.join(project_dir, 'models')\n",
    "\n",
    "# Random Seed\n",
    "seed = None\n",
    "\n",
    "# Configuring GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Tensorflow Seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Loading Full Dataset\n",
    "with open(os.path.join(path_to_data, 'dataset.pickle'), 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "    \n",
    "# Defining Helper Functions \n",
    "def write_hparams(model_name, hparams, verbose=True):\n",
    "    version_number = hparams['version']\n",
    "    path = os.path.join('logs', 'models', model_name, '_'.join(['version', str(version_number)]))\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    with open(os.path.join(path, 'hparams.pickle'), 'wb') as f:\n",
    "        pickle.dump(hparams, f)\n",
    "    if verbose:\n",
    "        return print('Saved hyperparameters to file: {}'.format(path))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def build_compiled_model(build_model, model_name, hparams, metrics, run_number):\n",
    "    hparam_version = hparams['version']\n",
    "    loss = hparams['loss']\n",
    "    optimizer = hparams['optimizer']\n",
    "    model_parameters = hparams['model_parameters']\n",
    "    model = build_model(**model_parameters)\n",
    "    path_to_ckpt = os.path.join('logs', 'models', model_name, '_'.join(['version', str(hparam_version)]),\n",
    "                               'runs', str(run_number), 'checkpoints')\n",
    "    if os.path.exists(path_to_ckpt):\n",
    "        latest = tf.train.latest_checkpoint(path_to_ckpt)\n",
    "        model.load_weights(latest)\n",
    "        print('Restored model from: {}'.format(latest))  \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_size=None, test_size=None, random_state=None, shuffle=True):\n",
    "    features = dataset[0]\n",
    "    targets = dataset[1]\n",
    "    feature_keys = list(features.keys())\n",
    "    feature_arrays = [features[k] for k in feature_keys]\n",
    "    target_keys = list(targets.keys())\n",
    "    target_arrays = [targets[k] for k in target_keys]\n",
    "    keys = feature_keys + target_keys\n",
    "    arrays = feature_arrays + target_arrays\n",
    "    array_splits = train_test_split(*arrays, train_size=train_size, test_size=test_size,\n",
    "                                    random_state=random_state, shuffle=shuffle)\n",
    "    train = {keys[i]: array_splits[2*i] for i in range(len(keys))}\n",
    "    train_features = {k: train[k] for k in feature_keys}\n",
    "    train_targets = {k: train[k] for k in target_keys}\n",
    "    \n",
    "    test = {keys[i]: array_splits[(2*i + 1)] for i in range(len(keys))}\n",
    "    test_features = {k: test[k] for k in feature_keys}\n",
    "    test_targets = {k: test[k] for k in target_keys}\n",
    "    \n",
    "    train_dataset = (train_features, train_targets)\n",
    "    test_dataset = (test_features, test_targets)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def plot_errors(predictions, true_labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    err = true_labels - predictions\n",
    "    ax.plot(err, 'bo')\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def plot_outputs_errors(predictions, true_labels, title):\n",
    "    for i in range(len(true_labels.keys())):\n",
    "        label_name = list(true_labels.keys())[i]\n",
    "        labels = true_labels[label_name]\n",
    "        preds = predictions[:, i]\n",
    "        assert len(preds) == len(labels)\n",
    "        name = '_'.join([label_name, title]).replace(\"_\",\" \").capitalize()\n",
    "        plot_errors(preds, labels, name)\n",
    "    return None\n",
    "\n",
    "def plot_ts_sample_ba(feature_value, target_value, prediction_b_value, prediction_a_value, ts_fname, sample_num):\n",
    "    name = ts_fname.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(feature_value, '-b')\n",
    "    ax.plot(len(feature_value), target_value, 'bo', label='True Value')\n",
    "    ax.plot(len(feature_value), prediction_b_value, 'g+', label='Prediction Before Training')\n",
    "    ax.plot(len(feature_value), prediction_a_value, 'rx', label='Prediction After Training')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title('Sample {}'.format(sample_num))\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print('True Target Value: {}'.format(target_value))\n",
    "    print('Predicted Target Value Before Training: {}'.format(prediction_b_value))\n",
    "    print('Predicted Target Value After Training: {}'.format(prediction_a_value))\n",
    "    print()\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def plot_ts_samples_ba(features, targets, predictions_b, predictions_a, ts_fname):\n",
    "    feature = features[ts_fname]\n",
    "    target = targets['_'.join([ts_fname, 'target'])]\n",
    "    prediction_b = None\n",
    "    prediction_a = None\n",
    "    for i in range(len(targets.keys())):\n",
    "        target_name = list(targets.keys())[i]\n",
    "        if target_name == '_'.join([ts_fname, 'target']):\n",
    "            prediction_b = predictions_b[:, i]\n",
    "            prediction_a = predictions_a[:, i]\n",
    "    assert len(prediction_b) == len(prediction_a) == len(target) == len(feature)\n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        plot_ts_sample_ba(feature[i], target[i], prediction_b[i], prediction_a[i], ts_fname, i)\n",
    "    return None\n",
    "            \n",
    "def plot_metric(history, metric):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history[metric], label='Train')\n",
    "    if 'val_' + metric in history.history:\n",
    "        ax.plot(history.epoch, history.history['val_' + metric], linestyle=\"--\", label='Val')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "def print_metric(metrics_values, metric_idx, name):\n",
    "    if isinstance(metrics_values, list):\n",
    "        metric_val = metrics_values[metric_idx]\n",
    "    else: \n",
    "        metric_val = metrics_values\n",
    "    return print(name.format(metric_val))\n",
    "    \n",
    "def plot_print_metrics(history, metrics_train, metrics_val, metrics_names):\n",
    "    for metric_idx, metric_name in enumerate(metrics_names):\n",
    "        if history != None:\n",
    "            plot_metric(history, metric_name)\n",
    "        name_train = metric_name.replace('_', ' ').capitalize() + ' on train dataset: {}'\n",
    "        print_metric(metrics_train, metric_idx, name_train)\n",
    "        name_val = metric_name.replace('_', ' ').capitalize() + ' on validation dataset: {}'\n",
    "        print_metric(metrics_val, metric_idx, name_val)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = tf.keras.layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                              weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                              input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = tf.keras.layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                              embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                              activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                              mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n",
    "\n",
    "def document_embedder_model(vocab=vocab, doc_embedding_size=100):\n",
    "    input_doc = tf.keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = tf.keras.layers.LSTM(doc_embedding_size)(word_embedding)\n",
    "    model = tf.keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "def model_0(lstm_layer_units=32, vocab=vocab, doc_embedding_size=100,\n",
    "            output_kernel_init=None, output_bias_init=None):\n",
    "    \n",
    "    if output_bias_init is not None:\n",
    "        output_bias_init = tf.keras.initializers.Constant(output_bias_init)\n",
    "    \n",
    "    inputs = {'log_adj_daily_returns': tf.keras.Input(shape=(5,), name='log_adj_daily_returns', dtype=tf.float32),\n",
    "              'docs': tf.keras.Input(shape=(None,), name='docs', dtype=tf.int64)}\n",
    "    \n",
    "    doc_embeddings = document_embedder_model(vocab, doc_embedding_size)(inputs['docs'])\n",
    "    \n",
    "    reshape_doc_embeddings = tf.keras.layers.Lambda(lambda x: tf.keras.backend.stack([x for i in range(5)], axis=1))(doc_embeddings)\n",
    "    reshape_price_features = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=-1))(inputs['log_adj_daily_returns'])\n",
    "    time_series_input = tf.keras.layers.Concatenate()([reshape_doc_embeddings, reshape_price_features])\n",
    "    \n",
    "    time_series_lstm = tf.keras.layers.LSTM(lstm_layer_units)(time_series_input)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(units=1, kernel_initializer=output_kernel_init,\n",
    "                                         bias_initializer=output_bias_init, name='log_adj_daily_returns_target')\n",
    "    outputs = {'log_adj_daily_returns_target': output_layer(time_series_lstm)}\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='model_0')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hyperparameters to file: logs/models/model_deployment/version_final\n"
     ]
    }
   ],
   "source": [
    "# Defining and Saving Hyperparameters\n",
    "LOSS = tf.keras.losses.MeanSquaredError()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()\n",
    "model_params = {'lstm_layer_units': 256, 'vocab': vocab, 'doc_embedding_size': 200, 'output_bias_init': 0}\n",
    "training_params = {'batch_size': 4, 'epochs': 30}\n",
    "model_version = 'final'\n",
    "hyperparameters = {'model_parameters': model_params, 'training_parameters': training_params,\n",
    "                   'loss': LOSS, 'optimizer': OPTIMIZER, 'version': model_version}\n",
    "write_hparams('model_deployment', hyperparameters)\n",
    "\n",
    "# Defining Metrics\n",
    "metrics = []\n",
    "\n",
    "# Setting unique Run Number \n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-59e8cae016af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_deployment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-1be5f255ae8d>\u001b[0m in \u001b[0;36mbuild_compiled_model\u001b[0;34m(build_model, model_name, hparams, metrics, run_number)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Restored model from: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \"\"\"\n\u001b[0;32m-> 1139\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m       \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_is_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m   return (filepath.endswith('.h5') or filepath.endswith('.keras') or\n\u001b[0m\u001b[1;32m   1450\u001b[0m           filepath.endswith('.hdf5'))\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "model = build_compiled_model(model_0, 'model_deployment', hyperparameters, metrics=metrics, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model on full train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-77858483f678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m model_history = model.fit(X_train, y_train, **training_parameters, validation_data=(X_test, y_test),\n\u001b[0m\u001b[1;32m     25\u001b[0m                           initial_epoch=initial_epoch, callbacks=callbacks)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting up callbacks\n",
    "path_to_run = os.path.join('logs', 'models', 'model_deployment',\n",
    "                            '_'.join(['version', str(hyperparameters['version'])]),\n",
    "                            'runs', str(run_number))\n",
    "path_to_ckpts = os.path.join(path_to_run, 'checkpoints')\n",
    "if not os.path.exists(path_to_ckpts):\n",
    "    os.makedirs(path_to_ckpts)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path_to_ckpts, 'cp-{epoch}.ckpt'),\n",
    "                                                 verbose=1, save_weights_only=True, period=2)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=os.path.join(path_to_run, 'history.log'), append=True)\n",
    "callbacks = [cp_callback, csv_logger]\n",
    "\n",
    "# Unpacking model training parameters\n",
    "training_parameters = hyperparameters['training_parameters']\n",
    "\n",
    "# Fetching last trained epoch if the model was reloaded\n",
    "latest_ckpt = tf.train.latest_checkpoint(path_to_ckpts)\n",
    "if latest_ckpt is not None:\n",
    "    initial_epoch = re.findall(r'cp-(\\d+)\\.ckpt', latest_ckpt)[0]\n",
    "    initial_epoch = int(initial_epoch) - 1\n",
    "else:\n",
    "    initial_epoch = 0\n",
    "\n",
    "model_history = model.fit(X, y, **training_parameters, validation_data=(X_test, y_test),\n",
    "                          initial_epoch=initial_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering Data\n",
    "metrics_train = model.evaluate(X_train, y_train, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "metrics_test = model.evaluate(X_test, y_test, batch_size=training_parameters['batch_size'], verbose=0)\n",
    "m_preds_train = model.predict(X_train, batch_size=training_parameters['batch_size'])\n",
    "m_preds_test = model.predict(X_test, batch_size=training_parameters['batch_size'])\n",
    "m_preds_up_train = (m_preds_train[:, 0] > 0).astype(int)\n",
    "m_preds_up_test = (m_preds_test[:, 0] > 0).astype(int)\n",
    "labels_up_train = y_train['log_adj_daily_returns_target'] > 0\n",
    "labels_up_test = y_test['log_adj_daily_returns_target'] > 0\n",
    "up_cls_acc_train = np.mean(np.equal(m_preds_up_train, labels_up_train))\n",
    "up_cls_acc_test = np.mean(np.equal(m_preds_up_test, labels_up_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Curves for Metrics:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train dataset: 0.0006485506063616562\n",
      "Loss on validation dataset: 0.0007747489441738396\n",
      "\n",
      "Metrics for Classifying Upward Movements\n",
      "Accuracy on train dataset: 0.5464237516869096\n",
      "Accuracy on validation dataset: 0.5040485829959515\n"
     ]
    }
   ],
   "source": [
    "# Reporting Data\n",
    "print('Learning Curves for Metrics:')\n",
    "plot_print_metrics(model_history, metrics_train=metrics_train, metrics_val=metrics_test, metrics_names=model.metrics_names)\n",
    "print()\n",
    "print('Metrics for Classifying Upward Movements')\n",
    "print('Accuracy on train dataset: {}'.format(up_cls_acc_train))\n",
    "print('Accuracy on validation dataset: {}'.format(up_cls_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /media/Data/Programs/FinTech/models/model_0/assets\n"
     ]
    }
   ],
   "source": [
    "m.save(os.path.join(path_to_models, 'model_0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
